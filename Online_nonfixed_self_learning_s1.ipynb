{"cells":[{"cell_type":"markdown","metadata":{"id":"F_LX9XAD32So"},"source":["# Load Data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33656,"status":"ok","timestamp":1673624938763,"user":{"displayName":"Alex Yang","userId":"09551439996217845755"},"user_tz":300},"id":"C3soh1b03deD","outputId":"e06898e2-042f-4150-dbf6-f5a8b12e88df"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytorch_pretrained_bert\n","  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 KB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from pytorch_pretrained_bert) (1.13.0+cu116)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pytorch_pretrained_bert) (1.21.6)\n","Collecting boto3\n","  Downloading boto3-1.26.49-py3-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 KB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from pytorch_pretrained_bert) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from pytorch_pretrained_bert) (2.25.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from pytorch_pretrained_bert) (4.64.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (4.4.0)\n","Collecting s3transfer<0.7.0,>=0.6.0\n","  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 KB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting botocore<1.30.0,>=1.29.49\n","  Downloading botocore-1.29.49-py3-none-any.whl (10.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n","  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->pytorch_pretrained_bert) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->pytorch_pretrained_bert) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n","Collecting urllib3<1.27,>=1.21.1\n","  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.8/dist-packages (from botocore<1.30.0,>=1.29.49->boto3->pytorch_pretrained_bert) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.49->boto3->pytorch_pretrained_bert) (1.15.0)\n","Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3, pytorch_pretrained_bert\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed boto3-1.26.49 botocore-1.29.49 jmespath-1.0.1 pytorch_pretrained_bert-0.6.2 s3transfer-0.6.0 urllib3-1.26.14\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchmetrics\n","  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.4/512.4 KB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.21.6)\n","Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.13.0+cu116)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (21.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->torchmetrics) (3.0.9)\n","Installing collected packages: torchmetrics\n","Successfully installed torchmetrics-0.11.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting kaleido\n","  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: kaleido\n","Successfully installed kaleido-0.2.1\n"]}],"source":["! pip install pytorch_pretrained_bert\n","! pip install torchmetrics\n","! pip install -U kaleido"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44699,"status":"ok","timestamp":1673624983452,"user":{"displayName":"Alex Yang","userId":"09551439996217845755"},"user_tz":300},"id":"jIFha6OOht8L","outputId":"2d1f2b73-7693-439e-b216-3a76333c4f8e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 213450/213450 [00:00<00:00, 240833.23B/s]\n"]},{"output_type":"stream","name":"stdout","text":["The number of samples: 30060\n","The number of tags 48\n","The number of samples: 1336\n","The number of tags 45\n","The number of samples: 1640\n","The number of tags 45\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import sys\n","sys.path.insert(0, '/content/drive/MyDrive/Colab Notebooks/Capstone')\n","from utils import read_conll_file, read_data, filter_tag, create_sub_dir, read_unlabeled_data\n","from utils import TAG2IDX, IDX2TAG, DATA_DIR, POS_FINE_DIR, UNLABELED_DIR\n","from utils import MODEL_DIR, INT_RESULT_DIR, METRICS_DIR, RESULT_DIR, PLOT_TAGS_DIR\n","# from utils import wsj_train_word_lst, wsj_train_tag_lst, wsj_test_word_lst, wsj_test_tag_lst\n","\n","from build_model import PosDataset, UnlabeledDataset, Net, DEVICE, TOKENIZER\n","from build_model import pad, train_one_epoch, eval\n","\n","from analysis import save_sns_fig, analysis_output, make_plot_metric\n","\n","from create_pseudo_data import gen_pseudo_data_by_unlabel\n","\n","import os\n","# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","\n","from collections import Counter\n","import pandas as pd\n","import numpy as np\n","\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import plotly\n","import plotly.express as px\n","import plotly.graph_objects as go\n","from plotly.subplots import make_subplots\n","\n","from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n","from tqdm import tqdm_notebook as tqdm\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils import data\n","import torch.optim as optim\n","from pytorch_pretrained_bert import BertTokenizer, BertModel\n","from torchmetrics.functional.classification import multiclass_f1_score, multiclass_precision, multiclass_recall, multiclass_accuracy\n","\n","torch.manual_seed(0)\n","\n","import time\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0ZDK1-UU6I5K"},"outputs":[],"source":["def run_online_nonfixed(domain, top_percent, threshold=0.1, max_loop=100, lr=0.000001):\n","\n","  print(\"=========================================================\")\n","  print(\"Create directories\")\n","  (sub_model_dir, sub_metrics_dir, sub_result_dir, \n","   sub_int_res_dir) = create_sub_dir(domain, method_name=\"Online_nonfixed_self_learning\")\n","\n","  print(\"=========================================================\")\n","  print(\"Load data\")\n","  time1 = time.time()\n","\n","  ul_domain_file = os.path.join(UNLABELED_DIR, f\"gweb-{domain}.unlabeled.txt\")\n","\n","  domain_dir = os.path.join(POS_FINE_DIR, f\"{domain}\")\n","  domain_dev_file = os.path.join(domain_dir, f\"gweb-{domain}-dev.conll\")\n","  domain_test_file = os.path.join(domain_dir, f\"gweb-{domain}-test.conll\")\n","\n","  domain_dev_word_lst, domain_dev_tag_lst, domain_dev_tag_set = read_data(domain_dev_file)\n","  domain_test_word_lst, domain_test_tag_lst, domain_test_tag_set = read_data(domain_test_file)\n","\n","  domain_dev_word_lst, domain_dev_tag_lst = filter_tag(domain_dev_word_lst, domain_dev_tag_lst)  \n","  domain_test_word_lst, domain_test_tag_lst = filter_tag(domain_test_word_lst, domain_test_tag_lst)\n","\n","  dev_dataset = PosDataset(domain_dev_word_lst, domain_dev_tag_lst)\n","  test_dataset = PosDataset(domain_test_word_lst, domain_test_tag_lst)\n","\n","  dev_iter = data.DataLoader(\n","      dataset=dev_dataset,\n","      batch_size=8,\n","      shuffle=True,\n","      num_workers=1,\n","      collate_fn=pad)\n","  test_iter = data.DataLoader(\n","      dataset=test_dataset,\n","      batch_size=8,\n","      shuffle=False,\n","      num_workers=1,\n","      collate_fn=pad)\n","  \n","  time2 = time.time()\n","  print(\" Running time:\", time2 - time1)\n","\n","  # =========================================================\n","  avg_domain_prec_lst = []\n","  avg_domain_rec_lst = []\n","  avg_domain_f1_lst = []\n","  avg_domain_acc_lst = []\n","\n","  micro_domain_prec_lst = []\n","  micro_domain_rec_lst = []\n","  micro_domain_f1_lst = []\n","  micro_domain_acc_lst = []\n","\n","  macro_domain_prec_lst = []\n","  macro_domain_rec_lst = []\n","  macro_domain_f1_lst = []\n","  macro_domain_acc_lst = []\n","\n","  prob_lst = []\n","\n","  print(\"=========================================================\")\n","  print(\"Start Self-training\")\n","\n","  loop_i = 0\n","\n","  domain_unlabeled_data = read_unlabeled_data(ul_domain_file, max_unlabeled=100_000)\n","  \n","  time3 = time.time()\n","  print(\" Running time:\", time3 - time2)\n","\n","  print(\"  The number of unlabeled data\", len(domain_unlabeled_data))\n","\n","  topn = int(top_percent * len(domain_unlabeled_data))\n","  print(\"  The number of sentences in top n\", topn)\n","\n","  last_top_sen = set()\n","  top_words = domain_unlabeled_data[:topn]\n","  new_top_sen = set([tuple(sen) for sen in top_words])\n","\n","  print(\"Stop condition\", int(threshold * topn))\n","  while len(new_top_sen.difference(last_top_sen)) > int(threshold * topn) and loop_i < max_loop:\n","    print(\"Difference\", len(new_top_sen.difference(last_top_sen)))\n","    time4 = time.time()\n","\n","    loop_i += 1\n","    print(\"\\nLoop\", loop_i)\n","    \n","\n","    # =========================================================\n","    # Load model\n","    if loop_i == 1:\n","      model_name = [name for name in os.listdir(MODEL_DIR) if \"base_model_\" in name][0]\n","      model_file = os.path.join(MODEL_DIR, model_name)\n","    else:\n","      model_name = [name for name in os.listdir(sub_model_dir) if f\"model-top{top_percent}-threshold{threshold}-loop{loop_i-1}-lr{lr}\" in name][0]\n","      model_file = os.path.join(sub_model_dir, model_name)\n","    \n","    print(model_file)\n","\n","    model = Net(vocab_size=len(TAG2IDX))\n","    model.to(DEVICE)\n","    model = nn.DataParallel(model)\n","    model.load_state_dict(torch.load(model_file))\n","\n","    # =========================================================\n","    # Performance on test dataset\n","\n","    output_res_file = os.path.join(sub_result_dir, f\"top{top_percent}-threshold{threshold}-loop{loop_i}-lr{lr}.txt\")\n","    \n","    (test_prec_avg, test_rec_avg, test_f1_avg, acc_avg, \n","      test_prec_micro, test_rec_micro, test_f1_micro, test_acc_micro, \n","      test_prec_macro, test_rec_macro, test_f1_macro, test_acc_macro) = eval(\n","        model, test_iter, save_output=True, output_file=output_res_file)\n","    \n","    time5 = time.time()\n","    print(\" Running time:\", time5 - time4)\n","\n","    avg_domain_prec_lst.append(test_prec_avg.item())\n","    avg_domain_rec_lst.append(test_rec_avg.item())\n","    avg_domain_f1_lst.append(test_f1_avg.item())\n","    avg_domain_acc_lst.append(acc_avg.item())\n","\n","    micro_domain_prec_lst.append(test_prec_micro.item())\n","    micro_domain_rec_lst.append(test_rec_micro.item())\n","    micro_domain_f1_lst.append(test_f1_micro.item())\n","    micro_domain_acc_lst.append(test_acc_micro.item())\n","\n","    macro_domain_prec_lst.append(test_prec_macro.item())\n","    macro_domain_rec_lst.append(test_rec_macro.item())\n","    macro_domain_f1_lst.append(test_f1_macro.item())\n","    macro_domain_acc_lst.append(test_acc_macro.item())\n","\n","    csv_file_name = os.path.join(sub_result_dir, f\"top{top_percent}-threshold{threshold}-loop{loop_i}-lr{lr}.csv\")\n","    output_plot_name = os.path.join(sub_result_dir, f\"top{top_percent}-threshold{threshold}-loop{loop_i}-lr{lr}.png\")\n","\n","    _ = analysis_output(\n","        output_res_file, csvsave=True, pngsave=True, \n","        csv_file_name=csv_file_name, output_plot_name=output_plot_name, \n","        figtitle=f\"{domain}-top{top_percent}-loop{loop_i} Test: Accuracy for each tag\")\n","\n","    print(\"=========================================================\")\n","    print(\"Generate new train dataset\")\n","\n","    print(\"  The number of unlabeled data\", len(domain_unlabeled_data))\n","    ul_domain_dataset = UnlabeledDataset(domain_unlabeled_data)\n","    unlabel_iter = data.DataLoader(\n","        dataset=ul_domain_dataset,\n","        batch_size=8,\n","        shuffle=True,\n","        num_workers=1,\n","        collate_fn=pad\n","        )\n","\n","    # Save analysis outputs for intermediate results\n","    output_int_res_file = os.path.join(sub_int_res_dir, f\"top{top_percent}-threshold{threshold}-loop{loop_i}-lr{lr}.txt\")\n","\n","    time6 = time.time()\n","    print(\" Running time:\", time6 - time5)\n","\n","    (top_words, top_pseudo_tags, top_prob, \n","     remain_words, remain_pseudo_tags, remain_prob)= gen_pseudo_data_by_unlabel(\n","          model, unlabel_iter, topn, save_output=True, output_file=output_int_res_file)\n","    \n","    last_top_sen = new_top_sen\n","    new_top_sen = set([tuple(sen) for sen in top_words])\n","\n","    time7 = time.time()\n","    print(\" Running time:\", time7 - time6)\n","    \n","    # Save top_prob\n","    prob_lst.append(top_prob)\n","\n","    new_train_dataset = PosDataset(top_words, top_pseudo_tags)\n","    new_train_iter = data.DataLoader(\n","        dataset=new_train_dataset,\n","        batch_size=8,\n","        shuffle=True,\n","        num_workers=1,\n","        collate_fn=pad)\n","    \n","    time8 = time.time()\n","    print(\" Running time:\", time8 - time7)\n","\n","    print(\"=========================================================\")\n","    print(\"Self training for epochs\")\n","\n","    epoch_number = 0\n","    EPOCHS = 3\n","    best_vloss = 1_000_000.\n","\n","    optimizer = optim.Adam(model.parameters(), lr = lr)\n","    loss_fn = nn.CrossEntropyLoss(ignore_index=0)\n","\n","    for epoch in range(EPOCHS):\n","        print('  EPOCH {}:'.format(epoch_number + 1))\n","\n","        model.train(True)\n","        avg_loss = train_one_epoch(model, new_train_iter, optimizer, loss_fn, epoch_number)\n","\n","        model.train(False)\n","\n","        running_vloss = 0.0\n","        for i, vbatch in enumerate(dev_iter):\n","          words, x, is_heads, tags, y, seqlens = vbatch\n","\n","          logits, y, _ = model(x, y)\n","          logits = logits.view(-1, logits.shape[-1]) # (N*T, VOCAB)\n","          y = y.view(-1)  # (N*T,)\n","          \n","          vloss = loss_fn(logits, y)\n","          running_vloss += vloss\n","\n","        avg_vloss = running_vloss / (i + 1)\n","        print('  LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n","\n","        # Track best performance, and save the model's state\n","        if avg_vloss < best_vloss:\n","            best_vloss = avg_vloss\n","            model_path = os.path.join(sub_model_dir, f'model-top{top_percent}-threshold{threshold}-loop{loop_i}-lr{lr}')\n","            torch.save(model.state_dict(), model_path)\n","\n","        epoch_number += 1\n","  \n","  time9 = time.time()\n","  print(\" Running time:\", time9 - time8)\n","  \n","  print(\"=========================================================\")\n","  print(\"Save metrics and probability list\")\n","\n","  metrics_df = pd.DataFrame({\n","      \"avg_domain_prec_lst\": avg_domain_prec_lst,\n","      \"avg_domain_rec_lst\": avg_domain_rec_lst,\n","      \"avg_domain_f1_lst\": avg_domain_f1_lst,\n","      \"avg_domain_acc_lst\": avg_domain_acc_lst,\n","\n","      \"micro_domain_prec_lst\": micro_domain_prec_lst,\n","      \"micro_domain_rec_lst\": micro_domain_rec_lst,\n","      \"micro_domain_f1_lst\": micro_domain_f1_lst,\n","      \"micro_domain_acc_lst\": micro_domain_acc_lst,\n","\n","      \"macro_domain_prec_lst\": macro_domain_prec_lst,\n","      \"macro_domain_rec_lst\": macro_domain_rec_lst,\n","      \"macro_domain_f1_lst\": macro_domain_f1_lst,\n","      \"macro_domain_acc_lst\": macro_domain_acc_lst\n","\n","  })\n","\n","  metrics_df.to_csv(os.path.join(sub_metrics_dir, f\"metrics_df-top{top_percent}-threshold{threshold}-lr{lr}.csv\"), index=False)\n","  make_plot_metric(metrics_df, sub_metrics_dir, name=f\"top{top_percent}-threshold{threshold}-lr{lr}\")\n","\n","  prob_df = pd.DataFrame({})\n","  for i in range(len(prob_lst)):\n","    prob_df[i+1] = prob_lst[i]\n","  prob_df.to_csv(os.path.join(sub_metrics_dir, f\"prob_df-top{top_percent}-threshold{threshold}-lr{lr}.csv\"), index=False)\n","  \n","  time10 = time.time()\n","  print(\" Running time:\", time10 - time9)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f5pQmdTS6I20"},"outputs":[],"source":["top_percent_lst = [0.05, 0.1, 0.2] #0.01, 0.02\n","threshold = 0.1\n","lr_lst = [0.000001, 0.00001]\n","DOMAIN_LST = [\"answers\", \"emails\", \"newsgroups\", \"reviews\", \"weblogs\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X1Wkbj2FykGF","colab":{"base_uri":"https://localhost:8080/"},"outputId":"adb0512a-74ed-4029-f4fd-b4de0b273089"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","$$$ Run answers, top_percent 0.2, max_loop 5\n","=========================================================\n","Create directories\n","Create /content/drive/.shortcut-targets-by-id/14c0k_vTOqyJvw3jILduI00xS9-yQkgb8/Capstone/model/Online_nonfixed_self_learning/answers\n","Create /content/drive/.shortcut-targets-by-id/14c0k_vTOqyJvw3jILduI00xS9-yQkgb8/Capstone/metrics/Online_nonfixed_self_learning/answers\n","Create /content/drive/.shortcut-targets-by-id/14c0k_vTOqyJvw3jILduI00xS9-yQkgb8/Capstone/result/Online_nonfixed_self_learning/answers\n","Create /content/drive/.shortcut-targets-by-id/14c0k_vTOqyJvw3jILduI00xS9-yQkgb8/Capstone/intermediate_result/Online_nonfixed_self_learning/answers\n","=========================================================\n","Load data\n","The number of samples: 1745\n","The number of tags 49\n","The number of samples: 1744\n","The number of tags 50\n","after filter tag 1713\n","after filter tag 1723\n"," Running time: 2.1591382026672363\n","=========================================================\n","Start Self-training\n","Loaded... 27260 unlabeled instances\n"," Running time: 10.351296186447144\n","  The number of unlabeled data 27260\n","  The number of sentences in top n 5452\n","Stop condition 545\n","Difference 5297\n","\n","Loop 1\n","/content/drive/.shortcut-targets-by-id/14c0k_vTOqyJvw3jILduI00xS9-yQkgb8/Capstone/model/base_model_20230105_184923_0\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 404400730/404400730 [00:35<00:00, 11489163.92B/s]\n"]},{"output_type":"stream","name":"stdout","text":[" Running time: 61.4574556350708\n","=========================================================\n","Generate new train dataset\n","  The number of unlabeled data 27260\n"," Running time: 1.8236007690429688\n"," Running time: 112.95535492897034\n"," Running time: 0.01085352897644043\n","=========================================================\n","Self training for epochs\n","  EPOCH 1:\n","  batch 500 loss: 0.0030635147439315915\n","  LOSS train 0.0030635147439315915 valid 0.4319385588169098\n","  EPOCH 2:\n","  batch 500 loss: 0.0013577278662123718\n","  LOSS train 0.0013577278662123718 valid 0.4497244656085968\n","  EPOCH 3:\n","  batch 500 loss: 0.0009883749855798668\n","  LOSS train 0.0009883749855798668 valid 0.4691442549228668\n","Difference 4151\n","\n","Loop 2\n","/content/drive/.shortcut-targets-by-id/14c0k_vTOqyJvw3jILduI00xS9-yQkgb8/Capstone/model/Online_nonfixed_self_learning/answers/model-top0.2-threshold0.1-loop1-lr1e-06\n"," Running time: 12.811413764953613\n","=========================================================\n","Generate new train dataset\n","  The number of unlabeled data 27260\n"," Running time: 0.8812494277954102\n"," Running time: 114.93291115760803\n"," Running time: 0.015539884567260742\n","=========================================================\n","Self training for epochs\n","  EPOCH 1:\n","  batch 500 loss: 0.0012611307674669661\n","  LOSS train 0.0012611307674669661 valid 0.46167054772377014\n","  EPOCH 2:\n","  batch 500 loss: 0.0008412000309326686\n","  LOSS train 0.0008412000309326686 valid 0.4683459997177124\n","  EPOCH 3:\n","  batch 500 loss: 0.0007402850448852405\n","  LOSS train 0.0007402850448852405 valid 0.4859146177768707\n"," Running time: 207.11154627799988\n","=========================================================\n","Save metrics and probability list\n"," Running time: 3.0033717155456543\n","\n","$$$ Run answers, top_percent 0.2, max_loop 5\n","=========================================================\n","Create directories\n","=========================================================\n","Load data\n","The number of samples: 1745\n","The number of tags 49\n","The number of samples: 1744\n","The number of tags 50\n","after filter tag 1713\n","after filter tag 1723\n"," Running time: 0.15894246101379395\n","=========================================================\n","Start Self-training\n","Loaded... 27260 unlabeled instances\n"," Running time: 6.2781453132629395\n","  The number of unlabeled data 27260\n","  The number of sentences in top n 5452\n","Stop condition 545\n","Difference 5297\n","\n","Loop 1\n","/content/drive/.shortcut-targets-by-id/14c0k_vTOqyJvw3jILduI00xS9-yQkgb8/Capstone/model/base_model_20230105_184923_0\n"," Running time: 13.274374723434448\n","=========================================================\n","Generate new train dataset\n","  The number of unlabeled data 27260\n"," Running time: 0.5381479263305664\n"," Running time: 117.92817974090576\n"," Running time: 0.010540485382080078\n","=========================================================\n","Self training for epochs\n","  EPOCH 1:\n","  batch 500 loss: 0.001710697314934805\n","  LOSS train 0.001710697314934805 valid 0.5194727778434753\n","  EPOCH 2:\n","  batch 500 loss: 0.0005350053459696937\n","  LOSS train 0.0005350053459696937 valid 0.5510627031326294\n","  EPOCH 3:\n","  batch 500 loss: 0.00030104418318660465\n","  LOSS train 0.00030104418318660465 valid 0.5882594585418701\n","Difference 4153\n","\n","Loop 2\n","/content/drive/.shortcut-targets-by-id/14c0k_vTOqyJvw3jILduI00xS9-yQkgb8/Capstone/model/Online_nonfixed_self_learning/answers/model-top0.2-threshold0.1-loop1-lr1e-05\n"," Running time: 12.74049711227417\n","=========================================================\n","Generate new train dataset\n","  The number of unlabeled data 27260\n"," Running time: 0.555166482925415\n"," Running time: 120.53124475479126\n"," Running time: 0.013878107070922852\n","=========================================================\n","Self training for epochs\n","  EPOCH 1:\n","  batch 500 loss: 0.00044912599081726513\n","  LOSS train 0.00044912599081726513 valid 0.7041098475456238\n","  EPOCH 2:\n","  batch 500 loss: 0.0001665640817154781\n","  LOSS train 0.0001665640817154781 valid 0.6663773655891418\n","  EPOCH 3:\n","  batch 500 loss: 8.647077966816142e-05\n","  LOSS train 8.647077966816142e-05 valid 0.6772302389144897\n","Difference 771\n","\n","Loop 3\n","/content/drive/.shortcut-targets-by-id/14c0k_vTOqyJvw3jILduI00xS9-yQkgb8/Capstone/model/Online_nonfixed_self_learning/answers/model-top0.2-threshold0.1-loop2-lr1e-05\n"," Running time: 13.006411075592041\n","=========================================================\n","Generate new train dataset\n","  The number of unlabeled data 27260\n"," Running time: 0.5366308689117432\n"," Running time: 115.34840250015259\n"," Running time: 0.014054059982299805\n","=========================================================\n","Self training for epochs\n","  EPOCH 1:\n","  batch 500 loss: 0.0006290994100481839\n","  LOSS train 0.0006290994100481839 valid 0.7870944142341614\n","  EPOCH 2:\n","  batch 500 loss: 0.00039263459676658384\n","  LOSS train 0.00039263459676658384 valid 0.7981448173522949\n","  EPOCH 3:\n","  batch 500 loss: 0.0003496957849320097\n","  LOSS train 0.0003496957849320097 valid 0.7923152446746826\n","Difference 716\n","\n","Loop 4\n","/content/drive/.shortcut-targets-by-id/14c0k_vTOqyJvw3jILduI00xS9-yQkgb8/Capstone/model/Online_nonfixed_self_learning/answers/model-top0.2-threshold0.1-loop3-lr1e-05\n"," Running time: 12.830683946609497\n","=========================================================\n","Generate new train dataset\n","  The number of unlabeled data 27260\n"," Running time: 0.5419473648071289\n"," Running time: 115.77162981033325\n"," Running time: 0.018468856811523438\n","=========================================================\n","Self training for epochs\n","  EPOCH 1:\n","  batch 500 loss: 0.0005011676975818773\n","  LOSS train 0.0005011676975818773 valid 0.8345300555229187\n","  EPOCH 2:\n","  batch 500 loss: 0.00023519567441189794\n","  LOSS train 0.00023519567441189794 valid 0.8385813236236572\n","  EPOCH 3:\n","  batch 500 loss: 0.0007374468685093234\n","  LOSS train 0.0007374468685093234 valid 0.7966070771217346\n","Difference 1093\n","\n","Loop 5\n","/content/drive/.shortcut-targets-by-id/14c0k_vTOqyJvw3jILduI00xS9-yQkgb8/Capstone/model/Online_nonfixed_self_learning/answers/model-top0.2-threshold0.1-loop4-lr1e-05\n"," Running time: 13.871800661087036\n","=========================================================\n","Generate new train dataset\n","  The number of unlabeled data 27260\n"," Running time: 1.036268711090088\n"," Running time: 115.1870346069336\n"," Running time: 0.017591476440429688\n","=========================================================\n","Self training for epochs\n","  EPOCH 1:\n","  batch 500 loss: 0.00047406601952616257\n","  LOSS train 0.00047406601952616257 valid 0.8297893404960632\n","  EPOCH 2:\n","  batch 500 loss: 0.000284895719555152\n","  LOSS train 0.000284895719555152 valid 0.8190352320671082\n","  EPOCH 3:\n","  batch 500 loss: 0.00018782201668545896\n","  LOSS train 0.00018782201668545896 valid 0.8320897817611694\n"," Running time: 207.97426462173462\n","=========================================================\n","Save metrics and probability list\n"," Running time: 1.386772871017456\n","\n","$$$ Run emails, top_percent 0.2, max_loop 5\n","=========================================================\n","Create directories\n","Create /content/drive/.shortcut-targets-by-id/14c0k_vTOqyJvw3jILduI00xS9-yQkgb8/Capstone/model/Online_nonfixed_self_learning/emails\n","Create /content/drive/.shortcut-targets-by-id/14c0k_vTOqyJvw3jILduI00xS9-yQkgb8/Capstone/metrics/Online_nonfixed_self_learning/emails\n","Create /content/drive/.shortcut-targets-by-id/14c0k_vTOqyJvw3jILduI00xS9-yQkgb8/Capstone/result/Online_nonfixed_self_learning/emails\n","Create /content/drive/.shortcut-targets-by-id/14c0k_vTOqyJvw3jILduI00xS9-yQkgb8/Capstone/intermediate_result/Online_nonfixed_self_learning/emails\n","=========================================================\n","Load data\n","The number of samples: 2450\n","The number of tags 49\n","The number of samples: 2450\n","The number of tags 48\n","after filter tag 2427\n","after filter tag 2402\n"," Running time: 2.467273473739624\n","=========================================================\n","Start Self-training\n","Loaded... 100000 unlabeled instances\n"," Running time: 21.804581880569458\n","  The number of unlabeled data 100000\n","  The number of sentences in top n 20000\n","Stop condition 2000\n","Difference 13582\n","\n","Loop 1\n","/content/drive/.shortcut-targets-by-id/14c0k_vTOqyJvw3jILduI00xS9-yQkgb8/Capstone/model/base_model_20230105_184923_0\n"," Running time: 14.7523934841156\n","=========================================================\n","Generate new train dataset\n","  The number of unlabeled data 100000\n"," Running time: 1.3807024955749512\n"," Running time: 367.2967109680176\n"," Running time: 0.06049537658691406\n","=========================================================\n","Self training for epochs\n","  EPOCH 1:\n","  batch 500 loss: 0.0021472929666051643\n","  batch 1000 loss: 0.0012358783216914163\n","  batch 1500 loss: 0.0008443561397725717\n","  batch 2000 loss: 0.0007995227434730623\n","  batch 2500 loss: 0.0007264141941268463\n","  LOSS train 0.0007264141941268463 valid 0.5589923858642578\n","  EPOCH 2:\n","  batch 500 loss: 0.0005434436666837427\n","  batch 1000 loss: 0.0004635268774582073\n","  batch 1500 loss: 0.0003670095558045432\n","  batch 2000 loss: 0.00041589203185867516\n","  batch 2500 loss: 0.0003304100825916976\n","  LOSS train 0.0003304100825916976 valid 0.6136444807052612\n","  EPOCH 3:\n","  batch 500 loss: 0.00038776228885399177\n","  batch 1000 loss: 0.0002949977417010814\n","  batch 1500 loss: 0.0002681898950249888\n","  batch 2000 loss: 0.00022463614233129192\n","  batch 2500 loss: 0.00021377190100611187\n","  LOSS train 0.00021377190100611187 valid 0.6464954614639282\n","Difference 10207\n","\n","Loop 2\n","/content/drive/.shortcut-targets-by-id/14c0k_vTOqyJvw3jILduI00xS9-yQkgb8/Capstone/model/Online_nonfixed_self_learning/emails/model-top0.2-threshold0.1-loop1-lr1e-06\n"," Running time: 15.33286738395691\n","=========================================================\n","Generate new train dataset\n","  The number of unlabeled data 100000\n"," Running time: 1.7533025741577148\n"," Running time: 366.18659138679504\n"," Running time: 0.04366159439086914\n","=========================================================\n","Self training for epochs\n","  EPOCH 1:\n","  batch 500 loss: 0.0003422710116428789\n","  batch 1000 loss: 0.0002530181157926563\n","  batch 1500 loss: 0.00039288439477968494\n","  batch 2000 loss: 0.00028614962752908466\n","  batch 2500 loss: 0.00018931335394154302\n","  LOSS train 0.00018931335394154302 valid 0.6398393511772156\n","  EPOCH 2:\n","  batch 500 loss: 0.00029287287789338734\n","  batch 1000 loss: 0.0001419611112360144\n","  batch 1500 loss: 0.0001208661890559597\n","  batch 2000 loss: 0.00013029265425575432\n","  batch 2500 loss: 9.732933658960974e-05\n","  LOSS train 9.732933658960974e-05 valid 0.6736584901809692\n","  EPOCH 3:\n","  batch 500 loss: 0.0001295345538528636\n","  batch 1000 loss: 0.0004457633350248216\n","  batch 1500 loss: 0.0001050671900229645\n","  batch 2000 loss: 0.0004160011737039895\n","  batch 2500 loss: 0.00019926838009996572\n","  LOSS train 0.00019926838009996572 valid 0.6803554892539978\n"," Running time: 758.3239266872406\n","=========================================================\n","Save metrics and probability list\n"," Running time: 1.318901777267456\n","\n","$$$ Run emails, top_percent 0.2, max_loop 5\n","=========================================================\n","Create directories\n","=========================================================\n","Load data\n","The number of samples: 2450\n","The number of tags 49\n","The number of samples: 2450\n","The number of tags 48\n","after filter tag 2427\n","after filter tag 2402\n"," Running time: 0.16160988807678223\n","=========================================================\n","Start Self-training\n","Loaded... 100000 unlabeled instances\n"," Running time: 20.487285375595093\n","  The number of unlabeled data 100000\n","  The number of sentences in top n 20000\n","Stop condition 2000\n","Difference 13582\n","\n","Loop 1\n","/content/drive/.shortcut-targets-by-id/14c0k_vTOqyJvw3jILduI00xS9-yQkgb8/Capstone/model/base_model_20230105_184923_0\n"," Running time: 14.59442138671875\n","=========================================================\n","Generate new train dataset\n","  The number of unlabeled data 100000\n"," Running time: 1.0780749320983887\n"," Running time: 367.98215985298157\n"," Running time: 0.7238109111785889\n","=========================================================\n","Self training for epochs\n","  EPOCH 1:\n","  batch 500 loss: 0.0009961170715105255\n","  batch 1000 loss: 0.0007725903408427258\n","  batch 1500 loss: 0.0009766690681426553\n","  batch 2000 loss: 0.0004947048696922139\n","  batch 2500 loss: 0.0006590826636384008\n","  LOSS train 0.0006590826636384008 valid 0.7255131006240845\n","  EPOCH 2:\n","  batch 500 loss: 0.0007537873100372963\n","  batch 1000 loss: 0.0005021674372110283\n","  batch 1500 loss: 0.0001685338219467667\n","  batch 2000 loss: 0.0002845465806531138\n","  batch 2500 loss: 0.0005821692727986374\n","  LOSS train 0.0005821692727986374 valid 0.7668769359588623\n","  EPOCH 3:\n","  batch 500 loss: 0.0006522303191959509\n","  batch 1000 loss: 0.0003740794078767067\n","  batch 1500 loss: 0.0003061028762822389\n","  batch 2000 loss: 0.00026347634873673085\n","  batch 2500 loss: 0.0004777449179055111\n","  LOSS train 0.0004777449179055111 valid 0.7539190649986267\n","Difference 10209\n","\n","Loop 2\n","/content/drive/.shortcut-targets-by-id/14c0k_vTOqyJvw3jILduI00xS9-yQkgb8/Capstone/model/Online_nonfixed_self_learning/emails/model-top0.2-threshold0.1-loop1-lr1e-05\n"," Running time: 15.39993929862976\n","=========================================================\n","Generate new train dataset\n","  The number of unlabeled data 100000\n"," Running time: 0.6871757507324219\n"," Running time: 365.46698236465454\n"," Running time: 0.044473886489868164\n","=========================================================\n","Self training for epochs\n","  EPOCH 1:\n","  batch 500 loss: 0.0002452709824538033\n","  batch 1000 loss: 0.00021944458666621358\n","  batch 1500 loss: 7.562552817034884e-05\n","  batch 2000 loss: 0.00016293241316452624\n","  batch 2500 loss: 0.00010633613025129307\n","  LOSS train 0.00010633613025129307 valid 0.852597177028656\n","  EPOCH 2:\n","  batch 500 loss: 0.0002504579286105582\n","  batch 1000 loss: 0.0005860967346525285\n","  batch 1500 loss: 0.00021017656908406935\n","  batch 2000 loss: 0.0002686276869681024\n","  batch 2500 loss: 0.000629584479001096\n","  LOSS train 0.000629584479001096 valid 0.8737098574638367\n","  EPOCH 3:\n","  batch 500 loss: 0.00017030551892639777\n","  batch 1000 loss: 0.00024821679168508126\n","  batch 1500 loss: 0.00011176408991286735\n","  batch 2000 loss: 4.14730763877742e-05\n","  batch 2500 loss: 0.0006689653007633751\n","  LOSS train 0.0006689653007633751 valid 0.9437301158905029\n"," Running time: 756.4360806941986\n","=========================================================\n","Save metrics and probability list\n"," Running time: 1.3083975315093994\n","\n","$$$ Run newsgroups, top_percent 0.2, max_loop 5\n","=========================================================\n","Create directories\n","Create /content/drive/.shortcut-targets-by-id/14c0k_vTOqyJvw3jILduI00xS9-yQkgb8/Capstone/model/Online_nonfixed_self_learning/newsgroups\n","Create /content/drive/.shortcut-targets-by-id/14c0k_vTOqyJvw3jILduI00xS9-yQkgb8/Capstone/metrics/Online_nonfixed_self_learning/newsgroups\n","Create /content/drive/.shortcut-targets-by-id/14c0k_vTOqyJvw3jILduI00xS9-yQkgb8/Capstone/result/Online_nonfixed_self_learning/newsgroups\n","Create /content/drive/.shortcut-targets-by-id/14c0k_vTOqyJvw3jILduI00xS9-yQkgb8/Capstone/intermediate_result/Online_nonfixed_self_learning/newsgroups\n","=========================================================\n","Load data\n","The number of samples: 1196\n","The number of tags 49\n","The number of samples: 1195\n","The number of tags 49\n","after filter tag 1190\n","after filter tag 1180\n"," Running time: 2.317438840866089\n","=========================================================\n","Start Self-training\n","Loaded... 100000 unlabeled instances\n"," Running time: 36.37770700454712\n","  The number of unlabeled data 100000\n","  The number of sentences in top n 20000\n","Stop condition 2000\n","Difference 15732\n","\n","Loop 1\n","/content/drive/.shortcut-targets-by-id/14c0k_vTOqyJvw3jILduI00xS9-yQkgb8/Capstone/model/base_model_20230105_184923_0\n"," Running time: 11.183963060379028\n","=========================================================\n","Generate new train dataset\n","  The number of unlabeled data 100000\n"," Running time: 1.1076838970184326\n"," Running time: 392.9545810222626\n"," Running time: 0.05200552940368652\n","=========================================================\n","Self training for epochs\n","  EPOCH 1:\n","  batch 500 loss: 0.002817787070409395\n","  batch 1000 loss: 0.0016617766100680456\n","  batch 1500 loss: 0.0012687027355423198\n","  batch 2000 loss: 0.0009940261182491668\n","  batch 2500 loss: 0.0009578684885636903\n","  LOSS train 0.0009578684885636903 valid 0.45312929153442383\n","  EPOCH 2:\n","  batch 500 loss: 0.0007042786676320248\n","  batch 1000 loss: 0.0007228566794656217\n","  batch 1500 loss: 0.0007095261212380137\n","  batch 2000 loss: 0.0005953508862294257\n","  batch 2500 loss: 0.0007179935477324761\n","  LOSS train 0.0007179935477324761 valid 0.49275749921798706\n","  EPOCH 3:\n","  batch 500 loss: 0.00040919382133870383\n","  batch 1000 loss: 0.0005926586686109659\n","  batch 1500 loss: 0.00043529329579905605\n","  batch 2000 loss: 0.0005124222626327537\n","  batch 2500 loss: 0.0004861635953420773\n","  LOSS train 0.0004861635953420773 valid 0.5037073493003845\n","Difference 12192\n","\n","Loop 2\n","/content/drive/.shortcut-targets-by-id/14c0k_vTOqyJvw3jILduI00xS9-yQkgb8/Capstone/model/Online_nonfixed_self_learning/newsgroups/model-top0.2-threshold0.1-loop1-lr1e-06\n"," Running time: 11.425720930099487\n","=========================================================\n","Generate new train dataset\n","  The number of unlabeled data 100000\n"," Running time: 1.6057579517364502\n"," Running time: 394.540967464447\n"," Running time: 0.8502087593078613\n","=========================================================\n","Self training for epochs\n","  EPOCH 1:\n","  batch 500 loss: 0.00044447551504708826\n","  batch 1000 loss: 0.00041860371676739303\n","  batch 1500 loss: 0.00034028481136192567\n","  batch 2000 loss: 0.0004226248514314648\n","  batch 2500 loss: 0.0004933741861605085\n","  LOSS train 0.0004933741861605085 valid 0.49596497416496277\n","  EPOCH 2:\n","  batch 500 loss: 0.0004005991544545395\n"]}],"source":["for top_percent in top_percent_lst[::-1]:\n","  for domain in DOMAIN_LST:\n","    for lr in lr_lst:\n","      max_loop = int(1 / top_percent)\n","      print(f\"\\n$$$ Run {domain}, top_percent {top_percent}, max_loop {max_loop}\")\n","      # run_online_nonfixed(domain, top_percent, threshold=0.1, max_loop=max_loop, lr=lr)\n","\n","      sub_metrics_dir = os.path.join(METRICS_DIR, \"Online_nonfixed_self_learning\", domain)\n","      if os.path.exists(os.path.join(sub_metrics_dir, f\"metrics_df-top{top_percent}-threshold{threshold}-lr{lr}.csv\")):\n","        print(\"Already run\")\n","      else:\n","        run_online_nonfixed(domain, top_percent, threshold=0.1, max_loop=max_loop, lr=lr)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Ngux9I-orPX"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uEACZ4DaGGRA"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
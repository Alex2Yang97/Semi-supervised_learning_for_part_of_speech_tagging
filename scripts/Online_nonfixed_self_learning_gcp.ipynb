{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1UqfWE5iUFuPdld9PqMyLoedrl4K2F0b1","timestamp":1669690469293}],"collapsed_sections":["6fVp31VJ5U64","cyvpy9QH4sQd"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Load Data"],"metadata":{"id":"F_LX9XAD32So"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C3soh1b03deD","executionInfo":{"status":"ok","timestamp":1669689880880,"user_tz":300,"elapsed":68752,"user":{"displayName":"Zheng Wu","userId":"01190949623920087412"}},"outputId":"02aa7e9a-f8f0-4d36-b07f-2a7c20a7b7e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch_pretrained_bert\n","  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting regex\n","  Downloading regex-2022.10.31-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.1/757.1 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from pytorch_pretrained_bert) (2.28.1)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from pytorch_pretrained_bert) (1.21.6)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from pytorch_pretrained_bert) (4.64.1)\n","Collecting torch>=0.4.1\n","  Downloading torch-1.13.0-cp37-cp37m-manylinux1_x86_64.whl (890.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m890.2/890.2 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting boto3\n","  Downloading boto3-1.26.17-py3-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n","  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n","  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n","  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (4.4.0)\n","Collecting nvidia-cuda-runtime-cu11==11.7.99\n","  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=0.4.1->pytorch_pretrained_bert) (0.37.1)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=0.4.1->pytorch_pretrained_bert) (59.8.0)\n","Collecting botocore<1.30.0,>=1.29.17\n","  Downloading botocore-1.29.17-py3-none-any.whl (10.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n","  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Collecting s3transfer<0.7.0,>=0.6.0\n","  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 kB\u001b[0m \u001b[31m297.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->pytorch_pretrained_bert) (1.26.11)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->pytorch_pretrained_bert) (3.4)\n","Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->pytorch_pretrained_bert) (2.1.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->pytorch_pretrained_bert) (2022.9.24)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.30.0,>=1.29.17->boto3->pytorch_pretrained_bert) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.17->boto3->pytorch_pretrained_bert) (1.16.0)\n","Installing collected packages: regex, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, jmespath, nvidia-cudnn-cu11, botocore, torch, s3transfer, boto3, pytorch_pretrained_bert\n","Successfully installed boto3-1.26.17 botocore-1.29.17 jmespath-1.0.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 pytorch_pretrained_bert-0.6.2 regex-2022.10.31 s3transfer-0.6.0 torch-1.13.0\n"]}],"source":["! pip install pytorch_pretrained_bert"]},{"cell_type":"code","source":["!pip install -U kaleido # for export plotly plots"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GmfxzXyoqeRk","executionInfo":{"status":"ok","timestamp":1669689936642,"user_tz":300,"elapsed":4969,"user":{"displayName":"Zheng Wu","userId":"01190949623920087412"}},"outputId":"da7af20e-dc6a-45a4-8321-0c2b32c7b620"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting kaleido\n","  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: kaleido\n","Successfully installed kaleido-0.2.1\n"]}]},{"cell_type":"code","source":["!pip install google-colab"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"70HTByGQR1p_","executionInfo":{"status":"ok","timestamp":1669690009426,"user_tz":300,"elapsed":17176,"user":{"displayName":"Zheng Wu","userId":"01190949623920087412"}},"outputId":"31dc4e29-c200-4966-85bb-b902fb278557"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting google-colab\n","  Downloading google-colab-1.0.0.tar.gz (72 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\n","\u001b[?25hCollecting google-auth~=1.4.0\n","  Downloading google_auth-1.4.2-py2.py3-none-any.whl (64 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ipykernel~=4.6.0\n","  Downloading ipykernel-4.6.1-py3-none-any.whl (104 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.5/104.5 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ipython~=5.5.0\n","  Downloading ipython-5.5.0-py3-none-any.whl (758 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m758.9/758.9 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting notebook~=5.2.0\n","  Downloading notebook-5.2.2-py2.py3-none-any.whl (8.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m109.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting six~=1.12.0\n","  Downloading six-1.12.0-py2.py3-none-any.whl (10 kB)\n","Collecting pandas~=0.24.0\n","  Downloading pandas-0.24.2-cp37-cp37m-manylinux1_x86_64.whl (10.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m116.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting portpicker~=1.2.0\n","  Downloading portpicker-1.2.0.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\n","\u001b[?25hCollecting requests~=2.21.0\n","  Downloading requests-2.21.0-py2.py3-none-any.whl (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tornado~=4.5.0\n","  Downloading tornado-4.5.3.tar.gz (484 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m484.2/484.2 kB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\n","\u001b[?25hRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth~=1.4.0->google-colab) (0.2.7)\n","Requirement already satisfied: cachetools>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth~=1.4.0->google-colab) (5.2.0)\n","Requirement already satisfied: rsa>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth~=1.4.0->google-colab) (4.9)\n","Requirement already satisfied: jupyter-client in /opt/conda/lib/python3.7/site-packages (from ipykernel~=4.6.0->google-colab) (7.4.4)\n","Requirement already satisfied: traitlets>=4.1.0 in /opt/conda/lib/python3.7/site-packages (from ipykernel~=4.6.0->google-colab) (5.5.0)\n","Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython~=5.5.0->google-colab) (5.1.1)\n","Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.7/site-packages (from ipython~=5.5.0->google-colab) (59.8.0)\n","Collecting simplegeneric>0.8\n","  Downloading simplegeneric-0.8.1.zip (12 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\n","\u001b[?25hRequirement already satisfied: pexpect in /opt/conda/lib/python3.7/site-packages (from ipython~=5.5.0->google-colab) (4.8.0)\n","Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython~=5.5.0->google-colab) (2.13.0)\n","Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython~=5.5.0->google-colab) (0.7.5)\n","Collecting prompt-toolkit<2.0.0,>=1.0.4\n","  Downloading prompt_toolkit-1.0.18-py3-none-any.whl (245 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.4/245.4 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: ipython-genutils in /opt/conda/lib/python3.7/site-packages (from notebook~=5.2.0->google-colab) (0.2.0)\n","Requirement already satisfied: terminado>=0.3.3 in /opt/conda/lib/python3.7/site-packages (from notebook~=5.2.0->google-colab) (0.17.0)\n","Requirement already satisfied: nbformat in /opt/conda/lib/python3.7/site-packages (from notebook~=5.2.0->google-colab) (5.7.0)\n","Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.7/site-packages (from notebook~=5.2.0->google-colab) (4.11.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from notebook~=5.2.0->google-colab) (3.1.2)\n","Requirement already satisfied: nbconvert in /opt/conda/lib/python3.7/site-packages (from notebook~=5.2.0->google-colab) (7.2.3)\n","Requirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/lib/python3.7/site-packages (from pandas~=0.24.0->google-colab) (2.8.2)\n","Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from pandas~=0.24.0->google-colab) (1.21.6)\n","Requirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.7/site-packages (from pandas~=0.24.0->google-colab) (2022.5)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests~=2.21.0->google-colab) (2022.9.24)\n","Collecting urllib3<1.25,>=1.21.1\n","  Downloading urllib3-1.24.3-py2.py3-none-any.whl (118 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.8/118.8 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting chardet<3.1.0,>=3.0.2\n","  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting idna<2.9,>=2.5\n","  Downloading idna-2.8-py2.py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.6/58.6 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython~=5.5.0->google-colab) (0.2.5)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth~=1.4.0->google-colab) (0.4.8)\n","Collecting terminado>=0.3.3\n","  Downloading terminado-0.16.0-py3-none-any.whl (16 kB)\n","  Downloading terminado-0.15.0-py3-none-any.whl (16 kB)\n","  Downloading terminado-0.13.3-py3-none-any.whl (14 kB)\n","Requirement already satisfied: ptyprocess in /opt/conda/lib/python3.7/site-packages (from terminado>=0.3.3->notebook~=5.2.0->google-colab) (0.7.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->notebook~=5.2.0->google-colab) (2.1.1)\n","Requirement already satisfied: nest-asyncio>=1.5.4 in /opt/conda/lib/python3.7/site-packages (from jupyter-client->ipykernel~=4.6.0->google-colab) (1.5.6)\n","Collecting jupyter-client\n","  Downloading jupyter_client-7.4.7-py3-none-any.whl (133 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.5/133.5 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading jupyter_client-7.4.6-py3-none-any.whl (133 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.5/133.5 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading jupyter_client-7.4.5-py3-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading jupyter_client-7.4.3-py3-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.2/132.2 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading jupyter_client-7.4.2-py3-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.2/132.2 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading jupyter_client-7.4.1-py3-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.1/132.1 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading jupyter_client-7.4.0-py3-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.2/132.2 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading jupyter_client-7.3.5-py3-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.1/132.1 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading jupyter_client-7.3.4-py3-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.1/132.1 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading jupyter_client-7.3.3-py3-none-any.whl (131 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading jupyter_client-7.3.2-py3-none-any.whl (131 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.9/131.9 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading jupyter_client-7.3.1-py3-none-any.whl (130 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.0/131.0 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading jupyter_client-7.3.0-py3-none-any.whl (130 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.9/130.9 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading jupyter_client-7.2.2-py3-none-any.whl (130 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.6/130.6 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading jupyter_client-7.2.1-py3-none-any.whl (130 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.4/130.4 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading jupyter_client-7.2.0-py3-none-any.whl (130 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading jupyter_client-7.1.2-py3-none-any.whl (130 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.3/130.3 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: entrypoints in /opt/conda/lib/python3.7/site-packages (from jupyter-client->ipykernel~=4.6.0->google-colab) (0.4)\n","Requirement already satisfied: pyzmq>=13 in /opt/conda/lib/python3.7/site-packages (from jupyter-client->ipykernel~=4.6.0->google-colab) (24.0.1)\n","Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook~=5.2.0->google-colab) (4.11.1)\n","Requirement already satisfied: tinycss2 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook~=5.2.0->google-colab) (1.2.1)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook~=5.2.0->google-colab) (21.3)\n","Requirement already satisfied: bleach in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook~=5.2.0->google-colab) (5.0.1)\n","Requirement already satisfied: defusedxml in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook~=5.2.0->google-colab) (0.7.1)\n","Requirement already satisfied: nbclient>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook~=5.2.0->google-colab) (0.7.0)\n","Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook~=5.2.0->google-colab) (0.2.2)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook~=5.2.0->google-colab) (1.5.0)\n","Requirement already satisfied: importlib-metadata>=3.6 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook~=5.2.0->google-colab) (4.11.4)\n","Requirement already satisfied: mistune<3,>=2.0.3 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook~=5.2.0->google-colab) (2.0.4)\n","Requirement already satisfied: jsonschema>=2.6 in /opt/conda/lib/python3.7/site-packages (from nbformat->notebook~=5.2.0->google-colab) (4.16.0)\n","Requirement already satisfied: fastjsonschema in /opt/conda/lib/python3.7/site-packages (from nbformat->notebook~=5.2.0->google-colab) (2.16.2)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=3.6->nbconvert->notebook~=5.2.0->google-colab) (4.4.0)\n","Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=3.6->nbconvert->notebook~=5.2.0->google-colab) (3.10.0)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=2.6->nbformat->notebook~=5.2.0->google-colab) (5.10.0)\n","Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=2.6->nbformat->notebook~=5.2.0->google-colab) (1.3.10)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=2.6->nbformat->notebook~=5.2.0->google-colab) (0.18.1)\n","Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=2.6->nbformat->notebook~=5.2.0->google-colab) (22.1.0)\n","Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->nbconvert->notebook~=5.2.0->google-colab) (2.3.2.post1)\n","Requirement already satisfied: webencodings in /opt/conda/lib/python3.7/site-packages (from bleach->nbconvert->notebook~=5.2.0->google-colab) (0.5.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->nbconvert->notebook~=5.2.0->google-colab) (3.0.9)\n","Building wheels for collected packages: google-colab, portpicker, tornado, simplegeneric\n","  Building wheel for google-colab (setup.py) ... \u001b[?25l-\b \bdone\n","\u001b[?25h  Created wheel for google-colab: filename=google_colab-1.0.0-py2.py3-none-any.whl size=102292 sha256=365e7e7e5786120aab62776d52d3f0c913d6f2e640fe9441837bc757f5fefadd\n","  Stored in directory: /home/zw2784/.cache/pip/wheels/0b/af/ed/0157613a3f8febbb90d3d44597f3605464cf3e2d411a8adf99\n","  Building wheel for portpicker (setup.py) ... \u001b[?25l-\b \bdone\n","\u001b[?25h  Created wheel for portpicker: filename=portpicker-1.2.0-py3-none-any.whl size=13384 sha256=62b7202fb973861dbca175845c5f2dfc0717aee9cba226ab06c6ee8b65a842b6\n","  Stored in directory: /home/zw2784/.cache/pip/wheels/b2/0e/fc/0bf9bab983ee205881fa1b70c875de99336ccb5f9ee779ed2c\n","  Building wheel for tornado (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n","\u001b[?25h  Created wheel for tornado: filename=tornado-4.5.3-cp37-cp37m-linux_x86_64.whl size=434169 sha256=84a2a2f1e81c6c32b02ba4d3904816c09507d08e127d87833f88bd42f67dc74e\n","  Stored in directory: /home/zw2784/.cache/pip/wheels/60/6b/b9/d6eb552745a31bde095241c890aeb584db30c41e29b0dee9a2\n","  Building wheel for simplegeneric (setup.py) ... \u001b[?25l-\b \bdone\n","\u001b[?25h  Created wheel for simplegeneric: filename=simplegeneric-0.8.1-py3-none-any.whl size=5078 sha256=9103ab63a134046a6d061122edfcbf7f26bcc17aba718c7dbd83c5ca5ec3eac0\n","  Stored in directory: /home/zw2784/.cache/pip/wheels/39/d7/b9/41b8c09f03813f87f8051e3b9885324ee7a4381172c468e668\n","Successfully built google-colab portpicker tornado simplegeneric\n","Installing collected packages: tornado, simplegeneric, portpicker, chardet, urllib3, terminado, six, idna, requests, prompt-toolkit, google-auth, pandas, jupyter-client, ipython, ipykernel, notebook, google-colab\n","  Attempting uninstall: tornado\n","    Found existing installation: tornado 6.2\n","    Uninstalling tornado-6.2:\n","      Successfully uninstalled tornado-6.2\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.26.11\n","    Uninstalling urllib3-1.26.11:\n","      Successfully uninstalled urllib3-1.26.11\n","  Attempting uninstall: terminado\n","    Found existing installation: terminado 0.17.0\n","    Uninstalling terminado-0.17.0:\n","      Successfully uninstalled terminado-0.17.0\n","  Attempting uninstall: six\n","    Found existing installation: six 1.16.0\n","    Uninstalling six-1.16.0:\n","      Successfully uninstalled six-1.16.0\n","  Attempting uninstall: idna\n","    Found existing installation: idna 3.4\n","    Uninstalling idna-3.4:\n","      Successfully uninstalled idna-3.4\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.28.1\n","    Uninstalling requests-2.28.1:\n","      Successfully uninstalled requests-2.28.1\n","  Attempting uninstall: prompt-toolkit\n","    Found existing installation: prompt-toolkit 3.0.31\n","    Uninstalling prompt-toolkit-3.0.31:\n","      Successfully uninstalled prompt-toolkit-3.0.31\n","  Attempting uninstall: google-auth\n","    Found existing installation: google-auth 2.13.0\n","    Uninstalling google-auth-2.13.0:\n","      Successfully uninstalled google-auth-2.13.0\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 1.3.5\n","    Uninstalling pandas-1.3.5:\n","      Successfully uninstalled pandas-1.3.5\n","  Attempting uninstall: jupyter-client\n","    Found existing installation: jupyter_client 7.4.4\n","    Uninstalling jupyter_client-7.4.4:\n","      Successfully uninstalled jupyter_client-7.4.4\n","  Attempting uninstall: ipython\n","    Found existing installation: ipython 7.33.0\n","    Uninstalling ipython-7.33.0:\n","      Successfully uninstalled ipython-7.33.0\n","  Attempting uninstall: ipykernel\n","    Found existing installation: ipykernel 6.16.2\n","    Uninstalling ipykernel-6.16.2:\n","      Successfully uninstalled ipykernel-6.16.2\n","  Attempting uninstall: notebook\n","    Found existing installation: notebook 6.4.12\n","    Uninstalling notebook-6.4.12:\n","      Successfully uninstalled notebook-6.4.12\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","visions 0.7.5 requires pandas>=0.25.3, but you have pandas 0.24.2 which is incompatible.\n","statsmodels 0.13.2 requires pandas>=0.25, but you have pandas 0.24.2 which is incompatible.\n","seaborn 0.12.1 requires pandas>=0.25, but you have pandas 0.24.2 which is incompatible.\n","phik 0.12.2 requires pandas>=0.25.1, but you have pandas 0.24.2 which is incompatible.\n","pandas-profiling 3.4.0 requires pandas!=1.4.0,<1.6,>1.1, but you have pandas 0.24.2 which is incompatible.\n","pandas-profiling 3.4.0 requires requests<2.29,>=2.24.0, but you have requests 2.21.0 which is incompatible.\n","nbclassic 0.4.7 requires tornado>=6.1, but you have tornado 4.5.3 which is incompatible.\n","jupyterlab 3.4.8 requires tornado>=6.1.0, but you have tornado 4.5.3 which is incompatible.\n","jupyter-server 1.21.0 requires tornado>=6.1.0, but you have tornado 4.5.3 which is incompatible.\n","ipywidgets 8.0.2 requires ipython>=6.1.0, but you have ipython 5.5.0 which is incompatible.\n","google-cloud-storage 2.5.0 requires google-auth<3.0dev,>=1.25.0, but you have google-auth 1.4.2 which is incompatible.\n","google-cloud-core 2.3.2 requires google-auth<3.0dev,>=1.25.0, but you have google-auth 1.4.2 which is incompatible.\n","google-cloud-bigquery 2.34.4 requires protobuf<4.0.0dev,>=3.12.0, but you have protobuf 4.21.8 which is incompatible.\n","google-auth-oauthlib 0.7.0 requires google-auth>=2.13.0, but you have google-auth 1.4.2 which is incompatible.\n","google-api-python-client 2.65.0 requires google-auth<3.0.0dev,>=1.19.0, but you have google-auth 1.4.2 which is incompatible.\n","google-api-core 2.8.0 requires google-auth<3.0dev,>=1.25.0, but you have google-auth 1.4.2 which is incompatible.\n","docker 6.0.0 requires requests>=2.26.0, but you have requests 2.21.0 which is incompatible.\n","docker 6.0.0 requires urllib3>=1.26.0, but you have urllib3 1.24.3 which is incompatible.\n","cloud-tpu-client 0.10 requires google-api-python-client==1.8.0, but you have google-api-python-client 2.65.0 which is incompatible.\n","botocore 1.29.17 requires urllib3<1.27,>=1.25.4, but you have urllib3 1.24.3 which is incompatible.\n","beatrix-jupyterlab 2022.1028.200048 requires google-auth>=1.22.0, but you have google-auth 1.4.2 which is incompatible.\n","beatrix-jupyterlab 2022.1028.200048 requires requests>=2.22.0, but you have requests 2.21.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed chardet-3.0.4 google-auth-1.4.2 google-colab-1.0.0 idna-2.8 ipykernel-4.6.1 ipython-5.5.0 jupyter-client-7.1.2 notebook-5.2.2 pandas-0.24.2 portpicker-1.2.0 prompt-toolkit-1.0.18 requests-2.21.0 simplegeneric-0.8.1 six-1.12.0 terminado-0.13.3 tornado-4.5.3 urllib3-1.24.3\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import sys\n","sys.path.insert(0, '/content/drive/MyDrive/Colab Notebooks/Capstone')\n","\n","import os\n","import pandas as pd\n","import numpy as np\n","\n","from utils import read_conll_file, read_data\n","\n","\n","data_dir = \"/content/drive/MyDrive/Colab Notebooks/Capstone/data/gweb_sancl\"\n","wsj_dir = os.path.join(data_dir, \"pos_fine\", \"wsj\")\n","model_dir = \"/content/drive/MyDrive/Colab Notebooks/Capstone/model\"\n","base_model_file = 'base_model.pt'\n","plot_dir = \"/content/drive/MyDrive/Colab Notebooks/Capstone/plots\"\n","metrics_dir = \"/content/drive/MyDrive/Colab Notebooks/Capstone/metrics\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":429},"id":"jIFha6OOht8L","executionInfo":{"status":"error","timestamp":1669690013100,"user_tz":300,"elapsed":350,"user":{"displayName":"Zheng Wu","userId":"01190949623920087412"}},"outputId":"fe60b6f0-39d0-4ba8-983f-49b430b1ebbd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/opt/conda/lib/python3.7/site-packages/IPython/utils/traitlets.py:5: UserWarning: IPython.utils.traitlets has moved to a top-level traitlets package.\n","  warn(\"IPython.utils.traitlets has moved to a top-level traitlets package.\")\n"]},{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_25807/2187944252.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/drive/MyDrive/Colab Notebooks/Capstone'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m   \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m   \u001b[0mhome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhome\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m   \u001b[0mroot_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_env\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m   \u001b[0mhome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'HOME'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m   root_dir = _os.path.realpath(\n\u001b[0;32m---> 43\u001b[0;31m       _os.path.join(_os.environ['CLOUDSDK_CONFIG'], '../..'))\n\u001b[0m\u001b[1;32m     44\u001b[0m   \u001b[0minet_family\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'IPV4_ONLY'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m   \u001b[0mdev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/dev/fuse'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'CLOUDSDK_CONFIG'"]}]},{"cell_type":"code","source":["wsj_train_file = os.path.join(wsj_dir, \"gweb-wsj-train.conll\")\n","wsj_dev_file = os.path.join(wsj_dir, \"gweb-wsj-dev.conll\")\n","wsj_test_file = os.path.join(wsj_dir, \"gweb-wsj-test.conll\")"],"metadata":{"id":"CPKysG3i3nsR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["wsj_train_word_lst, wsj_train_tag_lst, wsj_train_tag_set = read_data(wsj_train_file)\n","wsj_dev_word_lst, wsj_dev_tag_lst, wsj_dev_tag_set = read_data(wsj_dev_file)\n","wsj_test_word_lst, wsj_test_tag_lst, wsj_test_tag_set = read_data(wsj_test_file)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0KqectYYC30N","executionInfo":{"status":"ok","timestamp":1669686801315,"user_tz":300,"elapsed":2780,"user":{"displayName":"Zheng Wu","userId":"01190949623920087412"}},"outputId":"8f0f1d17-cf87-4bf1-d0a8-a1da139995ff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The number of samples: 30060\n","The number of tags 48\n","The number of samples: 1336\n","The number of tags 45\n","The number of samples: 1640\n","The number of tags 45\n"]}]},{"cell_type":"code","source":["wsj_tags = wsj_train_tag_set + wsj_dev_tag_set + wsj_test_tag_set\n","wsj_tags = sorted(list(set(wsj_tags)))\n","wsj_tags = [\"<pad>\"] + wsj_tags\n","tag2idx = {tag:idx for idx, tag in enumerate(wsj_tags)}\n","idx2tag = {idx:tag for idx, tag in enumerate(wsj_tags)}\n","print(len(wsj_tags))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CgySDvNl3xkh","executionInfo":{"status":"ok","timestamp":1669686801316,"user_tz":300,"elapsed":13,"user":{"displayName":"Zheng Wu","userId":"01190949623920087412"}},"outputId":"3875caeb-d8e9-49d1-b229-8151fef86408"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["49\n"]}]},{"cell_type":"markdown","source":["# Build Model"],"metadata":{"id":"V9yUXS679IFc"}},{"cell_type":"code","source":["from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n","\n","import os\n","from tqdm import tqdm_notebook as tqdm\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.utils import data\n","import torch.optim as optim\n","from pytorch_pretrained_bert import BertTokenizer"],"metadata":{"id":"7nIm4vqm3xiL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(device)"],"metadata":{"id":"zleK0sd96JRp","executionInfo":{"status":"ok","timestamp":1669686801316,"user_tz":300,"elapsed":8,"user":{"displayName":"Zheng Wu","userId":"01190949623920087412"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2e73a888-5e4f-435c-a96e-524e1716ca64"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"code","source":["tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)"],"metadata":{"id":"6fRrkkC26JP_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class PosDataset(data.Dataset):\n","    def __init__(self, word_lst, tag_lst):\n","        sents, tags_li = [], [] # list of lists\n","        for i in range(len(word_lst)):\n","            sents.append([\"[CLS]\"] + word_lst[i] + [\"[SEP]\"])\n","            tags_li.append([\"<pad>\"] + tag_lst[i] + [\"<pad>\"])\n","        self.sents, self.tags_li = sents, tags_li\n","\n","    def __len__(self):\n","        return len(self.sents)\n","\n","    def __getitem__(self, idx):\n","        words, tags = self.sents[idx], self.tags_li[idx] # words, tags: string list\n","\n","        # We give credits only to the first piece.\n","        x, y = [], [] # list of ids\n","        is_heads = [] # list. 1: the token is the first piece of a word\n","        for w, t in zip(words, tags):\n","            tokens = tokenizer.tokenize(w) if w not in (\"[CLS]\", \"[SEP]\") else [w]\n","            xx = tokenizer.convert_tokens_to_ids(tokens)\n","\n","            is_head = [1] + [0]*(len(tokens) - 1)\n","\n","            t = [t] + [\"<pad>\"] * (len(tokens) - 1)  # <PAD>: no decision\n","            yy = [tag2idx[each] for each in t]  # (T,)\n","\n","            x.extend(xx)\n","            is_heads.extend(is_head)\n","            y.extend(yy)\n","\n","        assert len(x)==len(y)==len(is_heads), \"len(x)={}, len(y)={}, len(is_heads)={}\".format(len(x), len(y), len(is_heads))\n","\n","        # seqlen\n","        seqlen = len(y)\n","\n","        # to string\n","        words = \" \".join(words)\n","        tags = \" \".join(tags)\n","        return words, x, is_heads, tags, y, seqlen\n"],"metadata":{"id":"RpKgRRbK6JMr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def pad(batch):\n","    '''Pads to the longest sample'''\n","    f = lambda x: [sample[x] for sample in batch]\n","    words = f(0)\n","    is_heads = f(2)\n","    tags = f(3)\n","    seqlens = f(-1)\n","    maxlen = np.array(seqlens).max()\n","\n","    f = lambda x, seqlen: [sample[x] + [0] * (seqlen - len(sample[x])) for sample in batch] # 0: <pad>\n","    x = f(1, maxlen)\n","    y = f(-2, maxlen)\n","\n","\n","    f = torch.LongTensor\n","\n","    return words, f(x), is_heads, tags, f(y), seqlens"],"metadata":{"id":"MZ_JndBu6LjA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pytorch_pretrained_bert import BertModel"],"metadata":{"id":"9mthfoFt6JFJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Net(nn.Module):\n","    def __init__(self, vocab_size=None):\n","        super().__init__()\n","        self.bert = BertModel.from_pretrained('bert-base-cased')\n","\n","        self.fc = nn.Linear(768, vocab_size)\n","        self.device = device\n","\n","    def forward(self, x, y):\n","        '''\n","        x: (N, T). int64\n","        y: (N, T). int64\n","        '''\n","        x = x.to(device)\n","        y = y.to(device)\n","        \n","        if self.training:\n","            self.bert.train()\n","            encoded_layers, _ = self.bert(x)\n","            enc = encoded_layers[-1]\n","        else:\n","            self.bert.eval()\n","            with torch.no_grad():\n","                encoded_layers, _ = self.bert(x)\n","                enc = encoded_layers[-1]\n","        \n","        logits = self.fc(enc)\n","        y_hat = logits.argmax(-1)\n","        return logits, y, y_hat"],"metadata":{"id":"e6ydlTI16JCz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(model, iterator, optimizer, criterion):\n","    model.train()\n","    for i, batch in enumerate(iterator):\n","        words, x, is_heads, tags, y, seqlens = batch\n","        _y = y # for monitoring\n","        optimizer.zero_grad()\n","        logits, y, _ = model(x, y) # logits: (N, T, VOCAB), y: (N, T)\n","\n","        logits = logits.view(-1, logits.shape[-1]) # (N*T, VOCAB)\n","        y = y.view(-1)  # (N*T,)\n","\n","        loss = criterion(logits, y)\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        if i%10==0: # monitoring\n","            print(\"step: {}, loss: {}\".format(i, loss.item()))"],"metadata":{"id":"DeD_19uq6JAd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def eval(model, iterator, average=\"macro\"):\n","    model.eval()\n","\n","    Words, Is_heads, Tags, Y, Y_hat = [], [], [], [], []\n","    with torch.no_grad():\n","        for i, batch in enumerate(iterator):\n","            words, x, is_heads, tags, y, seqlens = batch\n","\n","            _, _, y_hat = model(x, y)  # y_hat: (N, T)\n","\n","            Words.extend(words)\n","            Is_heads.extend(is_heads)\n","            Tags.extend(tags)\n","            Y.extend(y.numpy().tolist())\n","            Y_hat.extend(y_hat.cpu().numpy().tolist())\n","\n","    ## gets results and save\n","    with open(\"result\", 'w') as fout:\n","        for words, is_heads, tags, y_hat in zip(Words, Is_heads, Tags, Y_hat):\n","            y_hat = [hat for head, hat in zip(is_heads, y_hat) if head == 1]\n","            preds = [idx2tag[hat] for hat in y_hat]\n","            assert len(preds)==len(words.split())==len(tags.split())\n","            for w, t, p in zip(words.split()[1:-1], tags.split()[1:-1], preds[1:-1]):\n","                fout.write(\"{} {} {}\\n\".format(w, t, p))\n","            fout.write(\"\\n\")\n","            \n","    ## calc metric\n","    y_true =  np.array([tag2idx[line.split()[1]] for line in open('result', 'r').read().splitlines() if len(line) > 0])\n","    y_pred =  np.array([tag2idx[line.split()[2]] for line in open('result', 'r').read().splitlines() if len(line) > 0])\n","\n","    acc = (y_true==y_pred).astype(np.int32).sum() / len(y_true)\n","\n","    print(\"acc=%.2f\"%acc)\n","    print(\"classification_report\", classification_report(y_true, y_pred))\n","    precision_value = precision_score(y_true, y_pred, average=average)\n","    recall_value = recall_score(y_true, y_pred, average=average)\n","    f1_value = f1_score(y_true, y_pred, average=average)\n","\n","    return precision_value, recall_value, f1_value"],"metadata":{"id":"DW4KvG4x6I91"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Net(vocab_size=len(tag2idx))\n","model.to(device)\n","model = nn.DataParallel(model)"],"metadata":{"id":"0ZDK1-UU6I5K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = PosDataset(wsj_train_word_lst, wsj_train_tag_lst)\n","eval_dataset = PosDataset(wsj_test_word_lst, wsj_test_tag_lst)\n","\n","train_iter = data.DataLoader(dataset=train_dataset,\n","                             batch_size=8,\n","                             shuffle=True,\n","                             num_workers=1,\n","                             collate_fn=pad)\n","test_iter = data.DataLoader(dataset=eval_dataset,\n","                             batch_size=8,\n","                             shuffle=False,\n","                             num_workers=1,\n","                             collate_fn=pad)\n","\n","optimizer = optim.Adam(model.parameters(), lr = 0.00001) # 调低learning rate 可以调的更小 Online learning特色\n","\n","criterion = nn.CrossEntropyLoss(ignore_index=0)"],"metadata":{"id":"f5pQmdTS6I20"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Run this part only when there is no base_model before to save time\n","if base_model_file not in os.listdir(model_dir):\n","    train(model, train_iter, optimizer, criterion)\n","    eval(model, test_iter)"],"metadata":{"id":"B0x3gRfi9iyA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Save Model"],"metadata":{"id":"6fVp31VJ5U64"}},{"cell_type":"code","source":["model_file = os.path.join(model_dir, base_model_file)\n","# save the model only if we have not train the base model before\n","# all the models share the same base model\n","if base_model_file not in os.listdir(model_dir):\n","    torch.save(model.state_dict(), model_file)"],"metadata":{"id":"LtVeE3zd04C8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load Model"],"metadata":{"id":"cyvpy9QH4sQd"}},{"cell_type":"code","source":["model = Net(vocab_size=len(tag2idx))\n","model.to(device)\n","model = nn.DataParallel(model)\n","model.load_state_dict(torch.load(model_file))\n","wsj_precision_value, wsj_recall_value, wsj_f1_value = eval(model, test_iter)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hAD3Wd574v6Q","executionInfo":{"status":"ok","timestamp":1669686838323,"user_tz":300,"elapsed":19624,"user":{"displayName":"Zheng Wu","userId":"01190949623920087412"}},"outputId":"ed6572bb-12c8-4fb1-d9de-9f93a085ae2e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["acc=0.97\n","classification_report               precision    recall  f1-score   support\n","\n","           1       1.00      1.00      1.00       178\n","           2       1.00      1.00      1.00       352\n","           3       1.00      1.00      1.00      2000\n","           4       1.00      1.00      1.00        60\n","           5       1.00      1.00      1.00        60\n","           6       1.00      1.00      1.00      1613\n","           7       1.00      1.00      1.00       223\n","           9       1.00      0.99      1.00       935\n","          10       0.98      1.00      0.99      1266\n","          11       0.99      1.00      0.99      3309\n","          12       1.00      1.00      1.00        46\n","          13       1.00      0.20      0.33        20\n","          14       1.00      0.99      1.00       511\n","          15       0.97      0.99      0.98      4250\n","          16       0.97      0.89      0.93      2423\n","          17       0.96      0.93      0.94       139\n","          18       0.92      0.93      0.93        73\n","          19       1.00      0.75      0.86         4\n","          20       1.00      0.99      1.00       413\n","          22       0.98      0.98      0.98      5545\n","          23       0.99      0.96      0.97      4133\n","          24       0.21      0.71      0.32        45\n","          25       0.99      0.98      0.98      2316\n","          26       0.71      1.00      0.83        15\n","          27       0.99      0.99      0.99       373\n","          28       1.00      0.99      0.99       766\n","          29       0.99      1.00      1.00       357\n","          30       0.95      0.91      0.93      1405\n","          31       0.88      0.85      0.86        82\n","          32       0.85      0.89      0.87        37\n","          33       0.85      0.87      0.86       126\n","          34       0.75      0.82      0.78        11\n","          35       0.99      0.99      0.99       588\n","          36       0.88      1.00      0.93         7\n","          37       0.98      0.98      0.98      1124\n","          38       0.99      0.96      0.98      1162\n","          39       0.93      0.97      0.95       608\n","          40       0.82      0.99      0.90       829\n","          41       0.97      0.98      0.97       563\n","          42       0.98      0.99      0.99       873\n","          43       0.93      0.97      0.95       191\n","          44       1.00      1.00      1.00        90\n","          45       1.00      1.00      1.00        14\n","          46       1.00      0.99      0.99        89\n","          48       1.00      1.00      1.00       366\n","\n","    accuracy                           0.97     39590\n","   macro avg       0.94      0.94      0.93     39590\n","weighted avg       0.98      0.97      0.98     39590\n","\n"]}]},{"cell_type":"code","source":["wsj_precision_value, wsj_recall_value, wsj_f1_value"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2M6AkbHMD6VJ","executionInfo":{"status":"ok","timestamp":1669686838326,"user_tz":300,"elapsed":39,"user":{"displayName":"Zheng Wu","userId":"01190949623920087412"}},"outputId":"ca1186c5-78a7-41eb-8e74-154c75bfcf3b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.9417027899389416, 0.9425258210459151, 0.9318435575593024)"]},"metadata":{},"execution_count":56}]},{"cell_type":"markdown","source":["# Self Training"],"metadata":{"id":"reoycWJi5azd"}},{"cell_type":"code","source":["def filter_tag(process_words, process_tags, label_tags_set=wsj_tags):\n","  new_words = []\n","  new_tags = []\n","  for words, tags in zip(process_words, process_tags):\n","    w_lst = []\n","    t_lst = []\n","    for i, t in enumerate(tags):\n","      if t in label_tags_set:\n","        w_lst.append(words[i])\n","        t_lst.append(tags[i])\n","\n","    if w_lst:\n","      new_words.append(w_lst)\n","      new_tags.append(t_lst)\n","  print(\"after filter tag\", len(new_words))\n","  return new_words, new_tags"],"metadata":{"id":"agIHM1TmEYl3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["file_name_lst = [\"answers\", \"emails\", \"newsgroups\", \"reviews\", \"weblogs\"]"],"metadata":{"id":"mGm3QLNcD8bU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def prepare_for_domain(domain):\n","  print(\"preparing domain dir and files...\")\n","  domain_dir = os.path.join(data_dir, \"pos_fine\", f\"{domain}\")\n","  domain_dev_file = os.path.join(domain_dir, f\"gweb-{domain}-dev.conll\")\n","  domain_test_file = os.path.join(domain_dir, f\"gweb-{domain}-test.conll\")\n","\n","  print(\"reading data for domain dev and test...\")\n","  domain_dev_word_lst, domain_dev_tag_lst, domain_dev_tag_set = read_data(domain_dev_file)\n","  domain_test_word_lst, domain_test_tag_lst, domain_test_tag_set = read_data(domain_test_file)\n","  domain_dev_word_lst, domain_dev_tag_lst = filter_tag(domain_dev_word_lst, domain_dev_tag_lst)  \n","  domain_test_word_lst, domain_test_tag_lst = filter_tag(domain_test_word_lst, domain_test_tag_lst)\n","\n","  print(\"preparing evaluation placeholder for prevision, recall and f1...\")\n","  domain_precision_value_lst = []\n","  domain_recall_value_lst = []\n","  domain_f1_value_lst = []\n","\n","  domain_test_dataset = PosDataset(domain_test_word_lst, domain_test_tag_lst)\n","\n","  domain_test_iter = data.DataLoader(dataset=domain_test_dataset,\n","                              batch_size=8,\n","                              shuffle=False,\n","                              num_workers=1,\n","                              collate_fn=pad)\n","  \n","  print(f\"prepare base model for domain {domain}...\")\n","  model = Net(vocab_size=len(tag2idx))\n","  model.to(device)\n","  model = nn.DataParallel(model)\n","  model_file = os.path.join(model_dir, base_model_file)\n","  model.load_state_dict(torch.load(model_file))\n","\n","  print(\"evaluating prevision, recall and f1 for base model...\")\n","  domain_precision_value, domain_recall_value, domain_f1_value = eval(model, domain_test_iter)\n","\n","  domain_precision_value_lst.append(domain_precision_value)\n","  domain_recall_value_lst.append(domain_recall_value)\n","  domain_f1_value_lst.append(domain_f1_value)\n","  return model, domain_dev_word_lst, domain_dev_tag_lst, domain_test_iter, domain_precision_value_lst, domain_recall_value_lst, domain_f1_value_lst"],"metadata":{"id":"MgG4YgdUsBWJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prepare_for_domain(\"emails\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eQyu9t4nsk3L","executionInfo":{"status":"ok","timestamp":1669686861759,"user_tz":300,"elapsed":23464,"user":{"displayName":"Zheng Wu","userId":"01190949623920087412"}},"outputId":"19a43b71-39c4-4e10-85ff-c46d6ed8eb61"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["preparing domain dir and files...\n","reading data for domain dev and test...\n","The number of samples: 2450\n","The number of tags 49\n","The number of samples: 2450\n","The number of tags 48\n","after filter tag 2427\n","after filter tag 2402\n","preparing evaluation placeholder for prevision, recall and f1...\n","prepare base model for domain emails...\n","evaluating prevision, recall and f1 for base model...\n","acc=0.91\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.79      0.94      0.86        35\n","           2       0.87      0.52      0.65        77\n","           3       1.00      0.79      0.88      1030\n","           4       1.00      0.84      0.91       291\n","           5       0.91      0.84      0.87       294\n","           6       0.99      0.98      0.99      1570\n","           7       0.61      0.94      0.74       186\n","           8       0.00      0.00      0.00        11\n","           9       0.99      0.98      0.98       689\n","          10       0.93      0.98      0.96       901\n","          11       0.96      1.00      0.98      2111\n","          12       0.98      0.96      0.97        47\n","          13       0.60      0.46      0.52        13\n","          14       0.28      1.00      0.44        43\n","          15       0.93      0.98      0.95      2778\n","          16       0.90      0.80      0.85      1151\n","          17       0.91      0.95      0.93        41\n","          18       0.94      1.00      0.97        32\n","          19       0.68      0.57      0.62        40\n","          20       1.00      0.96      0.98       584\n","          21       0.00      0.00      0.00        52\n","          22       0.93      0.75      0.83      4175\n","          23       0.73      0.95      0.83      2253\n","          24       0.37      0.68      0.48        44\n","          25       0.87      0.92      0.89       888\n","          26       1.00      0.78      0.88         9\n","          27       0.71      0.99      0.82        69\n","          28       1.00      1.00      1.00      1864\n","          29       1.00      0.99      0.99       344\n","          30       0.81      0.86      0.83      1136\n","          31       0.55      0.63      0.59        19\n","          32       1.00      0.75      0.86         8\n","          33       0.75      0.97      0.84        86\n","          34       0.19      0.38      0.25        32\n","          35       0.97      1.00      0.98       474\n","          36       1.00      0.14      0.24       182\n","          37       0.89      0.96      0.92      1592\n","          38       0.98      0.96      0.97       404\n","          39       0.97      0.93      0.95       485\n","          40       0.90      0.98      0.94       573\n","          41       0.93      0.94      0.94       841\n","          42       0.98      0.99      0.99       575\n","          43       0.94      0.89      0.92       152\n","          44       0.87      0.92      0.90        75\n","          46       0.96      0.99      0.98        82\n","          48       0.00      0.00      0.00        79\n","\n","    accuracy                           0.91     28417\n","   macro avg       0.79      0.80      0.78     28417\n","weighted avg       0.91      0.91      0.90     28417\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["(DataParallel(\n","   (module): Net(\n","     (bert): BertModel(\n","       (embeddings): BertEmbeddings(\n","         (word_embeddings): Embedding(28996, 768, padding_idx=0)\n","         (position_embeddings): Embedding(512, 768)\n","         (token_type_embeddings): Embedding(2, 768)\n","         (LayerNorm): BertLayerNorm()\n","         (dropout): Dropout(p=0.1, inplace=False)\n","       )\n","       (encoder): BertEncoder(\n","         (layer): ModuleList(\n","           (0): BertLayer(\n","             (attention): BertAttention(\n","               (self): BertSelfAttention(\n","                 (query): Linear(in_features=768, out_features=768, bias=True)\n","                 (key): Linear(in_features=768, out_features=768, bias=True)\n","                 (value): Linear(in_features=768, out_features=768, bias=True)\n","                 (dropout): Dropout(p=0.1, inplace=False)\n","               )\n","               (output): BertSelfOutput(\n","                 (dense): Linear(in_features=768, out_features=768, bias=True)\n","                 (LayerNorm): BertLayerNorm()\n","                 (dropout): Dropout(p=0.1, inplace=False)\n","               )\n","             )\n","             (intermediate): BertIntermediate(\n","               (dense): Linear(in_features=768, out_features=3072, bias=True)\n","             )\n","             (output): BertOutput(\n","               (dense): Linear(in_features=3072, out_features=768, bias=True)\n","               (LayerNorm): BertLayerNorm()\n","               (dropout): Dropout(p=0.1, inplace=False)\n","             )\n","           )\n","           (1): BertLayer(\n","             (attention): BertAttention(\n","               (self): BertSelfAttention(\n","                 (query): Linear(in_features=768, out_features=768, bias=True)\n","                 (key): Linear(in_features=768, out_features=768, bias=True)\n","                 (value): Linear(in_features=768, out_features=768, bias=True)\n","                 (dropout): Dropout(p=0.1, inplace=False)\n","               )\n","               (output): BertSelfOutput(\n","                 (dense): Linear(in_features=768, out_features=768, bias=True)\n","                 (LayerNorm): BertLayerNorm()\n","                 (dropout): Dropout(p=0.1, inplace=False)\n","               )\n","             )\n","             (intermediate): BertIntermediate(\n","               (dense): Linear(in_features=768, out_features=3072, bias=True)\n","             )\n","             (output): BertOutput(\n","               (dense): Linear(in_features=3072, out_features=768, bias=True)\n","               (LayerNorm): BertLayerNorm()\n","               (dropout): Dropout(p=0.1, inplace=False)\n","             )\n","           )\n","           (2): BertLayer(\n","             (attention): BertAttention(\n","               (self): BertSelfAttention(\n","                 (query): Linear(in_features=768, out_features=768, bias=True)\n","                 (key): Linear(in_features=768, out_features=768, bias=True)\n","                 (value): Linear(in_features=768, out_features=768, bias=True)\n","                 (dropout): Dropout(p=0.1, inplace=False)\n","               )\n","               (output): BertSelfOutput(\n","                 (dense): Linear(in_features=768, out_features=768, bias=True)\n","                 (LayerNorm): BertLayerNorm()\n","                 (dropout): Dropout(p=0.1, inplace=False)\n","               )\n","             )\n","             (intermediate): BertIntermediate(\n","               (dense): Linear(in_features=768, out_features=3072, bias=True)\n","             )\n","             (output): BertOutput(\n","               (dense): Linear(in_features=3072, out_features=768, bias=True)\n","               (LayerNorm): BertLayerNorm()\n","               (dropout): Dropout(p=0.1, inplace=False)\n","             )\n","           )\n","           (3): BertLayer(\n","             (attention): BertAttention(\n","               (self): BertSelfAttention(\n","                 (query): Linear(in_features=768, out_features=768, bias=True)\n","                 (key): Linear(in_features=768, out_features=768, bias=True)\n","                 (value): Linear(in_features=768, out_features=768, bias=True)\n","                 (dropout): Dropout(p=0.1, inplace=False)\n","               )\n","               (output): BertSelfOutput(\n","                 (dense): Linear(in_features=768, out_features=768, bias=True)\n","                 (LayerNorm): BertLayerNorm()\n","                 (dropout): Dropout(p=0.1, inplace=False)\n","               )\n","             )\n","             (intermediate): BertIntermediate(\n","               (dense): Linear(in_features=768, out_features=3072, bias=True)\n","             )\n","             (output): BertOutput(\n","               (dense): Linear(in_features=3072, out_features=768, bias=True)\n","               (LayerNorm): BertLayerNorm()\n","               (dropout): Dropout(p=0.1, inplace=False)\n","             )\n","           )\n","           (4): BertLayer(\n","             (attention): BertAttention(\n","               (self): BertSelfAttention(\n","                 (query): Linear(in_features=768, out_features=768, bias=True)\n","                 (key): Linear(in_features=768, out_features=768, bias=True)\n","                 (value): Linear(in_features=768, out_features=768, bias=True)\n","                 (dropout): Dropout(p=0.1, inplace=False)\n","               )\n","               (output): BertSelfOutput(\n","                 (dense): Linear(in_features=768, out_features=768, bias=True)\n","                 (LayerNorm): BertLayerNorm()\n","                 (dropout): Dropout(p=0.1, inplace=False)\n","               )\n","             )\n","             (intermediate): BertIntermediate(\n","               (dense): Linear(in_features=768, out_features=3072, bias=True)\n","             )\n","             (output): BertOutput(\n","               (dense): Linear(in_features=3072, out_features=768, bias=True)\n","               (LayerNorm): BertLayerNorm()\n","               (dropout): Dropout(p=0.1, inplace=False)\n","             )\n","           )\n","           (5): BertLayer(\n","             (attention): BertAttention(\n","               (self): BertSelfAttention(\n","                 (query): Linear(in_features=768, out_features=768, bias=True)\n","                 (key): Linear(in_features=768, out_features=768, bias=True)\n","                 (value): Linear(in_features=768, out_features=768, bias=True)\n","                 (dropout): Dropout(p=0.1, inplace=False)\n","               )\n","               (output): BertSelfOutput(\n","                 (dense): Linear(in_features=768, out_features=768, bias=True)\n","                 (LayerNorm): BertLayerNorm()\n","                 (dropout): Dropout(p=0.1, inplace=False)\n","               )\n","             )\n","             (intermediate): BertIntermediate(\n","               (dense): Linear(in_features=768, out_features=3072, bias=True)\n","             )\n","             (output): BertOutput(\n","               (dense): Linear(in_features=3072, out_features=768, bias=True)\n","               (LayerNorm): BertLayerNorm()\n","               (dropout): Dropout(p=0.1, inplace=False)\n","             )\n","           )\n","           (6): BertLayer(\n","             (attention): BertAttention(\n","               (self): BertSelfAttention(\n","                 (query): Linear(in_features=768, out_features=768, bias=True)\n","                 (key): Linear(in_features=768, out_features=768, bias=True)\n","                 (value): Linear(in_features=768, out_features=768, bias=True)\n","                 (dropout): Dropout(p=0.1, inplace=False)\n","               )\n","               (output): BertSelfOutput(\n","                 (dense): Linear(in_features=768, out_features=768, bias=True)\n","                 (LayerNorm): BertLayerNorm()\n","                 (dropout): Dropout(p=0.1, inplace=False)\n","               )\n","             )\n","             (intermediate): BertIntermediate(\n","               (dense): Linear(in_features=768, out_features=3072, bias=True)\n","             )\n","             (output): BertOutput(\n","               (dense): Linear(in_features=3072, out_features=768, bias=True)\n","               (LayerNorm): BertLayerNorm()\n","               (dropout): Dropout(p=0.1, inplace=False)\n","             )\n","           )\n","           (7): BertLayer(\n","             (attention): BertAttention(\n","               (self): BertSelfAttention(\n","                 (query): Linear(in_features=768, out_features=768, bias=True)\n","                 (key): Linear(in_features=768, out_features=768, bias=True)\n","                 (value): Linear(in_features=768, out_features=768, bias=True)\n","                 (dropout): Dropout(p=0.1, inplace=False)\n","               )\n","               (output): BertSelfOutput(\n","                 (dense): Linear(in_features=768, out_features=768, bias=True)\n","                 (LayerNorm): BertLayerNorm()\n","                 (dropout): Dropout(p=0.1, inplace=False)\n","               )\n","             )\n","             (intermediate): BertIntermediate(\n","               (dense): Linear(in_features=768, out_features=3072, bias=True)\n","             )\n","             (output): BertOutput(\n","               (dense): Linear(in_features=3072, out_features=768, bias=True)\n","               (LayerNorm): BertLayerNorm()\n","               (dropout): Dropout(p=0.1, inplace=False)\n","             )\n","           )\n","           (8): BertLayer(\n","             (attention): BertAttention(\n","               (self): BertSelfAttention(\n","                 (query): Linear(in_features=768, out_features=768, bias=True)\n","                 (key): Linear(in_features=768, out_features=768, bias=True)\n","                 (value): Linear(in_features=768, out_features=768, bias=True)\n","                 (dropout): Dropout(p=0.1, inplace=False)\n","               )\n","               (output): BertSelfOutput(\n","                 (dense): Linear(in_features=768, out_features=768, bias=True)\n","                 (LayerNorm): BertLayerNorm()\n","                 (dropout): Dropout(p=0.1, inplace=False)\n","               )\n","             )\n","             (intermediate): BertIntermediate(\n","               (dense): Linear(in_features=768, out_features=3072, bias=True)\n","             )\n","             (output): BertOutput(\n","               (dense): Linear(in_features=3072, out_features=768, bias=True)\n","               (LayerNorm): BertLayerNorm()\n","               (dropout): Dropout(p=0.1, inplace=False)\n","             )\n","           )\n","           (9): BertLayer(\n","             (attention): BertAttention(\n","               (self): BertSelfAttention(\n","                 (query): Linear(in_features=768, out_features=768, bias=True)\n","                 (key): Linear(in_features=768, out_features=768, bias=True)\n","                 (value): Linear(in_features=768, out_features=768, bias=True)\n","                 (dropout): Dropout(p=0.1, inplace=False)\n","               )\n","               (output): BertSelfOutput(\n","                 (dense): Linear(in_features=768, out_features=768, bias=True)\n","                 (LayerNorm): BertLayerNorm()\n","                 (dropout): Dropout(p=0.1, inplace=False)\n","               )\n","             )\n","             (intermediate): BertIntermediate(\n","               (dense): Linear(in_features=768, out_features=3072, bias=True)\n","             )\n","             (output): BertOutput(\n","               (dense): Linear(in_features=3072, out_features=768, bias=True)\n","               (LayerNorm): BertLayerNorm()\n","               (dropout): Dropout(p=0.1, inplace=False)\n","             )\n","           )\n","           (10): BertLayer(\n","             (attention): BertAttention(\n","               (self): BertSelfAttention(\n","                 (query): Linear(in_features=768, out_features=768, bias=True)\n","                 (key): Linear(in_features=768, out_features=768, bias=True)\n","                 (value): Linear(in_features=768, out_features=768, bias=True)\n","                 (dropout): Dropout(p=0.1, inplace=False)\n","               )\n","               (output): BertSelfOutput(\n","                 (dense): Linear(in_features=768, out_features=768, bias=True)\n","                 (LayerNorm): BertLayerNorm()\n","                 (dropout): Dropout(p=0.1, inplace=False)\n","               )\n","             )\n","             (intermediate): BertIntermediate(\n","               (dense): Linear(in_features=768, out_features=3072, bias=True)\n","             )\n","             (output): BertOutput(\n","               (dense): Linear(in_features=3072, out_features=768, bias=True)\n","               (LayerNorm): BertLayerNorm()\n","               (dropout): Dropout(p=0.1, inplace=False)\n","             )\n","           )\n","           (11): BertLayer(\n","             (attention): BertAttention(\n","               (self): BertSelfAttention(\n","                 (query): Linear(in_features=768, out_features=768, bias=True)\n","                 (key): Linear(in_features=768, out_features=768, bias=True)\n","                 (value): Linear(in_features=768, out_features=768, bias=True)\n","                 (dropout): Dropout(p=0.1, inplace=False)\n","               )\n","               (output): BertSelfOutput(\n","                 (dense): Linear(in_features=768, out_features=768, bias=True)\n","                 (LayerNorm): BertLayerNorm()\n","                 (dropout): Dropout(p=0.1, inplace=False)\n","               )\n","             )\n","             (intermediate): BertIntermediate(\n","               (dense): Linear(in_features=768, out_features=3072, bias=True)\n","             )\n","             (output): BertOutput(\n","               (dense): Linear(in_features=3072, out_features=768, bias=True)\n","               (LayerNorm): BertLayerNorm()\n","               (dropout): Dropout(p=0.1, inplace=False)\n","             )\n","           )\n","         )\n","       )\n","       (pooler): BertPooler(\n","         (dense): Linear(in_features=768, out_features=768, bias=True)\n","         (activation): Tanh()\n","       )\n","     )\n","     (fc): Linear(in_features=768, out_features=49, bias=True)\n","   )\n"," ),\n"," [['Michael', ':'],\n","  ['Thanks', 'for', 'putting', 'the', 'paperwork', 'together', '.'],\n","  ['I',\n","   'would',\n","   'have',\n","   'interest',\n","   'in',\n","   'meeting',\n","   'if',\n","   'you',\n","   'can',\n","   'present',\n","   'unique',\n","   'investment',\n","   'opportunities',\n","   'that',\n","   'I',\n","   'do',\n","   \"n't\",\n","   'have',\n","   'access',\n","   'to',\n","   'now',\n","   '.'],\n","  ['Most',\n","   'of',\n","   'my',\n","   'contact',\n","   'with',\n","   'financial',\n","   'advisors',\n","   'in',\n","   'the',\n","   'past',\n","   'has',\n","   'consisted',\n","   'of',\n","   'them',\n","   'suggesting',\n","   'a',\n","   'mutual',\n","   'fund',\n","   ',',\n","   'telling',\n","   'me',\n","   'to',\n","   'invest',\n","   'in',\n","   'Home',\n","   'Depot',\n","   ',',\n","   'Sun',\n","   ',',\n","   'and',\n","   'Coke',\n","   ',',\n","   'or',\n","   'trying',\n","   'to',\n","   'pass',\n","   'off',\n","   'their',\n","   'banks',\n","   \"'\",\n","   'biased',\n","   'research',\n","   'reports',\n","   'as',\n","   'something',\n","   'valuable',\n","   '.'],\n","  ['The',\n","   'above',\n","   'services',\n","   'provide',\n","   'no',\n","   'value',\n","   'to',\n","   'me',\n","   'personally',\n","   '.'],\n","  ['If',\n","   'you',\n","   'can',\n","   'present',\n","   'opportunities',\n","   'such',\n","   'as',\n","   'access',\n","   'to',\n","   'private',\n","   'equity',\n","   'or',\n","   'hedge',\n","   'funds',\n","   ',',\n","   'or',\n","   'other',\n","   'ideas',\n","   'with',\n","   'strong',\n","   'growth',\n","   'potential',\n","   'and',\n","   'low',\n","   'correlation',\n","   'to',\n","   'the',\n","   'S@P',\n","   ',',\n","   'I',\n","   \"'d\",\n","   'listen',\n","   '.'],\n","  ['John'],\n","  ['John', '-'],\n","  ['We',\n","   \"'ll\",\n","   'get',\n","   'the',\n","   'paperwork',\n","   'together',\n","   'and',\n","   'sent',\n","   'to',\n","   'you',\n","   'for',\n","   'naked',\n","   'options',\n","   '.'],\n","  ['At',\n","   'some',\n","   'point',\n","   ',',\n","   'I',\n","   \"'d\",\n","   'like',\n","   'to',\n","   'talk',\n","   'about',\n","   'the',\n","   'diversification',\n","   'strategy',\n","   'in',\n","   'more',\n","   'detail',\n","   '--',\n","   'perhaps',\n","   'over',\n","   'dinner',\n","   'or',\n","   'a',\n","   'quick',\n","   'meeting',\n","   'after',\n","   'the',\n","   'markets',\n","   'close',\n","   '?'],\n","  ['Michael',\n","   'Gapinski',\n","   'Account',\n","   'Vice',\n","   'President',\n","   'Emery',\n","   'Financial',\n","   'Group',\n","   'PaineWebber',\n","   ',',\n","   'Inc.',\n","   '713-654-0365',\n","   '800-553-3119',\n","   'x365',\n","   'Fax',\n","   ':',\n","   '713-654-1281',\n","   'Cell',\n","   ':',\n","   '281-435-0295'],\n","  ['Michael', ':'],\n","  ['Appreciate', 'the', 'idea', '.'],\n","  ['However',\n","   ',',\n","   'with',\n","   'my',\n","   'natural',\n","   'long',\n","   ',',\n","   'I',\n","   \"'m\",\n","   'not',\n","   'looking',\n","   'to',\n","   'really',\n","   'trade',\n","   'around',\n","   'the',\n","   'position',\n","   '.'],\n","  ['I',\n","   'believe',\n","   'ENE',\n","   'will',\n","   'continue',\n","   'to',\n","   'be',\n","   'range',\n","   'bound',\n","   ',',\n","   'but',\n","   'in',\n","   'case',\n","   'it',\n","   'is',\n","   'not',\n","   ',',\n","   'I',\n","   'do',\n","   \"n't\",\n","   'want',\n","   'to',\n","   'forgo',\n","   '50',\n","   '%',\n","   'of',\n","   'my',\n","   'option',\n","   'premium',\n","   '.'],\n","  ['I',\n","   'have',\n","   'price',\n","   'targets',\n","   'of',\n","   'where',\n","   'I',\n","   'would',\n","   'like',\n","   'to',\n","   'lighten',\n","   'up',\n","   'exposure',\n","   'to',\n","   'ENE',\n","   'and',\n","   'will',\n","   'use',\n","   'calls',\n","   'to',\n","   'implement',\n","   'the',\n","   'stategy',\n","   '.'],\n","  ['To',\n","   'that',\n","   'regards',\n","   ',',\n","   'I',\n","   'noticed',\n","   'I',\n","   'was',\n","   'not',\n","   'approved',\n","   'to',\n","   'sell',\n","   'naked',\n","   'calls',\n","   '.'],\n","  ['I',\n","   'would',\n","   'like',\n","   'that',\n","   'ability',\n","   'in',\n","   'order',\n","   'to',\n","   'hedge',\n","   'some',\n","   'exposure',\n","   'I',\n","   'have',\n","   'of',\n","   'unexercised',\n","   'vested',\n","   'options',\n","   '.'],\n","  ['Please', 'look', 'into', 'that', 'for', 'me', '.'],\n","  ['John', '.'],\n","  ['John', '-'],\n","  ['I',\n","   'was',\n","   'looking',\n","   'at',\n","   'the',\n","   'recent',\n","   'pullback',\n","   'in',\n","   'ENE',\n","   'and',\n","   'thinking',\n","   'it',\n","   'might',\n","   'be',\n","   'an',\n","   'opportunity',\n","   'to',\n","   'buy',\n","   'back',\n","   'the',\n","   'calls',\n","   'you',\n","   'sold',\n","   '.'],\n","  ['Of',\n","   'course',\n","   ',',\n","   'you',\n","   'would',\n","   'then',\n","   'be',\n","   'in',\n","   'a',\n","   'position',\n","   'to',\n","   'sell',\n","   'calls',\n","   'again',\n","   'if',\n","   'the',\n","   'stock',\n","   'makes',\n","   'a',\n","   'bounce',\n","   '.'],\n","  ['I',\n","   \"'m\",\n","   'not',\n","   'sure',\n","   'that',\n","   'ENE',\n","   '@',\n","   '75',\n","   'is',\n","   'the',\n","   'place',\n","   ',',\n","   'but',\n","   'maybe',\n","   '@',\n","   '73',\n","   '.'],\n","  ['Call', 'me', 'if', 'you', \"'re\", 'interested', '.'],\n","  ['Michael',\n","   'Gapinski',\n","   'Account',\n","   'Vice',\n","   'President',\n","   'Emery',\n","   'Financial',\n","   'Group',\n","   'PaineWebber',\n","   ',',\n","   'Inc.',\n","   '713-654-0365',\n","   '800-553-3119',\n","   'x365',\n","   'Fax',\n","   ':',\n","   '713-654-1281',\n","   'Cell',\n","   ':',\n","   '281-435-0295'],\n","  ['Notice',\n","   'Regarding',\n","   'Entry',\n","   'of',\n","   'Orders',\n","   'and',\n","   'Instructions',\n","   ':',\n","   'Please',\n","   'do',\n","   'not',\n","   'transmit',\n","   'orders',\n","   'and',\n","   '/',\n","   'or',\n","   'instructions',\n","   'regarding',\n","   'your',\n","   'PaineWebber',\n","   'account',\n","   '-LRB-',\n","   's',\n","   '-RRB-',\n","   'by',\n","   'e-mail',\n","   '.'],\n","  ['Orders',\n","   'and',\n","   '/',\n","   'or',\n","   'instructions',\n","   'transmitted',\n","   'by',\n","   'e-mail',\n","   'will',\n","   'not',\n","   'be',\n","   'accepted',\n","   'by',\n","   'PaineWebber',\n","   'and',\n","   'PaineWebber',\n","   'will',\n","   'not',\n","   'be',\n","   'responsible',\n","   'for',\n","   'carrying',\n","   'out',\n","   'such',\n","   'orders',\n","   'and',\n","   '/',\n","   'or',\n","   'instructions',\n","   '.'],\n","  ['Notice',\n","   'Regarding',\n","   'Privacy',\n","   'and',\n","   'Confidentiality',\n","   ':',\n","   'PaineWebber',\n","   'reserves',\n","   'the',\n","   'right',\n","   'to',\n","   'monitor',\n","   'and',\n","   'review',\n","   'the',\n","   'content',\n","   'of',\n","   'all',\n","   'e-mail',\n","   'communications',\n","   'sent',\n","   'and',\n","   '/',\n","   'or',\n","   'received',\n","   'by',\n","   'its',\n","   'employees',\n","   '.'],\n","  ['Notice',\n","   'Regarding',\n","   'Entry',\n","   'of',\n","   'Orders',\n","   'and',\n","   'Instructions',\n","   ':',\n","   'Please',\n","   'do',\n","   'not',\n","   'transmit',\n","   'orders',\n","   'and',\n","   '/',\n","   'or',\n","   'instructions',\n","   'regarding',\n","   'your',\n","   'PaineWebber',\n","   'account',\n","   '-LRB-',\n","   's',\n","   '-RRB-',\n","   'by',\n","   'e-mail',\n","   '.'],\n","  ['Orders',\n","   'and',\n","   '/',\n","   'or',\n","   'instructions',\n","   'transmitted',\n","   'by',\n","   'e-mail',\n","   'will',\n","   'not',\n","   'be',\n","   'accepted',\n","   'by',\n","   'PaineWebber',\n","   'and',\n","   'PaineWebber',\n","   'will',\n","   'not',\n","   'be',\n","   'responsible',\n","   'for',\n","   'carrying',\n","   'out',\n","   'such',\n","   'orders',\n","   'and',\n","   '/',\n","   'or',\n","   'instructions',\n","   '.'],\n","  ['Notice',\n","   'Regarding',\n","   'Privacy',\n","   'and',\n","   'Confidentiality',\n","   ':',\n","   'PaineWebber',\n","   'reserves',\n","   'the',\n","   'right',\n","   'to',\n","   'monitor',\n","   'and',\n","   'review',\n","   'the',\n","   'content',\n","   'of',\n","   'all',\n","   'e-mail',\n","   'communications',\n","   'sent',\n","   'and',\n","   '/',\n","   'or',\n","   'received',\n","   'by',\n","   'its',\n","   'employees',\n","   '.'],\n","  ['Notice',\n","   'Regarding',\n","   'Entry',\n","   'of',\n","   'Orders',\n","   'and',\n","   'Instructions',\n","   ':',\n","   'Please',\n","   'do',\n","   'not',\n","   'transmit',\n","   'orders',\n","   'and',\n","   '/',\n","   'or',\n","   'instructions',\n","   'regarding',\n","   'your',\n","   'PaineWebber',\n","   'account',\n","   '-LRB-',\n","   's',\n","   '-RRB-',\n","   'by',\n","   'e-mail',\n","   '.'],\n","  ['Orders',\n","   'and',\n","   '/',\n","   'or',\n","   'instructions',\n","   'transmitted',\n","   'by',\n","   'e-mail',\n","   'will',\n","   'not',\n","   'be',\n","   'accepted',\n","   'by',\n","   'PaineWebber',\n","   'and',\n","   'PaineWebber',\n","   'will',\n","   'not',\n","   'be',\n","   'responsible',\n","   'for',\n","   'carrying',\n","   'out',\n","   'such',\n","   'orders',\n","   'and',\n","   '/',\n","   'or',\n","   'instructions',\n","   '.'],\n","  ['Notice',\n","   'Regarding',\n","   'Privacy',\n","   'and',\n","   'Confidentiality',\n","   ':',\n","   'PaineWebber',\n","   'reserves',\n","   'the',\n","   'right',\n","   'to',\n","   'monitor',\n","   'and',\n","   'review',\n","   'the',\n","   'content',\n","   'of',\n","   'all',\n","   'e-mail',\n","   'communications',\n","   'sent',\n","   'and',\n","   '/',\n","   'or',\n","   'received',\n","   'by',\n","   'its',\n","   'employees',\n","   '.'],\n","  ['Who', 'cares', '??????'],\n","  ['Please',\n","   'note',\n","   'that',\n","   'effective',\n","   'immediately',\n","   'my',\n","   'email',\n","   'address',\n","   'has',\n","   'changed',\n","   'to'],\n","  ['He', 'just', 'rescheduled', 'to', 'Wednesday', '.'],\n","  ['How', 'about', 'dinner', 'on', 'Wednesday', 'after', 'that', '?'],\n","  ['Your', 'buddy', 'Beau', 'invited', 'me', '.'],\n","  ['How',\n","   'about',\n","   'prior',\n","   'to',\n","   'that',\n","   'or',\n","   'after',\n","   'that',\n","   'on',\n","   'Tuesday',\n","   '.'],\n","  ['not', 'really', '...'],\n","  ['already', 'have', 'plans', 'on', 'thursday', '.'],\n","  ['are',\n","   'you',\n","   'going',\n","   'to',\n","   'the',\n","   'NYMEX',\n","   'candidate',\n","   'cocktail',\n","   'hour',\n","   'Tuesday',\n","   '?'],\n","  ['oh', 'god', 'is', 'there', 'an', 'agenda', '.'],\n","  ['Would', 'dinner', 'Thursday', 'work', 'instead', '.'],\n","  ['not', 'really', '...'],\n","  ['already', 'have', 'plans', 'on', 'thursday', '.'],\n","  ['are',\n","   'you',\n","   'going',\n","   'to',\n","   'the',\n","   'NYMEX',\n","   'candidate',\n","   'cocktail',\n","   'hour',\n","   'Tuesday',\n","   '?'],\n","  ['oh', 'god', 'is', 'there', 'an', 'agenda', '.'],\n","  ['Renee', ','],\n","  ['I',\n","   'would',\n","   'like',\n","   'to',\n","   'have',\n","   'a',\n","   'meeting',\n","   'to',\n","   'go',\n","   'over',\n","   'the',\n","   'payment',\n","   'methodology',\n","   '.'],\n","  ['Scott',\n","   'Neal',\n","   'and',\n","   'Tom',\n","   'Martin',\n","   'would',\n","   'like',\n","   'to',\n","   'attend',\n","   'as',\n","   'well',\n","   '.'],\n","  ['This',\n","   'afternoon',\n","   'at',\n","   '2',\n","   'PM',\n","   'or',\n","   'later',\n","   'would',\n","   'work',\n","   'for',\n","   'us',\n","   '.'],\n","  ['Please', 'let', 'me', 'know', 'what', 'time', 'we', 'could', 'meet', '.'],\n","  ['Thank', 'you', ','],\n","  ['Phillip'],\n","  ['Phillip', ','],\n","  ['This',\n","   'section',\n","   'pertains',\n","   'to',\n","   'terminated',\n","   'employees',\n","   'who',\n","   'are',\n","   'paid',\n","   'out',\n","   'in',\n","   'the',\n","   'year',\n","   'following',\n","   'the',\n","   'termination',\n","   'event',\n","   '.'],\n","  ['The',\n","   'way',\n","   'the',\n","   'tax',\n","   'law',\n","   'works',\n","   ',',\n","   'the',\n","   'tax',\n","   'basis',\n","   'for',\n","   'your',\n","   'share',\n","   'distribution',\n","   'will',\n","   'be',\n","   'based',\n","   'on',\n","   'the',\n","   'closing',\n","   'stock',\n","   'price',\n","   'the',\n","   'day',\n","   'preceding',\n","   'notification',\n","   'to',\n","   'the',\n","   'transfer',\n","   'agent',\n","   '.'],\n","  ['As',\n","   'such',\n","   ',',\n","   'we',\n","   'will',\n","   'distribute',\n","   'net',\n","   'shares',\n","   'calculating',\n","   'the',\n","   'proper',\n","   'withholding',\n","   'at',\n","   'fair',\n","   'market',\n","   'value',\n","   'the',\n","   'day',\n","   'prior',\n","   'to',\n","   'notifying',\n","   'the',\n","   'transfer',\n","   'agent',\n","   '.'],\n","  ['We',\n","   'will',\n","   'be',\n","   'distributing',\n","   'the',\n","   'shares',\n","   'reflected',\n","   'on',\n","   'your',\n","   '9/30/01',\n","   'statement',\n","   '-LRB-',\n","   '6,606',\n","   'shares',\n","   'plus',\n","   'cash',\n","   'for',\n","   'fractional',\n","   'shares',\n","   '-RRB-',\n","   '.'],\n","  ['If',\n","   'you',\n","   'would',\n","   'prefer',\n","   'to',\n","   'settle',\n","   'the',\n","   'taxes',\n","   'with',\n","   'a',\n","   'personal',\n","   'check',\n","   ',',\n","   'we',\n","   'can',\n","   'distribute',\n","   'gross',\n","   'shares',\n","   '.'],\n","  ['Please', 'let', 'me', 'know', 'you', 'preference', '.'],\n","  ['As',\n","   'you',\n","   'know',\n","   ',',\n","   'we',\n","   'are',\n","   'in',\n","   'the',\n","   'process',\n","   'of',\n","   'transferring',\n","   'recordkeeping',\n","   'services',\n","   'from',\n","   'NTRC',\n","   'to',\n","   'Hewitt',\n","   '.'],\n","  ['As',\n","   'such',\n","   ',',\n","   'we',\n","   'have',\n","   'a',\n","   'CPA',\n","   ',',\n","   'Larry',\n","   'Lewis',\n","   ',',\n","   'working',\n","   'with',\n","   'us',\n","   'to',\n","   'audit',\n","   'and',\n","   'set',\n","   'up',\n","   'transition',\n","   'files',\n","   '.'],\n","  ['He',\n","   'has',\n","   'become',\n","   'our',\n","   'department',\n","   'expert',\n","   'on',\n","   'the',\n","   'PSA',\n","   'account',\n","   '-LRB-',\n","   'much',\n","   'more',\n","   'knowledgeable',\n","   'than',\n","   'myself',\n","   '-RRB-',\n","   'and',\n","   'the',\n","   'various',\n","   'plan',\n","   'provision',\n","   'amendments',\n","   '.'],\n","  ['If',\n","   'you',\n","   'would',\n","   'like',\n","   ',',\n","   'we',\n","   'can',\n","   'set',\n","   'up',\n","   'a',\n","   'conference',\n","   'call',\n","   'with',\n","   'you',\n","   ',',\n","   'myself',\n","   ',',\n","   'and',\n","   'Larry',\n","   'to',\n","   'go',\n","   'over',\n","   'the',\n","   'payment',\n","   'methodology',\n","   '.'],\n","  ['Please',\n","   'let',\n","   'me',\n","   'know',\n","   'a',\n","   'date',\n","   'and',\n","   'time',\n","   'that',\n","   'is',\n","   'convenient',\n","   'for',\n","   'you',\n","   '.'],\n","  ['Thanks', ','],\n","  ['Renee'],\n","  ['Renee', ','],\n","  ['Thank',\n","   'you',\n","   'for',\n","   'digging',\n","   'in',\n","   'to',\n","   'the',\n","   'issue',\n","   'of',\n","   'Deferred',\n","   'Phantom',\n","   'Stock',\n","   'Units',\n","   '.'],\n","  ['It',\n","   'is',\n","   'clear',\n","   'that',\n","   'the',\n","   'payment',\n","   'will',\n","   'be',\n","   'made',\n","   'in',\n","   'shares',\n","   '.'],\n","  ['However',\n","   ',',\n","   'I',\n","   'still',\n","   'do',\n","   \"n't\",\n","   'understand',\n","   'which',\n","   'date',\n","   'will',\n","   'be',\n","   'used',\n","   'to',\n","   'determine',\n","   'the',\n","   'value',\n","   'and',\n","   'calculate',\n","   'how',\n","   'many',\n","   'shares',\n","   '.'],\n","  ['The', 'plan', 'document', 'under', 'VII', '.'],\n","  ['Amount',\n","   'of',\n","   'Benefit',\n","   'Payments',\n","   'reads',\n","   '\"',\n","   'The',\n","   'value',\n","   'of',\n","   'the',\n","   'shares',\n","   ',',\n","   'and',\n","   'resulting',\n","   'payment',\n","   'amount',\n","   'will',\n","   'be',\n","   'based',\n","   'on',\n","   'the',\n","   'closing',\n","   'price',\n","   'of',\n","   'Enron',\n","   'Corp.',\n","   'common',\n","   'stock',\n","   'on',\n","   'the',\n","   'January',\n","   '1',\n","   'before',\n","   'the',\n","   'date',\n","   'of',\n","   'payment',\n","   ',',\n","   'and',\n","   'such',\n","   'payment',\n","   'shall',\n","   'be',\n","   'made',\n","   'in',\n","   'shares',\n","   'of',\n","   'Enron',\n","   'Corp.',\n","   'common',\n","   'stock',\n","   '.',\n","   '\"'],\n","  ['Can',\n","   'you',\n","   'help',\n","   'me',\n","   'interpret',\n","   'this',\n","   'statement',\n","   'and',\n","   'work',\n","   'through',\n","   'the',\n","   'numbers',\n","   'on',\n","   'my',\n","   'account',\n","   '.'],\n","  ['Thank', 'you', ','],\n","  ['Phillip', 'Allen'],\n","  ['Let',\n","   'me',\n","   'know',\n","   'when',\n","   'you',\n","   'get',\n","   'the',\n","   'quotes',\n","   'from',\n","   'Pauline',\n","   '.'],\n","  ['I',\n","   'am',\n","   'expecting',\n","   'to',\n","   'pay',\n","   'something',\n","   'in',\n","   'the',\n","   '$',\n","   '3,',\n","   'to',\n","   '$',\n","   '5,000',\n","   'range',\n","   '.'],\n","  ['I',\n","   'would',\n","   'like',\n","   'to',\n","   'see',\n","   'the',\n","   'quotes',\n","   'and',\n","   'a',\n","   'description',\n","   'of',\n","   'the',\n","   'work',\n","   'to',\n","   'be',\n","   'done',\n","   '.'],\n","  ['It',\n","   'is',\n","   'my',\n","   'understanding',\n","   'that',\n","   'some',\n","   'rock',\n","   'will',\n","   'be',\n","   'removed',\n","   'and',\n","   'replaced',\n","   'with',\n","   'siding',\n","   '.'],\n","  ['If',\n","   'they',\n","   'are',\n","   'getting',\n","   'quotes',\n","   'to',\n","   'put',\n","   'up',\n","   'new',\n","   'rock',\n","   'then',\n","   'we',\n","   'will',\n","   'need',\n","   'to',\n","   'clarify',\n","   '.'],\n","  ['Jacques',\n","   'is',\n","   'ready',\n","   'to',\n","   'drop',\n","   'in',\n","   'a',\n","   'dollar',\n","   'amount',\n","   'on',\n","   'the',\n","   'release',\n","   '.'],\n","  ['If',\n","   'the',\n","   'negotiations',\n","   'stall',\n","   ',',\n","   'it',\n","   'seems',\n","   'like',\n","   'I',\n","   'need',\n","   'to',\n","   'go',\n","   'ahead',\n","   'and',\n","   'cut',\n","   'off',\n","   'the',\n","   'utilities',\n","   '.'],\n","  ['Hopefully', 'things', 'will', 'go', 'smoothly', '.'],\n","  ['Phillip'],\n","  ['Attendees', ':', 'Pam', 'Butler'],\n","  ['Renee', 'Ratcliff'],\n","  ['Larry', 'Lewis'],\n","  ['Tom', 'Martin'],\n","  ['Scott', 'Neal'],\n","  ['Phillip', 'Allen'],\n","  ['Greg', ','],\n","  ['I',\n","   'faxed',\n","   'you',\n","   'the',\n","   'promotional',\n","   'on',\n","   '10300',\n","   'Heritage',\n","   'Office',\n","   'Building',\n","   'with',\n","   'the',\n","   'Nimitz',\n","   'post',\n","   'office',\n","   '.'],\n","  ['The',\n","   'broker',\n","   'called',\n","   'back',\n","   'shortly',\n","   'after',\n","   'I',\n","   'spoke',\n","   'to',\n","   'you',\n","   'to',\n","   'let',\n","   'me',\n","   'know',\n","   'that',\n","   'the',\n","   'kestrel',\n","   'air',\n","   'park',\n","   'building',\n","   'and',\n","   'the',\n","   'strip',\n","   'center',\n","   'at',\n","   'fm78',\n","   '&',\n","   'walzem',\n","   'had',\n","   'both',\n","   'sold',\n","   '.'],\n","  ['Let', 'me', 'know', 'what', 'you', 'think', 'of', 'this', 'property', '.'],\n","  ['Also',\n","   ',',\n","   'let',\n","   'me',\n","   'know',\n","   'of',\n","   'any',\n","   'other',\n","   'ideas',\n","   'about',\n","   'replacement',\n","   'property',\n","   '.'],\n","  ['Phillip'],\n","  ['Jim', ','],\n","  ['Take', 'a', 'look', 'at', 'this', 'spreadsheet', '.'],\n","  ['I',\n","   'tried',\n","   'to',\n","   'calculate',\n","   'the',\n","   'IRR',\n","   'on',\n","   'the',\n","   'port',\n","   'Aransas',\n","   'and',\n","   'Roma',\n","   'post',\n","   'offices',\n","   '.'],\n","  ['Is',\n","   'this',\n","   'how',\n","   'your',\n","   'clients',\n","   'usually',\n","   'evaluate',\n","   'these',\n","   'properties',\n","   '?'],\n","  ['The', 'Roma', 'deal', 'looks', 'much', 'better', '.'],\n","  ['Phillip'],\n","  ['Mery', ','],\n","  ['This',\n","   'sounds',\n","   'better',\n","   'than',\n","   'the',\n","   'limitations',\n","   'you',\n","   'were',\n","   'describing',\n","   'in',\n","   'the',\n","   'meeting',\n","   '.'],\n","  ['We', 'should', 'be', 'able', 'to', 'work', 'with', 'this', '.'],\n","  ['Phillip'],\n","  ['Joan', 'Woodson'],\n","  ['08/10/2000', '08:28', 'AM'],\n","  ['Enron', 'Investment', 'Partners'],\n","  ['Congratulations', '!'],\n","  ['You', \"'ve\", 'all', 'won', '!'],\n","  ['...', 'Now', 'comes', 'the', 'fun', 'part', '....'],\n","  ['The',\n","   'following',\n","   'have',\n","   'made',\n","   'a',\n","   'team',\n","   'for',\n","   'the',\n","   'game',\n","   'show',\n","   'on',\n","   'August',\n","   '17th',\n","   '!.'],\n","  ['Thanks', 'to', 'all', 'who', 'volunteered', '.'],\n","  ['You', 'will', 'remain', 'as', 'alternates', '.'],\n","  ['Analyst', 'Team', 'Participants', ':'],\n","  ['Analyst', 'Team', '1', ':', 'Coach', ':', 'Lisa', 'Gilette'],\n","  ['Kristen',\n","   'Quinn',\n","   ',',\n","   'Sarah',\n","   'Mulholland',\n","   ',',\n","   'Samuel',\n","   'Pak',\n","   ',',\n","   'Daniel',\n","   'Kang'],\n","  ['Analyst', 'Team', '2', ':', 'Coach', ':', 'Doug', 'Sewell'],\n","  ['Jeffrey',\n","   'Synder',\n","   ',',\n","   'Ryan',\n","   'Hinze',\n","   ',',\n","   'Sheetal',\n","   'Patel',\n","   ',',\n","   'Johnathan',\n","   'Anderson'],\n","  ['Associate', 'Team', 'Participants', ':'],\n","  ['Associate', 'Team', '1', ':', 'Coach', ':', 'Ben', 'Markey'],\n","  ['Mary',\n","   'John',\n","   ',',\n","   'Russell',\n","   'Dyk',\n","   ',',\n","   'Webb',\n","   'Jennings',\n","   ',',\n","   'Martin',\n","   'Gonzales'],\n","  ['Mixed',\n","   'A',\n","   '/',\n","   'A',\n","   'Team',\n","   '2',\n","   ':',\n","   'Coach',\n","   ':',\n","   'Melanie',\n","   'King',\n","   'Brandon',\n","   'Luna',\n","   '-',\n","   'Analyst',\n","   ',',\n","   'Bryan',\n","   'Hull',\n","   '-',\n","   'Analyst',\n","   ',',\n","   'Eduardo',\n","   'Tellechea',\n","   '-',\n","   'Associate',\n","   ',',\n","   'Milson',\n","   'Mundim',\n","   '-',\n","   'Associate'],\n","  ['Alternates',\n","   ':',\n","   'Heather',\n","   'Johnson',\n","   ',',\n","   'Usman',\n","   'Shaukat',\n","   ',',\n","   'Gerard',\n","   'Benitez',\n","   ',',\n","   'Matthew',\n","   'Almy',\n","   ',',\n","   'Travis',\n","   'Hanson'],\n","  ['WHO', 'WANTS', 'TO', 'HELP', 'MILLIONS', 'FOR', 'UNITED', 'WAY', '?'],\n","  ['We', 'hope', 'you', 'do', '!'],\n","  ['How', 'to', 'Pledge', ':'],\n","  ['This',\n","   'year',\n","   'it',\n","   'is',\n","   'very',\n","   'easy',\n","   'to',\n","   'make',\n","   'your',\n","   'contribution',\n","   '.'],\n","  ['Simply',\n","   'type',\n","   'in',\n","   'the',\n","   'following',\n","   'United',\n","   'Way',\n","   'link',\n","   ',',\n","   'or',\n","   'go',\n","   'directly',\n","   'to',\n","   'Internet',\n","   'Explorer',\n","   'or',\n","   'Netscape',\n","   'and',\n","   'type',\n","   'in',\n","   'unitedway.enron.com',\n","   'in',\n","   'the',\n","   'address',\n","   'field',\n","   '.'],\n","  ['Either',\n","   'option',\n","   'should',\n","   'take',\n","   'you',\n","   'directly',\n","   'to',\n","   'Enron',\n","   \"'s\",\n","   'United',\n","   'Way',\n","   '2000',\n","   'Campaign',\n","   'site',\n","   '.'],\n","  ['PLEASE',\n","   'NOTE',\n","   ':',\n","   'Your',\n","   'pledge',\n","   'is',\n","   'to',\n","   'be',\n","   'made',\n","   'electronically',\n","   '-',\n","   'it',\n","   'only',\n","   'takes',\n","   'minutes',\n","   '.'],\n","  ['No', 'physical', 'pledge', 'cards', '.'],\n","  ['Questions',\n","   ':',\n","   'If',\n","   'you',\n","   'have',\n","   'any',\n","   'questions',\n","   'regarding',\n","   'the',\n","   'pledging',\n","   'process',\n","   ',',\n","   'please',\n","   'contact',\n","   'Joan',\n","   'Woodson',\n","   '-LRB-',\n","   '3-5213',\n","   '-RRB-',\n","   ',',\n","   'Bert',\n","   'Frazier',\n","   '-LRB-',\n","   '3-5076',\n","   '-RRB-',\n","   'or',\n","   'Kathy',\n","   'Mayfield',\n","   '-LRB-',\n","   '3-3264',\n","   '-RRB-',\n","   '.'],\n","  ['you', 'know', 'that', 'both', \"o'neal\", 'and', 'matt', 'are', 'out', '?'],\n","  ['Game',\n","   'tonight',\n","   'at',\n","   '7',\n","   ',',\n","   'it',\n","   \"'s\",\n","   'time',\n","   'to',\n","   'kick',\n","   'some',\n","   'ass',\n","   '.'],\n","  ['i',\n","   'have',\n","   'not',\n","   'gotten',\n","   'a',\n","   'good',\n","   'response',\n","   'so',\n","   'i',\n","   'think',\n","   'shanna',\n","   'and',\n","   'i',\n","   'are',\n","   'going',\n","   'to',\n","   'stay',\n","   'in',\n","   'town',\n","   '.'],\n","  ['the',\n","   'weather',\n","   'is',\n","   'going',\n","   'to',\n","   'be',\n","   'fine',\n","   ',',\n","   'hector',\n","   'was',\n","   'just',\n","   'blowing',\n","   'smoke',\n","   '.'],\n","  ['Christa', 'Winfrey'],\n","  ['08/08/2000', '11:36', 'AM'],\n","  ['have', 'you', 'heard', 'from', 'anyone', '?'],\n","  ['also',\n","   ',',\n","   'what',\n","   \"'s\",\n","   'the',\n","   'deal',\n","   'with',\n","   'the',\n","   'weather',\n","   'this',\n","   'weekend',\n","   '?'],\n","  ['is', 'it', 'supposed', 'to', 'be', 'storming', '?'],\n","  ['by',\n","   'the',\n","   'way',\n","   ',',\n","   'buy',\n","   'it',\n","   'now',\n","   'b/c',\n","   'it',\n","   'is',\n","   'going',\n","   'to',\n","   '100',\n","   'by',\n","   'year',\n","   'end',\n","   '.'],\n","  ['Your',\n","   'father',\n","   'never',\n","   'listens',\n","   'to',\n","   'me',\n","   ',',\n","   'what',\n","   'can',\n","   'I',\n","   'say',\n","   '?'],\n","  ['But', ',', 'I', \"'m\", 'very', 'happy', 'for', 'you', '!'],\n","  ['How', 'are', 'you', '?'],\n","  ['Any', 'news', 'on', 'Aunt', 'Toni', '?'],\n","  ['LU'],\n","  ['-', 'M'],\n","  ['Mike', 'Jordan'],\n","  ['26/09/2000', '14:14'],\n","  ['Fernley', '/', 'Sally'],\n","  ['Off',\n","   'and',\n","   'on',\n","   '-LRB-',\n","   'with',\n","   'Jackie',\n","   'Gentle',\n","   \"'s\",\n","   'help',\n","   '-RRB-',\n","   'I',\n","   'have',\n","   'pulled',\n","   'together',\n","   'a',\n","   'one',\n","   'page',\n","   'communication',\n","   'note',\n","   'on',\n","   'our',\n","   'fundamental',\n","   'operating',\n","   'standards',\n","   '-LRB-',\n","   'itself',\n","   'a',\n","   'one',\n","   'page',\n","   'summary',\n","   '-RRB-',\n","   '.'],\n","  ['We',\n","   'are',\n","   'in',\n","   'the',\n","   'final',\n","   'stages',\n","   'of',\n","   'this',\n","   'process',\n","   '-',\n","   'where',\n","   'we',\n","   'draft',\n","   'a',\n","   'cover',\n","   'letter',\n","   'for',\n","   'John',\n","   'which',\n","   'will',\n","   'introduce',\n","   'this',\n","   'for',\n","   'inclusion',\n","   'within',\n","   'Globalflash',\n","   '-LRB-',\n","   'the',\n","   'Enron',\n","   'Europe',\n","   'newsletter',\n","   '-RRB-'],\n","  ['Have',\n","   'you',\n","   'any',\n","   'thoughts',\n","   'on',\n","   'draft',\n","   'or',\n","   'cover',\n","   'note',\n","   '?'],\n","  ['Mike'],\n","  ['Late', 'Jan', 'sounds', 'great', '.'],\n","  ['Meagan',\n","   'does',\n","   'have',\n","   'a',\n","   'couple',\n","   'of',\n","   'big',\n","   'things',\n","   'on',\n","   'the',\n","   'weekend',\n","   'in',\n","   'January',\n","   '--',\n","   'National',\n","   'Charity',\n","   'League',\n","   'Senior',\n","   'Presentation',\n","   '-LRB-',\n","   'big',\n","   'dance',\n","   'that',\n","   'she',\n","   'and',\n","   'I',\n","   'are',\n","   'committed',\n","   'to',\n","   'help',\n","   'with',\n","   '-RRB-',\n","   ',',\n","   'the',\n","   'Bearkadette',\n","   'Ball',\n","   'and',\n","   'a',\n","   'winter',\n","   'party',\n","   'for',\n","   'Cotillion',\n","   '.'],\n","  ['I',\n","   'believe',\n","   'that',\n","   'these',\n","   'are',\n","   'three',\n","   'weekends',\n","   'in',\n","   'a',\n","   'row',\n","   ',',\n","   'January',\n","   '6',\n","   ',',\n","   '13',\n","   'and',\n","   '20th',\n","   '.'],\n","  ['So',\n","   'the',\n","   'last',\n","   'weekend',\n","   'in',\n","   'January',\n","   'would',\n","   'work',\n","   'well',\n","   '-LRB-',\n","   'and',\n","   'I',\n","   'will',\n","   'need',\n","   'a',\n","   'rest',\n","   'from',\n","   'formal',\n","   'affairs',\n","   '!',\n","   '-RRB-',\n","   '.'],\n","  ['Does', 'that', 'work', 'for', 'you', '?'],\n","  ['And',\n","   'do',\n","   'you',\n","   'want',\n","   'to',\n","   'do',\n","   'it',\n","   'on',\n","   'a',\n","   'Saturday',\n","   'or',\n","   'Sunday',\n","   '?'],\n","  ['Saturday',\n","   'probably',\n","   'works',\n","   'better',\n","   'for',\n","   'me',\n","   ',',\n","   'just',\n","   'so',\n","   'that',\n","   'I',\n","   'am',\n","   'back',\n","   'in',\n","   'Houston',\n","   'and',\n","   'doing',\n","   'laundry',\n","   'by',\n","   'Sunday',\n","   'afternoon',\n","   '!!'],\n","  ['Hi', '...'],\n","  ['Talked', 'to', 'the', 'little', 'mother', '-', 'to', '-', 'be', '.'],\n","  ['She', 'said', 'a', 'shower', 'would', 'be', 'grand', '.'],\n","  ['She', 'has', 'some', 'big', 'presentation', 'mid-January', '.'],\n","  ['How', 'does', 'late', 'January', 'sound', 'to', 'you', '.'],\n","  ['Should', 'we', 'set', 'a', 'date', 'now', '?'],\n","  ['Am', 'I', 'turning', 'into', 'Mother', '?'],\n","  ['Cindy'],\n","  ['I',\n","   'think',\n","   'that',\n","   'it',\n","   'is',\n","   'a',\n","   'great',\n","   'idea',\n","   'to',\n","   'get',\n","   'some',\n","   'press',\n","   'regarding',\n","   'our',\n","   'fundamental',\n","   'operating',\n","   'standards',\n","   ',',\n","   'but',\n","   'I',\n","   'wonder',\n","   'about',\n","   'the',\n","   'most',\n","   'appropriate',\n","   'timing',\n","   ',',\n","   'enough',\n","   'of',\n","   'a',\n","   'global',\n","   'message',\n","   'and',\n","   'the',\n","   'means',\n","   'of',\n","   'delivery',\n","   '.'],\n","  ['On',\n","   'the',\n","   'means',\n","   'of',\n","   'delivery',\n","   ',',\n","   'I',\n","   'am',\n","   'not',\n","   'sure',\n","   'from',\n","   'your',\n","   'note',\n","   'whether',\n","   'or',\n","   'not',\n","   'I',\n","   'fully',\n","   'understand',\n","   'the',\n","   'intent',\n","   '.'],\n","  ['Is',\n","   'there',\n","   'an',\n","   'article',\n","   'to',\n","   'be',\n","   'included',\n","   'in',\n","   'an',\n","   'Enron',\n","   'publication',\n","   'and',\n","   'in',\n","   'addition',\n","   'a',\n","   'letter',\n","   'to',\n","   'be',\n","   'sent',\n","   'under',\n","   'John',\n","   \"'s\",\n","   'name',\n","   '-LRB-',\n","   'if',\n","   'so',\n","   ',',\n","   'to',\n","   'whom',\n","   'will',\n","   'the',\n","   'letter',\n","   'be',\n","   'sent',\n","   '-RRB-',\n","   '?'],\n","  ['Or',\n","   'is',\n","   'the',\n","   'letter',\n","   'from',\n","   'John',\n","   'an',\n","   'introduction',\n","   'to',\n","   'be',\n","   'included',\n","   'as',\n","   'a',\n","   'lead',\n","   'in',\n","   'to',\n","   'the',\n","   'article',\n","   '?'],\n","  ['With',\n","   'regard',\n","   'to',\n","   'a',\n","   'global',\n","   'message',\n","   ',',\n","   'I',\n","   'think',\n","   'that',\n","   'one',\n","   'of',\n","   'the',\n","   'key',\n","   'points',\n","   'around',\n","   'fundamental',\n","   'operating',\n","   'standards',\n","   'are',\n","   'that',\n","   'they',\n","   'are',\n","   'intended',\n","   'to',\n","   'be',\n","   'global',\n","   'in',\n","   'nature',\n","   ',',\n","   'applied',\n","   'to',\n","   'every',\n","   'commodity',\n","   'and',\n","   'every',\n","   'location',\n","   'where',\n","   'we',\n","   'engage',\n","   'in',\n","   'trading',\n","   'activities',\n","   '.'],\n","  ['With',\n","   'these',\n","   'operating',\n","   'standards',\n","   'implemented',\n","   'worldwide',\n","   ',',\n","   'we',\n","   'will',\n","   'know',\n","   'as',\n","   'operations',\n","   'professionals',\n","   'that',\n","   'risk',\n","   'is',\n","   'being',\n","   'mitigated',\n","   'and',\n","   'we',\n","   'will',\n","   'be',\n","   'able',\n","   'to',\n","   'ensure',\n","   'Enron',\n","   'top',\n","   'management',\n","   'that',\n","   'there',\n","   'is',\n","   'consistency',\n","   'in',\n","   'operating',\n","   'standards',\n","   'worldwide',\n","   '.'],\n","  ['These',\n","   'global',\n","   'standards',\n","   'also',\n","   'should',\n","   'enable',\n","   'Enron',\n","   'to',\n","   'expand',\n","   'its',\n","   'business',\n","   'reach',\n","   'more',\n","   'quickly',\n","   ',',\n","   'with',\n","   'well',\n","   'defined',\n","   'requirements',\n","   'with',\n","   'regard',\n","   'to',\n","   'trading',\n","   'operations',\n","   '.'],\n","  ['I',\n","   'am',\n","   'not',\n","   'sure',\n","   'from',\n","   'the',\n","   'article',\n","   'as',\n","   'written',\n","   'that',\n","   'the',\n","   'global',\n","   'nature',\n","   'of',\n","   'this',\n","   'effort',\n","   'comes',\n","   'across',\n","   '.'],\n","  ['Finally', ',', 'a', 'question', 'regarding', 'timing', '.'],\n","  ['The',\n","   'last',\n","   'I',\n","   'knew',\n","   'after',\n","   'you',\n","   'and',\n","   'Brent',\n","   'drafted',\n","   'this',\n","   'starting',\n","   'point',\n","   'for',\n","   'fundamental',\n","   'operating',\n","   'standards',\n","   'was',\n","   'that',\n","   'this',\n","   'was',\n","   'being',\n","   'circulated',\n","   '-LRB-',\n","   'Shona',\n","   'took',\n","   'this',\n","   'to',\n","   'do',\n","   'after',\n","   'Brent',\n","   \"'s\",\n","   'return',\n","   'to',\n","   'Houston',\n","   '-RRB-',\n","   'for',\n","   'comments',\n","   'to',\n","   'all',\n","   'business',\n","   'controllers',\n","   '.'],\n","  ['I',\n","   'do',\n","   \"n't\",\n","   'believe',\n","   'that',\n","   'we',\n","   'are',\n","   'quite',\n","   'at',\n","   'the',\n","   'point',\n","   'that',\n","   'we',\n","   'can',\n","   'say',\n","   'that',\n","   'all',\n","   'business',\n","   'controllers',\n","   'worldwide',\n","   'have',\n","   'reviewed',\n","   ',',\n","   'understand',\n","   'and',\n","   'have',\n","   'implemented',\n","   'these',\n","   'standards',\n","   '.'],\n","  ['And',\n","   'not',\n","   'to',\n","   'belittle',\n","   'the',\n","   'process',\n","   'of',\n","   'creating',\n","   'the',\n","   'standards',\n","   ',',\n","   'the',\n","   'tough',\n","   'part',\n","   '-LRB-',\n","   'and',\n","   'the',\n","   'real',\n","   'meat',\n","   'behind',\n","   'this',\n","   '-RRB-',\n","   'will',\n","   'be',\n","   'an',\n","   'effective',\n","   'exception',\n","   'report',\n","   'on',\n","   'a',\n","   'global',\n","   'basis',\n","   'against',\n","   'these',\n","   'standards',\n","   '.'],\n","  ['My',\n","   'commitment',\n","   'to',\n","   'Rick',\n","   'Causey',\n","   'is',\n","   'that',\n","   'I',\n","   'will',\n","   'have',\n","   'that',\n","   'global',\n","   'report',\n","   'in',\n","   'production',\n","   'by',\n","   'the',\n","   'end',\n","   'of',\n","   'the',\n","   'year',\n","   '.'],\n","  ['There',\n","   'is',\n","   'much',\n","   'work',\n","   'to',\n","   'do',\n","   'in',\n","   'defining',\n","   'the',\n","   'content',\n","   'and',\n","   'regularity',\n","   'of',\n","   'the',\n","   'report',\n","   'and',\n","   'even',\n","   'more',\n","   'work',\n","   'to',\n","   'do',\n","   'to',\n","   'identify',\n","   'reliable',\n","   'sources',\n","   'of',\n","   'data',\n","   'for',\n","   'compiling',\n","   'the',\n","   'report',\n","   '.'],\n","  ['Shona',\n","   'has',\n","   'commissioned',\n","   'Mike',\n","   'Moscoso',\n","   'to',\n","   'work',\n","   'on',\n","   'this',\n","   ',',\n","   'and',\n","   'I',\n","   'believe',\n","   'that',\n","   'Mike',\n","   'has',\n","   'already',\n","   'been',\n","   'working',\n","   'with',\n","   'James',\n","   'New',\n","   '.'],\n","  ['So',\n","   'I',\n","   'question',\n","   'whether',\n","   'or',\n","   'not',\n","   'you',\n","   'want',\n","   'to',\n","   'publish',\n","   'info',\n","   'about',\n","   'fundamental',\n","   'standards',\n","   'that',\n","   'we',\n","   'can',\n","   'not',\n","   'yet',\n","   'report',\n","   'against',\n","   '.'],\n","  ['Would',\n","   'a',\n","   'more',\n","   'appropriate',\n","   'time',\n","   'be',\n","   'after',\n","   'the',\n","   'Global',\n","   'Operations',\n","   'Controller',\n","   'meeting',\n","   'in',\n","   'October',\n","   'when',\n","   'we',\n","   'should',\n","   'have',\n","   'worldwide',\n","   'buy',\n","   '-',\n","   'in',\n","   'and',\n","   'commitment',\n","   'to',\n","   'these',\n","   'standards',\n","   'and',\n","   '-LRB-',\n","   'hopefully',\n","   '-RRB-',\n","   'our',\n","   'first',\n","   'draft',\n","   'of',\n","   'a',\n","   'meaningful',\n","   'exception',\n","   'report',\n","   '?'],\n","  ['Sorry', 'that', 'this', 'response', 'looks', 'so', 'long', '.'],\n","  ['I',\n","   'have',\n","   'been',\n","   'interrupted',\n","   '20',\n","   'times',\n","   'while',\n","   'responding',\n","   ',',\n","   'so',\n","   'I',\n","   'hope',\n","   'that',\n","   'it',\n","   'makes',\n","   'sense',\n","   '.'],\n","  ['Thanks', 'for', 'sharing', 'this', 'with', 'me', '.'],\n","  ['Since',\n","   'you',\n","   'asked',\n","   'for',\n","   'input',\n","   ',',\n","   'I',\n","   'hope',\n","   'that',\n","   'you',\n","   'do',\n","   \"n't\",\n","   'mind',\n","   'that',\n","   'I',\n","   'gave',\n","   'you',\n","   'some',\n","   '.'],\n","  ['--', 'Sally'],\n","  ['Mike', 'Jordan'],\n","  ['04/04/2001', '09:27', 'AM'],\n","  ['Please',\n","   'find',\n","   'attached',\n","   'the',\n","   'most',\n","   'recent',\n","   'update',\n","   'for',\n","   'Merchanting',\n","   'Metals',\n","   '.'],\n","  ['In',\n","   'summary',\n","   'the',\n","   'planned',\n","   'systems',\n","   'changes',\n","   'and',\n","   'manual',\n","   'substantiation',\n","   'efforts',\n","   'are',\n","   'behind',\n","   'schedule',\n","   '.'],\n","  ['Additional',\n","   'resources',\n","   'are',\n","   'being',\n","   'allocated',\n","   'and',\n","   'the',\n","   'situation',\n","   'is',\n","   'being',\n","   'closely',\n","   'monitored',\n","   '-LRB-',\n","   'both',\n","   'for',\n","   'quarter',\n","   'end',\n","   'signoff',\n","   'and',\n","   'going',\n","   'operations',\n","   '-RRB-',\n","   '.'],\n","  ['Please',\n","   'contact',\n","   'me',\n","   'if',\n","   'you',\n","   'require',\n","   'any',\n","   'additional',\n","   'information'],\n","  ['Mike'],\n","  ['Mike', 'Jordan'],\n","  ['03/04/2001', '16:29'],\n","  ['The',\n","   'intention',\n","   'of',\n","   'the',\n","   'efforts',\n","   'and',\n","   'actions',\n","   'documented',\n","   'in',\n","   'my',\n","   'earlier',\n","   'update',\n","   '-LRB-',\n","   'see',\n","   'attached',\n","   'email',\n","   '-RRB-',\n","   'was',\n","   'to',\n","   'provide',\n","   'a',\n","   'robust',\n","   'position',\n","   'signoff',\n","   'process',\n","   'for',\n","   'total',\n","   'metal',\n","   'tonnage',\n","   ',',\n","   'spread',\n","   'and',\n","   'brand',\n","   'and',\n","   'location',\n","   'a',\n","   'timely',\n","   'substantiation',\n","   'of',\n","   'stock',\n","   'on',\n","   'balance',\n","   'sheet',\n","   'forward',\n","   'MTM',\n","   'debtors',\n","   'and',\n","   'creditor',\n","   'balances',\n","   'OBSF',\n","   'transactional',\n","   'values',\n","   'and',\n","   'a',\n","   'reconciliation',\n","   'of',\n","   'the',\n","   'barclays',\n","   'intercompany',\n","   'account'],\n","  ['Despite',\n","   'the',\n","   'best',\n","   'efforts',\n","   'of',\n","   'IT',\n","   ',',\n","   'continuing',\n","   'problems',\n","   'with',\n","   'the',\n","   'AS400',\n","   'application',\n","   ',',\n","   'a',\n","   'better',\n","   'understanding',\n","   'of',\n","   'the',\n","   'inconsistency',\n","   'between',\n","   'stock',\n","   'reconciliation',\n","   'reports',\n","   ',',\n","   'and',\n","   'concerns',\n","   'over',\n","   'the',\n","   'useability',\n","   'of',\n","   'the',\n","   'outright',\n","   'stock',\n","   'screen',\n","   'enquiry',\n","   'are',\n","   'such',\n","   'that',\n","   'I',\n","   'am',\n","   'currently',\n","   'not',\n","   'confident',\n","   'of',\n","   'delivering',\n","   'sufficient',\n","   'accurate',\n","   'information',\n","   'to',\n","   'AA',\n","   'to',\n","   'satisfy',\n","   'their',\n","   'audit',\n","   'requirements',\n","   '-',\n","   'which',\n","   'at',\n","   'a',\n","   'macro',\n","   'level',\n","   'is',\n","   'the',\n","   'transparent',\n","   'audit',\n","   'trail',\n","   'between',\n","   'stock',\n","   'and',\n","   'forward',\n","   'positions',\n","   'to',\n","   'full',\n","   'accounting',\n","   'values',\n","   '.'],\n","  ['Consequently',\n","   'I',\n","   'need',\n","   'to',\n","   'inform',\n","   'you',\n","   'of',\n","   ',',\n","   'and',\n","   '/',\n","   'or',\n","   'require',\n","   'your',\n","   'approval',\n","   'for',\n","   ',',\n","   'the',\n","   'following',\n","   ':'],\n","  ['I', 'will', 'discuss', 'with', 'AA', 'the', 'following'],\n","  ['that',\n","   'OBSF',\n","   'values',\n","   'within',\n","   'the',\n","   'extended',\n","   'trial',\n","   'balance',\n","   'may',\n","   'be',\n","   'misstated',\n","   'due',\n","   'to',\n","   'data',\n","   'issues',\n","   '-LRB-',\n","   'above',\n","   'and',\n","   'beyond',\n","   'existing',\n","   'conversations',\n","   'with',\n","   'AA',\n","   'on',\n","   'model',\n","   'simplifications',\n","   '-RRB-'],\n","  ['that',\n","   'there',\n","   'are',\n","   'reconciling',\n","   'differences',\n","   'between',\n","   'trader',\n","   'position',\n","   'analyses',\n","   ',',\n","   'AS400',\n","   'on',\n","   'screen',\n","   'enquiries',\n","   'and',\n","   'the',\n","   'formal',\n","   'global',\n","   'position',\n","   'report',\n","   '-LRB-',\n","   'these',\n","   'differences',\n","   'are',\n","   'at',\n","   'present',\n","   'not',\n","   'understood',\n","   'but',\n","   'would',\n","   'need',\n","   'to',\n","   'be',\n","   'provided',\n","   'to',\n","   'AA',\n","   'within',\n","   'the',\n","   'audit',\n","   'timetable',\n","   '-RRB-'],\n","  ['an',\n","   'outline',\n","   'of',\n","   'the',\n","   'internal',\n","   'balance',\n","   'sheet',\n","   'review',\n","   'process',\n","   'described',\n","   'in',\n","   'my',\n","   'earlier',\n","   'note',\n","   'which',\n","   'must',\n","   'now',\n","   'be',\n","   'reprioritised',\n","   'and',\n","   'rescoped',\n","   '-LRB-',\n","   'see',\n","   'MO',\n","   'work',\n","   '-RRB-'],\n","  ['The',\n","   'creation',\n","   'of',\n","   'an',\n","   'incentive',\n","   'payment',\n","   'pool',\n","   '-LRB-',\n","   'possibly',\n","   'via',\n","   'personal',\n","   'best',\n","   'awards',\n","   '-RRB-',\n","   'for',\n","   'key',\n","   'Metals',\n","   'staff',\n","   'who',\n","   'continue',\n","   'to',\n","   'work',\n","   'exceptionally',\n","   'unsociable',\n","   'hours',\n","   'to',\n","   'meet',\n","   'the',\n","   'above',\n","   'stated',\n","   'objectives'],\n","  ['The',\n","   'signoff',\n","   'for',\n","   'additional',\n","   'permanent',\n","   \"'\",\n","   'Enron',\n","   \"'\",\n","   'headcount',\n","   'who',\n","   'will',\n","   \"'\",\n","   'duplicate',\n","   \"'\",\n","   'certain',\n","   'key',\n","   'position',\n","   'control',\n","   'processes',\n","   'ultimately',\n","   'replacing',\n","   'some',\n","   'existing',\n","   'Traffic',\n","   'staff'],\n","  ['A',\n","   'reconciling',\n","   'difference',\n","   'of',\n","   '$',\n","   '15',\n","   'mm',\n","   'exists',\n","   'between',\n","   'the',\n","   'reported',\n","   'DPR',\n","   'and',\n","   'the',\n","   'final',\n","   'accounting',\n","   'p&l',\n","   'as',\n","   'generated',\n","   'on',\n","   'the',\n","   'AS400',\n","   '.'],\n","  ['We',\n","   'will',\n","   'continue',\n","   'to',\n","   'investigate',\n","   'potential',\n","   'misstatements',\n","   'in',\n","   'the',\n","   'system',\n","   'p&l',\n","   ',',\n","   'as',\n","   'a',\n","   'result',\n","   'of',\n","   'data',\n","   'or',\n","   'system',\n","   'valuation',\n","   'problems',\n","   ',',\n","   'within',\n","   'the',\n","   'month',\n","   'end',\n","   'reporting',\n","   'timeframe',\n","   '.'],\n","  ['However',\n","   ',',\n","   'this',\n","   'difference',\n","   'may',\n","   'need',\n","   'to',\n","   'be',\n","   'adjusted',\n","   'for',\n","   'following',\n","   'a',\n","   'final',\n","   'review',\n","   'and',\n","   'signoff',\n","   'of',\n","   'system',\n","   'p&l',\n","   'values',\n","   'with',\n","   'traders',\n","   '.'],\n","  ['The',\n","   'recall',\n","   'of',\n","   'all',\n","   'OBSF',\n","   'stock',\n","   'in',\n","   'early',\n","   'April',\n","   'and',\n","   'retention',\n","   'on',\n","   'balance',\n","   'sheet',\n","   '-LRB-',\n","   'reduced',\n","   'where',\n","   'economically',\n","   'viable',\n","   '-RRB-',\n","   'until',\n","   'positions',\n","   'are',\n","   'fully',\n","   'reconciled',\n","   'and',\n","   'repeatable',\n","   'daily',\n","   'signoff',\n","   'process',\n","   'can',\n","   'be',\n","   'instigated',\n","   '.'],\n","  ['Middle', 'Office', 'work', 'being', 'prioritised', 'is', 'as', 'follows'],\n","  ['the',\n","   'stock',\n","   'circularisation',\n","   'initiated',\n","   'for',\n","   'close',\n","   'of',\n","   'business',\n","   '23rd',\n","   '-',\n","   'with',\n","   'full',\n","   'reconciliation',\n","   'of',\n","   'returns',\n","   'to',\n","   'current',\n","   'system',\n","   'data',\n","   'by',\n","   'traffic',\n","   '/',\n","   'co-ordination',\n","   'an',\n","   'audit',\n","   'of',\n","   'the',\n","   'stock',\n","   'and',\n","   'forward',\n","   'valuation',\n","   'report',\n","   'for',\n","   'the',\n","   '30th',\n","   '-LRB-',\n","   'replacing',\n","   'planned',\n","   '23rd',\n","   'review',\n","   'due',\n","   'to',\n","   'system',\n","   'issues',\n","   '-RRB-',\n","   ',',\n","   'requiring',\n","   'full',\n","   'download',\n","   'of',\n","   'contract',\n","   'detail',\n","   'for',\n","   'later',\n","   'reference'],\n","  ['reconciliation',\n","   'of',\n","   'stock',\n","   'movements',\n","   'between',\n","   '23rd',\n","   'and',\n","   '30th',\n","   'sample',\n","   'tests',\n","   'of',\n","   'vanilla',\n","   'forward',\n","   'transactions'],\n","  ['detailed',\n","   'position',\n","   'analysis',\n","   'of',\n","   'all',\n","   'OBSF',\n","   'contracts',\n","   'that',\n","   'must',\n","   'be',\n","   'reconciled',\n","   'to',\n","   'Barclays',\n","   'documentation'],\n","  ['spreadsheet',\n","   'recalculation',\n","   'of',\n","   'OBSF',\n","   'option',\n","   'premium',\n","   'utilising',\n","   'the',\n","   'above',\n","   'manually',\n","   'created',\n","   'position',\n","   'analysis'],\n","  ['the',\n","   'circularisation',\n","   'of',\n","   'Barclays',\n","   'intercompany',\n","   'account',\n","   'and',\n","   'comparison',\n","   'to',\n","   'our',\n","   'cut',\n","   'off',\n","   'and',\n","   'substantiation',\n","   'analysis'],\n","  ['the',\n","   'debtors',\n","   '/',\n","   'creditors',\n","   'partial',\n","   'circularisation',\n","   'initiated',\n","   'for',\n","   'close',\n","   'of',\n","   'business',\n","   '23rd'],\n","  ['I',\n","   'will',\n","   'be',\n","   'in',\n","   'touch',\n","   'directly',\n","   're',\n","   'the',\n","   'items',\n","   'needing',\n","   'approval'],\n","  ['Regards'],\n","  ['Mike'],\n","  ['Mike', 'Jordan'],\n","  ['21/03/2001', '18:20'],\n","  ['Several',\n","   'related',\n","   'issues',\n","   'have',\n","   'resulted',\n","   'in',\n","   'an',\n","   'increase',\n","   'in',\n","   'the',\n","   'level',\n","   'of',\n","   'operating',\n","   'risk',\n","   'for',\n","   'the',\n","   'Merchanting',\n","   'Metals',\n","   'business',\n","   '.'],\n","  ['Complexities',\n","   'surrounding',\n","   'the',\n","   'operation',\n","   'of',\n","   'the',\n","   'Off',\n","   'Balance',\n","   'Sheet',\n","   'Facility',\n","   '-LRB-',\n","   '\"',\n","   'OBSF',\n","   '\"',\n","   '-RRB-',\n","   'which',\n","   'commenced',\n","   'two',\n","   'weeks',\n","   'before',\n","   'the',\n","   'year',\n","   'end',\n","   '.'],\n","  ['The',\n","   'uncertainty',\n","   'generated',\n","   'by',\n","   'the',\n","   'revocation',\n","   'of',\n","   'AA',\n","   \"'s\",\n","   'signoff',\n","   'for',\n","   'the',\n","   'facility',\n","   'late',\n","   'in',\n","   'the',\n","   'year',\n","   'end',\n","   'audit',\n","   '.'],\n","  ['The',\n","   'discovery',\n","   'of',\n","   'a',\n","   'number',\n","   'of',\n","   \"'\",\n","   'bugs',\n","   \"'\",\n","   'within',\n","   'the',\n","   'AS400',\n","   'Merchanting',\n","   'code',\n","   ',',\n","   'arising',\n","   'from',\n","   'the',\n","   'release',\n","   'of',\n","   'OBSF',\n","   'designed',\n","   'functionality',\n","   ',',\n","   'which',\n","   'compounded',\n","   'the',\n","   'operational',\n","   'burden',\n","   'of',\n","   'supporting',\n","   'the',\n","   'OBSF',\n","   '.'],\n","  ['The',\n","   'requirement',\n","   'to',\n","   'amend',\n","   'the',\n","   'operational',\n","   'process',\n","   'and',\n","   'OBSF',\n","   'IT',\n","   'code',\n","   'as',\n","   'a',\n","   'result',\n","   'of',\n","   'the',\n","   'current',\n","   'renegotiation',\n","   'of',\n","   'the',\n","   'OBSF',\n","   'with',\n","   'Barclays',\n","   '-LRB-',\n","   'and',\n","   'AA',\n","   '-RRB-',\n","   '.'],\n","  ['The',\n","   'senior',\n","   'IT',\n","   'developer',\n","   'for',\n","   'Merchanting',\n","   'has',\n","   'resigned',\n","   'and',\n","   'been',\n","   'sent',\n","   'on',\n","   'gardening',\n","   'leave',\n","   '.'],\n","  ['The',\n","   'Corporate',\n","   'requirement',\n","   'to',\n","   'lower',\n","   'working',\n","   'capital',\n","   'usage',\n","   'for',\n","   'the',\n","   'Merchanting',\n","   'business',\n","   'irrespective',\n","   'of',\n","   'the',\n","   'above',\n","   'parochial',\n","   'business',\n","   'issues',\n","   '.'],\n","  ['Various',\n","   'mitigating',\n","   'actions',\n","   'have',\n","   'been',\n","   'and',\n","   'will',\n","   'be',\n","   'taken',\n","   'to',\n","   'provide',\n","   'focus',\n","   ',',\n","   'gain',\n","   'comfort',\n","   'over',\n","   'control',\n","   'levels',\n","   'and',\n","   'to',\n","   'provide',\n","   'assurance',\n","   'to',\n","   'senior',\n","   'management',\n","   'as',\n","   'to',\n","   'the',\n","   'accuracy',\n","   'of',\n","   'the',\n","   'Q1',\n","   'DPR',\n","   'and',\n","   'business',\n","   'balance',\n","   'sheet',\n","   '.'],\n","  ['The',\n","   'implementation',\n","   'for',\n","   'SAP',\n","   'for',\n","   'the',\n","   'Merchanting',\n","   'business',\n","   'has',\n","   'been',\n","   'delayed',\n","   'and',\n","   'effectively',\n","   'decoupled',\n","   'from',\n","   'the',\n","   'higher',\n","   'risk',\n","   '-LRB-',\n","   'higher',\n","   'benefit',\n","   '-RRB-',\n","   'Brokerage',\n","   'implementation',\n","   '-',\n","   'benefit',\n","   'is',\n","   'to',\n","   'provide',\n","   'sole',\n","   'focus',\n","   'on',\n","   'OBSF',\n","   'for',\n","   'IT',\n","   'Merchanting',\n","   'developers',\n","   '.'],\n","  ['The',\n","   'AR',\n","   '/',\n","   'AP',\n","   'SAP',\n","   'data',\n","   'quality',\n","   'reviews',\n","   'for',\n","   'both',\n","   'businesses',\n","   'are',\n","   'continuing',\n","   'so',\n","   'as',\n","   'to',\n","   'provide',\n","   'a',\n","   'detailed',\n","   'analysis',\n","   'as',\n","   'at',\n","   'end',\n","   'Q1',\n","   '.'],\n","  ['Middle',\n","   'Office',\n","   'have',\n","   'instigated',\n","   'a',\n","   'new',\n","   'daily',\n","   'working',\n","   'capital',\n","   'report',\n","   'process',\n","   'tracking',\n","   'cash',\n","   'settlement',\n","   '/',\n","   'funding',\n","   'data',\n","   'to',\n","   'working',\n","   'capital',\n","   'components',\n","   'for',\n","   'all',\n","   'Metals',\n","   'businesses',\n","   '.'],\n","  ['An',\n","   'enhanced',\n","   'position',\n","   'signoff',\n","   'process',\n","   'will',\n","   'be',\n","   'implemented',\n","   'prior',\n","   'to',\n","   'end',\n","   'Q1',\n","   'covering',\n","   'gross',\n","   'tonnage',\n","   ',',\n","   'spread',\n","   'positions',\n","   'and',\n","   'summarised',\n","   'analyses',\n","   'for',\n","   'brand',\n","   'and',\n","   'locations',\n","   '.'],\n","  ['The',\n","   'necessary',\n","   'report',\n","   'functionality',\n","   'should',\n","   'be',\n","   'available',\n","   'within',\n","   'the',\n","   'AS400',\n","   ',',\n","   'however',\n","   'contingencies',\n","   'have',\n","   'been',\n","   'initiated',\n","   'to',\n","   'build',\n","   'tactical',\n","   'VBA',\n","   '/',\n","   'excel',\n","   'reports',\n","   'outside',\n","   'of',\n","   'the',\n","   'AS400',\n","   'but',\n","   'using',\n","   'AS400',\n","   'data',\n","   'downloads',\n","   '.'],\n","  ['User',\n","   'requests',\n","   'for',\n","   'additional',\n","   'AS400',\n","   'functionality',\n","   'and',\n","   'reports',\n","   'have',\n","   'been',\n","   'aggressively',\n","   'prioritised',\n","   'and',\n","   'a',\n","   'code',\n","   'freeze',\n","   'will',\n","   'commence',\n","   'prior',\n","   'to',\n","   'the',\n","   'end',\n","   'of',\n","   'Q1',\n","   'following',\n","   'the',\n","   'delivery',\n","   'of',\n","   'three',\n","   'reports',\n","   'determined',\n","   'as',\n","   'minimum',\n","   'requirements',\n","   'for',\n","   'the',\n","   'support',\n","   'of',\n","   'OBSF',\n","   '.'],\n","  ['A',\n","   'resubstantiation',\n","   'of',\n","   'the',\n","   'full',\n","   'Q1',\n","   'DPR',\n","   'will',\n","   'be',\n","   'completed',\n","   'by',\n","   'the',\n","   'Risk',\n","   'control',\n","   'staff',\n","   'reconciling',\n","   'the',\n","   'full',\n","   'trial',\n","   'balances',\n","   'between',\n","   'Q1',\n","   'open',\n","   'and',\n","   'Q1',\n","   'close'],\n","  ['A',\n","   'full',\n","   'internal',\n","   'balance',\n","   'sheet',\n","   'review',\n","   'will',\n","   'be',\n","   'completed',\n","   'within',\n","   'the',\n","   'Q1',\n","   'audit',\n","   'timetable',\n","   'which',\n","   'incorporates'],\n","  ['A',\n","   'full',\n","   'circularisation',\n","   'of',\n","   'inventory',\n","   'balances',\n","   ',',\n","   'and',\n","   'matching',\n","   'to',\n","   'source',\n","   'documentation',\n","   'within',\n","   'Enron'],\n","  ['Inspection',\n","   'of',\n","   'certain',\n","   'of',\n","   'the',\n","   'above',\n","   'inventory',\n","   'balances',\n","   ',',\n","   'by',\n","   'third',\n","   'party',\n","   'inspectors',\n","   ',',\n","   'where',\n","   'there',\n","   'is',\n","   'an',\n","   'expectation',\n","   'that',\n","   'circularisation',\n","   'replies',\n","   'will',\n","   'not',\n","   'be',\n","   'received',\n","   'on',\n","   'a',\n","   'timely',\n","   'basis'],\n","  ['Substantive',\n","   'checks',\n","   'back',\n","   'to',\n","   'source',\n","   'contract',\n","   'documentation',\n","   'for',\n","   'the',\n","   'forward',\n","   'priced',\n","   'and',\n","   'unpriced',\n","   'positions',\n","   'report',\n","   '-LRB-',\n","   'spot',\n","   'checking',\n","   'the',\n","   'key',\n","   'position',\n","   'report',\n","   'signed',\n","   'off',\n","   'by',\n","   'the',\n","   'traders',\n","   '-RRB-'],\n","  ['Full',\n","   'reconciliation',\n","   'and',\n","   'recalculation',\n","   'of',\n","   'OBSF',\n","   'option',\n","   'premium',\n","   'values'],\n","  ['Full',\n","   'reconciliation',\n","   'of',\n","   'contracts',\n","   'within',\n","   'the',\n","   'OBSF',\n","   'to',\n","   'Barclays',\n","   'documentation',\n","   '-LRB-',\n","   'thereby',\n","   'substantiating',\n","   'existence',\n","   'of',\n","   'stock',\n","   'that',\n","   'we',\n","   'have',\n","   'option',\n","   'to',\n","   'purchase',\n","   '-RRB-',\n","   'and',\n","   'to',\n","   'AS400',\n","   'Barclays',\n","   'account'],\n","  ['A',\n","   'risk',\n","   'based',\n","   'debtors',\n","   'review',\n","   '-',\n","   'matching',\n","   'to',\n","   'source',\n","   'documentation',\n","   ',',\n","   'where',\n","   'applicable',\n","   ',',\n","   'and',\n","   'any',\n","   'subsequent',\n","   'post',\n","   'quarter',\n","   'end',\n","   'cash',\n","   'movements'],\n","  ['A',\n","   'full',\n","   'substantiation',\n","   'of',\n","   'creditors',\n","   'to',\n","   'internal',\n","   '-LRB-',\n","   'contract',\n","   'commitments',\n","   '-RRB-',\n","   'or',\n","   'external',\n","   'documentation',\n","   '-LRB-',\n","   'invoices',\n","   '/',\n","   'request',\n","   'for',\n","   'payment',\n","   '-RRB-'],\n","  ['A', 'full', 'reconciliation', 'of', 'intercompany', 'accounts'],\n","  ['A',\n","   'full',\n","   'substantive',\n","   'reconciliation',\n","   'of',\n","   'cash',\n","   'and',\n","   'funding',\n","   'accounts'],\n","  ['I',\n","   'intend',\n","   'to',\n","   'provide',\n","   'weekly',\n","   'updates',\n","   'on',\n","   'the',\n","   'status',\n","   'of',\n","   'the',\n","   'above',\n","   'actions',\n","   'during',\n","   'April'],\n","  ['If',\n","   'you',\n","   'have',\n","   'any',\n","   'questions',\n","   'please',\n","   'call',\n","   'me',\n","   'on',\n","   'x34703'],\n","  ['Regards'],\n","  ['Mike'],\n","  ['I',\n","   \"'m\",\n","   'handling',\n","   'the',\n","   'afternoon',\n","   '--',\n","   'I',\n","   'think',\n","   'that',\n","   'Harry',\n","   'has',\n","   'this',\n","   'morning',\n","   '.'],\n","  ['MHC'],\n","  ['Can', 'you', 'cover', 'for', 'me', 'today', '?'],\n","  ['I', 'am', 'in', 'mediation', '.'],\n","  ['I',\n","   'left',\n","   'a',\n","   'voicemail',\n","   'for',\n","   'Sharon',\n","   'Butcher',\n","   ',',\n","   'as',\n","   'well',\n","   ',',\n","   'just',\n","   'to',\n","   'make',\n","   'sure',\n","   'it',\n","   'is',\n","   'handled',\n","   '.'],\n","  ['My', 'schedule', 'shows', 'an', 'afternoon', 'session', '.'],\n","  ['Do', 'we', 'have', '2', 'sessions', 'today', '?'],\n","  ['If', 'so', ',', 'you', 'may', 'want', 'to', 'split', 'and', 'cover', '.'],\n","  ['Thanks', 'a', 'ton', '.'],\n","  ['I', 'will', 'take', 'you', 'next', 'one', 'in', 'August', '.'],\n","  ['Thanks', ','],\n","  ['Kriste'],\n","  ['Kriste',\n","   'K.',\n","   'Sullivan',\n","   'Enron',\n","   'Corp.',\n","   '-',\n","   'Legal',\n","   'EB',\n","   '4861',\n","   '-LRB-',\n","   '713',\n","   '-RRB-',\n","   '853-7557',\n","   'Phone',\n","   '-LRB-',\n","   '713',\n","   '-RRB-',\n","   '646-5847',\n","   'Fax'],\n","  ['I', 'got', 'this', '.'],\n","  ['I', 'assume', 'this', 'is', '12:30', 'Central', 'Time', '?'],\n","  ['When',\n","   ':',\n","   'Wednesday',\n","   ',',\n","   'September',\n","   '19',\n","   ',',\n","   '2001',\n","   '10:30',\n","   'AM',\n","   '-',\n","   '11:30',\n","   'AM',\n","   '-LRB-',\n","   'GMT',\n","   '-',\n","   '08:00',\n","   '-RRB-',\n","   'Pacific',\n","   'Time',\n","   '-LRB-',\n","   'US',\n","   '&',\n","   'Canada',\n","   '-RRB-',\n","   ';',\n","   'Tijuana',\n","   '.'],\n","  ['Where', ':', 'Conf.', 'Call'],\n","  ['*~*~*~*~*~*~*~*~*~*'],\n","  ['10:30', '-', '11:30', 'PST'],\n","  ['Call', '-', 'in', '#', ':', '800/711-8000'],\n","  ['Passcode', ':', '4153030'],\n","  ['Here',\n","   'is',\n","   'the',\n","   'overview',\n","   'of',\n","   'Bob',\n","   'Henderson',\n","   \"'s\",\n","   'Employment',\n","   'Agreement',\n","   '.'],\n","  ['What', 'do', 'you', 'think', '?'],\n","  ['MHC'],\n","  ['Michelle', ',', 'please', 'comment', '.'],\n","  ['Please',\n","   'send',\n","   'me',\n","   'an',\n","   'email',\n","   'response',\n","   'about',\n","   'whether',\n","   'you',\n","   'and',\n","   'Michelle',\n","   'Cash',\n","   'are',\n","   'OK',\n","   'with',\n","   'what',\n","   'he',\n","   \"'s\",\n","   'written',\n","   '.'],\n","  ['After', 'that', ',', 'what', 'do', 'we', 'do', '?'],\n","  ['Brad'],\n","  ['After',\n","   'a',\n","   'conversation',\n","   'with',\n","   'Ryan',\n","   'Seleznov',\n","   'I',\n","   'herewith',\n","   'like',\n","   'disclose',\n","   'in',\n","   'writing',\n","   'my',\n","   'intentions',\n","   'in',\n","   'respect',\n","   'to',\n","   'Dealbench',\n","   '.'],\n","  ['Please', 'see', 'attached', 'Word', 'file'],\n","  ['Best', 'regards'],\n","  ['Tobias', 'Munk'],\n","  ['Please', 'see', 'the', 'attached', '.'],\n","  ['Teresa'],\n","  ['Please',\n","   'send',\n","   'David',\n","   'Lund',\n","   'copies',\n","   'of',\n","   'our',\n","   'standard',\n","   'corporate',\n","   'services',\n","   'agreement',\n","   'and',\n","   'the',\n","   'standard',\n","   'assignment',\n","   'letter',\n","   '-LRB-',\n","   'use',\n","   'Bridgeline',\n","   'example',\n","   '--',\n","   'with',\n","   'and',\n","   'without',\n","   'non-compete',\n","   '-RRB-',\n","   '.'],\n","  ['Michelle'],\n","  ['We',\n","   \"'re\",\n","   'formatting',\n","   'one',\n","   'this',\n","   'week',\n","   ',',\n","   'and',\n","   'we',\n","   \"'ll\",\n","   'send',\n","   'it',\n","   'when',\n","   'it',\n","   \"'s\",\n","   'done',\n","   '.'],\n","  ['Michelle'],\n","  ['Thanks', 'very', 'much', '.'],\n","  ['Do', 'you', 'also', 'have', 'a', 'SSD', 'we', 'can', 'use', '?'],\n","  ['Jane'],\n","  ['<<',\n","   'File',\n","   ':',\n","   'Services.doc',\n","   '>>',\n","   '<<',\n","   'File',\n","   ':',\n","   'Services.DOC',\n","   '>>'],\n","  ['Here', 'are', 'the', 'sample', 'Agreements', '.'],\n","  ['Please',\n","   'let',\n","   'us',\n","   'know',\n","   'if',\n","   'you',\n","   'need',\n","   'anything',\n","   'else',\n","   '.'],\n","  ['Thanks', '.'],\n","  ['Diane', 'Goode', 'Senior', 'Specialist'],\n","  ['I',\n","   'agree',\n","   'also',\n","   ',',\n","   'but',\n","   'I',\n","   'do',\n","   \"n't\",\n","   'know',\n","   'all',\n","   'the',\n","   'parties',\n","   'or',\n","   'complications',\n","   'involved',\n","   '.'],\n","  ['Should',\n","   'there',\n","   'be',\n","   'a',\n","   '-LRB-',\n","   'groan',\n","   '-RRB-',\n","   'meeting',\n","   'on',\n","   'this',\n","   '?'],\n","  ['Can', 'you', 'please', 'help', 'with', 'this', 'one', '?'],\n","  ['I', 'agree', 'with', 'what', 'the', 'concern', 'is', 'below', '.'],\n","  ['We',\n","   'have',\n","   'GIS',\n","   'ids',\n","   ',',\n","   'and',\n","   'Eid',\n","   '-LRB-',\n","   'external',\n","   'id',\n","   '-',\n","   'just',\n","   'like',\n","   'GIS',\n","   'id',\n","   '-RRB-',\n","   '.'],\n","  ['I',\n","   'think',\n","   'we',\n","   'should',\n","   'try',\n","   'to',\n","   'migrate',\n","   'to',\n","   'one',\n","   'of',\n","   'these',\n","   '.'],\n","  ['Please',\n","   'let',\n","   'me',\n","   'know',\n","   'what',\n","   'type',\n","   'of',\n","   'statement',\n","   'I',\n","   'should',\n","   'make',\n","   'back',\n","   'to',\n","   'the',\n","   'customer',\n","   '.'],\n","  ['Thanks', '.'],\n","  ['Kathy', ','],\n","  ['Per',\n","   'my',\n","   'voicemail',\n","   'message',\n","   ',',\n","   'please',\n","   'review',\n","   'the',\n","   'note',\n","   'below',\n","   '.'],\n","  ['I',\n","   \"'d\",\n","   'like',\n","   'to',\n","   'work',\n","   'with',\n","   'you',\n","   'on',\n","   'a',\n","   'response',\n","   'to',\n","   'this',\n","   'customer',\n","   '.'],\n","  ['Thanks', ','],\n","  ['Brandee'],\n","  ['Brandee',\n","   'Sanborn',\n","   'I.S.C.',\n","   'Customer',\n","   'Care',\n","   'Design',\n","   '&',\n","   'Process',\n","   'Support'],\n","  ['<<',\n","   'OLE',\n","   'Object',\n","   ':',\n","   'Picture',\n","   '-LRB-',\n","   'Device',\n","   'Independent',\n","   'Bitmap',\n","   '-RRB-',\n","   '>>'],\n","  ['08/07/2001', '12:36', 'PM'],\n","  ['To', 'Whom', 'It', 'May', 'Concern', ':'],\n","  ['Through',\n","   'TV',\n","   'and',\n","   'newspapers',\n","   ',',\n","   'I',\n","   'hear',\n","   'constantly',\n","   'about',\n","   'identity',\n","   'fraud',\n","   'using',\n","   'stolen',\n","   'social',\n","   'security',\n","   'information',\n","   '.'],\n","  ['I', 'am', 'very', 'concerned', 'about', 'this', 'issue', '.'],\n","  ['I',\n","   'have',\n","   'the',\n","   'following',\n","   'suggestion',\n","   'for',\n","   'our',\n","   'company',\n","   '.'],\n","  ['Since',\n","   'Enron',\n","   \"'s\",\n","   'employees',\n","   'are',\n","   'assigned',\n","   'an',\n","   'SAP',\n","   'identification',\n","   'numbers',\n","   '-LRB-',\n","   'P',\n","   'number',\n","   '-RRB-',\n","   'and',\n","   'an',\n","   'HR',\n","   'number',\n","   ',',\n","   'could',\n","   'Enron',\n","   'as',\n","   'a',\n","   'company',\n","   'use',\n","   'these',\n","   'IDs',\n","   'instead',\n","   'of',\n","   'the',\n","   'SS',\n","   'numbers',\n","   '?'],\n","  ['This', 'will', 'be', 'safer', 'for', 'all', 'employees', '.'],\n","  ['For',\n","   'example',\n","   ',',\n","   'I',\n","   'am',\n","   'concerned',\n","   'when',\n","   'I',\n","   'buy',\n","   'the',\n","   'monthly',\n","   'bus',\n","   'passes',\n","   'and',\n","   'I',\n","   'have',\n","   'to',\n","   'fill',\n","   'in',\n","   'my',\n","   'SS',\n","   'number',\n","   '.'],\n","  ['I',\n","   'do',\n","   'not',\n","   'feel',\n","   'secure',\n","   'at',\n","   'all',\n","   'to',\n","   'see',\n","   'my',\n","   'SS',\n","   'in',\n","   'so',\n","   'many',\n","   'databases',\n","   'at',\n","   'Enron',\n","   ',',\n","   'especially',\n","   'when',\n","   'some',\n","   'databases',\n","   'are',\n","   'from',\n","   'third',\n","   '-',\n","   'parties',\n","   '-LRB-',\n","   'out',\n","   '-',\n","   'sourcing',\n","   '-RRB-',\n","   '.'],\n","  ['We',\n","   'could',\n","   'use',\n","   'our',\n","   'badge',\n","   'number',\n","   'there',\n","   'instead',\n","   'of',\n","   'our',\n","   'SS',\n","   '.'],\n","  ['Please',\n","   'let',\n","   'me',\n","   'know',\n","   'how',\n","   'your',\n","   'organization',\n","   'can',\n","   'help',\n","   'the',\n","   'Enron',\n","   'employees',\n","   'feel',\n","   'safer',\n","   'about',\n","   'the',\n","   'safeguard',\n","   'of',\n","   'their',\n","   'SS',\n","   'number',\n","   '.'],\n","  ['Please',\n","   'calendar',\n","   'and',\n","   'print',\n","   'for',\n","   'my',\n","   'files',\n","   'on',\n","   'this',\n","   'meeting',\n","   '.'],\n","  ['Thanks', '.'],\n","  ['MHC'],\n","  ['All', ','],\n","  ['A',\n","   'reminder',\n","   'that',\n","   'the',\n","   'HR',\n","   'Associate',\n","   'Points',\n","   'Meeting',\n","   'will',\n","   'take',\n","   'place',\n","   'as',\n","   'below',\n","   ':'],\n","  ['Thursday',\n","   ',',\n","   '23rd',\n","   'August',\n","   '3.30',\n","   'pm',\n","   '-',\n","   '5.30',\n","   'pm',\n","   '-LRB-',\n","   'EB',\n","   '46C1',\n","   '-RRB-',\n","   '.'],\n","  ['The',\n","   'Leads',\n","   'who',\n","   'are',\n","   'responsible',\n","   'for',\n","   'Associates',\n","   'are',\n","   'as',\n","   'follows',\n","   ':'],\n","  ['Sunjay', 'Arya'],\n","  ['Gary', 'Buck'],\n","  ['Khymberly', 'Booth'],\n","  ['Ryan', 'Seleznov'],\n","  ['Mecole', 'Brown'],\n","  ['Tim', \"O'Rourke\"],\n","  ['Tana', 'Cashion'],\n","  ['Sheila', 'Walton'],\n","  ['Wendy', 'Fincher'],\n","  ['Sheila', 'Knudsen'],\n","  ['Karen', 'Phillips'],\n","  ['Neil', 'Davies'],\n","  ['Noel', 'Ryan'],\n","  ['Cindy', 'Skinner'],\n","  ['Simone', 'Scott', 'Walker'],\n","  ['Shanna', 'Funkhouser'],\n","  ['Peer',\n","   'reviews',\n","   'are',\n","   'currently',\n","   'been',\n","   'gathered',\n","   'on',\n","   'the',\n","   'above',\n","   '.'],\n","  ['Upon',\n","   'receipt',\n","   ',',\n","   'I',\n","   'shall',\n","   'forward',\n","   'to',\n","   'each',\n","   'of',\n","   'you',\n","   'a',\n","   'copy',\n","   'of',\n","   'the',\n","   'reviews',\n","   'for',\n","   'your',\n","   'respective',\n","   'associate',\n","   '.'],\n","  ['In',\n","   'addition',\n","   'they',\n","   'will',\n","   'be',\n","   'contacting',\n","   'you',\n","   'to',\n","   'discuss',\n","   'their',\n","   'participation',\n","   'in',\n","   'projects',\n","   'outside',\n","   'their',\n","   'rotation',\n","   '.'],\n","  ['Those',\n","   'who',\n","   'are',\n","   'not',\n","   'assigned',\n","   'an',\n","   'associate',\n","   'may',\n","   'also',\n","   'allocate',\n","   'points',\n","   '-LRB-',\n","   'a',\n","   'max',\n","   'of',\n","   '150',\n","   '-RRB-',\n","   'at',\n","   'the',\n","   'meeting',\n","   'based',\n","   'on',\n","   'contribution',\n","   'to',\n","   'your',\n","   'areas',\n","   'for',\n","   'the',\n","   'first',\n","   'review',\n","   'period',\n","   '.'],\n","  ['If',\n","   'anyone',\n","   'has',\n","   'any',\n","   'questions',\n","   'on',\n","   'the',\n","   'above',\n","   'please',\n","   'let',\n","   'me',\n","   'know',\n","   '.'],\n","  ['Kind', 'regards', ','],\n","  ['Karen', '.', 'x54667'],\n","  ['Shanna',\n","   ',',\n","   'I',\n","   'spoke',\n","   'with',\n","   'Per',\n","   'tonight',\n","   'about',\n","   'this',\n","   '.'],\n","  ['Let', \"'s\", 'talk', 'tomorrow', '.'],\n","  ['Thanks', '.'],\n","  ['Michelle'],\n","  ['This',\n","   'is',\n","   'the',\n","   'background',\n","   'to',\n","   'my',\n","   'conversation',\n","   'with',\n","   'Shanna',\n","   '.'],\n","  ['I',\n","   'have',\n","   'a',\n","   'copy',\n","   'of',\n","   'the',\n","   'document',\n","   'I',\n","   'can',\n","   'give',\n","   'to',\n","   'you',\n","   'tomorrow',\n","   '.'],\n","  ['Thanks', 'for', 'following', 'up', 'on', 'this', '.'],\n","  ['Per'],\n","  ['Per', '-'],\n","  ['I',\n","   'did',\n","   'not',\n","   'hear',\n","   'back',\n","   'from',\n","   'Shanna',\n","   'or',\n","   'Sharon',\n","   'Butcher',\n","   '.'],\n","  ['Could',\n","   'you',\n","   'please',\n","   'ask',\n","   'Shanna',\n","   'to',\n","   'take',\n","   'this',\n","   'situation',\n","   'to',\n","   'Sharon',\n","   'tomorrow',\n","   '?'],\n","  ['John',\n","   ',',\n","   'Per',\n","   'and',\n","   'I',\n","   'discussed',\n","   'the',\n","   'hostile',\n","   'environment',\n","   'issue',\n","   'and',\n","   'we',\n","   'are',\n","   'both',\n","   'concerned',\n","   'that',\n","   'we',\n","   'may',\n","   'have',\n","   'some',\n","   'repercussions',\n","   '.'],\n","  ['I',\n","   'am',\n","   'vacation',\n","   'until',\n","   'the',\n","   '22nd',\n","   'but',\n","   'Per',\n","   'is',\n","   'up',\n","   'to',\n","   'speed',\n","   'and',\n","   'I',\n","   'would',\n","   'like',\n","   'to',\n","   'make',\n","   'sure',\n","   'that',\n","   'you',\n","   'keep',\n","   'up',\n","   'with',\n","   'him',\n","   'and',\n","   'any',\n","   'HR',\n","   '/',\n","   'Legal',\n","   'activity',\n","   'that',\n","   'may',\n","   'occur',\n","   '.'],\n","  ['Thank', 'you'],\n","  ['Paula'],\n","  ['Let',\n","   \"'s\",\n","   'discuss',\n","   'exactly',\n","   'what',\n","   'is',\n","   'involved',\n","   'here',\n","   '--',\n","   'confidentiality',\n","   ',',\n","   'etc',\n","   '.'],\n","  ['Thanks', '.'],\n","  ['MHC'],\n","  ['Hi', \"Ya'll\", ','],\n","  ['I',\n","   'wanted',\n","   'to',\n","   'let',\n","   'you',\n","   'know',\n","   'about',\n","   'this',\n","   'before',\n","   'I',\n","   'respond',\n","   'to',\n","   'her',\n","   'request',\n","   '.'],\n","  ['Let', 'me', 'know', 'if', 'you', 'have', 'any', 'questions', '.'],\n","  ['Regards', ','],\n","  ['Sandra'],\n","  ['Kathy',\n","   'McMahon',\n","   'suggested',\n","   'that',\n","   'I',\n","   'contact',\n","   'you',\n","   'in',\n","   'an',\n","   'effort',\n","   'to',\n","   'gather',\n","   'information',\n","   'on',\n","   ':',\n","   'Enron',\n","   \"'s\",\n","   'Affirmative',\n","   'Action',\n","   'Policy',\n","   'and',\n","   'plans',\n","   ';',\n","   'as',\n","   'well',\n","   'as',\n","   'demographic',\n","   'analysis',\n","   'of',\n","   'workforce',\n","   '-LRB-',\n","   'gender',\n","   ',',\n","   'age',\n","   ',',\n","   'ethnic',\n","   'origin',\n","   ',',\n","   'nationality',\n","   '-RRB-'],\n","  ['Jeff',\n","   'Skilling',\n","   'has',\n","   'agreed',\n","   'to',\n","   'work',\n","   'with',\n","   'Harvard',\n","   'Business',\n","   'School',\n","   '-LRB-',\n","   'HBS',\n","   '-RRB-',\n","   'on',\n","   'a',\n","   '5',\n","   '-',\n","   'year',\n","   'case',\n","   'study',\n","   'called',\n","   \"'\",\n","   'Modern',\n","   'Giants',\n","   \"'\",\n","   '.'],\n","  ['HBS',\n","   'will',\n","   'shadow',\n","   'Enron',\n","   'and',\n","   'a',\n","   'number',\n","   'of',\n","   'other',\n","   'companies',\n","   'over',\n","   'the',\n","   'next',\n","   'five',\n","   'years',\n","   'to',\n","   'assess',\n","   'how',\n","   'we',\n","   'react',\n","   'to',\n","   'market',\n","   'changes',\n","   'and',\n","   'to',\n","   'see',\n","   'how',\n","   'we',\n","   'morph',\n","   'during',\n","   'this',\n","   'time',\n","   'period',\n","   '.'],\n","  ['Please',\n","   'let',\n","   'me',\n","   'know',\n","   'at',\n","   'your',\n","   'earliest',\n","   'convience',\n","   'if',\n","   'you',\n","   'can',\n","   'help',\n","   'me',\n","   '.'],\n","  ['Regards', ','],\n","  ['Cindy'],\n","  ['please', 'print', 'all', 'these', 'for', 'me', '.'],\n","  ['Thanks', '.'],\n","  ['MHC'],\n","  ['Ryan', ','],\n","  ['Try', 'this', '.'],\n","  ['bob', 'k'],\n","  ['FYI', 're', ':', 'NEPCO', 'picketing', 'issues', '.'],\n","  ['Michelle'],\n","  ['Michelle', ','],\n","  ['Two', 'in', 'one', 'day', '.'],\n","  ['We',\n","   'understand',\n","   'that',\n","   'the',\n","   'pipe',\n","   'fitters',\n","   'are',\n","   'also',\n","   'planning',\n","   'to',\n","   'picket',\n","   'the',\n","   'Lake',\n","   'Worth',\n","   ',',\n","   'Florida',\n","   'project',\n","   'as',\n","   'well',\n","   '.'],\n","  ['Our',\n","   'execution',\n","   'team',\n","   'needs',\n","   'to',\n","   'get',\n","   'some',\n","   'guidance',\n","   'and',\n","   'planning',\n","   'for',\n","   'this',\n","   'picketing',\n","   'should',\n","   'it',\n","   'interfere',\n","   'with',\n","   'the',\n","   'progress',\n","   'of',\n","   'the',\n","   'work',\n","   '.'],\n","  ['In',\n","   'that',\n","   'respect',\n","   ',',\n","   'we',\n","   'need',\n","   'to',\n","   'dial',\n","   'in',\n","   'Rick',\n","   'Johnson',\n","   'and',\n","   'Olgletree',\n","   'to',\n","   'plan',\n","   'and',\n","   'communicate',\n","   'that',\n","   'plan',\n","   'to',\n","   'the',\n","   'execution',\n","   'team',\n","   '.'],\n","  ['I',\n","   'think',\n","   'the',\n","   'first',\n","   'step',\n","   'is',\n","   'a',\n","   'call',\n","   'between',\n","   'yourself',\n","   ',',\n","   'me',\n","   ',',\n","   'Mark',\n","   'Stubley',\n","   'and',\n","   'Mike',\n","   'Indivero',\n","   '.'],\n","  ['And',\n","   'then',\n","   'another',\n","   'call',\n","   'with',\n","   'all',\n","   'folks',\n","   'or',\n","   'a',\n","   'meeting',\n","   'at',\n","   'the',\n","   'jobsite',\n","   'to',\n","   'lay',\n","   'out',\n","   'the',\n","   'plan',\n","   '.'],\n","  ['Barbara',\n","   ',',\n","   'please',\n","   'organize',\n","   'a',\n","   'call',\n","   'for',\n","   'Mike',\n","   ',',\n","   'Michelle',\n","   ',',\n","   'Mark',\n","   'Stubley',\n","   'and',\n","   'me',\n","   '.'],\n","  ['Thanks', '.'],\n","  ['David', ','],\n","  ['I',\n","   'have',\n","   'been',\n","   'advised',\n","   'by',\n","   'our',\n","   'Construction',\n","   'Manager',\n","   ',',\n","   'Mr.',\n","   'Joe',\n","   'Osler',\n","   'that',\n","   'while',\n","   'he',\n","   'was',\n","   'visiting',\n","   'the',\n","   'City',\n","   'of',\n","   'Lake',\n","   'Worth',\n","   'Building',\n","   'Planning',\n","   'and',\n","   'Zoning',\n","   'dept',\n","   'regarding',\n","   'our',\n","   'permit',\n","   'status',\n","   'he',\n","   'learned',\n","   'that',\n","   'the',\n","   'pipefitters',\n","   'have',\n","   'inquired',\n","   'about',\n","   'permit',\n","   'requirements',\n","   'to',\n","   'picket',\n","   'our',\n","   'site',\n","   '.'],\n","  ['Apparently',\n","   'the',\n","   'City',\n","   'informed',\n","   'them',\n","   'that',\n","   'no',\n","   'permit',\n","   'is',\n","   'required',\n","   '.'],\n","  ['I',\n","   'have',\n","   'heard',\n","   'that',\n","   'the',\n","   'pipefitters',\n","   'have',\n","   'established',\n","   'a',\n","   'picket',\n","   'line',\n","   'at',\n","   'the',\n","   'Payne',\n","   'Creek',\n","   'site',\n","   'today',\n","   '.'],\n","  ['We',\n","   'will',\n","   'need',\n","   'local',\n","   'legal',\n","   'counsel',\n","   'to',\n","   'assist',\n","   'us',\n","   'in',\n","   'this',\n","   'regard',\n","   '.'],\n","  ['Mike',\n","   'Indivero',\n","   ',',\n","   'I',\n","   'understand',\n","   'that',\n","   'Mr.',\n","   'Mike',\n","   'Croall',\n","   \"'s\",\n","   'release',\n","   'date',\n","   'from',\n","   'NEPCO',\n","   'is',\n","   'Oct',\n","   '31',\n","   ',',\n","   '2001',\n","   '.'],\n","  ['Please',\n","   'advise',\n","   'as',\n","   'to',\n","   'who',\n","   'his',\n","   'replacement',\n","   'is',\n","   'and',\n","   'their',\n","   'report',\n","   'date',\n","   '.'],\n","  ['Thanks', ','],\n","  ['Galen',\n","   'J.',\n","   'Torneby',\n","   'Project',\n","   'Manager',\n","   'National',\n","   'Energy',\n","   'Production',\n","   'Corporation',\n","   '-LRB-',\n","   'NEPCO',\n","   '-RRB-',\n","   '11831',\n","   'North',\n","   'Creek',\n","   'Parkway',\n","   'North',\n","   'Bothell',\n","   ',',\n","   'WA',\n","   '98011',\n","   'USA',\n","   'Tel',\n","   ':',\n","   '425-415-3052',\n","   'Cell',\n","   ':',\n","   '425-922-0475',\n","   'Fax',\n","   ':',\n","   '425-415-3098',\n","   'email',\n","   ':',\n","   '<',\n","   '>'],\n","  ['yeah', 'i', 'got', 'yelled', 'at', 'also', '.'],\n","  ['i',\n","   'tried',\n","   'to',\n","   'say',\n","   'i',\n","   'was',\n","   \"n't\",\n","   'that',\n","   'drunk',\n","   'but',\n","   'z',\n","   'was',\n","   \"n't\",\n","   'having',\n","   'any',\n","   'of',\n","   'that',\n","   'conversation',\n","   '.'],\n","  ['she',\n","   'told',\n","   'me',\n","   'that',\n","   'after',\n","   'friday',\n","   'and',\n","   'saturday',\n","   'she',\n","   'felt',\n","   'i',\n","   'was',\n","   'slowly',\n","   'regressing',\n","   '.'],\n","  ['then',\n","   'i',\n","   'told',\n","   'her',\n","   'i',\n","   'felt',\n","   'i',\n","   'should',\n","   'be',\n","   'able',\n","   'to',\n","   'screw',\n","   'missy',\n","   'just',\n","   'once',\n","   '.'],\n","  ['she', 'said', 'that', 'was', 'ok', '.'],\n","  ['Did',\n","   'you',\n","   'get',\n","   'in',\n","   'as',\n","   'much',\n","   'trouble',\n","   'as',\n","   'I',\n","   'did',\n","   'this',\n","   'weekend',\n","   '-',\n","   'Lori',\n","   'seems',\n","   'to',\n","   'think',\n","   'I',\n","   'need',\n","   'to',\n","   'get',\n","   'help',\n","   '-',\n","   'I',\n","   'told',\n","   'her',\n","   'it',\n","   \"'s\",\n","   'normal',\n","   'to',\n","   'drink',\n","   'all',\n","   'day',\n","   'at',\n","   'a',\n","   'bar',\n","   ',',\n","   'then',\n","   'go',\n","   'to',\n","   'dinner',\n","   'where',\n","   'you',\n","   'do',\n","   \"n't\",\n","   'know',\n","   'half',\n","   'the',\n","   'people',\n","   'there',\n","   'and',\n","   'proceed',\n","   'to',\n","   'get',\n","   'extremely',\n","   'fucked',\n","   'up'],\n","  ['*******************',\n","   'Internet',\n","   'Email',\n","   'Confidentiality',\n","   'Footer',\n","   '*******************'],\n","  ['Privileged',\n","   '/',\n","   'Confidential',\n","   'Information',\n","   'may',\n","   'be',\n","   'contained',\n","   'in',\n","   'this',\n","   'message',\n","   '.'],\n","  ['If',\n","   'you',\n","   'are',\n","   'not',\n","   'the',\n","   'addressee',\n","   'indicated',\n","   'in',\n","   'this',\n","   'message',\n","   '-LRB-',\n","   'or',\n","   'responsible',\n","   'for',\n","   'delivery',\n","   'of',\n","   'the',\n","   'message',\n","   'to',\n","   'such',\n","   'person',\n","   '-RRB-',\n","   ',',\n","   'you',\n","   'may',\n","   'not',\n","   'copy',\n","   'or',\n","   'deliver',\n","   'this',\n","   'message',\n","   'to',\n","   'anyone',\n","   '.'],\n","  ['In',\n","   'such',\n","   'case',\n","   ',',\n","   'you',\n","   'should',\n","   'destroy',\n","   'this',\n","   'message',\n","   'and',\n","   'kindly',\n","   'notify',\n","   'the',\n","   'sender',\n","   'by',\n","   'reply',\n","   'email',\n","   '.'],\n","  ['Please',\n","   'advise',\n","   'immediately',\n","   'if',\n","   'you',\n","   'or',\n","   'your',\n","   'employer',\n","   'do',\n","   'not',\n","   'consent',\n","   'to',\n","   'Internet',\n","   'email',\n","   'for',\n","   'messages',\n","   'of',\n","   'this',\n","   'kind',\n","   '.'],\n","  ['Opinions',\n","   ',',\n","   'conclusions',\n","   'and',\n","   'other',\n","   'information',\n","   'in',\n","   'this',\n","   'message',\n","   'that',\n","   'do',\n","   'not',\n","   'relate',\n","   'to',\n","   'the',\n","   'official',\n","   'business',\n","   'of',\n","   'my',\n","   'firm',\n","   'shall',\n","   'be',\n","   'understood',\n","   'as',\n","   'neither',\n","   'given',\n","   'nor',\n","   'endorsed',\n","   'by',\n","   'it',\n","   '.'],\n","  ['Job', 'ID', ':', 'J12746KM'],\n","  ['Job', 'Title', ':', 'Attorney'],\n","  ['Location', ':', 'Houston', ',', 'Texas', 'USA'],\n","  ['Compensation', ':', '$', '60000', '-', '70000'],\n","  ['Description', ':'],\n","  ['Our',\n","   'client',\n","   'is',\n","   'a',\n","   'small',\n","   'law',\n","   'firm',\n","   'that',\n","   'is',\n","   'looking',\n","   'for',\n","   'an',\n","   'individual',\n","   'to',\n","   'join',\n","   'their',\n","   'team',\n","   'handling',\n","   'toxic',\n","   'tort',\n","   'with',\n","   'some',\n","   'minor',\n","   'PI',\n","   'defense',\n","   '.'],\n","  ['They',\n","   'offer',\n","   'an',\n","   'exceptional',\n","   'compensation',\n","   'package',\n","   'including',\n","   'a',\n","   'healthy',\n","   'salary',\n","   ',',\n","   'comprehensive',\n","   'benefits',\n","   'program',\n","   ',',\n","   'and',\n","   'ample',\n","   'room',\n","   'for',\n","   'associates',\n","   'to',\n","   'grow',\n","   'within',\n","   'the',\n","   'firm',\n","   '.'],\n","  ['KM'],\n","  ['Requirements', ':'],\n","  ['You',\n","   \"'ll\",\n","   'be',\n","   'able',\n","   'to',\n","   'use',\n","   'your',\n","   '1',\n","   '-',\n","   '4',\n","   'years',\n","   'of',\n","   'experience',\n","   'with',\n","   'Toxic',\n","   'Tort',\n","   'to',\n","   'complement',\n","   'your',\n","   'desire',\n","   'to',\n","   'stay',\n","   'with',\n","   'the',\n","   'firm',\n","   '.'],\n","  ['Company', ':'],\n","  ['Marvel',\n","   'Consultants',\n","   ',',\n","   'Inc.',\n","   '28601',\n","   'Chagrin',\n","   'Blvd.',\n","   'Cleveland',\n","   ',',\n","   'Ohio',\n","   '44122',\n","   'USA',\n","   'Email',\n","   ':',\n","   '<',\n","   '>',\n","   'Phone',\n","   ':',\n","   '216-292-2855',\n","   'Fax',\n","   ':',\n","   '216-292-7207'],\n","  ['thanks'],\n","  ['I',\n","   \"'ve\",\n","   'thought',\n","   'about',\n","   'you',\n","   'a',\n","   'few',\n","   'times',\n","   'in',\n","   'the',\n","   'last',\n","   'few',\n","   'months',\n","   ',',\n","   'did',\n","   \"n't\",\n","   'want',\n","   'to',\n","   'intrude',\n","   'upon',\n","   'an',\n","   'already',\n","   'bad',\n","   'situation',\n","   'with',\n","   'my',\n","   'bullshit',\n","   'questions',\n","   '.'],\n","  ['I',\n","   \"'m\",\n","   'hearing',\n","   'some',\n","   'pretty',\n","   'depressing',\n","   'stuff',\n","   'from',\n","   'the',\n","   'people',\n","   'I',\n","   'know',\n","   'at',\n","   'ENE',\n","   '.'],\n","  ['I',\n","   'wish',\n","   'I',\n","   'had',\n","   'the',\n","   'capital',\n","   'to',\n","   'open',\n","   'my',\n","   'own',\n","   'shop',\n","   '?'],\n","  ['there',\n","   'will',\n","   'be',\n","   'talent',\n","   'and',\n","   'opportunity',\n","   'a',\n","   'plenty',\n","   'on',\n","   'the',\n","   'market',\n","   'soon',\n","   '.'],\n","  ['I', \"'ll\", 'ask', 'around', '?'],\n","  ['I',\n","   \"'ve\",\n","   'got',\n","   'some',\n","   'friends',\n","   'at',\n","   'Duke',\n","   'and',\n","   'Dynegy',\n","   'from',\n","   'B',\n","   '-',\n","   'school',\n","   ',',\n","   'the',\n","   'Gianoucous',\n","   '-LRB-',\n","   'spelling',\n","   '??',\n","   '-RRB-',\n","   'brothers',\n","   '-LRB-',\n","   'John',\n","   'and',\n","   'Dimitri',\n","   '?',\n","   'from',\n","   'elementary',\n","   'school',\n","   '-RRB-',\n","   'started',\n","   'their',\n","   'own',\n","   'outfit',\n","   'a',\n","   'while',\n","   'back',\n","   ',',\n","   'and',\n","   'my',\n","   'old',\n","   'man',\n","   'is',\n","   'at',\n","   'Schlumberger',\n","   'and',\n","   'has',\n","   'good',\n","   'contacts',\n","   'in',\n","   'general',\n","   '-LRB-',\n","   'if',\n","   'you',\n","   'are',\n","   \"n't\",\n","   'married',\n","   'to',\n","   'a',\n","   'trading',\n","   'environment',\n","   '-RRB-',\n","   '.'],\n","  ['Give',\n","   'me',\n","   'a',\n","   'few',\n","   'days',\n","   ',',\n","   'and',\n","   'I',\n","   \"'ll\",\n","   'be',\n","   'in',\n","   'touch',\n","   '.'],\n","  ['Michael'],\n","  ['you',\n","   'guys',\n","   'have',\n","   'any',\n","   'job',\n","   'opening',\n","   'for',\n","   'ex',\n","   'natural',\n","   'gas',\n","   'traders',\n","   'that',\n","   'made',\n","   'their',\n","   'now',\n","   'almost',\n","   'defunctc',\n","   'ompany',\n","   'over',\n","   '40',\n","   'million',\n","   'in',\n","   'the',\n","   'last',\n","   'two',\n","   'years',\n","   '?'],\n","  ['not',\n","   'sure',\n","   'how',\n","   'much',\n","   'longer',\n","   'ene',\n","   'is',\n","   'going',\n","   'to',\n","   'be',\n","   'around',\n","   'and',\n","   'i',\n","   \"'m\",\n","   'checking',\n","   'out',\n","   'my',\n","   'options',\n","   '!'],\n","  ['not',\n","   'sure',\n","   ',',\n","   'but',\n","   'i',\n","   'assume',\n","   'that',\n","   'the',\n","   'bluegrass',\n","   'songbook',\n","   'is',\n","   'mine',\n","   '.'],\n","  ['is', 'it', 'for', 'guitar', '?'],\n","  ['I', \"'ll\", 'need', 'to', 'ponder', '.'],\n","  ['I', \"'ll\", 'try', 'to', 'get', 'back', 'to', 'you', 'pronto', '.'],\n","  ['FYI', '.'],\n","  ['We', 'have', 'this', 'report', '?'],\n","  ['Hi', 'David', ':'],\n","  ['Thought', 'that', 'you', 'might', 'be', 'interested', '.'],\n","  ['Best', ','],\n","  ['Jeff'],\n","  ['Well', ',', 'he', 'launched', 'today', '.'],\n","  ['Have',\n","   'you',\n","   'seen',\n","   'the',\n","   'materials',\n","   'from',\n","   'the',\n","   'press',\n","   'conference',\n","   'that',\n","   'he',\n","   'launched',\n","   'today',\n","   '?'],\n","  ['I',\n","   'think',\n","   'this',\n","   'is',\n","   'actually',\n","   'a',\n","   'good',\n","   'thing',\n","   '--',\n","   'makes',\n","   'our',\n","   'proposal',\n","   'look',\n","   'like',\n","   'a',\n","   'much',\n","   'more',\n","   'preferable',\n","   'alternative',\n","   'by',\n","   'comparison',\n","   ',',\n","   'makes',\n","   'our',\n","   'support',\n","   'in',\n","   'the',\n","   'process',\n","   'more',\n","   'important',\n","   ',',\n","   'and',\n","   'sets',\n","   'Harvey',\n","   'up',\n","   'as',\n","   'the',\n","   'Ralph',\n","   'Nader',\n","   'equivalent',\n","   'in',\n","   'the',\n","   'election',\n","   'to',\n","   'fix',\n","   'California',\n","   \"'s\",\n","   'broken',\n","   'system',\n","   '---',\n","   'a',\n","   'potential',\n","   'spoiler',\n","   '.'],\n","  ['Hi', '.'],\n","  ['Well', ',', 'would', \"n't\", 'you', 'know', 'it', '.'],\n","  ['I',\n","   \"'m\",\n","   'not',\n","   'driving',\n","   'tonite',\n","   ',',\n","   'but',\n","   'I',\n","   'bet',\n","   'that',\n","   'we',\n","   'could',\n","   'hitch',\n","   'a',\n","   'ride',\n","   'back',\n","   'with',\n","   'Anil',\n","   '.'],\n","  ['I',\n","   \"'m\",\n","   'not',\n","   'sure',\n","   ',',\n","   'but',\n","   'I',\n","   'think',\n","   'that',\n","   'he',\n","   \"'s\",\n","   'got',\n","   'class',\n","   'tonite',\n","   ',',\n","   'too',\n","   '.'],\n","  ['I',\n","   \"'ll\",\n","   'search',\n","   'him',\n","   'out',\n","   'before',\n","   'class',\n","   'or',\n","   'after',\n","   'that',\n","   'break',\n","   'and',\n","   'see',\n","   'if',\n","   'I',\n","   'can',\n","   'set',\n","   'it',\n","   'up',\n","   '.'],\n","  ['\"', 'Les', 'Spahnn', '\"', '<', '>'],\n","  ['02/13/2001', '08:02', 'PM'],\n","  ['All', ':'],\n","  ['It',\n","   'is',\n","   'my',\n","   'understanding',\n","   ',',\n","   'from',\n","   'good',\n","   'sources',\n","   'in',\n","   'the',\n","   'Gov',\n","   's',\n","   'office',\n","   'that',\n","   'the',\n","   'Gov',\n","   'will',\n","   'order',\n","   'Loretta',\n","   'Lynch',\n","   'to',\n","   'expeditiously',\n","   'implement',\n","   'the',\n","   'provision',\n","   'to',\n","   'suspend',\n","   'all',\n","   'parties',\n","   'auhtority',\n","   'to',\n","   'enter',\n","   'into',\n","   'direct',\n","   'access',\n","   'contracts',\n","   '.'],\n","  ['The',\n","   'premise',\n","   'with',\n","   'which',\n","   'the',\n","   'administartion',\n","   'is',\n","   'acting',\n","   'is',\n","   'that',\n","   'if',\n","   'they',\n","   'expeditiously',\n","   'suspend',\n","   'everyone',\n","   \"'s\",\n","   'right',\n","   'to',\n","   'bilateral',\n","   'contracts',\n","   'quickly',\n","   ',',\n","   'it',\n","   'sets',\n","   'up',\n","   'a',\n","   'barrier',\n","   'which',\n","   'the',\n","   'direct',\n","   'access',\n","   'coalition',\n","   'must',\n","   'break',\n","   'through',\n","   '.'],\n","  ['In', 'other', 'words', 'the', 'table', 'is', 'set', '.'],\n","  ['Deal',\n","   'your',\n","   'meal',\n","   'from',\n","   'where',\n","   'the',\n","   'dishes',\n","   'are',\n","   'located',\n","   '.'],\n","  ['I.E.',\n","   'the',\n","   'Davis',\n","   'Administration',\n","   'wants',\n","   'to',\n","   'place',\n","   'all',\n","   'direct',\n","   'access',\n","   'advocates',\n","   'in',\n","   'the',\n","   'position',\n","   'of',\n","   'having',\n","   'to',\n","   'justify',\n","   'why',\n","   'each',\n","   'and',\n","   'every',\n","   'party',\n","   'should',\n","   'be',\n","   'the',\n","   'exception',\n","   'to',\n","   'the',\n","   'suspension',\n","   'rather',\n","   'than',\n","   'have',\n","   'a',\n","   'general',\n","   'rule',\n","   'concerning',\n","   'how',\n","   'direct',\n","   'access',\n","   'should',\n","   'work',\n","   'for',\n","   'all',\n","   'parties',\n","   '.'],\n","  ['It',\n","   'clearly',\n","   'gives',\n","   'the',\n","   'Admin',\n","   'a',\n","   'very',\n","   'strong',\n","   'upper',\n","   'hand',\n","   'to',\n","   'control',\n","   'who',\n","   'when',\n","   'and',\n","   'where',\n","   'direct',\n","   'access',\n","   'can',\n","   'occur',\n","   'without',\n","   'having',\n","   'to',\n","   'say',\n","   'that',\n","   'they',\n","   'oppose',\n","   'direct',\n","   'access',\n","   '.'],\n","  ['Power', 'be', 'where', 'power', 'lies', '.'],\n","  ['JMB', '<', '>'],\n","  ['12/22/2000', '06:28', 'PM'],\n","  ['Parties',\n","   ',',\n","   'attached',\n","   'is',\n","   'the',\n","   'promised',\n","   'ruling',\n","   'that',\n","   'provides',\n","   'procedural',\n","   'guidance',\n","   'for',\n","   'the',\n","   'hearings',\n","   'on',\n","   '12/27',\n","   'and',\n","   '12/28',\n","   '.'],\n","  ['The',\n","   'ruling',\n","   'will',\n","   'also',\n","   'be',\n","   'posted',\n","   'on',\n","   'the',\n","   'web',\n","   'site',\n","   'as',\n","   'quickly',\n","   'as',\n","   'possible',\n","   '.'],\n","  ['Thank',\n","   'you',\n","   'for',\n","   'your',\n","   'patience',\n","   'and',\n","   'I',\n","   'hope',\n","   'you',\n","   'can',\n","   'take',\n","   'a',\n","   'few',\n","   'moments',\n","   'to',\n","   'enjoy',\n","   'the',\n","   'holidays',\n","   '.'],\n","  ['--', 'Angela', 'Minkin', 'Administrative', 'Law', 'Judge'],\n","  ['<<', '1%P701!.doc', '>>'],\n","  ['Note',\n","   'that',\n","   'this',\n","   'communication',\n","   'is',\n","   'confidential',\n","   ',',\n","   'covered',\n","   'by',\n","   'CA',\n","   \"'s\",\n","   'settlement',\n","   'rules',\n","   '.'],\n","  ['\"', 'Lindh', ',', 'Frank', '-LRB-', 'Law', '-RRB-', '\"', '<', '>'],\n","  ['12/21/2000', '07:50', 'PM'],\n","  ['Confidential', 'Settlement', 'Document', 'Per', 'CPUC', 'Rule', '51'],\n","  ['Gas', 'Accord', 'II', 'Settlement', 'Participants', ':'],\n","  ['Attached',\n","   'is',\n","   'PG&E',\n","   \"'s\",\n","   'Gas',\n","   'Accord',\n","   'II',\n","   '-LRB-',\n","   'GA',\n","   'II',\n","   '-RRB-',\n","   'Settlement',\n","   'Proposal',\n","   '.'],\n","  ['We',\n","   'believe',\n","   'it',\n","   'addresses',\n","   'many',\n","   'of',\n","   'the',\n","   'issues',\n","   'and',\n","   'concerns',\n","   'you',\n","   'have',\n","   'raised',\n","   'in',\n","   'the',\n","   'workshops',\n","   '.'],\n","  ['As',\n","   'an',\n","   'overview',\n","   ',',\n","   'this',\n","   'proposal',\n","   ':',\n","   '*',\n","   'Maintains',\n","   'the',\n","   'basic',\n","   'Gas',\n","   'Accord',\n","   'structure',\n","   'in',\n","   'place',\n","   'today',\n","   'for',\n","   'the',\n","   'period',\n","   '2003',\n","   'to',\n","   '2007',\n","   '.',\n","   '*'],\n","  ['*',\n","   'Offers',\n","   'end',\n","   'user',\n","   'transportation',\n","   'rates',\n","   'for',\n","   '2003',\n","   'lower',\n","   'for',\n","   'most',\n","   'customers',\n","   'than',\n","   'rates',\n","   'in',\n","   'effect',\n","   'today',\n","   '.',\n","   '*'],\n","  ['*',\n","   'Provides',\n","   'for',\n","   'vintaged',\n","   'Redwood',\n","   'path',\n","   'rates',\n","   'for',\n","   'core',\n","   'customers',\n","   '.',\n","   '*'],\n","  ['*',\n","   'Offers',\n","   'a',\n","   '7.5',\n","   'cent',\n","   '/',\n","   'dth',\n","   'rate',\n","   'to',\n","   'large',\n","   'customers',\n","   'while',\n","   'minimizing',\n","   'rate',\n","   'changes',\n","   'to',\n","   'other',\n","   'customers',\n","   ',',\n","   'minimizing',\n","   'the',\n","   'incentive',\n","   'for',\n","   'these',\n","   'customers',\n","   'to',\n","   'seek',\n","   'to',\n","   'bypass',\n","   'local',\n","   'transmission',\n","   'charges',\n","   'and',\n","   'other',\n","   'CPUC',\n","   '-',\n","   'approved',\n","   'charges',\n","   '.',\n","   '*'],\n","  ['*',\n","   'Adopts',\n","   'guidelines',\n","   'to',\n","   'improve',\n","   'reliability',\n","   'and',\n","   'help',\n","   'moderate',\n","   'prices',\n","   'in',\n","   'gas',\n","   'commodity',\n","   'markets',\n","   ',',\n","   'and',\n","   'identifies',\n","   'the',\n","   'capital',\n","   'projects',\n","   'needed',\n","   'to',\n","   'meet',\n","   'these',\n","   'guidelines',\n","   'over',\n","   'the',\n","   'course',\n","   'of',\n","   'the',\n","   'GA',\n","   'II',\n","   'period',\n","   '-LRB-',\n","   '2003',\n","   '-',\n","   '2007',\n","   '-RRB-',\n","   '.',\n","   '*'],\n","  ['*',\n","   'Provides',\n","   'a',\n","   'high',\n","   'degree',\n","   'of',\n","   'rate',\n","   'stability',\n","   ',',\n","   'with',\n","   'a',\n","   '3.5',\n","   '%',\n","   'escalator',\n","   'to',\n","   'capture',\n","   'both',\n","   'inflation',\n","   'and',\n","   'the',\n","   'cost',\n","   'of',\n","   'needed',\n","   'capital',\n","   'projects',\n","   '.'],\n","  ['The',\n","   'guaranteed',\n","   'rates',\n","   'will',\n","   'be',\n","   'adjustable',\n","   'only',\n","   'for',\n","   'significant',\n","   'changes',\n","   'in',\n","   'the',\n","   'cost',\n","   'of',\n","   'capital',\n","   'or',\n","   'increased',\n","   'costs',\n","   'due',\n","   'to',\n","   'governmental',\n","   'requirements',\n","   'or',\n","   'catastrophic',\n","   'events',\n","   '.',\n","   '*'],\n","  ['*',\n","   'Preserves',\n","   'a',\n","   'rate',\n","   'differential',\n","   'between',\n","   'the',\n","   'Redwood',\n","   'and',\n","   'Baja',\n","   'paths',\n","   ',',\n","   'although',\n","   'somewhat',\n","   'less',\n","   'than',\n","   'the',\n","   'current',\n","   'differential',\n","   '.',\n","   '*'],\n","  ['*',\n","   'Proposes',\n","   'a',\n","   'two',\n","   '-',\n","   'stage',\n","   'open',\n","   'season',\n","   'for',\n","   'firm',\n","   'transportation',\n","   'services',\n","   'beginning',\n","   'in',\n","   '2003',\n","   ',',\n","   'with',\n","   'end',\n","   'users',\n","   'receiving',\n","   'a',\n","   'first',\n","   'option',\n","   'on',\n","   'available',\n","   'capacity',\n","   '.',\n","   '*'],\n","  ['*',\n","   'Maintains',\n","   'the',\n","   'core',\n","   'aggregation',\n","   'program',\n","   'with',\n","   'some',\n","   'adjustments',\n","   '.'],\n","  ['PG&E',\n","   'also',\n","   'anticipates',\n","   'that',\n","   'the',\n","   'Core',\n","   'Procurement',\n","   'Incentive',\n","   'Mechanism',\n","   '-LRB-',\n","   'CPIM',\n","   '-RRB-',\n","   'will',\n","   'be',\n","   'similar',\n","   'to',\n","   'today',\n","   \"'s\",\n","   'mechanism',\n","   ',',\n","   'but',\n","   'will',\n","   'reflect',\n","   'the',\n","   'somewhat',\n","   'larger',\n","   'capacity',\n","   'holdings',\n","   'needed',\n","   'to',\n","   'meet',\n","   'anticipated',\n","   'increases',\n","   'in',\n","   'core',\n","   'demand',\n","   'and',\n","   'to',\n","   'meet',\n","   'a',\n","   '1',\n","   '-',\n","   'day',\n","   'in',\n","   '10',\n","   '-',\n","   'year',\n","   'cold',\n","   'weather',\n","   'event',\n","   '.'],\n","  ['This',\n","   'also',\n","   'will',\n","   'serve',\n","   'as',\n","   'a',\n","   'reminder',\n","   'that',\n","   'an',\n","   'all',\n","   '-',\n","   'Party',\n","   'meeting',\n","   'is',\n","   'scheduled',\n","   'at',\n","   'PG&E',\n","   \"'s\",\n","   'headquarters',\n","   'in',\n","   'San',\n","   'Francisco',\n","   'on',\n","   'January',\n","   '10',\n","   'and',\n","   '11',\n","   ',',\n","   'to',\n","   'discuss',\n","   'this',\n","   'proposal',\n","   'and',\n","   'to',\n","   'respond',\n","   'to',\n","   'your',\n","   'questions',\n","   '.'],\n","  ['We',\n","   'look',\n","   'forward',\n","   'to',\n","   'answering',\n","   'your',\n","   'questions',\n","   'and',\n","   'receiving',\n","   'your',\n","   'feedback',\n","   '.'],\n","  ['The',\n","   'attached',\n","   'documents',\n","   'include',\n","   'the',\n","   'GA',\n","   'II',\n","   'Settlement',\n","   'proposal',\n","   ',',\n","   'an',\n","   'Attachment',\n","   '-LRB-',\n","   'a',\n","   'copy',\n","   'of',\n","   'PG&E',\n","   \"'s\",\n","   'proposed',\n","   'Gas',\n","   'Rule',\n","   '27',\n","   '-RRB-',\n","   ',',\n","   'and',\n","   'a',\n","   'set',\n","   'of',\n","   'supporting',\n","   'workpapers',\n","   '.'],\n","  ['Finally',\n","   ',',\n","   'please',\n","   'note',\n","   'that',\n","   'the',\n","   'Settlement',\n","   'document',\n","   'and',\n","   'the',\n","   'Attachment',\n","   'are',\n","   'in',\n","   '\"',\n","   'Word',\n","   '2000',\n","   '\"',\n","   'format',\n","   '.'],\n","  ['We',\n","   'would',\n","   'be',\n","   'glad',\n","   'to',\n","   'provide',\n","   'the',\n","   'same',\n","   'documents',\n","   'in',\n","   'an',\n","   'earlier',\n","   'version',\n","   'of',\n","   'Word',\n","   ',',\n","   'upon',\n","   'request',\n","   'by',\n","   'individual',\n","   'Parties',\n","   '.'],\n","  ['We',\n","   'look',\n","   'forward',\n","   'to',\n","   'seeing',\n","   'you',\n","   'on',\n","   'January',\n","   '10',\n","   '-',\n","   '11',\n","   '.'],\n","  ['In',\n","   'the',\n","   'meantime',\n","   ',',\n","   'we',\n","   'extend',\n","   'our',\n","   'best',\n","   'wishes',\n","   'for',\n","   'a',\n","   'safe',\n","   'and',\n","   'happy',\n","   'holiday',\n","   'season',\n","   '.'],\n","  ['Frank',\n","   'Lindh',\n","   'Ray',\n","   'Williams',\n","   '-LRB-',\n","   '415',\n","   '-RRB-',\n","   '973-2776',\n","   '-LRB-',\n","   '415',\n","   '-RRB-',\n","   '973-3634'],\n","  ['<<',\n","   '12-20-00.doc',\n","   '>>',\n","   '<<',\n","   '27.doc',\n","   '>>',\n","   '<<',\n","   'Proposal.xls',\n","   '>>'],\n","  ['Greetings', 'Judge', 'Minkin', ':'],\n","  ['This',\n","   'is',\n","   'to',\n","   'inform',\n","   'that',\n","   'a',\n","   'representative',\n","   'of',\n","   'Enron',\n","   'Corp',\n","   'would',\n","   'like',\n","   'to',\n","   'address',\n","   'the',\n","   'Commission',\n","   'on',\n","   'the',\n","   'issue',\n","   'of',\n","   'utility',\n","   'rate',\n","   'stabilization',\n","   'plans',\n","   'at',\n","   'the',\n","   'Commission',\n","   \"'s\",\n","   'hearings',\n","   'scheduled',\n","   'for',\n","   'December',\n","   '27th',\n","   'and',\n","   '28th',\n","   '.'],\n","  ['Thank', 'you', '.'],\n","  ['Sincerely', ','],\n","  ['Jeffrey', 'Dasovich', 'Director', ',', 'Enron', 'Corp'],\n","  ['Attached',\n","   'is',\n","   'a',\n","   'draft',\n","   'of',\n","   'the',\n","   'talking',\n","   'points',\n","   'for',\n","   'the',\n","   'Commission',\n","   \"'s\",\n","   'hearings',\n","   '.'],\n","  ['Few', 'points', ':'],\n","  ['Our',\n","   'time',\n","   'is',\n","   'likely',\n","   'to',\n","   'be',\n","   'limited',\n","   'to',\n","   '5',\n","   '-',\n","   '10',\n","   'minutes',\n","   '.'],\n","  ['Mike',\n","   'Day',\n","   ',',\n","   'our',\n","   'outside',\n","   'counsel',\n","   ',',\n","   'will',\n","   'make',\n","   'the',\n","   'presentation',\n","   'on',\n","   'our',\n","   'behalf',\n","   '.'],\n","  ['Mike',\n","   'Day',\n","   'is',\n","   'fleshing',\n","   'out',\n","   'the',\n","   'legal',\n","   'details',\n","   'of',\n","   'our',\n","   'presentation',\n","   'and',\n","   'he',\n","   'will',\n","   'forward',\n","   'that',\n","   'along',\n","   'for',\n","   'folks',\n","   'review',\n","   'later',\n","   'today',\n","   '.'],\n","  ['Comments',\n","   'can',\n","   'be',\n","   'forwarded',\n","   'to',\n","   'me',\n","   'via',\n","   'email',\n","   ',',\n","   'pager',\n","   '-LRB-',\n","   '888.916.7184',\n","   '-RRB-',\n","   ',',\n","   'voicemail',\n","   '-LRB-',\n","   '415.782.7822',\n","   '-RRB-',\n","   ',',\n","   'or',\n","   'home',\n","   '-LRB-',\n","   '415.621.8317',\n","   '-RRB-',\n","   '.'],\n","  ['We',\n","   'will',\n","   'finalize',\n","   'the',\n","   'message',\n","   'points',\n","   'on',\n","   'tomorrow',\n","   \"'s\",\n","   'daily',\n","   'call',\n","   '-LRB-',\n","   '10',\n","   'AM',\n","   'CST',\n","   '-RRB-',\n","   '.'],\n","  ['The', 'call', 'in', 'number', 'is', '800.713.8600', '.'],\n","  ['Code', 'is', '80435', '.'],\n","  ['The',\n","   'Commission',\n","   \"'s\",\n","   'hearings',\n","   'begin',\n","   'tomorrow',\n","   'at',\n","   '10',\n","   'AM',\n","   '-LRB-',\n","   'PST',\n","   '-RRB-',\n","   '.'],\n","  ['Jeff', 'Dasovich'],\n","  ['Sent', 'by', ':', 'Jeff', 'Dasovich'],\n","  ['12/26/2000', '03:15', 'PM'],\n","  ['Attached',\n","   'is',\n","   'a',\n","   'draft',\n","   'of',\n","   'the',\n","   'talking',\n","   'points',\n","   'for',\n","   'the',\n","   'Commission',\n","   \"'s\",\n","   'hearings',\n","   '.'],\n","  ['Few', 'points', ':'],\n","  ['Our',\n","   'time',\n","   'is',\n","   'likely',\n","   'to',\n","   'be',\n","   'limited',\n","   'to',\n","   '5',\n","   '-',\n","   '10',\n","   'minutes',\n","   '.'],\n","  ['Mike',\n","   'Day',\n","   ',',\n","   'our',\n","   'outside',\n","   'counsel',\n","   ',',\n","   'will',\n","   'make',\n","   'the',\n","   'presentation',\n","   'on',\n","   'our',\n","   'behalf',\n","   '.'],\n","  ['Mike',\n","   'Day',\n","   'is',\n","   'fleshing',\n","   'out',\n","   'the',\n","   'legal',\n","   'details',\n","   'of',\n","   'our',\n","   'presentation',\n","   'and',\n","   'he',\n","   'will',\n","   'forward',\n","   'that',\n","   'along',\n","   'for',\n","   'folks',\n","   'review',\n","   'later',\n","   'today',\n","   '.'],\n","  ['Comments',\n","   'can',\n","   'be',\n","   'forwarded',\n","   'to',\n","   'me',\n","   'via',\n","   'email',\n","   ',',\n","   'pager',\n","   '-LRB-',\n","   '888.916.7184',\n","   '-RRB-',\n","   ',',\n","   'voicemail',\n","   '-LRB-',\n","   '415.782.7822',\n","   '-RRB-',\n","   ',',\n","   'or',\n","   'home',\n","   '-LRB-',\n","   '415.621.8317',\n","   '-RRB-',\n","   '.'],\n","  ['We',\n","   'will',\n","   'finalize',\n","   'the',\n","   'message',\n","   'points',\n","   'on',\n","   'tomorrow',\n","   \"'s\",\n","   'daily',\n","   'call',\n","   '-LRB-',\n","   '10',\n","   'AM',\n","   'CST',\n","   '-RRB-',\n","   '.'],\n","  ['The', 'call', 'in', 'number', 'is', '800.713.8600', '.'],\n","  ['Code', 'is', '80435', '.'],\n","  ['The',\n","   'Commission',\n","   \"'s\",\n","   'hearings',\n","   'begin',\n","   'tomorrow',\n","   'at',\n","   '10',\n","   'AM',\n","   '-LRB-',\n","   'PST',\n","   '-RRB-',\n","   '.'],\n","  ['Nice', 'job', '.'],\n","  ['Going', 'to', 'be', 'a', 'wild', 'ride', '.'],\n","  ['That', \"'s\", 'a', 'very', 'good', 'point', '.'],\n","  ['I', \"'ll\", 'make', 'the', 'change', '.'],\n","  ['Best', ','],\n","  ['Jeff'],\n","  ['Harry', 'Kingerski'],\n","  ['12/26/2000', '03:33', 'PM'],\n","  ['Jeff', '-'],\n","  ['instead',\n","   'of',\n","   'suggesting',\n","   'a',\n","   'specific',\n","   'rate',\n","   'increase',\n","   '-',\n","   '10',\n","   'or',\n","   '15',\n","   '%',\n","   ',',\n","   'I',\n","   'think',\n","   'we',\n","   'should',\n","   'acknowledge',\n","   'that',\n","   'a',\n","   '\"',\n","   'modest',\n","   '\"',\n","   'increase',\n","   'may',\n","   'be',\n","   'necessary',\n","   'and',\n","   'may',\n","   'in',\n","   'fact',\n","   'be',\n","   'desirable',\n","   '-',\n","   'but',\n","   'that',\n","   'the',\n","   'specific',\n","   'amount',\n","   'of',\n","   'increase',\n","   'should',\n","   'be',\n","   'reasoned',\n","   'and',\n","   'subject',\n","   'to',\n","   'well',\n","   'thought',\n","   'out',\n","   'evidence',\n","   'and',\n","   'hearings',\n","   ',',\n","   'not',\n","   'just',\n","   'determined',\n","   'by',\n","   'whim',\n","   '.'],\n","  ['In',\n","   'general',\n","   ',',\n","   'we',\n","   'should',\n","   'not',\n","   'be',\n","   'overly',\n","   'prescriptive',\n","   'at',\n","   'this',\n","   'point',\n","   'and',\n","   'I',\n","   'know',\n","   'you',\n","   'agree',\n","   'with',\n","   'that',\n","   '.'],\n","  ['Otherwise',\n","   ',',\n","   'I',\n","   'think',\n","   'you',\n","   'have',\n","   'captured',\n","   'the',\n","   'points',\n","   'excellently',\n","   '.'],\n","  ['We',\n","   \"'re\",\n","   'in',\n","   'the',\n","   'process',\n","   'of',\n","   'developing',\n","   'a',\n","   'strategy',\n","   'to',\n","   'take',\n","   'us',\n","   'through',\n","   'the',\n","   'next',\n","   'few',\n","   'months',\n","   '.'],\n","  ['But',\n","   'while',\n","   'the',\n","   '-LRB-',\n","   'otherwise',\n","   'perishable',\n","   '-RRB-',\n","   'thoughts',\n","   'are',\n","   'still',\n","   'fresh',\n","   'in',\n","   'my',\n","   'mind',\n","   'from',\n","   'the',\n","   'hearings',\n","   'on',\n","   'Monday',\n","   'and',\n","   'Tuesday',\n","   ',',\n","   'I',\n","   'wanted',\n","   'to',\n","   'throw',\n","   'out',\n","   'some',\n","   'observations',\n","   'for',\n","   'discussion',\n","   'in',\n","   'the',\n","   'days',\n","   '/',\n","   'weeks',\n","   'ahead',\n","   '.'],\n","  ['OBSERVATION',\n","   '--',\n","   'The',\n","   'pressure',\n","   'to',\n","   'finger',\n","   'somebody',\n","   'for',\n","   '\"',\n","   'price',\n","   'gouging',\n","   '\"',\n","   'is',\n","   'increasing',\n","   '.'],\n","  ['The',\n","   'administration',\n","   'is',\n","   'hell',\n","   'bent',\n","   'on',\n","   'finding',\n","   'a',\n","   '\"',\n","   'fall',\n","   'guy',\n","   '.',\n","   '\"'],\n","  ['The',\n","   'price',\n","   'spikes',\n","   'pose',\n","   'real',\n","   'political',\n","   'risks',\n","   'for',\n","   'Davis',\n","   'and',\n","   'he',\n","   'and',\n","   'his',\n","   'folks',\n","   'need',\n","   'and',\n","   'want',\n","   'an',\n","   'easy',\n","   'way',\n","   'out',\n","   '.'],\n","  ['His',\n","   'press',\n","   'release',\n","   'following',\n","   'the',\n","   'hearing',\n","   'renewed',\n","   'the',\n","   'call',\n","   'for',\n","   '\"',\n","   'refunds',\n","   '.',\n","   '\"'],\n","  ['On',\n","   'my',\n","   'panel',\n","   ',',\n","   'Loretta',\n","   'Lynch',\n","   'asked',\n","   'Reliant',\n","   'and',\n","   'Duke',\n","   'to',\n","   'supply',\n","   'her',\n","   'with',\n","   'the',\n","   'details',\n","   'of',\n","   'the',\n","   'contracts',\n","   'they',\n","   'cut',\n","   'to',\n","   'sell',\n","   'their',\n","   'power',\n","   'forward',\n","   'to',\n","   'marketers',\n","   '.'],\n","  ['And', 'Carl', 'Wood', \"'s\", 'remarks', 'were', 'extreme', '.'],\n","  ['At',\n","   'the',\n","   'Barton',\n","   'hearing',\n","   ',',\n","   'a',\n","   'liberal',\n","   'democrat',\n","   '-LRB-',\n","   'Filner',\n","   '-RRB-',\n","   'and',\n","   'a',\n","   'conservative',\n","   'Republican',\n","   '-LRB-',\n","   'Hunter',\n","   '-RRB-',\n","   'locked',\n","   'arms',\n","   'in',\n","   'calling',\n","   'for',\n","   'refunds',\n","   '.'],\n","  ['Bilbray', 'joined', 'the', '\"', 'gouging', '\"', 'band', 'wagon', '.'],\n","  ['The',\n","   'utilities',\n","   'repeatedly',\n","   'called',\n","   'on',\n","   'FERC',\n","   'to',\n","   'do',\n","   'a',\n","   '\"',\n","   'real',\n","   '\"',\n","   'investigation',\n","   ',',\n","   'with',\n","   'hearings',\n","   ',',\n","   'testimony',\n","   ',',\n","   'data',\n","   'discovery',\n","   '---',\n","   'the',\n","   'works',\n","   '.'],\n","  ['On',\n","   'the',\n","   'positive',\n","   'side',\n","   ',',\n","   'the',\n","   'FERC',\n","   'commissioners',\n","   'lauded',\n","   'Wolak',\n","   ',',\n","   'his',\n","   'analysis',\n","   ',',\n","   'and',\n","   'his',\n","   'remarks',\n","   'on',\n","   'the',\n","   'panel',\n","   '.'],\n","  ['Wolak',\n","   'said',\n","   'somewhat',\n","   'emphatically',\n","   'that',\n","   'the',\n","   'nature',\n","   'of',\n","   'California',\n","   \"'s\",\n","   'market',\n","   'structure',\n","   'makes',\n","   'it',\n","   'impossible',\n","   'to',\n","   'single',\n","   'out',\n","   'a',\n","   'single',\n","   'participant',\n","   'as',\n","   'the',\n","   'culprit',\n","   '.'],\n","  ['He',\n","   'also',\n","   'stated',\n","   'that',\n","   'just',\n","   'everyone',\n","   \"'s\",\n","   'just',\n","   'acting',\n","   'in',\n","   'their',\n","   'own',\n","   'self',\n","   '-',\n","   'interest',\n","   ',',\n","   'responding',\n","   'to',\n","   'the',\n","   'screwed',\n","   'incentives',\n","   'embedded',\n","   'in',\n","   'the',\n","   'structure',\n","   '.'],\n","  ['IMPLICATION',\n","   '--',\n","   'It',\n","   'seems',\n","   'prudent',\n","   'for',\n","   'Enron',\n","   'to',\n","   'understand',\n","   'better',\n","   'its',\n","   'risks',\n","   'of',\n","   'getting',\n","   'fingered',\n","   '.'],\n","  ['In',\n","   'the',\n","   'best',\n","   'case',\n","   ',',\n","   'the',\n","   'clamoring',\n","   'for',\n","   'a',\n","   '\"',\n","   'refund',\n","   '\"',\n","   'subsides',\n","   '.'],\n","  ['In',\n","   'which',\n","   'case',\n","   ',',\n","   'the',\n","   'only',\n","   'cost',\n","   'to',\n","   'Enron',\n","   'is',\n","   'the',\n","   'internal',\n","   'cost',\n","   'incurred',\n","   'to',\n","   'understand',\n","   'better',\n","   'the',\n","   'risks',\n","   'of',\n","   'getting',\n","   'fingered',\n","   '.'],\n","  ['In',\n","   'the',\n","   'medium',\n","   'case',\n","   ',',\n","   'investigations',\n","   'find',\n","   'that',\n","   'Enron',\n","   '-LRB-',\n","   'like',\n","   'others',\n","   '-RRB-',\n","   '\"',\n","   'played',\n","   'by',\n","   'the',\n","   'rules',\n","   ',',\n","   '\"',\n","   'but',\n","   'the',\n","   'rules',\n","   'stunk',\n","   ',',\n","   'and',\n","   'Enron',\n","   'profited',\n","   'at',\n","   'the',\n","   'expense',\n","   'of',\n","   'California',\n","   'consumers',\n","   '.'],\n","  ['You', \"'re\", 'right', ',', 'Sue', '.'],\n","  ['Rates',\n","   'ca',\n","   \"n't\",\n","   'go',\n","   'up',\n","   'w/out',\n","   'declaring',\n","   'the',\n","   'rate',\n","   'freeze',\n","   'over',\n","   'in',\n","   'some',\n","   'fashion',\n","   '---',\n","   'trying',\n","   'to',\n","   'finesse',\n","   'it',\n","   '.'],\n","  ['Thanks', 'very', 'much', 'for', 'the', 'comments', '.'],\n","  ['Harry',\n","   'also',\n","   'had',\n","   'a',\n","   'good',\n","   'comment',\n","   '---',\n","   'do',\n","   \"n't\",\n","   'specify',\n","   'the',\n","   'amount',\n","   'of',\n","   'rate',\n","   'increase',\n","   'in',\n","   'our',\n","   'comments',\n","   ';',\n","   'rather',\n","   'note',\n","   'that',\n","   'the',\n","   'rate',\n","   'increase',\n","   'needs',\n","   'to',\n","   'be',\n","   'well',\n","   '-',\n","   'reasoned',\n","   'and',\n","   'based',\n","   'on',\n","   'facts',\n","   'and',\n","   'evidence',\n","   '.'],\n","  ['Will', 'make', 'that', 'change', '.'],\n","  ['\"', 'Katie', 'Kaplan', '\"', '<', '>'],\n","  ['10/27/2000', '06:20', 'PM'],\n","  ['Please', 'respond', 'to', 'kaplan'],\n","  ['Greetings', ':'],\n","  ['IEP',\n","   'will',\n","   'be',\n","   'hosting',\n","   'a',\n","   'dinner',\n","   'for',\n","   'California',\n","   'Governor',\n","   'Gray',\n","   'Davis',\n","   'on',\n","   'Thursday',\n","   ',',\n","   'December',\n","   '7',\n","   ',',\n","   '2000',\n","   'at',\n","   'the',\n","   'historic',\n","   'Julia',\n","   'Morgan',\n","   'House',\n","   'in',\n","   'Sacramento',\n","   '.'],\n","  ['We',\n","   'will',\n","   'be',\n","   'targeting',\n","   'to',\n","   'raise',\n","   'at',\n","   'least',\n","   '$',\n","   '100,000',\n","   'so',\n","   'company',\n","   'contributions',\n","   'will',\n","   'range',\n","   'from',\n","   '$',\n","   '10,000',\n","   '-',\n","   '$',\n","   '20,000',\n","   'per',\n","   'person',\n","   '-LRB-',\n","   '$',\n","   '10',\n","   'k',\n","   'minimum',\n","   'per',\n","   'person',\n","   '-RRB-',\n","   'depending',\n","   'on',\n","   'the',\n","   'number',\n","   'of',\n","   'respondents',\n","   '.'],\n","  ['We',\n","   'have',\n","   'already',\n","   'received',\n","   'firm',\n","   'commitments',\n","   'from',\n","   '3',\n","   'companies',\n","   '.'],\n","  ['If',\n","   'you',\n","   'are',\n","   'interested',\n","   'in',\n","   'attending',\n","   'please',\n","   'e-mail',\n","   'me',\n","   'as',\n","   'soon',\n","   'as',\n","   'possible',\n","   '.'],\n","  ['A',\n","   'formal',\n","   'invitation',\n","   'will',\n","   'follow',\n","   'to',\n","   'those',\n","   'who',\n","   'respond',\n","   '.'],\n","  ['We',\n","   'need',\n","   'responses',\n","   'or',\n","   'direction',\n","   'by',\n","   'no',\n","   'later',\n","   'than',\n","   'COB',\n","   'on',\n","   'Monday',\n","   ',',\n","   'October',\n","   '30',\n","   ',',\n","   '2000',\n","   '.'],\n","  ['Please', 'contact', 'me', 'with', 'any', 'questions', '.'],\n","  ['Thank', 'you', ','],\n","  ['Katie',\n","   'Kaplan',\n","   'Manager',\n","   'of',\n","   'Policy',\n","   'IEP',\n","   '-LRB-',\n","   '916',\n","   '-RRB-',\n","   '448-9499'],\n","  ['Congratulations', '.'],\n","  ['Everyone',\n","   'is',\n","   'extremely',\n","   'pleased',\n","   'that',\n","   'you',\n","   \"'re\",\n","   'joining',\n","   '.'],\n","  ['Best',\n","   'of',\n","   'luck',\n","   'and',\n","   'very',\n","   'much',\n","   'looking',\n","   'forward',\n","   'to',\n","   'working',\n","   'together',\n","   '.'],\n","  ['Best', ','],\n","  ['Jeff'],\n","  ['I', \"'ll\", 'believe', 'it', 'when', 'I', 'see', 'it', '.'],\n","  ['Seems',\n","   'like',\n","   'a',\n","   'good',\n","   'idea',\n","   'to',\n","   'keep',\n","   'the',\n","   'heat',\n","   'on',\n","   'Hoecker',\n","   '&',\n","   'Co.',\n","   'right',\n","   'up',\n","   'until',\n","   'Nov.',\n","   '1',\n","   '.'],\n","  ['Thanks', '.'],\n","  ['I',\n","   \"'m\",\n","   'glad',\n","   'they',\n","   'want',\n","   'to',\n","   'follow',\n","   '-',\n","   'up',\n","   'with',\n","   'Steve',\n","   '-LRB-',\n","   'I',\n","   \"'ve\",\n","   'been',\n","   'pushing',\n","   'it',\n","   '-RRB-',\n","   'and',\n","   'I',\n","   \"'ve\",\n","   'got',\n","   'some',\n","   'follow',\n","   '-',\n","   'up',\n","   'as',\n","   'well',\n","   'based',\n","   'on',\n","   'chats',\n","   'I',\n","   'had',\n","   'in',\n","   'the',\n","   'afternoon',\n","   'on',\n","   'Friday',\n","   'with',\n","   'folks',\n","   'post-call',\n","   '.'],\n","  ['Let', \"'s\", 'regroup', 'on', 'Monday', '.'],\n","  ['I', \"'ll\", 'be', 'in', 'Portland', 'but', 'can', 'call', 'you', '.'],\n","  ['Best', ','],\n","  ['Jeff'],\n","  ['Jeremy', 'Meier', '<', '>'],\n","  ['10/29/2000', '11:48', 'AM'],\n","  ['Jeff', ':'],\n","  ['FYI',\n","   ',',\n","   'we',\n","   'had',\n","   'an',\n","   'instructive',\n","   'rest',\n","   'of',\n","   'the',\n","   'conference',\n","   'call',\n","   'on',\n","   'Friday',\n","   'with',\n","   'Sue',\n","   'and',\n","   'Robbie',\n","   'et',\n","   'al',\n","   '.'],\n","  ['They',\n","   'indicated',\n","   'they',\n","   'could',\n","   'use',\n","   'Steve',\n","   \"'s\",\n","   'help',\n","   'face',\n","   'to',\n","   'face',\n","   'at',\n","   'some',\n","   'point',\n","   '.'],\n","  ['We',\n","   'are',\n","   'following',\n","   'up',\n","   'with',\n","   'Sue',\n","   'and',\n","   'Robbie',\n","   'on',\n","   'a',\n","   'couple',\n","   'legal',\n","   'issues',\n","   ',',\n","   'case',\n","   'law',\n","   'and',\n","   'MSA',\n","   'self',\n","   '-',\n","   'certification',\n","   'language',\n","   ',',\n","   'and',\n","   'let',\n","   'me',\n","   'know',\n","   'if',\n","   'you',\n","   'have',\n","   'additional',\n","   'items',\n","   '.'],\n","  ['We',\n","   'await',\n","   'approval',\n","   'on',\n","   'the',\n","   'final',\n","   'tariff',\n","   'language',\n","   'and',\n","   'can',\n","   'then',\n","   'file',\n","   'at',\n","   'the',\n","   'CPUC',\n","   '.'],\n","  ['Let', 'me', 'know', 'what', 'schedule', 'works', 'for', 'you', '.'],\n","  ['Also',\n","   ',',\n","   'can',\n","   'you',\n","   'confirm',\n","   'the',\n","   'correct',\n","   'names',\n","   ',',\n","   'email',\n","   'addresses',\n","   ',',\n","   'titles',\n","   'for',\n","   'those',\n","   'new',\n","   'folks',\n","   'on',\n","   'Friday',\n","   \"'s\",\n","   'call',\n","   ':',\n","   'Robbie',\n","   'Rossi',\n","   ',',\n","   'Michelle',\n","   ',',\n","   'Melissa',\n","   'Lloyd',\n","   '?'],\n","  ['Thanks', '.'],\n","  ['Jeremy', 'Meier', 'Blumenfeld', '&', 'Cohen'],\n","  ['Attached',\n","   'for',\n","   'your',\n","   'review',\n","   'are',\n","   'draft',\n","   'talking',\n","   'points',\n","   'for',\n","   'the',\n","   'Cal',\n","   'Energy',\n","   'Markets',\n","   'conference',\n","   'I',\n","   \"'m\",\n","   'speaking',\n","   'at',\n","   'on',\n","   'Thursday',\n","   'in',\n","   'SF',\n","   '.'],\n","  ['All',\n","   'comments',\n","   ',',\n","   'suggestions',\n","   ',',\n","   'etc.',\n","   'are',\n","   'appreciated',\n","   '.'],\n","  ['Thanks', '.'],\n","  ['Yes', ',', 'I', 'would', 'like', 'to', 'participate', '.'],\n","  ['Thanks', '.'],\n","  ['thanks', 'a', 'million', '.'],\n","  ['talk', 'to', 'you', 'then', '.'],\n","  ['10/31/2000', '03:48', 'PM'],\n","  ['Here', \"'s\", 'the', 'info', 'for', 'calling', 'in', '--', 'thanks', '!'],\n","  ['Lara'],\n","  ['Angie', 'Buis'],\n","  ['10/31/00', '02:17', 'PM'],\n","  ['The',\n","   'call',\n","   '-',\n","   'in',\n","   'number',\n","   'and',\n","   'instructions',\n","   'for',\n","   'the',\n","   '11/2',\n","   '8:30',\n","   'a.m.',\n","   'meeting',\n","   'are',\n","   'as',\n","   'follows',\n","   ':'],\n","  ['Everyone',\n","   'will',\n","   'dial',\n","   'the',\n","   'toll',\n","   'free',\n","   'number',\n","   '1-877-331-6867',\n","   '.'],\n","  ['All',\n","   'the',\n","   'outside',\n","   'participants',\n","   'will',\n","   'be',\n","   'prompted',\n","   'to',\n","   'enter',\n","   'their',\n","   'access',\n","   'code',\n","   ',',\n","   'which',\n","   'is',\n","   '600-480',\n","   '.'],\n","  ['Wayne',\n","   ',',\n","   'your',\n","   'access',\n","   'code',\n","   '-LRB-',\n","   'room',\n","   '4434',\n","   '-RRB-',\n","   'after',\n","   'dialing',\n","   'the',\n","   'toll',\n","   'free',\n","   'number',\n","   'will',\n","   'be',\n","   '857-771',\n","   '.'],\n","  ['I',\n","   'have',\n","   'asked',\n","   'for',\n","   '4',\n","   'outside',\n","   'ports',\n","   'and',\n","   'should',\n","   'anyone',\n","   'else',\n","   'need',\n","   'to',\n","   'join',\n","   'in',\n","   ',',\n","   'they',\n","   'may',\n","   'do',\n","   'so',\n","   'with',\n","   'the',\n","   'access',\n","   'code',\n","   'and',\n","   'without',\n","   'operator',\n","   'assistance',\n","   '.'],\n","  ['The', 'duration', 'of', 'the', 'call', 'is', '3.5', 'hours', '.'],\n","  ['The',\n","   'call',\n","   'will',\n","   'terminate',\n","   'once',\n","   'everyone',\n","   'has',\n","   'hung',\n","   'up',\n","   '.'],\n","  ['Please',\n","   'let',\n","   'me',\n","   'know',\n","   'if',\n","   'any',\n","   'of',\n","   'you',\n","   'need',\n","   'additional',\n","   'information',\n","   '.'],\n","  ['Thanks', '.'],\n","  ['Angie', 'Buis', 'EBS', '-', 'Tax', 'x-37097'],\n","  ['Attached',\n","   'for',\n","   'your',\n","   'review',\n","   'are',\n","   'copies',\n","   'of',\n","   'the',\n","   'settlement',\n","   'documents',\n","   'that',\n","   'were',\n","   'filed',\n","   'today',\n","   'in',\n","   'the',\n","   'Gas',\n","   'Industry',\n","   'Restructuring',\n","   '/',\n","   'Natural',\n","   'Gas',\n","   'Strategy',\n","   'proceeding',\n","   ',',\n","   'including',\n","   'the',\n","   'Motion',\n","   'for',\n","   'Approval',\n","   'of',\n","   'the',\n","   'Comprehensive',\n","   'Settlement',\n","   'that',\n","   'is',\n","   'supported',\n","   'by',\n","   'thirty',\n","   'signatories',\n","   'to',\n","   'the',\n","   'Comprehensive',\n","   'Settlement',\n","   ',',\n","   'the',\n","   'Comprehensive',\n","   'Settlement',\n","   'document',\n","   'itself',\n","   ',',\n","   'and',\n","   'the',\n","   'various',\n","   'appendices',\n","   'to',\n","   'the',\n","   'settlement',\n","   '.?'],\n","  ['Because',\n","   'a',\n","   'number',\n","   'of',\n","   'the',\n","   'declarations',\n","   'and',\n","   'signature',\n","   'pages',\n","   'are',\n","   'not',\n","   'yet',\n","   'available',\n","   'electronically',\n","   ',',\n","   'they',\n","   'have',\n","   'not',\n","   'been',\n","   'included',\n","   'with',\n","   'this',\n","   'note',\n","   '.?'],\n","  ['Hard',\n","   'copies',\n","   'of',\n","   'the',\n","   'Comprehensive',\n","   'Settlement',\n","   ',',\n","   'including',\n","   'all',\n","   'declarations',\n","   'and',\n","   'signature',\n","   'pages',\n","   ',',\n","   'are',\n","   'being',\n","   'shipped',\n","   'tonight',\n","   'via',\n","   'US',\n","   'mail',\n","   'to',\n","   'all',\n","   'parties',\n","   'on',\n","   'the',\n","   'service',\n","   'list',\n","   '.?'],\n","  ['Additional',\n","   'printed',\n","   'copies',\n","   'should',\n","   'be',\n","   'available',\n","   'within',\n","   'the',\n","   'next',\n","   'day',\n","   'or',\n","   'so',\n","   'and',\n","   'I',\n","   'will',\n","   'make',\n","   'them',\n","   'available',\n","   'to',\n","   'all',\n","   'of',\n","   'you',\n","   '-',\n","   'just',\n","   'let',\n","   'me',\n","   'know',\n","   'how',\n","   'many',\n","   'copies',\n","   'you',\n","   'need',\n","   '.'],\n","  ['I',\n","   'would',\n","   'like',\n","   'to',\n","   'thank',\n","   'all',\n","   'of',\n","   'the',\n","   'parties',\n","   'who',\n","   'participated',\n","   'in',\n","   'this',\n","   'settlement',\n","   'process',\n","   '.?'],\n","  ['You',\n","   'have',\n","   'all',\n","   'devoted',\n","   'considerable',\n","   'time',\n","   ',',\n","   'resources',\n","   'and',\n","   'spirit',\n","   'in',\n","   'the',\n","   'preparation',\n","   'of',\n","   'this',\n","   'document',\n","   '-',\n","   'and',\n","   'it',\n","   'shows',\n","   '.?'],\n","  ['We',\n","   'now',\n","   'have',\n","   'a',\n","   'settlement',\n","   'before',\n","   'the',\n","   'Commission',\n","   'that',\n","   'includes',\n","   'ratepayer',\n","   'advocates',\n","   ',',\n","   'commercial',\n","   'and',\n","   'industrial',\n","   'customers',\n","   ',',\n","   'electric',\n","   'generators',\n","   ',',\n","   'marketers',\n","   ',',\n","   'shippers',\n","   ',',\n","   'independent',\n","   'storage',\n","   'providers',\n","   ',?',\n","   'gas',\n","   'suppliers',\n","   ',?',\n","   'producers',\n","   ',',\n","   'utilities',\n","   ',',\n","   'aggregators',\n","   ',',\n","   'pipeline',\n","   'companies',\n","   ',',\n","   'wholesale',\n","   'customers',\n","   ',',\n","   'municipalities',\n","   ',',\n","   'and',\n","   'retail',\n","   'mass',\n","   'marketers',\n","   ',',\n","   'among',\n","   'others',\n","   '.?'],\n","  ['While',\n","   'we',\n","   'should',\n","   'be',\n","   'proud',\n","   'of',\n","   'our',\n","   'accomplishment',\n","   ',',\n","   'we',\n","   'now',\n","   'must',\n","   'turn',\n","   'to',\n","   'the',\n","   'task',\n","   'of',\n","   'getting',\n","   'our',\n","   'testimony',\n","   'ready',\n","   'by',\n","   'May',\n","   '5',\n","   'deadline',\n","   '.?'],\n","  ['Assignments',\n","   'have',\n","   'already',\n","   'been',\n","   'made',\n","   'and',\n","   'I',\n","   'will',\n","   'schedule',\n","   'a',\n","   'conference',\n","   'call',\n","   'later',\n","   'this',\n","   'week',\n","   'to',\n","   'discuss',\n","   'related',\n","   'details',\n","   '.?'],\n","  ['So', 'much', 'for', 'resting', 'on', 'our', 'laurels', '.?'],\n","  ['Once',\n","   'again',\n","   ',',\n","   'thank',\n","   'you',\n","   'all',\n","   'for',\n","   'an',\n","   'outstanding',\n","   'accomplishment',\n","   '.'],\n","  ['<<',\n","   'ld2d-#69366-1.DOC',\n","   '>>',\n","   '<<',\n","   'ld2d-#69345-1.DOC',\n","   '>>',\n","   '?',\n","   '<<',\n","   'ld2d-#69397-1.DOC',\n","   '>>',\n","   '<<',\n","   'ld2d-#69396-1.DOC',\n","   '>>',\n","   '<<',\n","   'ld2d-#69377-1.XLS',\n","   '>>',\n","   '<<',\n","   'ld2d-#69381-1.DOC',\n","   '>>',\n","   '<<',\n","   'ld2d-#69366-1.DOC',\n","   '>>',\n","   '<<',\n","   'ld2d-#69336-1.XLS',\n","   '>>',\n","   '<<',\n","   '.doc',\n","   '>>',\n","   '<<',\n","   'ld2d-#69334-1.DOC',\n","   '>>',\n","   '<<',\n","   'ld2d-#69345-1.DOC',\n","   '>>'],\n","  ['-', 'ld2d-#69366-1.DOC'],\n","  ['-', 'ld2d-#69345-1.DOC'],\n","  ['-', 'ld2d-#69397-1.DOC'],\n","  ['-', 'ld2d-#69396-1.DOC'],\n","  ['-', 'ld2d-#69377-1.XLS'],\n","  ['-', 'ld2d-#69381-1.DOC'],\n","  ['-', 'ld2d-#69366-1.DOC'],\n","  ['-', 'ld2d-#69336-1.XLS'],\n","  ['-', '.doc'],\n","  ['-', 'ld2d-#69334-1.DOC'],\n","  ['-', 'ld2d-#69345-1.DOC'],\n","  ['Severin', 'Borenstein'],\n","  ['E.T.',\n","   'Grether',\n","   'Professor',\n","   'of',\n","   'Business',\n","   'Administration',\n","   'and',\n","   'Public',\n","   'Policy',\n","   'Director',\n","   'Haas',\n","   'School',\n","   'of',\n","   'Business',\n","   'U.C.',\n","   'Energy',\n","   'Institute',\n","   'University',\n","   'of',\n","   'California',\n","   '2539',\n","   'Channing',\n","   'Way',\n","   'Berkeley',\n","   ',',\n","   'CA',\n","   '94720-1900',\n","   'Berkeley',\n","   ',',\n","   'CA',\n","   '94720-5180',\n","   '-LRB-',\n","   'p',\n","   '-RRB-',\n","   '510-642-3689',\n","   '-LRB-',\n","   'p',\n","   '-RRB-',\n","   '510-642-5145',\n","   '-LRB-',\n","   'f',\n","   '-RRB-',\n","   '707-885-2508',\n","   'Email',\n","   ':',\n","   'WWW',\n","   ':'],\n","  ['Attached',\n","   'is',\n","   'a',\n","   'rough',\n","   'draft',\n","   'of',\n","   'my',\n","   'talking',\n","   'points',\n","   'for',\n","   'a',\n","   'panel',\n","   'I',\n","   \"'ll\",\n","   'be',\n","   'on',\n","   'at',\n","   'a',\n","   'CEM',\n","   'conference',\n","   'in',\n","   'SF',\n","   'on',\n","   'Thursday',\n","   'afternoon',\n","   '.'],\n","  ['Have',\n","   'distributed',\n","   'to',\n","   'Western',\n","   'GA',\n","   'team',\n","   '-LRB-',\n","   'plus',\n","   'Steffes',\n","   '-RRB-',\n","   'for',\n","   'comment',\n","   'and',\n","   'thought',\n","   'you',\n","   'may',\n","   'have',\n","   'some',\n","   ',',\n","   'too',\n","   '.'],\n","  ['Topic', 'for', 'panel', ',', '\"', 'PUC', 'Priorities', '.', '\"'],\n","  ['Goal',\n","   'is',\n","   'to',\n","   '-LRB-',\n","   'politely',\n","   '?',\n","   '-RRB-',\n","   'refute',\n","   'Loretta',\n","   'Lynch',\n","   \"'s\",\n","   'and',\n","   'Carl',\n","   'Woods',\n","   \"'\",\n","   'continued',\n","   'assertions',\n","   'that',\n","   '1',\n","   '-RRB-',\n","   'California',\n","   \"'s\",\n","   'move',\n","   'to',\n","   'deregulate',\n","   'was',\n","   'based',\n","   'solely',\n","   'on',\n","   'ideology',\n","   'with',\n","   'no',\n","   'basis',\n","   'in',\n","   'fact',\n","   'and',\n","   '2',\n","   '-RRB-',\n","   'the',\n","   'solution',\n","   'is',\n","   'to',\n","   'turn',\n","   'back',\n","   'the',\n","   'clock',\n","   'to',\n","   'command',\n","   '-',\n","   'and',\n","   '-',\n","   'control',\n","   'regulation',\n","   '.'],\n","  ['The',\n","   'FERC',\n","   'order',\n","   'tomorrow',\n","   'is',\n","   'likely',\n","   'to',\n","   'alter',\n","   'the',\n","   'points',\n","   'somewhat',\n","   '.'],\n","  ['Comments', 'are', 'much', 'appreciated', '.'],\n","  ['Best', ','],\n","  ['Jeff'],\n","  ['Chris', ':'],\n","  ['As',\n","   'we',\n","   'discussed',\n","   'yesterday',\n","   ',',\n","   'Laird',\n","   'and',\n","   'I',\n","   'spoke',\n","   'and',\n","   'we',\n","   'think',\n","   'that',\n","   'the',\n","   'presentation',\n","   'is',\n","   'good',\n","   'to',\n","   'go',\n","   'for',\n","   'Thursday',\n","   '.'],\n","  ['We',\n","   \"'ll\",\n","   'need',\n","   'to',\n","   'update',\n","   'the',\n","   'numbers',\n","   'for',\n","   'the',\n","   'offer',\n","   'we',\n","   'made',\n","   'to',\n","   'S.D.',\n","   'last',\n","   'week',\n","   '.'],\n","  ['You',\n","   'had',\n","   'mentioned',\n","   'that',\n","   'you',\n","   'might',\n","   'want',\n","   'to',\n","   'include',\n","   'a',\n","   'shaped',\n","   'product',\n","   '.'],\n","  ['You', 'still', 'considering', 'it', '?'],\n","  ['Let',\n","   'us',\n","   'know',\n","   'and',\n","   'we',\n","   'can',\n","   'add',\n","   'it',\n","   ',',\n","   'and',\n","   'make',\n","   'any',\n","   'other',\n","   'changes',\n","   'you',\n","   \"'d\",\n","   'like',\n","   'to',\n","   'make',\n","   'at',\n","   'this',\n","   'end',\n","   '.'],\n","  ['My',\n","   'flight',\n","   'gets',\n","   'into',\n","   'S.D.',\n","   'at',\n","   'at',\n","   '8:35',\n","   'on',\n","   'southwest',\n","   '.'],\n","  ['Best', ','],\n","  ['Jeff'],\n","  ['Sandi',\n","   'sez',\n","   'it',\n","   \"'s\",\n","   'actually',\n","   'happening',\n","   'at',\n","   '10',\n","   'AM',\n","   'and',\n","   'it',\n","   \"'s\",\n","   'renewable',\n","   '-',\n","   'focused',\n","   '.'],\n","  ['Listening',\n","   'to',\n","   'the',\n","   'Edison',\n","   'call',\n","   'w/',\n","   'investors',\n","   'Edison',\n","   'says',\n","   'they',\n","   'will',\n","   'pay',\n","   'everyone',\n","   'at',\n","   'the',\n","   'same',\n","   'time',\n","   '-LRB-',\n","   '\"',\n","   'big',\n","   'bang',\n","   '\"',\n","   'approach',\n","   '-RRB-',\n","   'sometime',\n","   'in',\n","   'Q1',\n","   \"'02\",\n","   '.'],\n","  ['My',\n","   'concern',\n","   'is',\n","   'that',\n","   'between',\n","   'now',\n","   'and',\n","   'then',\n","   'Dunn',\n","   ',',\n","   'the',\n","   'AG',\n","   'have',\n","   'the',\n","   'time',\n","   'and',\n","   'resources',\n","   'to',\n","   'make',\n","   'a',\n","   'heckuvalot',\n","   'of',\n","   'mischief',\n","   ',',\n","   'which',\n","   'could',\n","   'be',\n","   'detrimental',\n","   'to',\n","   'generators',\n","   '/',\n","   'marketers',\n","   \"'\",\n","   'claims',\n","   '.'],\n","  ['Investors',\n","   'are',\n","   'asking',\n","   'what',\n","   'Edison',\n","   'intends',\n","   'for',\n","   'QFs',\n","   'and',\n","   'generators',\n","   '--',\n","   'asking',\n","   'about',\n","   'haircuts',\n","   'in',\n","   'particular',\n","   '--',\n","   'and',\n","   'Edison',\n","   'is',\n","   'side',\n","   '-',\n","   'stepping',\n","   'the',\n","   'questions',\n","   '.'],\n","  ['Great', '.'],\n","  ['Figured',\n","   'they',\n","   \"'d\",\n","   'contacted',\n","   'them',\n","   ',',\n","   'but',\n","   'wanted',\n","   'to',\n","   'make',\n","   'sure',\n","   '.'],\n","  ['You',\n","   'know',\n","   'when',\n","   'the',\n","   'meeting',\n","   'with',\n","   'schedulers',\n","   'will',\n","   'be',\n","   '?'],\n","  ['I',\n","   'apologize',\n","   ',',\n","   'I',\n","   \"'m\",\n","   'on',\n","   'the',\n","   'road',\n","   'and',\n","   'have',\n","   \"n't\",\n","   'heard',\n","   'when',\n","   'that',\n","   'will',\n","   'be',\n","   '.'],\n","  ['I', \"'m\", 'thinking', 'that', 'I', 'may', 'want', 'to', 'attend', '.'],\n","  ['Thanks', '.'],\n","  ['Best', ','],\n","  ['Jeff'],\n","  ['Thanks',\n","   'for',\n","   'the',\n","   'info',\n","   '-',\n","   'a',\n","   'few',\n","   'people',\n","   'from',\n","   'our',\n","   'shop',\n","   'will',\n","   'be',\n","   'in',\n","   'attendance',\n","   './'],\n","  ['If',\n","   'you',\n","   'have',\n","   \"n't\",\n","   'heard',\n","   ',',\n","   'SoCal',\n","   \"'s\",\n","   'announced',\n","   'their',\n","   'abandoning',\n","   'windows',\n","   'for',\n","   'OFOs',\n","   '.'],\n","  ['They',\n","   \"'re\",\n","   'holding',\n","   '\"',\n","   'workshops',\n","   '\"',\n","   'on',\n","   'how',\n","   'it',\n","   'will',\n","   'all',\n","   'work',\n","   'soon',\n","   '.'],\n","  ['I', \"'ll\", 'get', 'you', 'the', 'announcement', '.'],\n","  ['Best', ','],\n","  ['Jeff'],\n","  ['Probing', 'the', \"'\", 'palace', 'coup', \"'\"],\n","  ['Electricity',\n","   ':',\n","   'A',\n","   'panel',\n","   'focuses',\n","   'on',\n","   'price',\n","   'hikes',\n","   'and',\n","   'the',\n","   'actions',\n","   'of',\n","   'the',\n","   'ISO',\n","   'president',\n","   '.'],\n","  ['September', '26', ',', '2001'],\n","  ['By', 'KIMBERLY', 'KINDY'],\n","  ['The', 'Orange', 'County', 'Register'],\n","  ['SACRAMENTO'],\n","  ['A',\n","   'state',\n","   'Senate',\n","   'committee',\n","   'is',\n","   'set',\n","   'today',\n","   'to',\n","   'start',\n","   'serving',\n","   '16',\n","   'subpoenas',\n","   'on',\n","   'electricity',\n","   'producers',\n","   'and',\n","   'officials',\n","   'who',\n","   'manage',\n","   'California',\n","   \"'s\",\n","   'energy',\n","   'grid',\n","   'to',\n","   'determine',\n","   'whether',\n","   'they',\n","   'acted',\n","   'in',\n","   'concert',\n","   'to',\n","   'manipulate',\n","   'energy',\n","   'prices',\n","   '.'],\n","  ['The',\n","   'investigative',\n","   'committee',\n","   ',',\n","   'headed',\n","   'by',\n","   'state',\n","   'Sen.',\n","   'Joe',\n","   'Dunn',\n","   ',',\n","   'D',\n","   '-',\n","   'Santa',\n","   'Ana',\n","   ',',\n","   'is',\n","   'focusing',\n","   'on',\n","   'a',\n","   'series',\n","   'of',\n","   'events',\n","   'last',\n","   'fall',\n","   'filled',\n","   'with',\n","   'enough',\n","   'Shakespearean',\n","   'plot',\n","   'twists',\n","   'and',\n","   'intrigue',\n","   'that',\n","   'it',\n","   'has',\n","   'earned',\n","   'a',\n","   'name',\n","   'around',\n","   'the',\n","   'Capitol',\n","   ':',\n","   '\"',\n","   'the',\n","   'palace',\n","   'coup',\n","   '.',\n","   '\"'],\n","  ['Lawmakers',\n","   'and',\n","   'consumer',\n","   'groups',\n","   'allege',\n","   'that',\n","   'the',\n","   'events',\n","   '-',\n","   'directed',\n","   'by',\n","   'the',\n","   'man',\n","   'who',\n","   'heads',\n","   'the',\n","   'state',\n","   \"'s\",\n","   'energy',\n","   'grid',\n","   '-',\n","   'fueled',\n","   'the',\n","   'California',\n","   'energy',\n","   'crisis',\n","   ',',\n","   'pushed',\n","   'the',\n","   'state',\n","   'into',\n","   'the',\n","   'power',\n","   '-',\n","   'buying',\n","   'business',\n","   'and',\n","   'helped',\n","   'make',\n","   'billions',\n","   'of',\n","   'dollars',\n","   'for',\n","   'power',\n","   'producers',\n","   '.'],\n","  ['The',\n","   'central',\n","   'question',\n","   'behind',\n","   'the',\n","   'palace',\n","   'coup',\n","   'is',\n","   'whether',\n","   'Terry',\n","   'Winter',\n","   ',',\n","   'the',\n","   'president',\n","   'of',\n","   'the',\n","   'Independent',\n","   'System',\n","   'Operator',\n","   ',',\n","   'acted',\n","   'alone',\n","   'when',\n","   'he',\n","   'took',\n","   'steps',\n","   'to',\n","   'remove',\n","   'key',\n","   'price',\n","   'caps',\n","   'designed',\n","   'to',\n","   'limit',\n","   'the',\n","   'amount',\n","   'power',\n","   'generators',\n","   'could',\n","   'charge',\n","   '.'],\n","  ['Winter',\n","   'defied',\n","   'his',\n","   'own',\n","   'board',\n","   'and',\n","   'Gov.',\n","   'Gray',\n","   'Davis',\n","   'when',\n","   'he',\n","   'filed',\n","   'a',\n","   '50',\n","   '-',\n","   'page',\n","   'request',\n","   'to',\n","   'remove',\n","   'the',\n","   'caps',\n","   ',',\n","   'records',\n","   'and',\n","   'interviews',\n","   'show',\n","   '.'],\n","  ['\"',\n","   'I',\n","   'do',\n","   \"n't\",\n","   'know',\n","   'how',\n","   'these',\n","   'events',\n","   'could',\n","   'have',\n","   'taken',\n","   'place',\n","   'without',\n","   'some',\n","   'concerted',\n","   'effort',\n","   ',',\n","   '\"',\n","   'said',\n","   'Dunn',\n","   '.'],\n","  ['The',\n","   'subpoenas',\n","   'will',\n","   'force',\n","   'those',\n","   'involved',\n","   ',',\n","   'including',\n","   'Winter',\n","   ',',\n","   'to',\n","   'provide',\n","   'sworn',\n","   'testimony',\n","   'about',\n","   'the',\n","   'events',\n","   'to',\n","   'the',\n","   'committee',\n","   ',',\n","   'and',\n","   'to',\n","   'turn',\n","   'over',\n","   'e-mails',\n","   ',',\n","   'personal',\n","   'calendars',\n","   'and',\n","   'memos',\n","   '.'],\n","  ['Davis',\n","   'spokesman',\n","   'Steve',\n","   'Maviglio',\n","   'said',\n","   'the',\n","   'governor',\n","   'felt',\n","   '\"',\n","   'betrayed',\n","   '\"',\n","   'by',\n","   'the',\n","   'actions',\n","   'of',\n","   'Winter',\n","   '.'],\n","  ['\"',\n","   'The',\n","   'governor',\n","   'believes',\n","   'it',\n","   'was',\n","   'the',\n","   'defining',\n","   'moment',\n","   ',',\n","   'when',\n","   'what',\n","   'was',\n","   'a',\n","   'mounting',\n","   'problem',\n","   'turned',\n","   'into',\n","   'an',\n","   'instant',\n","   'crisis',\n","   ',',\n","   '\"',\n","   'Maviglio',\n","   'said',\n","   '.'],\n","  ['Winter',\n","   'refused',\n","   'comment',\n","   ',',\n","   'referring',\n","   'all',\n","   'questions',\n","   'to',\n","   'the',\n","   'public',\n","   'relations',\n","   'office',\n","   '.'],\n","  ['ISO',\n","   'spokesman',\n","   'Gregg',\n","   'Fishman',\n","   'said',\n","   'Dunn',\n","   \"'s\",\n","   'committee',\n","   'will',\n","   'find',\n","   'no',\n","   'criminal',\n","   'conduct',\n","   '.'],\n","  ['The',\n","   'decision',\n","   'was',\n","   'made',\n","   'by',\n","   'ISO',\n","   'upper',\n","   'management',\n","   'with',\n","   'one',\n","   'goal',\n","   'in',\n","   'mind',\n","   ':',\n","   'to',\n","   'keep',\n","   'the',\n","   'lights',\n","   'on',\n","   '.'],\n","  ['At',\n","   'the',\n","   'time',\n","   ',',\n","   'generators',\n","   'were',\n","   'refusing',\n","   'to',\n","   'sell',\n","   'power',\n","   'in',\n","   'California',\n","   'because',\n","   'of',\n","   'the',\n","   'price',\n","   'caps',\n","   '.'],\n","  ['\"', 'It', 'was', 'an', 'emergency', ',', '\"', 'Fishman', 'said', '.'],\n","  ['\"', 'We', 'had', 'to', 'take', 'action', '.', \"''\"],\n","  ['What',\n","   'became',\n","   'known',\n","   'as',\n","   'the',\n","   'palace',\n","   'coup',\n","   'began',\n","   'on',\n","   'Oct.',\n","   '26',\n","   'when',\n","   'ISO',\n","   'board',\n","   'members',\n","   'voted',\n","   'for',\n","   'severe',\n","   'restrictions',\n","   'on',\n","   'the',\n","   'amount',\n","   'of',\n","   'money',\n","   'electricity',\n","   'producers',\n","   'could',\n","   'charge',\n","   'for',\n","   'power',\n","   '.'],\n","  ['The',\n","   'restrictions',\n","   'would',\n","   'drive',\n","   'prices',\n","   'as',\n","   'low',\n","   'as',\n","   '$',\n","   '65',\n","   'per',\n","   'megawatt',\n","   '-',\n","   'nearly',\n","   '12',\n","   'times',\n","   'below',\n","   'the',\n","   '$',\n","   '750',\n","   'per',\n","   'megawatt',\n","   'limits',\n","   'of',\n","   'seven',\n","   'months',\n","   'earlier',\n","   '.'],\n","  ['\"',\n","   'They',\n","   '-LRB-',\n","   'electricity',\n","   'generators',\n","   '-RRB-',\n","   'grinned',\n","   'and',\n","   'beared',\n","   'the',\n","   '$',\n","   '750',\n","   'price',\n","   'cap',\n","   ',',\n","   'but',\n","   'this',\n","   'new',\n","   'plan',\n","   'by',\n","   'ISO',\n","   'was',\n","   'too',\n","   'much',\n","   ',',\n","   '\"',\n","   'said',\n","   'Dunn',\n","   ',',\n","   'whose',\n","   'committee',\n","   'has',\n","   'been',\n","   'investigating',\n","   'since',\n","   'March',\n","   '.'],\n","  ['\"', 'All', 'hell', 'broke', 'loose', '.', \"''\"],\n","  ['Records',\n","   'show',\n","   'that',\n","   'on',\n","   'Oct.',\n","   '31',\n","   ',',\n","   'power',\n","   'generators',\n","   'and',\n","   'electricity',\n","   'traders',\n","   'filed',\n","   'letters',\n","   'with',\n","   'the',\n","   'Federal',\n","   'Energy',\n","   'Regulatory',\n","   'Commission',\n","   ',',\n","   'demanding',\n","   'that',\n","   'the',\n","   'new',\n","   'plan',\n","   'be',\n","   'killed',\n","   '.'],\n","  ['The',\n","   'letters',\n","   ',',\n","   'six',\n","   'in',\n","   'all',\n","   ',',\n","   'were',\n","   'sent',\n","   'within',\n","   'two',\n","   'hours',\n","   'of',\n","   'each',\n","   'other',\n","   'and',\n","   'represented',\n","   'dozens',\n","   'of',\n","   'power',\n","   'generators',\n","   '.'],\n","  ['\"',\n","   'If',\n","   'not',\n","   'removed',\n","   'immediately',\n","   ',',\n","   'the',\n","   '-LRB-',\n","   'ISO',\n","   '-RRB-',\n","   'price',\n","   'cap',\n","   'will',\n","   'sow',\n","   'confusion',\n","   'in',\n","   'the',\n","   'market',\n","   ',',\n","   'threaten',\n","   'reliability',\n","   'and',\n","   'stifle',\n","   'new',\n","   'investment',\n","   'in',\n","   'generating',\n","   'capacity',\n","   ',',\n","   \"''\",\n","   'read',\n","   'one',\n","   'letter',\n","   'written',\n","   'by',\n","   'Duke',\n","   'Energy',\n","   'Vice',\n","   'President',\n","   'William',\n","   'Hall',\n","   'III',\n","   '.'],\n","  ['Although',\n","   'there',\n","   'is',\n","   'nothing',\n","   'illegal',\n","   'about',\n","   'the',\n","   'generators',\n","   'acting',\n","   'together',\n","   'to',\n","   'lobby',\n","   'against',\n","   'price',\n","   'caps',\n","   ',',\n","   'Dunn',\n","   'believes',\n","   'the',\n","   'letters',\n","   'and',\n","   'other',\n","   'actions',\n","   'around',\n","   'the',\n","   'same',\n","   'time',\n","   'showed',\n","   'clear',\n","   'coordination',\n","   'among',\n","   'energy',\n","   'officials',\n","   '.'],\n","  ['He',\n","   'said',\n","   'the',\n","   'main',\n","   'aim',\n","   'of',\n","   'the',\n","   'subpoenas',\n","   'will',\n","   'be',\n","   'to',\n","   'determine',\n","   'whether',\n","   'collusion',\n","   'occurred',\n","   'to',\n","   '\"',\n","   'fix',\n","   '\"',\n","   'prices',\n","   ',',\n","   'which',\n","   'would',\n","   'violate',\n","   'federal',\n","   'trade',\n","   'laws',\n","   '.'],\n","  ['In',\n","   'the',\n","   'Oct.',\n","   '31',\n","   'letters',\n","   ',',\n","   'electricity',\n","   'producers',\n","   'told',\n","   'federal',\n","   'officials',\n","   'that',\n","   'if',\n","   'price',\n","   'caps',\n","   'were',\n","   \"n't\",\n","   'removed',\n","   'it',\n","   'would',\n","   'lead',\n","   'to',\n","   'a',\n","   'collapse',\n","   'of',\n","   'the',\n","   'energy',\n","   'market',\n","   '.'],\n","  ['The', 'generators', 'got', 'their', 'way', '.'],\n","  ['The',\n","   'next',\n","   'day',\n","   ',',\n","   'the',\n","   'federal',\n","   'commission',\n","   'killed',\n","   'the',\n","   'new',\n","   'pricing',\n","   'plan',\n","   '.'],\n","  ['What',\n","   'was',\n","   'left',\n","   'in',\n","   'place',\n","   'was',\n","   'a',\n","   '$',\n","   '250',\n","   'price',\n","   'cap',\n","   'established',\n","   'five',\n","   'months',\n","   'earlier',\n","   '.'],\n","  ['Power',\n","   'producers',\n","   'then',\n","   'turned',\n","   'their',\n","   'attention',\n","   'toward',\n","   'killing',\n","   'that',\n","   'cap',\n","   ',',\n","   'saying',\n","   'they',\n","   'could',\n","   \"n't\",\n","   'make',\n","   'a',\n","   'profit',\n","   'even',\n","   'under',\n","   'these',\n","   'constraints',\n","   '.'],\n","  ['They',\n","   'began',\n","   'to',\n","   'withhold',\n","   'power',\n","   'from',\n","   'California',\n","   ',',\n","   'and',\n","   'on',\n","   'Dec.',\n","   '7',\n","   'the',\n","   'ISO',\n","   'declared',\n","   'its',\n","   'first',\n","   'Stage',\n","   '3',\n","   'emergency',\n","   'and',\n","   'braced',\n","   'for',\n","   'blackouts',\n","   ',',\n","   'which',\n","   'were',\n","   'narrowly',\n","   'averted',\n","   '.'],\n","  ['What',\n","   'followed',\n","   'the',\n","   'next',\n","   'day',\n","   'is',\n","   'considered',\n","   'by',\n","   'the',\n","   'governor',\n","   'and',\n","   'Dunn',\n","   'to',\n","   'be',\n","   'the',\n","   'pivotal',\n","   'moment',\n","   'of',\n","   'the',\n","   'energy',\n","   'crisis',\n","   '.'],\n","  ['Winter',\n","   ',',\n","   'who',\n","   'in',\n","   'his',\n","   'position',\n","   'as',\n","   'president',\n","   'and',\n","   'chief',\n","   'operating',\n","   'officer',\n","   'of',\n","   'the',\n","   'ISO',\n","   ',',\n","   'submitted',\n","   'a',\n","   '50',\n","   '-',\n","   'page',\n","   'emergency',\n","   'request',\n","   ',',\n","   'asking',\n","   'federal',\n","   'officials',\n","   'to',\n","   'abolish',\n","   'the',\n","   '$',\n","   '250',\n","   'price',\n","   'cap',\n","   '.'],\n","  ['Final',\n","   'authority',\n","   'over',\n","   'lifting',\n","   'the',\n","   'cap',\n","   'rested',\n","   'with',\n","   'the',\n","   'federal',\n","   'government',\n","   '.'],\n","  ['Neither',\n","   'the',\n","   'ISO',\n","   'board',\n","   ',',\n","   'which',\n","   'had',\n","   'established',\n","   'the',\n","   'price',\n","   'cap',\n","   ',',\n","   'nor',\n","   'the',\n","   'governor',\n","   'learned',\n","   'of',\n","   'Winter',\n","   \"'s\",\n","   'actions',\n","   'until',\n","   'the',\n","   'cap',\n","   'had',\n","   'been',\n","   'removed',\n","   '.'],\n","  ['In',\n","   'fact',\n","   ',',\n","   'the',\n","   'attorney',\n","   'who',\n","   'helped',\n","   'draft',\n","   'the',\n","   'emergency',\n","   'request',\n","   ',',\n","   'Charles',\n","   'Robinson',\n","   ',',\n","   'was',\n","   'in',\n","   'a',\n","   'meeting',\n","   'with',\n","   'representatives',\n","   'of',\n","   'the',\n","   'governor',\n","   'and',\n","   'ISO',\n","   'board',\n","   'members',\n","   'just',\n","   'hours',\n","   'before',\n","   'the',\n","   'filing',\n","   'was',\n","   'made',\n","   '.'],\n","  ['He', 'did', \"n't\", 'mention', 'anything', 'about', 'it', '.'],\n","  ['\"',\n","   'In',\n","   'retrospect',\n","   ',',\n","   'we',\n","   'should',\n","   'have',\n","   'told',\n","   'them',\n","   ',',\n","   \"''\",\n","   'Robinson',\n","   'said',\n","   '.'],\n","  ['With',\n","   'the',\n","   'price',\n","   'caps',\n","   'gone',\n","   ',',\n","   'the',\n","   'generators',\n","   'filed',\n","   'paperwork',\n","   'with',\n","   'federal',\n","   'regulators',\n","   'justifying',\n","   'higher',\n","   'costs',\n","   '.'],\n","  ['\"',\n","   'The',\n","   'ISO',\n","   'staff',\n","   'sat',\n","   'in',\n","   'a',\n","   'meeting',\n","   'with',\n","   'the',\n","   'governor',\n","   \"'s\",\n","   'key',\n","   'energy',\n","   'advisers',\n","   'with',\n","   'poker',\n","   'faces',\n","   ',',\n","   'not',\n","   'saying',\n","   'a',\n","   'word',\n","   'about',\n","   'something',\n","   'that',\n","   'was',\n","   'going',\n","   'on',\n","   'at',\n","   'the',\n","   'exact',\n","   'same',\n","   'moment',\n","   ',',\n","   \"''\",\n","   'Maviglio',\n","   'said',\n","   '.'],\n","  ['\"',\n","   'It',\n","   'was',\n","   'beyond',\n","   'belief',\n","   'that',\n","   'they',\n","   'failed',\n","   'to',\n","   'mention',\n","   'something',\n","   'so',\n","   'significant',\n","   '.'],\n","  ['This',\n","   'action',\n","   'accelerated',\n","   'the',\n","   'utilities',\n","   \"'\",\n","   'move',\n","   'toward',\n","   'bankruptcy',\n","   'and',\n","   'forced',\n","   'the',\n","   'governor',\n","   'to',\n","   'move',\n","   'the',\n","   'state',\n","   'into',\n","   'the',\n","   'power',\n","   '-',\n","   'buying',\n","   'business',\n","   '.',\n","   '\"'],\n","  ['Prices',\n","   'for',\n","   'electricity',\n","   'jumped',\n","   'from',\n","   'an',\n","   'average',\n","   'of',\n","   '$',\n","   '249',\n","   'a',\n","   'megawatt',\n","   'to',\n","   '$',\n","   '700',\n","   'a',\n","   'megawatt',\n","   'within',\n","   'three',\n","   'days',\n","   ',',\n","   'ISO',\n","   'records',\n","   'show',\n","   '.'],\n","  ['Dunn',\n","   'believes',\n","   'the',\n","   'resulting',\n","   'overcharges',\n","   'for',\n","   'electricity',\n","   'exceeded',\n","   '$',\n","   '30',\n","   'billion',\n","   '.'],\n","  ['Robinson',\n","   'said',\n","   'the',\n","   'filing',\n","   '-',\n","   'granted',\n","   'two',\n","   'hours',\n","   'after',\n","   'the',\n","   'request',\n","   '-',\n","   'helped',\n","   'rather',\n","   'than',\n","   'hurt',\n","   'Californians',\n","   '.'],\n","  ['Prices',\n","   ',',\n","   'he',\n","   'said',\n","   ',',\n","   'did',\n","   'not',\n","   'spike',\n","   'as',\n","   'a',\n","   'result',\n","   '.'],\n","  ['Instead',\n","   'they',\n","   'followed',\n","   'the',\n","   'skyrocketing',\n","   'price',\n","   'of',\n","   'natural',\n","   'gas',\n","   '-',\n","   'which',\n","   'is',\n","   'used',\n","   'to',\n","   'run',\n","   'power',\n","   'plants',\n","   'to',\n","   'generate',\n","   'electricity',\n","   '.'],\n","  ['Robinson',\n","   'said',\n","   'the',\n","   'emergency',\n","   'order',\n","   'allowed',\n","   'the',\n","   'ISO',\n","   'to',\n","   'secure',\n","   'refunds',\n","   'should',\n","   'overcharges',\n","   'for',\n","   'electricity',\n","   'be',\n","   'proven',\n","   'to',\n","   'federal',\n","   'officials',\n","   '.'],\n","  ['\"',\n","   'We',\n","   'believe',\n","   'the',\n","   'action',\n","   'we',\n","   'took',\n","   'addressed',\n","   'a',\n","   'severe',\n","   'concern',\n","   ',',\n","   \"''\",\n","   'Robinson',\n","   'said',\n","   '.'],\n","  ['\"',\n","   'In',\n","   'our',\n","   'view',\n","   ',',\n","   'we',\n","   'did',\n","   'not',\n","   'believe',\n","   'we',\n","   'changed',\n","   'or',\n","   'made',\n","   'worse',\n","   'the',\n","   'financial',\n","   'situation',\n","   '.'],\n","  ['We',\n","   'felt',\n","   'we',\n","   'made',\n","   'it',\n","   'better',\n","   'because',\n","   'it',\n","   'introduced',\n","   'a',\n","   'process',\n","   'for',\n","   'review',\n","   'and',\n","   'refund',\n","   '.',\n","   '\"'],\n","  ['Jan',\n","   'Smutney',\n","   '-',\n","   'Jones',\n","   ',',\n","   'who',\n","   'was',\n","   'the',\n","   'ISO',\n","   'board',\n","   'chairman',\n","   'at',\n","   'the',\n","   'time',\n","   'and',\n","   'executive',\n","   'director',\n","   'of',\n","   'a',\n","   'group',\n","   'that',\n","   'represents',\n","   'power',\n","   'generators',\n","   ',',\n","   'said',\n","   'Winter',\n","   'did',\n","   'not',\n","   'consult',\n","   'him',\n","   'about',\n","   'eliminating',\n","   'the',\n","   'price',\n","   'cap',\n","   '.'],\n","  ['Smutney',\n","   '-',\n","   'Jones',\n","   'also',\n","   'said',\n","   'he',\n","   'was',\n","   'unaware',\n","   'of',\n","   'anyone',\n","   'in',\n","   'the',\n","   'power',\n","   '-',\n","   'generating',\n","   'community',\n","   'being',\n","   'consulted',\n","   '.'],\n","  ['\"',\n","   'Terry',\n","   'did',\n","   'this',\n","   'by',\n","   'himself',\n","   ',',\n","   \"''\",\n","   'said',\n","   'Smutney',\n","   '-',\n","   'Jones',\n","   ',',\n","   'executive',\n","   'director',\n","   'of',\n","   'the',\n","   'Independent',\n","   'Energy',\n","   'Producers',\n","   '.'],\n","  ['\"',\n","   'He',\n","   'did',\n","   'what',\n","   'he',\n","   'thought',\n","   'had',\n","   'to',\n","   'be',\n","   'done',\n","   'at',\n","   'the',\n","   'time',\n","   'to',\n","   'keep',\n","   'the',\n","   'power',\n","   'flowing',\n","   '.',\n","   '\"'],\n","  ['The',\n","   'ISO',\n","   'board',\n","   'called',\n","   'an',\n","   'emergency',\n","   'meeting',\n","   'the',\n","   'next',\n","   'week',\n","   'demanding',\n","   'Winter',\n","   'explain',\n","   'his',\n","   'actions',\n","   '.'],\n","  ['Some',\n","   'board',\n","   'members',\n","   'pushed',\n","   'to',\n","   'have',\n","   'Winter',\n","   'removed',\n","   ',',\n","   'but',\n","   'there',\n","   'were',\n","   'concerns',\n","   'such',\n","   'action',\n","   'would',\n","   'lead',\n","   'to',\n","   'more',\n","   'chaos',\n","   ',',\n","   'the',\n","   'governor',\n","   \"'s\",\n","   'spokesman',\n","   'Maviglio',\n","   'said',\n","   '.'],\n","  ['James',\n","   'J.',\n","   'Hoecker',\n","   ',',\n","   'the',\n","   'former',\n","   'Federal',\n","   'Energy',\n","   'Regulatory',\n","   'Commission',\n","   'chairman',\n","   ',',\n","   'defended',\n","   'making',\n","   'the',\n","   'December',\n","   'decision',\n","   'and',\n","   'also',\n","   'defended',\n","   'Winter',\n","   '.'],\n","  ['\"',\n","   'They',\n","   'filed',\n","   'an',\n","   'emergency',\n","   'motion',\n","   ',',\n","   'and',\n","   'we',\n","   'were',\n","   'not',\n","   'about',\n","   'to',\n","   'let',\n","   'California',\n","   'go',\n","   'dark',\n","   ',',\n","   \"''\",\n","   'Hoecker',\n","   'said',\n","   '.'],\n","  ['\"',\n","   'They',\n","   '-LRB-',\n","   'ISO',\n","   'management',\n","   '-RRB-',\n","   'did',\n","   'what',\n","   'any',\n","   'independent',\n","   'system',\n","   'operator',\n","   'would',\n","   'do',\n","   '.',\n","   '\"'],\n","  ['What',\n","   'Dunn',\n","   \"'s\",\n","   'committee',\n","   'hopes',\n","   'to',\n","   'learn',\n","   'is',\n","   'why',\n","   'all',\n","   'these',\n","   'events',\n","   'transpired',\n","   '.'],\n","  ['He',\n","   'believes',\n","   'memos',\n","   'and',\n","   'e-mails',\n","   'around',\n","   'the',\n","   'time',\n","   'of',\n","   'Winter',\n","   \"'s\",\n","   'Dec.',\n","   '8',\n","   'actions',\n","   'should',\n","   'provide',\n","   'vital',\n","   'clues',\n","   '.'],\n","  ['\"',\n","   'We',\n","   'do',\n","   \"n't\",\n","   'know',\n","   'why',\n","   'he',\n","   'did',\n","   'what',\n","   'he',\n","   'did',\n","   ',',\n","   'but',\n","   'we',\n","   'are',\n","   'eager',\n","   'to',\n","   'find',\n","   'out',\n","   ',',\n","   '\"',\n","   'Dunn',\n","   'said',\n","   '.'],\n","  ['\"',\n","   'Terry',\n","   'said',\n","   'he',\n","   'made',\n","   'that',\n","   'filing',\n","   'in',\n","   'the',\n","   'interest',\n","   'of',\n","   'Californians',\n","   ',',\n","   'but',\n","   'I',\n","   'find',\n","   'that',\n","   'argument',\n","   'has',\n","   'no',\n","   'basis',\n","   'in',\n","   'fact',\n","   '.',\n","   \"''\"],\n","  ['We',\n","   'should',\n","   'resurrect',\n","   'Mike',\n","   'Smith',\n","   \"'s\",\n","   'note',\n","   'and',\n","   'get',\n","   'him',\n","   'on',\n","   'the',\n","   'call',\n","   'in',\n","   'the',\n","   'attempt',\n","   'to',\n","   'avoid',\n","   'recreating',\n","   'the',\n","   'wheel',\n","   'on',\n","   'this',\n","   'one',\n","   '.'],\n","  ['I', 'can', 'dig', 'it', 'up', 'if', 'you', \"'d\", 'like', '.'],\n","  ['Sue', 'and', 'Jeff', '--'],\n","  ['I',\n","   'am',\n","   'having',\n","   'a',\n","   'meeting',\n","   'with',\n","   'Vicki',\n","   'and',\n","   'Janet',\n","   'Dietrich',\n","   'on',\n","   'Thursday',\n","   'to',\n","   'discuss',\n","   'our',\n","   'view',\n","   'on',\n","   'the',\n","   'ability',\n","   'to',\n","   'extend',\n","   'our',\n","   'current',\n","   'contracts',\n","   'in',\n","   'CA',\n","   '-LRB-',\n","   'for',\n","   'customers',\n","   'already',\n","   'on',\n","   'DA',\n","   '-RRB-',\n","   '.'],\n","  ['Can', 'we', 'discuss', 'this', 'today', 'or', 'soon', 'thereafter', '.'],\n","  ['My',\n","   'take',\n","   'is',\n","   'that',\n","   'the',\n","   'UDCs',\n","   'will',\n","   'be',\n","   'indifferent',\n","   'to',\n","   'this',\n","   '-LRB-',\n","   'maybe',\n","   '?',\n","   '-RRB-',\n","   'and',\n","   'our',\n","   '#',\n","   '1',\n","   'priority',\n","   'is',\n","   'to',\n","   'work',\n","   'to',\n","   'get',\n","   'the',\n","   'PG&E',\n","   'model',\n","   'adopted',\n","   'across',\n","   'the',\n","   'state',\n","   '.'],\n","  ['Any',\n","   'news',\n","   'on',\n","   'how',\n","   'SCE',\n","   'and',\n","   'SDG&E',\n","   'will',\n","   'move',\n","   'forward',\n","   '?'],\n","  ['Thanks', '.'],\n","  ['Sounds', 'good', '.'],\n","  ['I',\n","   'suggest',\n","   'a',\n","   '\"',\n","   'blind',\n","   'draw',\n","   '\"',\n","   'on',\n","   'the',\n","   'teams',\n","   ',',\n","   'best',\n","   'ball',\n","   'not',\n","   'scramble',\n","   'on',\n","   'the',\n","   'golf',\n","   ',',\n","   'and',\n","   'as',\n","   'for',\n","   'the',\n","   'wager',\n","   ',',\n","   'no',\n","   'emails',\n","   'from',\n","   'the',\n","   'losing',\n","   'team',\n","   'for',\n","   'one',\n","   'week',\n","   '!'],\n","  ['Is', 'there', 'any', 'question', '?'],\n","  ['I', \"'ll\", 'leave', 'to', 'Steve', 'to', 'structure', 'the', 'deal', '.'],\n","  ['As',\n","   'I',\n","   'recall',\n","   ',',\n","   'Montavano',\n","   ',',\n","   'Shapiro',\n","   'and',\n","   'I',\n","   'usually',\n","   'make',\n","   'up',\n","   'one',\n","   'team',\n","   ',',\n","   'but',\n","   'I',\n","   \"'m\",\n","   'willing',\n","   'to',\n","   'switch',\n","   'around',\n","   'a',\n","   'bit',\n","   '.'],\n","  ['Best', ','],\n","  ['Jeff'],\n","  ['Are', 'you', 'playing', 'golf', '?'],\n","  ['And',\n","   'if',\n","   'yes',\n","   ',',\n","   'what',\n","   \"'s\",\n","   'the',\n","   'game',\n","   'and',\n","   'wager',\n","   '???'],\n","  ['Jim'],\n","  ['Glad', 'to', 'hear', 'all', 'is', 'well', '.'],\n","  ['I',\n","   'meant',\n","   'to',\n","   'comment',\n","   'that',\n","   'I',\n","   'thought',\n","   'the',\n","   'people',\n","   'profiled',\n","   'in',\n","   'the',\n","   'article',\n","   'should',\n","   'pull',\n","   'their',\n","   'heads',\n","   'out',\n","   'of',\n","   'their',\n","   'self',\n","   'important',\n","   'asses',\n","   '.'],\n","  ['It',\n","   'is',\n","   \"n't\",\n","   'about',\n","   'finding',\n","   'the',\n","   'meaning',\n","   'of',\n","   'life',\n","   'at',\n","   'work',\n","   '.'],\n","  ['It', 'is', 'all', 'about', 'the', '$$$', '.'],\n","  ['Work', 'hard', '.'],\n","  ['Make', '$$$', '.'],\n","  ['Retire', 'young', '.'],\n","  ['Things', 'with', 'me', 'are', 'great', '.'],\n","  ['Moving',\n","   'back',\n","   'to',\n","   'Calgary',\n","   'in',\n","   'about',\n","   'a',\n","   'month',\n","   'which',\n","   'is',\n","   'a',\n","   'little',\n","   'sooner',\n","   'than',\n","   'I',\n","   'thought',\n","   'I',\n","   'would',\n","   'be',\n","   'going',\n","   'back',\n","   'but',\n","   'when',\n","   'opportunity',\n","   'knocks',\n","   'you',\n","   'got',\n","   'ta',\n","   'go',\n","   '.'],\n","  ['Take', 'care', '.'],\n","  ['I',\n","   'do',\n","   \"n't\",\n","   'hear',\n","   'from',\n","   'you',\n","   'in',\n","   'months',\n","   'and',\n","   'then',\n","   'you',\n","   'level',\n","   'me',\n","   'with',\n","   'such',\n","   'a',\n","   'thought',\n","   'provoking',\n","   ',',\n","   'soul',\n","   'searching',\n","   'article',\n","   '.'],\n","  ['Thanks', 'for', 'thinking', 'of', 'me', 'to', 'send', 'it', 'to', '.'],\n","  ['I', 'really', 'enjoyed', 'reading', 'it', '.'],\n","  ['We',\n","   'certainly',\n","   'fit',\n","   'into',\n","   'certain',\n","   'parts',\n","   'of',\n","   'the',\n","   'article',\n","   '.'],\n","  ['There',\n","   'are',\n","   'a',\n","   'few',\n","   'life',\n","   'theories',\n","   'like',\n","   'that',\n","   'which',\n","   'working',\n","   'through',\n","   '.'],\n","  ['It', 's', 'all', 'interesting', 'stuff', '.'],\n","  ['How', 'are', 'things', 'going', 'with', 'you', '?'],\n","  ['Are', 'you', 'enjoying', 'Houston', '?'],\n","  ['London', 'has', 'been', 'great', '.'],\n","  ['Brokering', 'over', 'here', 'has', 'been', 'pretty', 'rewarding', '.'],\n","  ['Traders',\n","   'over',\n","   'here',\n","   'seem',\n","   'to',\n","   'have',\n","   'a',\n","   'lot',\n","   'more',\n","   'respect',\n","   'for',\n","   'other',\n","   'humans',\n","   '.'],\n","  ['Catriona',\n","   'is',\n","   'well',\n","   'and',\n","   'has',\n","   'landed',\n","   'herself',\n","   'a',\n","   'pretty',\n","   'cool',\n","   'job',\n","   'in',\n","   'PR',\n","   '.'],\n","  ['Keep', 'in', 'touch', ','],\n","  ['Mike'],\n","  ['Michael', 'J.', 'McDermott'],\n","  ['_________________________________________________________________'],\n","  ['Get', 'your', 'FREE', 'download', 'of', 'MSN', 'Explorer', 'at'],\n","  ['For',\n","   'me',\n","   'it',\n","   'is',\n","   \"n't\",\n","   'about',\n","   'fulfillment',\n","   'or',\n","   'finding',\n","   'my',\n","   'life',\n","   \"'s\",\n","   'purpose',\n","   'in',\n","   'my',\n","   'work',\n","   '.'],\n","  ['It', \"'s\", 'all', 'about', 'the', '$$$', '.'],\n","  ['Work', 'hard', 'and', 'retire', 'early', '.'],\n","  ['Cheers'],\n","  ['Chris'],\n","  ['P.S.',\n","   'I',\n","   'am',\n","   'moving',\n","   'back',\n","   'to',\n","   'Calgary',\n","   'in',\n","   'about',\n","   'a',\n","   'month',\n","   '.'],\n","  ['Enron',\n","   'continues',\n","   'to',\n","   'feel',\n","   'free',\n","   'to',\n","   'move',\n","   'me',\n","   'around',\n","   'at',\n","   'will',\n","   '.'],\n","  ['I', 'am', 'actually', 'really', 'looking', 'forward', 'to', 'it', '.'],\n","  ['let',\n","   \"'s\",\n","   'discuss',\n","   'next',\n","   'time',\n","   'we',\n","   'have',\n","   'amstel',\n","   'lights',\n","   'together',\n","   '.'],\n","  ['Jolene', 'Harvey'],\n","  ['05/22/2001', '09:25', 'AM'],\n","  ['about', 'our', 'lifestyle', '...'],\n","  ['-LRB-', 'See', 'attached', 'file', ':', 'TEXT.htm', '-RRB-'],\n","  ['********************************',\n","   'NOTICE',\n","   '*************************************'],\n","  ['This',\n","   'transmittal',\n","   'and',\n","   '/',\n","   'or',\n","   'attachments',\n","   'may',\n","   'be',\n","   'a',\n","   'confidential',\n","   'attorney',\n","   '-',\n","   'client',\n","   'communication',\n","   'or',\n","   'may',\n","   'otherwise',\n","   'be',\n","   'privileged',\n","   'or',\n","   'confidential',\n","   '.'],\n","  ['If',\n","   'you',\n","   'are',\n","   'not',\n","   'the',\n","   'intended',\n","   'recipient',\n","   ',',\n","   'you',\n","   'are',\n","   'hereby',\n","   'notified',\n","   'that',\n","   'you',\n","   'have',\n","   'received',\n","   'this',\n","   'transmittal',\n","   'in',\n","   'error',\n","   ';',\n","   'any',\n","   'review',\n","   ',',\n","   'dissemination',\n","   ',',\n","   'distribution',\n","   'or',\n","   'copying',\n","   'of',\n","   'this',\n","   'transmittal',\n","   'is',\n","   'strictly',\n","   'prohibited',\n","   '.'],\n","  ['If',\n","   'you',\n","   'have',\n","   'received',\n","   'this',\n","   'transmittal',\n","   'and',\n","   '/',\n","   'or',\n","   'attachments',\n","   'in',\n","   'error',\n","   ',',\n","   'please',\n","   'notify',\n","   'us',\n","   'immediately',\n","   'by',\n","   'reply',\n","   'or',\n","   'by',\n","   'telephone',\n","   '-LRB-',\n","   'call',\n","   'us',\n","   'collect',\n","   'at',\n","   '+1',\n","   '212-848-8400',\n","   '-RRB-',\n","   'and',\n","   'immediately',\n","   'delete',\n","   'this',\n","   'message',\n","   'and',\n","   'all',\n","   'its',\n","   'attachments',\n","   '.'],\n","  ['Thank', 'you', '.'],\n","  ['-', 'TEXT.htm', '<<', 'File', ':', 'TEXT.htm', '>>'],\n","  ['I',\n","   'was',\n","   'thinking',\n","   'of',\n","   'converting',\n","   'it',\n","   'to',\n","   'a',\n","   'hover',\n","   'vehicle',\n","   '.'],\n","  ['I',\n","   'might',\n","   'just',\n","   'sell',\n","   'the',\n","   'car',\n","   'and',\n","   'get',\n","   'you',\n","   'to',\n","   'drive',\n","   'me',\n","   'around',\n","   'all',\n","   'winter',\n","   '.'],\n","  ['How',\n","   'about',\n","   'skidoo',\n","   'skis',\n","   'for',\n","   'the',\n","   'front',\n","   'and',\n","   'tracks',\n","   'for',\n","   'the',\n","   'back',\n","   '..'],\n","  ['Lexus', 'IS', '300', '.'],\n","  ['Not',\n","   'sure',\n","   'if',\n","   'I',\n","   'am',\n","   'going',\n","   'to',\n","   'buy',\n","   '17',\n","   '\"',\n","   'or',\n","   '16',\n","   '\"',\n","   'wheels',\n","   'for',\n","   'the',\n","   'winter',\n","   '.'],\n","  ['Jackass', '.'],\n","  ['Mom', \"'s\", 'birthday', 'is', 'tommorow', '.'],\n","  ['What', 'are', 'we', 'going', 'to', 'get', 'her', '?'],\n","  ['Chris'],\n","  ['That', 'is', 'some', 'good', 'stuff', '.'],\n","  ['I', 'hear', 'you', 'are', 'coming', 'our', 'way', 'soon', '.'],\n","  ['Look', 'forward', 'to', 'drinking', 'a', 'few', 'beers', '.'],\n","  ['Chris'],\n","  ['Michael', 'McDermott', '<', '>', 'on', '06/01/2000', '06:00:56', 'AM'],\n","  ['Yo', 'Mama', '`s', 'so', 'fat', '....'],\n","  ['Your',\n","   'mama',\n","   'is',\n","   'so',\n","   'fat',\n","   ':',\n","   'When',\n","   'she',\n","   'hauls',\n","   'ass',\n","   'she',\n","   'has',\n","   'to',\n","   'make',\n","   'two',\n","   'trips',\n","   '.'],\n","  ['When', 'she', 'dances', 'she', 'makes', 'the', 'band', 'skip', '.'],\n","  ['When',\n","   'she',\n","   'was',\n","   'diagnosed',\n","   'with',\n","   'the',\n","   'flesh',\n","   'eating',\n","   'disease',\n","   'the',\n","   'doctor',\n","   'gave',\n","   'her',\n","   '13',\n","   'years',\n","   'to',\n","   'live',\n","   '.'],\n","  ['She',\n","   'puts',\n","   'mayonnaise',\n","   'on',\n","   'aspirin',\n","   '.',\n","   '-LRB-',\n","   '<-',\n","   'clearly',\n","   'the',\n","   'winner',\n","   '-RRB-'],\n","  ['Her', 'cereal', 'bowl', 'came', 'with', 'a', 'lifeguard', '.'],\n","  ['When',\n","   'she',\n","   'goes',\n","   'to',\n","   'the',\n","   'zoo',\n","   'the',\n","   'elephants',\n","   'throw',\n","   'her',\n","   'peanuts',\n","   '.'],\n","  ['Her',\n","   'high',\n","   'school',\n","   'graduation',\n","   'picture',\n","   'was',\n","   'an',\n","   'aerial',\n","   'photograph',\n","   '.'],\n","  ['Her',\n","   'driver',\n","   '`s',\n","   'license',\n","   'says',\n","   '\"',\n","   'Picture',\n","   'continued',\n","   'on',\n","   'other',\n","   'side',\n","   '.',\n","   '\"'],\n","  ['She', 'has', 'to', 'iron', 'her', 'pants', 'on', 'the', 'driveway', '.'],\n","  ['The',\n","   'back',\n","   'of',\n","   'her',\n","   'neck',\n","   'looks',\n","   'like',\n","   'a',\n","   'pack',\n","   'of',\n","   'hot',\n","   'dogs',\n","   '.'],\n","  ['Yo',\n","   'mama',\n","   '`s',\n","   'so',\n","   'fat',\n","   ',',\n","   'all',\n","   'the',\n","   'restaurants',\n","   'in',\n","   'town',\n","   'have',\n","   'signs',\n","   'that',\n","   'say',\n","   ':',\n","   '\"',\n","   'Maximum',\n","   'Occupancy',\n","   ':',\n","   '240',\n","   'Patrons',\n","   'OR',\n","   'Yo',\n","   'Mama',\n","   '\"',\n","   'Yo',\n","   'mama',\n","   '`s',\n","   'so',\n","   'fat',\n","   ',',\n","   'when',\n","   'she',\n","   'ran',\n","   'away',\n","   ',',\n","   'they',\n","   'had',\n","   'to',\n","   'use',\n","   'all',\n","   'four',\n","   'sides',\n","   'of',\n","   'the',\n","   'milk',\n","   'carton',\n","   '.'],\n","  ['Yo',\n","   'mama',\n","   '`s',\n","   'so',\n","   'fat',\n","   ',',\n","   'instead',\n","   'of',\n","   'Levis',\n","   '501',\n","   'jeans',\n","   ',',\n","   'she',\n","   'wears',\n","   'Levi`s',\n","   '1002`s',\n","   '.'],\n","  ['Yo',\n","   'mama',\n","   '`s',\n","   'so',\n","   'fat',\n","   ',',\n","   'when',\n","   'she',\n","   'gets',\n","   'in',\n","   'an',\n","   'elevator',\n","   ',',\n","   'it',\n","   'HAS',\n","   'to',\n","   'go',\n","   'down',\n","   '.'],\n","  ['Yo',\n","   'mama',\n","   '`s',\n","   'so',\n","   'fat',\n","   ',',\n","   'she',\n","   'was',\n","   'born',\n","   'with',\n","   'a',\n","   'silver',\n","   'shovel',\n","   'in',\n","   'her',\n","   'mouth',\n","   '.'],\n","  ['Yo',\n","   'mama',\n","   '`s',\n","   'so',\n","   'fat',\n","   ',',\n","   'she',\n","   '`s',\n","   'got',\n","   'smaller',\n","   'fat',\n","   'women',\n","   'orbiting',\n","   'around',\n","   'her',\n","   '.'],\n","  ['Yo', 'mama', '`s', 'so', 'fat', ',', 'she', 'could', 'sell', 'shade', '.'],\n","  ['You', 'will', 'have', 'to', 'wait', 'and', 'see', ':--RRB-'],\n","  ['Done', '!'],\n","  ['Expect', 'a', 'call', 'from', 'Paul', 'tonight', '.'],\n","  ['Chris'],\n","  ['What', 'are', 'some', 'good', 'interview', 'questions', '?'],\n","  ['Poll', 'your', 'co-workers', '.'],\n","  ['cd'],\n","  ['I',\n","   'told',\n","   'Paul',\n","   'that',\n","   'you',\n","   'called',\n","   'him',\n","   'yesterday',\n","   'so',\n","   'abruptly',\n","   'because',\n","   'you',\n","   'did',\n","   \"n't\",\n","   'want',\n","   'to',\n","   'waste',\n","   'his',\n","   'time',\n","   'while',\n","   'you',\n","   'got',\n","   'tests',\n","   'done',\n","   'for',\n","   'arthritis',\n","   '.'],\n","  ['I',\n","   'told',\n","   'him',\n","   'I',\n","   'told',\n","   'you',\n","   'to',\n","   'call',\n","   'him',\n","   'back',\n","   'and',\n","   'at',\n","   'least',\n","   'hear',\n","   'what',\n","   'he',\n","   'has',\n","   'to',\n","   'say',\n","   '.'],\n","  ['He',\n","   'said',\n","   'they',\n","   'are',\n","   'looking',\n","   'for',\n","   'people',\n","   'and',\n","   'based',\n","   'on',\n","   'what',\n","   'I',\n","   'told',\n","   'him',\n","   'an',\n","   'interview',\n","   'was',\n","   'a',\n","   'formality',\n","   '.'],\n","  ['Chris'],\n","  ['Is',\n","   'that',\n","   'Microwave',\n","   'that',\n","   'you',\n","   'gave',\n","   'Dan',\n","   'really',\n","   'expensive',\n","   '?'],\n","  ['All',\n","   'the',\n","   'guys',\n","   'at',\n","   'work',\n","   'are',\n","   'saying',\n","   'I',\n","   'should',\n","   \"n't\",\n","   'bother',\n","   'having',\n","   'it',\n","   'fixed',\n","   'I',\n","   'should',\n","   'just',\n","   'buy',\n","   'a',\n","   'new',\n","   'one',\n","   '.'],\n","  ['Chris'],\n","  ['Jai', 'Hawker', '974-6721'],\n","  ['I', 'wo', \"n't\", 'forget', 'about', 'the', '$', '.'],\n","  ['Do',\n","   'I',\n","   'need',\n","   'to',\n","   'cross',\n","   'reference',\n","   'the',\n","   'deals',\n","   'in',\n","   'my',\n","   'model',\n","   'to',\n","   'the',\n","   'deals',\n","   'in',\n","   'the',\n","   'system',\n","   'or',\n","   'did',\n","   'you',\n","   'already',\n","   'do',\n","   'that',\n","   '?'],\n","  ['Chris'],\n","  ['Kathy', ','],\n","  ['Do',\n","   \"n't\",\n","   'take',\n","   'that',\n","   'deal',\n","   'out',\n","   'until',\n","   'I',\n","   'look',\n","   'at',\n","   'it',\n","   '.'],\n","  ['I',\n","   'think',\n","   'it',\n","   'is',\n","   'mine',\n","   'but',\n","   'I',\n","   'forgot',\n","   'to',\n","   'write',\n","   'it',\n","   'in',\n","   'the',\n","   'blue',\n","   'FX',\n","   'book',\n","   '-LRB-',\n","   'I',\n","   'only',\n","   'wrote',\n","   'it',\n","   'in',\n","   'my',\n","   'red',\n","   'book',\n","   '-RRB-',\n","   '.'],\n","  ['Thanx', ','],\n","  ['Chris'],\n","  ['Just',\n","   'a',\n","   'reminder',\n","   'to',\n","   'send',\n","   'me',\n","   'a',\n","   'currency',\n","   'report',\n","   '.'],\n","  ['Thanx', ','],\n","  ['Chris'],\n","  ['Paul', 'called', 'me', 'today', '.'],\n","  ['He',\n","   'will',\n","   'be',\n","   'in',\n","   'Calgary',\n","   'in',\n","   'a',\n","   'couple',\n","   'of',\n","   'weeks',\n","   'and',\n","   'will',\n","   'interview',\n","   'you',\n","   'then',\n","   '.'],\n","  ['Chris'],\n","  ['You', 'should', 'reply', 'ASAP', '.'],\n","  ['Do', \"n't\", 'make', 'Peters', 'and', 'Co.', 'wait', '.'],\n","  ['Chris'],\n","  ['I',\n","   'did',\n","   \"n't\",\n","   'get',\n","   'a',\n","   'chance',\n","   'to',\n","   'talk',\n","   'to',\n","   'Paul',\n","   'today',\n","   '.'],\n","  ['Give', 'him', 'a', 'call', 'tommorow', '.'],\n","  ['Chris'],\n","  ['Will',\n","   'you',\n","   'please',\n","   'run',\n","   'a',\n","   'June',\n","   'NX3',\n","   '/',\n","   'NX1',\n","   'for',\n","   'our',\n","   'book',\n","   '.'],\n","  ['Paul'],\n","  ['How', 'about', 'meeting', 'at', '11:30', 'or', '12', '?'],\n","  ['I', 'am', 'in', 'the', 'office', 'so', 'give', 'me', 'a', 'call', '.'],\n","  ['CD', '3-1663'],\n","  ['The', 'deed', 'is', 'done', '.'],\n","  ['Chris'],\n","  ['Find', 'attached', 'resume', 'and', 'cover', 'letter', '.'],\n","  ['Hopefully', 'he', 'did', \"n't\", 'spel', 'anyting', 'incorrectly', '.'],\n","  ['Dan', 'is', 'really', 'smart', 'and', 'a', 'hard', 'worker', '.'],\n","  ['I', 'think', 'he', 'would', 'be', 'a', 'good', 'fit', '.'],\n","  ['Give',\n","   'me',\n","   'a',\n","   'call',\n","   'Tuesday',\n","   'afternoon',\n","   'to',\n","   'discuss',\n","   '-LRB-',\n","   'gone',\n","   'to',\n","   'Kelowna',\n","   'golfing',\n","   'for',\n","   'the',\n","   'weekend',\n","   '-RRB-',\n","   '.'],\n","  ['Cheers', ','],\n","  ['Chris'],\n","  ['I', 'have', \"n't\", 'had', 'a', 'chance', 'to', 'send', 'it', 'yet', '.'],\n","  ['Paul',\n","   'is',\n","   'out',\n","   'of',\n","   'the',\n","   'office',\n","   'today',\n","   'so',\n","   'I',\n","   'have',\n","   \"n't\",\n","   'had',\n","   'a',\n","   'chance',\n","   'to',\n","   'talk',\n","   'to',\n","   'him',\n","   '.'],\n","  ['I',\n","   \"'ll\",\n","   'send',\n","   'it',\n","   'as',\n","   'soon',\n","   'as',\n","   'you',\n","   'resond',\n","   'wether',\n","   'I',\n","   'should',\n","   'or',\n","   'not',\n","   '.'],\n","  ['Chris'],\n","  ['Are', 'you', 'guys', 'still', 'looking', 'for', 'an', 'analyst', '?'],\n","  ['Should',\n","   'I',\n","   'send',\n","   'the',\n","   'resume',\n","   'to',\n","   'Dawn',\n","   'or',\n","   'you',\n","   'directly',\n","   '?'],\n","  ['Chris',\n","   'Enron',\n","   'Canada',\n","   'Corp.',\n","   'Suite',\n","   '1100',\n","   ',',\n","   '70',\n","   'York',\n","   'Street',\n","   'Toronto',\n","   ',',\n","   'Ontario',\n","   'M5J',\n","   '1S9',\n","   '416-865-3700'],\n","  ['Paul', 'DeVries', '-', 'Director', '416-865-3703'],\n","  ['Jan', 'Wilson', '-', 'Manager', '416-865-3704'],\n","  ['Attached',\n","   'is',\n","   'a',\n","   'forecast',\n","   'for',\n","   'the',\n","   'rest',\n","   'of',\n","   'the',\n","   'summer',\n","   'for',\n","   'the',\n","   'X',\n","   '-LRB-',\n","   'NWP',\n","   'and',\n","   'PGT',\n","   '-RRB-',\n","   '.'],\n","  ['We',\n","   'should',\n","   'try',\n","   'to',\n","   'have',\n","   'a',\n","   'conference',\n","   'call',\n","   'with',\n","   'the',\n","   'west',\n","   'desk',\n","   'to',\n","   'discuss',\n","   'as',\n","   'soon',\n","   'as',\n","   'we',\n","   'can',\n","   '.'],\n","  ['Chris'],\n","  ['See', 'you', 'there', '!'],\n","  ['CD'],\n","  ['Sushi', 'tonight', '?'],\n","  ['Ryan', 'Watt', 'says', 'high', '.'],\n","  ['Chris'],\n","  ['I', 'will', 'be', 'able', 'to', 'attend', '.'],\n","  ['Chris'],\n","  ['I',\n","   'need',\n","   'to',\n","   'check',\n","   'something',\n","   'in',\n","   '969',\n","   \"'s\",\n","   '2000',\n","   'tax',\n","   'return',\n","   '.'],\n","  ['Who', 'has', 'the', '2000', 'tax', 'return', 'file', 'for', '969', '?'],\n","  ['Essie'],\n","  ['Sonya', 'City'],\n","  ['07/30/2001', '05:17', 'PM'],\n","  ['<',\n","   'Embedded',\n","   'Picture',\n","   '-LRB-',\n","   'Device',\n","   'Independent',\n","   'Bitmap',\n","   '-RRB-',\n","   '>'],\n","  ['I',\n","   'think',\n","   'that',\n","   'this',\n","   'is',\n","   'for',\n","   'you',\n","   'since',\n","   'I',\n","   'do',\n","   \"n't\",\n","   'know',\n","   'any',\n","   'of',\n","   'these',\n","   'people',\n","   '.'],\n","  ['WHO', ':', 'Enron'],\n","  ['WHAT', ':', 'Happy', 'Hour', 'for', 'John', 'Suarez'],\n","  ['WHEN', ':', 'Today', 'at', '5', 'pm'],\n","  ['WHERE',\n","   ':',\n","   'The',\n","   'Front',\n","   'Porch',\n","   '217',\n","   'Gray',\n","   'St.',\n","   '-LRB-',\n","   '713',\n","   '-RRB-',\n","   '571-9571'],\n","  ['WHY', ':', 'Today', 'is', 'John', \"'s\", 'last', 'day', 'at', 'EBS', '.'],\n","  ['This', 'is', 'NOT', 'an', 'Enron', '-', 'sponsored', 'event', '.'],\n","  ['How',\n","   'do',\n","   'you',\n","   'feel',\n","   'about',\n","   'taking',\n","   'on',\n","   'another',\n","   'company',\n","   '?'],\n","  ['Essie',\n","   'and',\n","   'Leon',\n","   'have',\n","   'proposed',\n","   'xferring',\n","   'Co.',\n","   '1691',\n","   'to',\n","   'your',\n","   'world',\n","   '-LRB-',\n","   'see',\n","   'below',\n","   '-RRB-',\n","   '.'],\n","  ['Do', 'you', 'concur', '?'],\n","  ['Please', 'let', 'me', 'know', 'Monday', 'morning', '.'],\n","  ['Regards', ','],\n","  ['Vicsandra'],\n","  ['If',\n","   'you',\n","   'have',\n","   'not',\n","   'already',\n","   'made',\n","   'these',\n","   'decisions',\n","   ',',\n","   'Essie',\n","   \"'s\",\n","   'guidance',\n","   'should',\n","   'be',\n","   'helpful',\n","   '.'],\n","  ['Patty', 'Lee', 'Corporate', 'Tax', 'x35172', 'EB', '1774'],\n","  ['Please', 'see', 'my', 'comments', 'in', 'red', 'below', '.'],\n","  ['Essie'],\n","  ['Essie', ','],\n","  ['Can',\n","   'you',\n","   'recommend',\n","   'where',\n","   'these',\n","   'companies',\n","   'each',\n","   'fit',\n","   'within',\n","   'the',\n","   'new',\n","   'organization',\n","   '?'],\n","  ['If',\n","   'possible',\n","   ',',\n","   'can',\n","   'you',\n","   'also',\n","   'give',\n","   'an',\n","   'indication',\n","   'of',\n","   'the',\n","   'rank',\n","   '-',\n","   '1',\n","   'through',\n","   '5',\n","   '?'],\n","  ['Thanks', ','],\n","  ['Patty'],\n","  ['I',\n","   'have',\n","   'a',\n","   'few',\n","   'entities',\n","   'that',\n","   'may',\n","   'need',\n","   'to',\n","   'change',\n","   'groups',\n","   'or',\n","   'be',\n","   'assigned',\n","   'to',\n","   'a',\n","   'group',\n","   '.'],\n","  ['18T', '-', 'EI', 'Indonesia', 'Operations', 'LLC'],\n","  ['This',\n","   'entity',\n","   'is',\n","   'not',\n","   'in',\n","   'TIS',\n","   ',',\n","   'SAP',\n","   ',',\n","   'nor',\n","   'Hyperion',\n","   '.'],\n","  ['The',\n","   '2000',\n","   'tax',\n","   'return',\n","   'has',\n","   'no',\n","   'income',\n","   ',',\n","   'assets',\n","   ',',\n","   'or',\n","   'liabilities',\n","   '.'],\n","  ['There',\n","   'is',\n","   'a',\n","   'corporate',\n","   'data',\n","   'sheet',\n","   'for',\n","   'this',\n","   'company',\n","   ',',\n","   'but',\n","   'this',\n","   'entity',\n","   'seems',\n","   'to',\n","   'have',\n","   'been',\n","   'inactive',\n","   'since',\n","   'it',\n","   \"'s\",\n","   'creation',\n","   '.'],\n","  ['86M', '-', 'Enron', 'Net', 'Works', 'LLC'],\n","  ['Despite',\n","   'the',\n","   'name',\n","   ',',\n","   'this',\n","   'entity',\n","   'appears',\n","   'to',\n","   'be',\n","   'a',\n","   'MTM',\n","   'company',\n","   '.'],\n","  ['Per',\n","   'September',\n","   'financials',\n","   ',',\n","   'this',\n","   'company',\n","   'has',\n","   'about',\n","   '$',\n","   '3',\n","   'M',\n","   'of',\n","   'MTM',\n","   'and',\n","   'about',\n","   '$',\n","   '8',\n","   'K',\n","   'of',\n","   'expenses',\n","   ',',\n","   'nothing',\n","   'else',\n","   '.'],\n","  ['The',\n","   'next',\n","   '5',\n","   'companies',\n","   'were',\n","   'my',\n","   'responsibility',\n","   'while',\n","   'in',\n","   'EBS',\n","   ',',\n","   'and',\n","   'did',\n","   'not',\n","   'get',\n","   'assigned',\n","   'during',\n","   'the',\n","   'reorg',\n","   '.'],\n","  ['80Y', '-', 'Enron', 'Broadband', 'Acquisition', ',', 'Inc', '.'],\n","  ['This',\n","   'entity',\n","   'was',\n","   'created',\n","   'in',\n","   '2000',\n","   'for',\n","   'the',\n","   'acquistion',\n","   'of',\n","   'WarpSpeed',\n","   'Communications',\n","   '-LRB-',\n","   'now',\n","   'Enron',\n","   'WarpSpeed',\n","   'Services',\n","   ',',\n","   'Inc.',\n","   '83N',\n","   '-RRB-',\n","   ',',\n","   'and',\n","   'then',\n","   'dissolved',\n","   'upon',\n","   'completion',\n","   'of',\n","   'merger',\n","   '.'],\n","  ['Company',\n","   'is',\n","   'around',\n","   'with',\n","   'a',\n","   'small',\n","   'amount',\n","   'of',\n","   'assets',\n","   'and',\n","   'liabilities',\n","   ',',\n","   'but',\n","   'no',\n","   'I/S',\n","   'items',\n","   '.'],\n","  ['83N', 'is', 'my', 'responsibility', '.'],\n","  ['I', 'think', 'this', 'entity', 'should', 'stay', 'with', '83N', '.'],\n","  ['So', 'I', 'suggest', 'it', 'be', 'assigned', 'to', 'Leon', '.'],\n","  ['It', 'should', 'be', '4', '-', 'easy', '.'],\n","  ['1579', '-', 'EBS', 'Network', 'Co.', 'Division', 'of', '17H', '.'],\n","  ['This',\n","   'one',\n","   'should',\n","   'possibly',\n","   'be',\n","   'assigned',\n","   'to',\n","   'Networks',\n","   '&',\n","   'Services',\n","   'group',\n","   '.'],\n","  ['Not', 'currently', 'on', 'our', 'list', 'of', 'companies', '.'],\n","  ['I',\n","   'think',\n","   'this',\n","   'could',\n","   'go',\n","   'to',\n","   'either',\n","   'Holding',\n","   '/',\n","   'Administrative',\n","   'Companies',\n","   '-LRB-',\n","   'Same',\n","   'as',\n","   '17H',\n","   '-RRB-',\n","   'or',\n","   'Network',\n","   '&',\n","   'Services',\n","   '-LRB-',\n","   'Leon',\n","   '-RRB-',\n","   '.'],\n","  ['4', '-', 'easy', '.'],\n","  ['1691', '-', 'EPI', '-', 'EBS', 'Europe'],\n","  ['Set',\n","   'up',\n","   'last',\n","   'month',\n","   'to',\n","   'centralize',\n","   'merchant',\n","   'asset',\n","   'activities',\n","   '.'],\n","  ['Broke', 'out', 'the', 'activities', 'of', '1179', '.'],\n","  ['A',\n","   'similar',\n","   'entity',\n","   '-LRB-',\n","   '1179',\n","   '-RRB-',\n","   'was',\n","   'assigned',\n","   'to',\n","   'Commodity',\n","   'and',\n","   'Trade',\n","   '-LRB-',\n","   'Todd',\n","   'Richards',\n","   'and',\n","   'Mary',\n","   'Fischer',\n","   '-RRB-',\n","   'so',\n","   'this',\n","   'one',\n","   'should',\n","   'be',\n","   'assigned',\n","   'to',\n","   'them',\n","   'as',\n","   'well',\n","   '.'],\n","  ['4', '-', 'easy', '.'],\n","  ['1307', '-', 'EBIC', '-', 'Apache', ',', 'LLC'],\n","  ['Rolls', 'up', 'to', 'Cherokee', 'Finance', 'VOF', ',', 'a', 'CFC', '.'],\n","  ['Cherokee',\n","   'Finance',\n","   'VOF',\n","   'is',\n","   'assigned',\n","   'to',\n","   'North',\n","   'America',\n","   '-LRB-',\n","   'Glen',\n","   'Walloch',\n","   'and',\n","   'Kevin',\n","   'Walker',\n","   '-RRB-',\n","   '.'],\n","  ['Maybe',\n","   'this',\n","   'one',\n","   'should',\n","   'also',\n","   'go',\n","   'to',\n","   'them',\n","   'as',\n","   'the',\n","   'only',\n","   'tax',\n","   'which',\n","   'may',\n","   'have',\n","   'to',\n","   'be',\n","   'provided',\n","   'would',\n","   'be',\n","   'foreign',\n","   'tax',\n","   '.'],\n","  ['4', '-', 'easy', '.'],\n","  ['1689', '-', 'EPI', '-', 'EBS', 'Ventures', ',', 'LLC'],\n","  ['Set',\n","   'up',\n","   'last',\n","   'month',\n","   'to',\n","   'centralize',\n","   'merchant',\n","   'asset',\n","   'activities',\n","   '.'],\n","  ['Broke', 'out', 'the', 'activities', 'of', '1307', '.'],\n","  ['Same', 'as', '1307', '.'],\n","  ['It',\n","   'should',\n","   'be',\n","   'assigned',\n","   'to',\n","   'North',\n","   'America',\n","   '-LRB-',\n","   'Glen',\n","   'Walloch',\n","   'and',\n","   'Kevin',\n","   'Walker',\n","   '-RRB-',\n","   '.'],\n","  ['4', '-', 'easy', '.'],\n","  ['Let', 'me', 'know', 'if', 'you', 'have', 'any', 'questions', '.'],\n","  ['Leon',\n","   'Branom',\n","   'Senior',\n","   'Tax',\n","   'Analyst',\n","   'Networks',\n","   'and',\n","   'Services',\n","   '-LRB-',\n","   '713',\n","   '-RRB-',\n","   '345-8702',\n","   'office'],\n","  ['No', 'problem', 'about', 'moving', 'Company', '1691', 'over'],\n","  ['I',\n","   'see',\n","   'that',\n","   'it',\n","   'is',\n","   'a',\n","   '4',\n","   ',',\n","   'so',\n","   'that',\n","   'will',\n","   'be',\n","   'no',\n","   'problem',\n","   '.'],\n","  ['How',\n","   'do',\n","   'you',\n","   'feel',\n","   'about',\n","   'taking',\n","   'on',\n","   'another',\n","   'company',\n","   '?'],\n","  ...],\n"," [['NNP', ':'],\n","  ['NN', 'IN', 'VBG', 'DT', 'NN', 'RB', '.'],\n","  ['PRP',\n","   'MD',\n","   'VB',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'IN',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'JJ',\n","   'NN',\n","   'NNS',\n","   'WDT',\n","   'PRP',\n","   'VBP',\n","   'RB',\n","   'VB',\n","   'NN',\n","   'IN',\n","   'RB',\n","   '.'],\n","  ['JJS',\n","   'IN',\n","   'PRP$',\n","   'NN',\n","   'IN',\n","   'JJ',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'VBZ',\n","   'VBN',\n","   'IN',\n","   'PRP',\n","   'VBG',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   ',',\n","   'VBG',\n","   'PRP',\n","   'TO',\n","   'VB',\n","   'IN',\n","   'NNP',\n","   'NNP',\n","   ',',\n","   'NNP',\n","   ',',\n","   'CC',\n","   'NNP',\n","   ',',\n","   'CC',\n","   'VBG',\n","   'TO',\n","   'VB',\n","   'RP',\n","   'PRP$',\n","   'NNS',\n","   'POS',\n","   'JJ',\n","   'NN',\n","   'NNS',\n","   'IN',\n","   'NN',\n","   'JJ',\n","   '.'],\n","  ['DT', 'JJ', 'NNS', 'VBP', 'DT', 'NN', 'IN', 'PRP', 'RB', '.'],\n","  ['IN',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'NNS',\n","   'JJ',\n","   'IN',\n","   'NN',\n","   'IN',\n","   'JJ',\n","   'NN',\n","   'CC',\n","   'NN',\n","   'NNS',\n","   ',',\n","   'CC',\n","   'JJ',\n","   'NNS',\n","   'IN',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   'CC',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   ',',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   '.'],\n","  ['NNP'],\n","  ['NNP', ','],\n","  ['PRP',\n","   'MD',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'RB',\n","   'CC',\n","   'VBN',\n","   'IN',\n","   'PRP',\n","   'IN',\n","   'JJ',\n","   'NNS',\n","   '.'],\n","  ['IN',\n","   'DT',\n","   'NN',\n","   ',',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'TO',\n","   'VB',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'JJR',\n","   'NN',\n","   ',',\n","   'RB',\n","   'IN',\n","   'NN',\n","   'CC',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NNS',\n","   'VBP',\n","   '.'],\n","  ['NNP',\n","   'NNP',\n","   'NN',\n","   'NN',\n","   'NN',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   ',',\n","   'NNP',\n","   'CD',\n","   'CD',\n","   'NN',\n","   'NN',\n","   ':',\n","   'CD',\n","   'NN',\n","   ':',\n","   'CD'],\n","  ['NNP', ':'],\n","  ['VBP', 'DT', 'NN', '.'],\n","  ['RB',\n","   ',',\n","   'IN',\n","   'PRP$',\n","   'JJ',\n","   'NN',\n","   ',',\n","   'PRP',\n","   'VBP',\n","   'RB',\n","   'VBG',\n","   'TO',\n","   'RB',\n","   'VB',\n","   'IN',\n","   'DT',\n","   'NN',\n","   '.'],\n","  ['PRP',\n","   'VBP',\n","   'NNP',\n","   'MD',\n","   'VB',\n","   'TO',\n","   'VB',\n","   'NN',\n","   'JJ',\n","   ',',\n","   'CC',\n","   'IN',\n","   'NN',\n","   'PRP',\n","   'VBZ',\n","   'RB',\n","   ',',\n","   'PRP',\n","   'VBP',\n","   'RB',\n","   'VB',\n","   'TO',\n","   'VB',\n","   'CD',\n","   'NN',\n","   'IN',\n","   'PRP$',\n","   'NN',\n","   'NN',\n","   '.'],\n","  ['PRP',\n","   'VBP',\n","   'NN',\n","   'NNS',\n","   'IN',\n","   'WRB',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'TO',\n","   'VB',\n","   'RP',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   'CC',\n","   'MD',\n","   'VB',\n","   'NNS',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'NN',\n","   '.'],\n","  ['IN',\n","   'DT',\n","   'NNS',\n","   ',',\n","   'PRP',\n","   'VBD',\n","   'PRP',\n","   'VBD',\n","   'RB',\n","   'VBN',\n","   'TO',\n","   'VB',\n","   'JJ',\n","   'NNS',\n","   '.'],\n","  ['PRP',\n","   'MD',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'PRP',\n","   'VBP',\n","   'IN',\n","   'JJ',\n","   'JJ',\n","   'NNS',\n","   '.'],\n","  ['UH', 'VB', 'IN', 'DT', 'IN', 'PRP', '.'],\n","  ['NNP', '.'],\n","  ['NNP', ','],\n","  ['PRP',\n","   'VBD',\n","   'VBG',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   'CC',\n","   'VBG',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'RP',\n","   'DT',\n","   'NNS',\n","   'PRP',\n","   'VBD',\n","   '.'],\n","  ['RB',\n","   'RB',\n","   ',',\n","   'PRP',\n","   'MD',\n","   'RB',\n","   'VB',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'NNS',\n","   'RB',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'VBZ',\n","   'DT',\n","   'NN',\n","   '.'],\n","  ['PRP',\n","   'VBP',\n","   'RB',\n","   'JJ',\n","   'IN',\n","   'NNP',\n","   'IN',\n","   'CD',\n","   'VBZ',\n","   'DT',\n","   'NN',\n","   ',',\n","   'CC',\n","   'RB',\n","   'IN',\n","   'CD',\n","   '.'],\n","  ['VB', 'PRP', 'IN', 'PRP', 'VBP', 'JJ', '.'],\n","  ['NNP',\n","   'NNP',\n","   'NN',\n","   'NN',\n","   'NN',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   ',',\n","   'NNP',\n","   'CD',\n","   'CD',\n","   'NN',\n","   'NN',\n","   ':',\n","   'CD',\n","   'NN',\n","   ':',\n","   'CD'],\n","  ['NN',\n","   'VBG',\n","   'NN',\n","   'IN',\n","   'NNS',\n","   'CC',\n","   'NNS',\n","   ':',\n","   'UH',\n","   'VB',\n","   'RB',\n","   'VB',\n","   'NNS',\n","   'CC',\n","   ',',\n","   'CC',\n","   'NNS',\n","   'VBG',\n","   'PRP$',\n","   'NNP',\n","   'NN',\n","   '-LRB-',\n","   'AFX',\n","   '-RRB-',\n","   'IN',\n","   'NN',\n","   '.'],\n","  ['NNS',\n","   'CC',\n","   ',',\n","   'CC',\n","   'NNS',\n","   'VBN',\n","   'IN',\n","   'NN',\n","   'MD',\n","   'RB',\n","   'VB',\n","   'VBN',\n","   'IN',\n","   'NNP',\n","   'CC',\n","   'NNP',\n","   'MD',\n","   'RB',\n","   'VB',\n","   'JJ',\n","   'IN',\n","   'VBG',\n","   'RP',\n","   'JJ',\n","   'NNS',\n","   'CC',\n","   ',',\n","   'CC',\n","   'NNS',\n","   '.'],\n","  ['NN',\n","   'VBG',\n","   'NN',\n","   'CC',\n","   'NN',\n","   ':',\n","   'NNP',\n","   'VBZ',\n","   'DT',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'CC',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NNS',\n","   'VBN',\n","   'CC',\n","   ',',\n","   'CC',\n","   'VBN',\n","   'IN',\n","   'PRP$',\n","   'NNS',\n","   '.'],\n","  ['NN',\n","   'VBG',\n","   'NN',\n","   'IN',\n","   'NNS',\n","   'CC',\n","   'NNS',\n","   ':',\n","   'UH',\n","   'VB',\n","   'RB',\n","   'VB',\n","   'NNS',\n","   'CC',\n","   ',',\n","   'CC',\n","   'NNS',\n","   'VBG',\n","   'PRP$',\n","   'NNP',\n","   'NN',\n","   '-LRB-',\n","   'AFX',\n","   '-RRB-',\n","   'IN',\n","   'NN',\n","   '.'],\n","  ['NNS',\n","   'CC',\n","   ',',\n","   'CC',\n","   'NNS',\n","   'VBN',\n","   'IN',\n","   'NN',\n","   'MD',\n","   'RB',\n","   'VB',\n","   'VBN',\n","   'IN',\n","   'NNP',\n","   'CC',\n","   'NNP',\n","   'MD',\n","   'RB',\n","   'VB',\n","   'JJ',\n","   'IN',\n","   'VBG',\n","   'RP',\n","   'JJ',\n","   'NNS',\n","   'CC',\n","   ',',\n","   'CC',\n","   'NNS',\n","   '.'],\n","  ['NNP',\n","   'VBG',\n","   'NN',\n","   'CC',\n","   'NN',\n","   ':',\n","   'NNP',\n","   'VBZ',\n","   'DT',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'CC',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NNS',\n","   'VBN',\n","   'CC',\n","   ',',\n","   'CC',\n","   'VBN',\n","   'IN',\n","   'PRP$',\n","   'NNS',\n","   '.'],\n","  ['NN',\n","   'VBG',\n","   'NN',\n","   'IN',\n","   'NNS',\n","   'CC',\n","   'NNS',\n","   ':',\n","   'UH',\n","   'VB',\n","   'RB',\n","   'VB',\n","   'NNS',\n","   'CC',\n","   ',',\n","   'CC',\n","   'NNS',\n","   'VBG',\n","   'PRP$',\n","   'NNP',\n","   'NN',\n","   '-LRB-',\n","   'AFX',\n","   '-RRB-',\n","   'IN',\n","   'NN',\n","   '.'],\n","  ['NNS',\n","   'CC',\n","   ',',\n","   'CC',\n","   'NNS',\n","   'VBN',\n","   'IN',\n","   'NN',\n","   'MD',\n","   'RB',\n","   'VB',\n","   'VBN',\n","   'IN',\n","   'NNP',\n","   'CC',\n","   'NNP',\n","   'MD',\n","   'RB',\n","   'VB',\n","   'JJ',\n","   'IN',\n","   'VBG',\n","   'RP',\n","   'JJ',\n","   'NNS',\n","   'CC',\n","   ',',\n","   'CC',\n","   'NNS',\n","   '.'],\n","  ['NN',\n","   'VBG',\n","   'NN',\n","   'CC',\n","   'NN',\n","   ':',\n","   'NNP',\n","   'VBZ',\n","   'DT',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'CC',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NNS',\n","   'VBN',\n","   'CC',\n","   ',',\n","   'CC',\n","   'VBN',\n","   'IN',\n","   'PRP$',\n","   'NNS',\n","   '.'],\n","  ['WP', 'VBZ', '.'],\n","  ['UH', 'VB', 'IN', 'JJ', 'RB', 'PRP$', 'NN', 'NN', 'VBZ', 'VBN', 'IN'],\n","  ['PRP', 'RB', 'VBN', 'IN', 'NNP', '.'],\n","  ['WRB', 'IN', 'NN', 'IN', 'NNP', 'IN', 'DT', '.'],\n","  ['PRP$', 'NN', 'NNP', 'VBD', 'PRP', '.'],\n","  ['WRB', 'IN', 'JJ', 'IN', 'DT', 'CC', 'IN', 'DT', 'IN', 'NNP', '.'],\n","  ['RB', 'RB', '.'],\n","  ['RB', 'VBP', 'NNS', 'IN', 'NNP', '.'],\n","  ['VBP', 'PRP', 'VBG', 'IN', 'DT', 'NNP', 'NN', 'NN', 'NN', 'NNP', '.'],\n","  ['UH', 'NNP', 'VBZ', 'EX', 'DT', 'NN', '.'],\n","  ['MD', 'NN', 'NNP', 'VB', 'RB', '.'],\n","  ['RB', 'RB', '.'],\n","  ['RB', 'VBP', 'NNS', 'IN', 'NNP', '.'],\n","  ['VBP', 'PRP', 'VBG', 'IN', 'DT', 'NNP', 'NN', 'NN', 'NN', 'NNP', '.'],\n","  ['UH', 'NNP', 'VBZ', 'EX', 'DT', 'NN', '.'],\n","  ['NNP', ','],\n","  ['PRP',\n","   'MD',\n","   'VB',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   '.'],\n","  ['NNP', 'NNP', 'CC', 'NNP', 'NNP', 'MD', 'VB', 'TO', 'VB', 'RB', 'RB', '.'],\n","  ['DT', 'NN', 'IN', 'CD', 'NN', 'CC', 'RB', 'MD', 'VB', 'IN', 'PRP', '.'],\n","  ['UH', 'VB', 'PRP', 'VB', 'WDT', 'NN', 'PRP', 'MD', 'VB', '.'],\n","  ['VBP', 'PRP', ','],\n","  ['NNP'],\n","  ['NNP', ','],\n","  ['DT',\n","   'NN',\n","   'VBZ',\n","   'IN',\n","   'VBN',\n","   'NNS',\n","   'WP',\n","   'VBP',\n","   'VBN',\n","   'RP',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'VBG',\n","   'DT',\n","   'NN',\n","   'NN',\n","   '.'],\n","  ['DT',\n","   'NN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'VBZ',\n","   ',',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'PRP$',\n","   'NN',\n","   'NN',\n","   'MD',\n","   'VB',\n","   'VBN',\n","   'IN',\n","   'DT',\n","   'VBG',\n","   'NN',\n","   'NN',\n","   'DT',\n","   'NN',\n","   'VBG',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   '.'],\n","  ['IN',\n","   'JJ',\n","   ',',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'JJ',\n","   'NNS',\n","   'VBG',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   'DT',\n","   'NN',\n","   'JJ',\n","   'IN',\n","   'VBG',\n","   'DT',\n","   'NN',\n","   'NN',\n","   '.'],\n","  ['PRP',\n","   'MD',\n","   'VB',\n","   'VBG',\n","   'DT',\n","   'NNS',\n","   'VBN',\n","   'IN',\n","   'PRP$',\n","   'CD',\n","   'NN',\n","   '-LRB-',\n","   'CD',\n","   'NNS',\n","   'CC',\n","   'NN',\n","   'IN',\n","   'JJ',\n","   'NNS',\n","   '-RRB-',\n","   '.'],\n","  ['IN',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   ',',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'JJ',\n","   'NNS',\n","   '.'],\n","  ['UH', 'VB', 'PRP', 'VB', 'PRP$', 'NN', '.'],\n","  ['IN',\n","   'PRP',\n","   'VBP',\n","   ',',\n","   'PRP',\n","   'VBP',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'VBG',\n","   'NN',\n","   'NNS',\n","   'IN',\n","   'NNP',\n","   'IN',\n","   'NNP',\n","   '.'],\n","  ['IN',\n","   'JJ',\n","   ',',\n","   'PRP',\n","   'VBP',\n","   'DT',\n","   'NN',\n","   ',',\n","   'NNP',\n","   'NNP',\n","   ',',\n","   'VBG',\n","   'IN',\n","   'PRP',\n","   'TO',\n","   'VB',\n","   'CC',\n","   'VB',\n","   'RP',\n","   'NN',\n","   'NNS',\n","   '.'],\n","  ['PRP',\n","   'VBZ',\n","   'VBN',\n","   'PRP$',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   '-LRB-',\n","   'RB',\n","   'RBR',\n","   'JJ',\n","   'IN',\n","   'PRP',\n","   '-RRB-',\n","   'CC',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   'NNS',\n","   '.'],\n","  ['IN',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   ',',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'RP',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'PRP',\n","   ',',\n","   'PRP',\n","   ',',\n","   'CC',\n","   'NNP',\n","   'TO',\n","   'VB',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   '.'],\n","  ['UH',\n","   'VB',\n","   'PRP',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'CC',\n","   'NN',\n","   'WDT',\n","   'VBZ',\n","   'JJ',\n","   'IN',\n","   'PRP',\n","   '.'],\n","  ['NN', ','],\n","  ['NNP'],\n","  ['NNP', ','],\n","  ['VBP',\n","   'PRP',\n","   'IN',\n","   'VBG',\n","   'IN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'VBN',\n","   'NN',\n","   'NN',\n","   'NNS',\n","   '.'],\n","  ['PRP', 'VBZ', 'JJ', 'IN', 'DT', 'NN', 'MD', 'VB', 'VBN', 'IN', 'NNS', '.'],\n","  ['RB',\n","   ',',\n","   'PRP',\n","   'RB',\n","   'VBP',\n","   'RB',\n","   'VB',\n","   'WDT',\n","   'NN',\n","   'MD',\n","   'VB',\n","   'VBN',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'CC',\n","   'VB',\n","   'WRB',\n","   'JJ',\n","   'NNS',\n","   '.'],\n","  ['DT', 'NN', 'NN', 'IN', 'CD', '.'],\n","  ['NNP',\n","   'IN',\n","   'NNP',\n","   'NNPS',\n","   'VBZ',\n","   '``',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NNS',\n","   ',',\n","   'CC',\n","   'VBG',\n","   'NN',\n","   'NN',\n","   'MD',\n","   'VB',\n","   'VBN',\n","   'IN',\n","   'DT',\n","   'VBG',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   'NNP',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NNP',\n","   'CD',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NN',\n","   ',',\n","   'CC',\n","   'JJ',\n","   'NN',\n","   'MD',\n","   'VB',\n","   'VBN',\n","   'IN',\n","   'NNS',\n","   'IN',\n","   'NNP',\n","   'NNP',\n","   'JJ',\n","   'NN',\n","   '.',\n","   \"''\"],\n","  ['MD',\n","   'PRP',\n","   'VB',\n","   'PRP',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'CC',\n","   'VB',\n","   'IN',\n","   'DT',\n","   'NNS',\n","   'IN',\n","   'PRP$',\n","   'NN',\n","   '.'],\n","  ['VBP', 'PRP', ','],\n","  ['NNP', 'NNP'],\n","  ['VB', 'PRP', 'VB', 'WRB', 'PRP', 'VBP', 'DT', 'NNS', 'IN', 'NNP', '.'],\n","  ['PRP',\n","   'VBP',\n","   'VBG',\n","   'TO',\n","   'VB',\n","   'NN',\n","   'IN',\n","   'DT',\n","   '$',\n","   'CD',\n","   'IN',\n","   '$',\n","   'CD',\n","   'NN',\n","   '.'],\n","  ['PRP',\n","   'MD',\n","   'VB',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'NNS',\n","   'CC',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'VBN',\n","   '.'],\n","  ['PRP',\n","   'VBZ',\n","   'PRP$',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'MD',\n","   'VB',\n","   'VBN',\n","   'CC',\n","   'VBN',\n","   'IN',\n","   'NN',\n","   '.'],\n","  ['IN',\n","   'PRP',\n","   'VBP',\n","   'VBG',\n","   'NNS',\n","   'TO',\n","   'VB',\n","   'RP',\n","   'JJ',\n","   'NN',\n","   'RB',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'TO',\n","   'VB',\n","   '.'],\n","  ['NNP',\n","   'VBZ',\n","   'JJ',\n","   'TO',\n","   'VB',\n","   'RB',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   '.'],\n","  ['IN',\n","   'DT',\n","   'NNS',\n","   'VBP',\n","   ',',\n","   'PRP',\n","   'VBZ',\n","   'IN',\n","   'PRP',\n","   'VBP',\n","   'TO',\n","   'VB',\n","   'RB',\n","   'CC',\n","   'VB',\n","   'RP',\n","   'DT',\n","   'NNS',\n","   '.'],\n","  ['RB', 'NNS', 'MD', 'VB', 'RB', '.'],\n","  ['NNP'],\n","  ['NNS', ':', 'NNP', 'NNP'],\n","  ['NNP', 'NNP'],\n","  ['NNP', 'NNP'],\n","  ['NNP', 'NNP'],\n","  ['NNP', 'NNP'],\n","  ['NNP', 'NNP'],\n","  ['NNP', ','],\n","  ['PRP',\n","   'VBD',\n","   'PRP',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'CD',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   'IN',\n","   'DT',\n","   'NNP',\n","   'NN',\n","   'NN',\n","   '.'],\n","  ['DT',\n","   'NN',\n","   'VBD',\n","   'RP',\n","   'RB',\n","   'IN',\n","   'PRP',\n","   'VBD',\n","   'IN',\n","   'PRP',\n","   'TO',\n","   'VB',\n","   'PRP',\n","   'VB',\n","   'IN',\n","   'DT',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   'CC',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   'CC',\n","   'NNP',\n","   'VBD',\n","   'RB',\n","   'VBN',\n","   '.'],\n","  ['VB', 'PRP', 'VB', 'WP', 'PRP', 'VBP', 'IN', 'DT', 'NN', '.'],\n","  ['RB',\n","   ',',\n","   'VB',\n","   'PRP',\n","   'VB',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NNS',\n","   'IN',\n","   'NN',\n","   'NN',\n","   '.'],\n","  ['NNP'],\n","  ['NNP', ','],\n","  ['VB', 'DT', 'NN', 'IN', 'DT', 'NN', '.'],\n","  ['PRP',\n","   'VBD',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NNP',\n","   'NNP',\n","   'CC',\n","   'NNP',\n","   'NN',\n","   'NNS',\n","   '.'],\n","  ['VBZ', 'DT', 'WRB', 'PRP$', 'NNS', 'RB', 'VBP', 'DT', 'NNS', '.'],\n","  ['DT', 'NNP', 'NN', 'VBZ', 'RB', 'JJR', '.'],\n","  ['NNP'],\n","  ['NNP', ','],\n","  ['DT',\n","   'VBZ',\n","   'JJR',\n","   'IN',\n","   'DT',\n","   'NNS',\n","   'PRP',\n","   'VBD',\n","   'VBG',\n","   'IN',\n","   'DT',\n","   'NN',\n","   '.'],\n","  ['PRP', 'MD', 'VB', 'JJ', 'TO', 'VB', 'IN', 'DT', '.'],\n","  ['NNP'],\n","  ['NNP', 'NNP'],\n","  ['CD', 'CD', 'NN'],\n","  ['NNP', 'NNP', 'NNPS'],\n","  ['NNS', '.'],\n","  ['PRP', 'VBP', 'RB', 'VBN', '.'],\n","  [',', 'RB', 'VBZ', 'DT', 'JJ', 'NN', '.'],\n","  ['DT',\n","   'VBG',\n","   'VBP',\n","   'VBN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   'NN',\n","   '.'],\n","  ['NN', 'IN', 'DT', 'WP', 'VBD', '.'],\n","  ['PRP', 'MD', 'VB', 'IN', 'NNS', '.'],\n","  ['NN', 'NN', 'NNS', ':'],\n","  ['NN', 'NN', 'CD', ':', 'NN', ':', 'NNP', 'NNP'],\n","  ['NNP', 'NNP', ',', 'NNP', 'NNP', ',', 'NNP', 'NNP', ',', 'NNP', 'NNP'],\n","  ['NN', 'NN', 'CD', ':', 'NN', ':', 'NNP', 'NNP'],\n","  ['NNP', 'NNP', ',', 'NNP', 'NNP', ',', 'NNP', 'NNP', ',', 'NNP', 'NNP'],\n","  ['NN', 'NN', 'NNS', ':'],\n","  ['NN', 'NN', 'CD', ':', 'NN', ':', 'NNP', 'NNP'],\n","  ['NNP', 'NNP', ',', 'NNP', 'NNP', ',', 'NNP', 'NNP', ',', 'NNP', 'NNP'],\n","  ['VBN',\n","   'NN',\n","   ',',\n","   'NN',\n","   'NN',\n","   'CD',\n","   ':',\n","   'NN',\n","   ':',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   ',',\n","   'NN',\n","   ',',\n","   'NNP',\n","   'NNP',\n","   ',',\n","   'NN',\n","   ',',\n","   'NNP',\n","   'NNP',\n","   ',',\n","   'NN',\n","   ',',\n","   'NNP',\n","   'NNP',\n","   ',',\n","   'NN'],\n","  ['NNS',\n","   ':',\n","   'NNP',\n","   'NNP',\n","   ',',\n","   'NNP',\n","   'NNP',\n","   ',',\n","   'NNP',\n","   'NNP',\n","   ',',\n","   'NNP',\n","   'NNP',\n","   ',',\n","   'NNP',\n","   'NNP'],\n","  ['WP', 'VBZ', 'TO', 'VB', 'NNS', 'IN', 'NNP', 'NNP', '.'],\n","  ['PRP', 'VBP', 'PRP', 'VBP', '.'],\n","  ['WRB', 'TO', 'VB', ':'],\n","  ['DT', 'NN', 'PRP', 'VBZ', 'RB', 'JJ', 'TO', 'VB', 'PRP$', 'NN', '.'],\n","  ['RB',\n","   'VB',\n","   'RB',\n","   'DT',\n","   'VBG',\n","   'NNP',\n","   'NNP',\n","   'NN',\n","   ',',\n","   'CC',\n","   'VB',\n","   'RB',\n","   'IN',\n","   'NNP',\n","   'NNP',\n","   'CC',\n","   'NNP',\n","   'CC',\n","   'VB',\n","   'RB',\n","   'RP',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   '.'],\n","  ['DT',\n","   'NN',\n","   'MD',\n","   'VB',\n","   'PRP',\n","   'RB',\n","   'IN',\n","   'NNP',\n","   'POS',\n","   'NNP',\n","   'NNP',\n","   'CD',\n","   'NN',\n","   'NN',\n","   '.'],\n","  ['UH',\n","   'VB',\n","   ':',\n","   'PRP$',\n","   'NN',\n","   'VBZ',\n","   'TO',\n","   'VB',\n","   'VBN',\n","   'RB',\n","   ',',\n","   'PRP',\n","   'RB',\n","   'VBZ',\n","   'NNS',\n","   '.'],\n","  ['DT', 'JJ', 'NN', 'NNS', '.'],\n","  ['NNS',\n","   ':',\n","   'IN',\n","   'PRP',\n","   'VBP',\n","   'DT',\n","   'NNS',\n","   'VBG',\n","   'DT',\n","   'NN',\n","   'NN',\n","   ',',\n","   'UH',\n","   'VB',\n","   'NNP',\n","   'NNP',\n","   '-LRB-',\n","   'CD',\n","   '-RRB-',\n","   ',',\n","   'NNP',\n","   'NNP',\n","   '-LRB-',\n","   'CD',\n","   '-RRB-',\n","   'CC',\n","   'NNP',\n","   'NNP',\n","   '-LRB-',\n","   'CD',\n","   '-RRB-',\n","   '.'],\n","  ['PRP', 'VBP', 'IN', 'CC', 'NNP', 'CC', 'NNP', 'VBP', 'RB', '.'],\n","  ['NN',\n","   'NN',\n","   'IN',\n","   'CD',\n","   ',',\n","   'PRP',\n","   'VBZ',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'NN',\n","   '.'],\n","  ['PRP',\n","   'VBP',\n","   'RB',\n","   'VBN',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'RB',\n","   'PRP',\n","   'VBP',\n","   'NNP',\n","   'CC',\n","   'PRP',\n","   'VBP',\n","   'VBG',\n","   'TO',\n","   'VB',\n","   'IN',\n","   'NN',\n","   '.'],\n","  ['DT',\n","   'NN',\n","   'VBZ',\n","   'VBG',\n","   'TO',\n","   'VB',\n","   'JJ',\n","   ',',\n","   'NNP',\n","   'VBD',\n","   'RB',\n","   'VBG',\n","   'NN',\n","   '.'],\n","  ['NNP', 'NNP'],\n","  ['CD', 'CD', 'NN'],\n","  ['VBP', 'PRP', 'VBN', 'IN', 'NN', '.'],\n","  ['RB', ',', 'WP', 'VBZ', 'DT', 'NN', 'IN', 'DT', 'NN', 'DT', 'NN', '.'],\n","  ['VBZ', 'PRP', 'VBN', 'TO', 'VB', 'VBG', '.'],\n","  ['IN',\n","   'DT',\n","   'NN',\n","   ',',\n","   'VB',\n","   'PRP',\n","   'RB',\n","   'IN',\n","   'PRP',\n","   'VBZ',\n","   'VBG',\n","   'IN',\n","   'CD',\n","   'IN',\n","   'NN',\n","   'NN',\n","   '.'],\n","  ['PRP$', 'NN', 'RB', 'VBZ', 'IN', 'PRP', ',', 'WP', 'MD', 'PRP', 'VB', '.'],\n","  ['CC', ',', 'PRP', 'VBP', 'RB', 'JJ', 'IN', 'PRP', '.'],\n","  ['WRB', 'VBP', 'PRP', '.'],\n","  ['DT', 'NN', 'IN', 'NNP', 'NNP', '.'],\n","  ['UH'],\n","  ['NFP', 'NNP'],\n","  ['NNP', 'NNP'],\n","  ['CD', 'CD'],\n","  ['NNP', ',', 'NNP'],\n","  ['RB',\n","   'CC',\n","   'RB',\n","   '-LRB-',\n","   'IN',\n","   'NNP',\n","   'NNP',\n","   'POS',\n","   'NN',\n","   '-RRB-',\n","   'PRP',\n","   'VBP',\n","   'VBN',\n","   'RB',\n","   'DT',\n","   'CD',\n","   'NN',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'PRP$',\n","   'JJ',\n","   'NN',\n","   'NNS',\n","   '-LRB-',\n","   'PRP',\n","   'DT',\n","   'CD',\n","   'NN',\n","   'NN',\n","   '-RRB-',\n","   '.'],\n","  ['PRP',\n","   'VBP',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NN',\n","   ',',\n","   'WRB',\n","   'PRP',\n","   'VBP',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   'WDT',\n","   'MD',\n","   'VB',\n","   'DT',\n","   'IN',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   '-LRB-',\n","   'DT',\n","   'NNP',\n","   'NNP',\n","   'NN',\n","   '-RRB-'],\n","  ['VBP', 'PRP', 'DT', 'NNS', 'IN', 'NN', 'CC', 'NN', 'NN', '.'],\n","  ['NNP'],\n","  ['JJ', 'NNP', 'VBZ', 'JJ', '.'],\n","  ['NNP',\n","   'VBZ',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'JJ',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   ',',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   '-LRB-',\n","   'JJ',\n","   'NN',\n","   'WDT',\n","   'PRP',\n","   'CC',\n","   'PRP',\n","   'VBP',\n","   'JJ',\n","   'TO',\n","   'VB',\n","   'IN',\n","   '-RRB-',\n","   ',',\n","   'DT',\n","   'NNP',\n","   'NNP',\n","   'CC',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   '.'],\n","  ['PRP',\n","   'VBP',\n","   'IN',\n","   'DT',\n","   'VBP',\n","   'CD',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NN',\n","   ',',\n","   'NNP',\n","   'CD',\n","   ',',\n","   'CD',\n","   'CC',\n","   'NN',\n","   '.'],\n","  ['RB',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   'MD',\n","   'VB',\n","   'RB',\n","   '-LRB-',\n","   'CC',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'JJ',\n","   'NNS',\n","   '.',\n","   '-RRB-',\n","   '.'],\n","  ['VBZ', 'DT', 'VB', 'IN', 'PRP', '.'],\n","  ['CC',\n","   'VBP',\n","   'PRP',\n","   'VB',\n","   'TO',\n","   'VB',\n","   'PRP',\n","   'IN',\n","   'DT',\n","   'NNP',\n","   'CC',\n","   'NNP',\n","   '.'],\n","  ['NNP',\n","   'RB',\n","   'VBZ',\n","   'RBR',\n","   'IN',\n","   'PRP',\n","   ',',\n","   'RB',\n","   'IN',\n","   'IN',\n","   'PRP',\n","   'VBP',\n","   'RB',\n","   'IN',\n","   'NNP',\n","   'CC',\n","   'VBG',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   'NN',\n","   '.'],\n","  ['UH', ','],\n","  ['VBD', 'IN', 'DT', 'JJ', 'NN', 'HYPH', 'NN', 'HYPH', 'NN', '.'],\n","  ['PRP', 'VBD', 'DT', 'NN', 'MD', 'VB', 'JJ', '.'],\n","  ['PRP', 'VBZ', 'DT', 'JJ', 'NN', 'NNP', '.'],\n","  ['WRB', 'VBZ', 'JJ', 'NNP', 'VB', 'IN', 'PRP', '.'],\n","  ['MD', 'PRP', 'VB', 'DT', 'NN', 'RB', '.'],\n","  ['VBP', 'PRP', 'VBG', 'IN', 'NN', '.'],\n","  ['NNP'],\n","  ['PRP',\n","   'VBP',\n","   'IN',\n","   'PRP',\n","   'VBZ',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'VBG',\n","   'PRP$',\n","   'JJ',\n","   'NN',\n","   'NNS',\n","   ',',\n","   'CC',\n","   'PRP',\n","   'VBP',\n","   'IN',\n","   'DT',\n","   'RBS',\n","   'JJ',\n","   'NN',\n","   ',',\n","   'JJ',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'CC',\n","   'DT',\n","   'NNS',\n","   'IN',\n","   'NN',\n","   '.'],\n","  ['IN',\n","   'DT',\n","   'NNS',\n","   'IN',\n","   'NN',\n","   ',',\n","   'PRP',\n","   'VBP',\n","   'RB',\n","   'JJ',\n","   'IN',\n","   'PRP$',\n","   'NN',\n","   'IN',\n","   'CC',\n","   'RB',\n","   'PRP',\n","   'RB',\n","   'VBP',\n","   'DT',\n","   'NN',\n","   '.'],\n","  ['VBZ',\n","   'EX',\n","   'DT',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'VBN',\n","   'IN',\n","   'DT',\n","   'NNP',\n","   'NN',\n","   'CC',\n","   'IN',\n","   'NN',\n","   'DT',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'VBN',\n","   'IN',\n","   'NNP',\n","   'POS',\n","   'NN',\n","   '-LRB-',\n","   'IN',\n","   'RB',\n","   ',',\n","   'IN',\n","   'WP',\n","   'MD',\n","   'DT',\n","   'NN',\n","   'VB',\n","   'VBN',\n","   '-RRB-',\n","   '.'],\n","  ['CC',\n","   'VBZ',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   'DT',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'VBN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   '.'],\n","  ['IN',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   ',',\n","   'PRP',\n","   'VBP',\n","   'IN',\n","   'CD',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NNS',\n","   'IN',\n","   'JJ',\n","   'NN',\n","   'NNS',\n","   'VBP',\n","   'IN',\n","   'PRP',\n","   'VBP',\n","   'VBN',\n","   'TO',\n","   'VB',\n","   'JJ',\n","   'IN',\n","   'NN',\n","   ',',\n","   'VBN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'CC',\n","   'DT',\n","   'NN',\n","   'WRB',\n","   'PRP',\n","   'VBP',\n","   'IN',\n","   'NN',\n","   'NNS',\n","   '.'],\n","  ['IN',\n","   'DT',\n","   'NN',\n","   'NNS',\n","   'VBN',\n","   'RB',\n","   ',',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'IN',\n","   'NNS',\n","   'NNS',\n","   'IN',\n","   'NN',\n","   'VBZ',\n","   'VBG',\n","   'VBN',\n","   'CC',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'JJ',\n","   'TO',\n","   'VB',\n","   'NNP',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'EX',\n","   'VBZ',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'NNS',\n","   'RB',\n","   '.'],\n","  ['DT',\n","   'JJ',\n","   'NNS',\n","   'RB',\n","   'MD',\n","   'VB',\n","   'NNP',\n","   'TO',\n","   'VB',\n","   'PRP$',\n","   'NN',\n","   'NN',\n","   'RBR',\n","   'RB',\n","   ',',\n","   'IN',\n","   'RB',\n","   'VBN',\n","   'NNS',\n","   'IN',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'NNS',\n","   '.'],\n","  ['PRP',\n","   'VBP',\n","   'RB',\n","   'JJ',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'VBN',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'VBZ',\n","   'RB',\n","   '.'],\n","  ['RB', ',', 'DT', 'NN', 'VBG', 'NN', '.'],\n","  ['DT',\n","   'JJ',\n","   'PRP',\n","   'VBD',\n","   'IN',\n","   'PRP',\n","   'CC',\n","   'NNP',\n","   'VBD',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'JJ',\n","   'NN',\n","   'NNS',\n","   'VBD',\n","   'IN',\n","   'DT',\n","   'VBD',\n","   'VBG',\n","   'VBN',\n","   '-LRB-',\n","   'NNP',\n","   'VBD',\n","   'DT',\n","   'TO',\n","   'VB',\n","   'IN',\n","   'NNP',\n","   'POS',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   '-RRB-',\n","   'IN',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NNS',\n","   '.'],\n","  ['PRP',\n","   'VBP',\n","   'RB',\n","   'VB',\n","   'IN',\n","   'PRP',\n","   'VBP',\n","   'RB',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'WRB',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NNS',\n","   'RB',\n","   'VBP',\n","   'VBN',\n","   ',',\n","   'VBP',\n","   'CC',\n","   'VBP',\n","   'VBN',\n","   'DT',\n","   'NNS',\n","   '.'],\n","  ['CC',\n","   'RB',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'VBG',\n","   'DT',\n","   'NNS',\n","   ',',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   '-LRB-',\n","   'CC',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'DT',\n","   '-RRB-',\n","   'MD',\n","   'VB',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NNS',\n","   '.'],\n","  ['PRP$',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   'NNP',\n","   'VBZ',\n","   'IN',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   '.'],\n","  ['EX',\n","   'VBZ',\n","   'JJ',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'IN',\n","   'VBG',\n","   'DT',\n","   'NN',\n","   'CC',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'CC',\n","   'RB',\n","   'JJR',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'TO',\n","   'VB',\n","   'JJ',\n","   'NNS',\n","   'IN',\n","   'NN',\n","   'IN',\n","   'VBG',\n","   'DT',\n","   'NN',\n","   '.'],\n","  ['NNP',\n","   'VBZ',\n","   'VBN',\n","   'NNP',\n","   'NNP',\n","   'TO',\n","   'VB',\n","   'IN',\n","   'DT',\n","   ',',\n","   'CC',\n","   'PRP',\n","   'VBP',\n","   'IN',\n","   'NNP',\n","   'VBZ',\n","   'RB',\n","   'VBN',\n","   'VBG',\n","   'IN',\n","   'NNP',\n","   'NNP',\n","   '.'],\n","  ['RB',\n","   'PRP',\n","   'VBP',\n","   'IN',\n","   'CC',\n","   'RB',\n","   'PRP',\n","   'VBP',\n","   'TO',\n","   'VB',\n","   'NN',\n","   'IN',\n","   'JJ',\n","   'NNS',\n","   'WDT',\n","   'PRP',\n","   'MD',\n","   'RB',\n","   'RB',\n","   'VB',\n","   'IN',\n","   '.'],\n","  ['MD',\n","   'DT',\n","   'RBR',\n","   'JJ',\n","   'NN',\n","   'VB',\n","   'IN',\n","   'DT',\n","   'NNP',\n","   'NNPS',\n","   'NNP',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   'WRB',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'JJ',\n","   'NN',\n","   'HYPH',\n","   'NN',\n","   'CC',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NNS',\n","   'CC',\n","   '-LRB-',\n","   'RB',\n","   '-RRB-',\n","   'PRP$',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   '.'],\n","  ['JJ', 'IN', 'DT', 'NN', 'VBZ', 'RB', 'JJ', '.'],\n","  ['PRP',\n","   'VBP',\n","   'VBN',\n","   'VBN',\n","   'CD',\n","   'NNS',\n","   'IN',\n","   'VBG',\n","   ',',\n","   'RB',\n","   'PRP',\n","   'VBP',\n","   'IN',\n","   'PRP',\n","   'VBZ',\n","   'NN',\n","   '.'],\n","  ['NN', 'IN', 'VBG', 'DT', 'IN', 'PRP', '.'],\n","  ['IN',\n","   'PRP',\n","   'VBD',\n","   'IN',\n","   'NN',\n","   ',',\n","   'PRP',\n","   'VBP',\n","   'IN',\n","   'PRP',\n","   'VBP',\n","   'RB',\n","   'VB',\n","   'IN',\n","   'PRP',\n","   'VBD',\n","   'PRP',\n","   'DT',\n","   '.'],\n","  ['NFP', 'NNP'],\n","  ['NNP', 'NNP'],\n","  ['CD', 'CD', 'NN'],\n","  ['UH', 'VB', 'VBN', 'DT', 'RBS', 'JJ', 'NN', 'IN', 'NNP', 'NNPS', '.'],\n","  ['IN',\n","   'NN',\n","   'DT',\n","   'VBN',\n","   'NNS',\n","   'NNS',\n","   'CC',\n","   'JJ',\n","   'NN',\n","   'NNS',\n","   'VBP',\n","   'IN',\n","   'NN',\n","   '.'],\n","  ['JJ',\n","   'NNS',\n","   'VBP',\n","   'VBG',\n","   'VBN',\n","   'CC',\n","   'DT',\n","   'NN',\n","   'VBZ',\n","   'VBG',\n","   'RB',\n","   'VBN',\n","   '-LRB-',\n","   'CC',\n","   'IN',\n","   'NN',\n","   'NN',\n","   'NN',\n","   'CC',\n","   'JJ',\n","   'NNS',\n","   '-RRB-',\n","   '.'],\n","  ['UH', 'VB', 'PRP', 'IN', 'PRP', 'VBP', 'DT', 'JJ', 'NN'],\n","  ['NNP'],\n","  ['NNP', 'NNP'],\n","  ['CD', 'CD'],\n","  ['DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NNS',\n","   'CC',\n","   'NNS',\n","   'VBN',\n","   'IN',\n","   'PRP$',\n","   'JJR',\n","   'NN',\n","   '-LRB-',\n","   'VB',\n","   'VBN',\n","   'NN',\n","   '-RRB-',\n","   'VBD',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   ',',\n","   'NN',\n","   'CC',\n","   'NN',\n","   'CC',\n","   'NN',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'NN',\n","   'JJ',\n","   'NN',\n","   'NNS',\n","   'CC',\n","   'NN',\n","   'NNS',\n","   'NN',\n","   'JJ',\n","   'NNS',\n","   'CC',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NNP',\n","   'JJ',\n","   'NN'],\n","  ['IN',\n","   'DT',\n","   'JJS',\n","   'NNS',\n","   'IN',\n","   'NN',\n","   ',',\n","   'VBG',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   ',',\n","   'DT',\n","   'JJR',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'NN',\n","   'NNS',\n","   ',',\n","   'CC',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   'NN',\n","   'VBP',\n","   'JJ',\n","   'IN',\n","   'PRP',\n","   'VBP',\n","   'RB',\n","   'RB',\n","   'JJ',\n","   'IN',\n","   'VBG',\n","   'JJ',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'PRP$',\n","   'NN',\n","   'NNS',\n","   ',',\n","   'WDT',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'VBZ',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'CC',\n","   'JJ',\n","   'NNS',\n","   'IN',\n","   'JJ',\n","   'NN',\n","   'NNS',\n","   '.'],\n","  ['RB',\n","   'PRP',\n","   'VBP',\n","   'TO',\n","   'VB',\n","   'PRP',\n","   'IN',\n","   ',',\n","   'CC',\n","   ',',\n","   'CC',\n","   'VB',\n","   'PRP$',\n","   'NN',\n","   'IN',\n","   ',',\n","   'DT',\n","   'VBG',\n","   ':'],\n","  ['PRP', 'MD', 'VB', 'IN', 'NN', 'DT', 'VBG'],\n","  ['IN',\n","   'NN',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'VBN',\n","   'NN',\n","   'NN',\n","   'MD',\n","   'VB',\n","   'VBN',\n","   'IN',\n","   'IN',\n","   'NN',\n","   'NNS',\n","   '-LRB-',\n","   'IN',\n","   'CC',\n","   'IN',\n","   'VBG',\n","   'NNS',\n","   'IN',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'NNS',\n","   '-RRB-'],\n","  ['IN',\n","   'EX',\n","   'VBP',\n","   'NN',\n","   'NNS',\n","   'IN',\n","   'NN',\n","   'NN',\n","   'NNS',\n","   ',',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'NNS',\n","   'CC',\n","   'DT',\n","   'JJ',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   '-LRB-',\n","   'DT',\n","   'NNS',\n","   'VBP',\n","   'IN',\n","   'JJ',\n","   'RB',\n","   'VBN',\n","   'CC',\n","   'MD',\n","   'VB',\n","   'TO',\n","   'VB',\n","   'VBN',\n","   'IN',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   '-RRB-'],\n","  ['DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   'NN',\n","   'NN',\n","   'VBN',\n","   'IN',\n","   'PRP$',\n","   'JJR',\n","   'NN',\n","   'WDT',\n","   'MD',\n","   'RB',\n","   'VB',\n","   'VBN',\n","   'CC',\n","   'VBN',\n","   '-LRB-',\n","   'VB',\n","   'NN',\n","   'NN',\n","   '-RRB-'],\n","  ['DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'NN',\n","   '-LRB-',\n","   'RB',\n","   'IN',\n","   'JJ',\n","   'JJS',\n","   'NNS',\n","   '-RRB-',\n","   'IN',\n","   'JJ',\n","   'NNPS',\n","   'NNS',\n","   'WP',\n","   'VBP',\n","   'TO',\n","   'VB',\n","   'RB',\n","   'JJ',\n","   'NNS',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'RB',\n","   'VBN',\n","   'NNS'],\n","  ['DT',\n","   'NN',\n","   'IN',\n","   'JJ',\n","   'JJ',\n","   '``',\n","   'NNP',\n","   \"''\",\n","   'NN',\n","   'WP',\n","   'MD',\n","   '``',\n","   'VB',\n","   \"''\",\n","   'JJ',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   'NNS',\n","   'RB',\n","   'VBG',\n","   'DT',\n","   'VBG',\n","   'NNP',\n","   'NNS'],\n","  ['DT',\n","   'NN',\n","   'NN',\n","   'IN',\n","   '$',\n","   'CD',\n","   'CD',\n","   'VBZ',\n","   'IN',\n","   'DT',\n","   'VBN',\n","   'NN',\n","   'CC',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'VBN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   '.'],\n","  ['PRP',\n","   'MD',\n","   'VB',\n","   'TO',\n","   'VB',\n","   'JJ',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   ',',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'CC',\n","   'NN',\n","   'NN',\n","   'NNS',\n","   ',',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'NN',\n","   'NN',\n","   '.'],\n","  ['RB',\n","   ',',\n","   'DT',\n","   'NN',\n","   'MD',\n","   'VB',\n","   'TO',\n","   'VB',\n","   'VBN',\n","   'IN',\n","   'VBG',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'CC',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'NN',\n","   'NNS',\n","   'IN',\n","   'NNS',\n","   '.'],\n","  ['DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'JJ',\n","   'NNP',\n","   'CC',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'NN',\n","   '-LRB-',\n","   'VBN',\n","   'WRB',\n","   'RB',\n","   'JJ',\n","   '-RRB-',\n","   'IN',\n","   'NNS',\n","   'VBP',\n","   'RB',\n","   'VBN',\n","   'CC',\n","   'JJ',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   'MD',\n","   'VB',\n","   'VBN',\n","   '.'],\n","  ['NNP', 'NNP', 'NN', 'VBG', 'VBN', 'VBZ', 'IN', 'VBZ'],\n","  ['DT',\n","   'NN',\n","   'NN',\n","   'VBN',\n","   'IN',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'NN',\n","   ',',\n","   'IN',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'NNS',\n","   'IN',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'NN',\n","   ',',\n","   'NN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'CC',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   '-LRB-',\n","   'VBG',\n","   'VBN',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'IN',\n","   'NN',\n","   'NNS',\n","   '-RRB-',\n","   ',',\n","   'VBG',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'JJR',\n","   'NN'],\n","  ['NN',\n","   'IN',\n","   'NN',\n","   'NNS',\n","   'IN',\n","   'NN',\n","   'CC',\n","   'NN',\n","   'NN',\n","   'NNS',\n","   'IN',\n","   'NN',\n","   'JJ',\n","   'NNS'],\n","  ['JJ',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NNS',\n","   'WDT',\n","   'MD',\n","   'VB',\n","   'VBN',\n","   'IN',\n","   'NNP',\n","   'NN'],\n","  ['NN',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'NN',\n","   'NN',\n","   'VBG',\n","   'DT',\n","   'JJ',\n","   'RB',\n","   'VBN',\n","   'NN',\n","   'NN'],\n","  ['DT',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   'JJ',\n","   'NN',\n","   'CC',\n","   'NN',\n","   'IN',\n","   'PRP$',\n","   'NN',\n","   'NN',\n","   'CC',\n","   'NN',\n","   'NN'],\n","  ['DT', 'NNS', ',', 'NNS', 'JJ', 'NN', 'VBN', 'IN', 'NN', 'IN', 'NN', 'NN'],\n","  ['PRP', 'MD', 'VB', 'IN', 'NN', 'RB', 'IN', 'DT', 'NNS', 'VBG', 'NN'],\n","  ['NNS'],\n","  ['NNP'],\n","  ['NNP', 'NNP'],\n","  ['CD', 'CD'],\n","  ['JJ',\n","   'JJ',\n","   'NNS',\n","   'VBP',\n","   'VBN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NNP',\n","   'NNPS',\n","   'NN',\n","   '.'],\n","  ['NNS',\n","   'VBG',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'IN',\n","   'NN',\n","   'NN',\n","   'NN',\n","   '-LRB-',\n","   '``',\n","   'NN',\n","   \"''\",\n","   '-RRB-',\n","   'WDT',\n","   'VBD',\n","   'CD',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   '.'],\n","  ['DT',\n","   'NN',\n","   'VBN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'POS',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'RB',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'NN',\n","   '.'],\n","  ['DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   '``',\n","   'NNS',\n","   \"''\",\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NNP',\n","   'NN',\n","   ',',\n","   'VBG',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'VBN',\n","   'NN',\n","   ',',\n","   'WDT',\n","   'VBD',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'VBG',\n","   'DT',\n","   'NN',\n","   '.'],\n","  ['DT',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'CC',\n","   'NN',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   '-LRB-',\n","   'CC',\n","   'NN',\n","   '-RRB-',\n","   '.'],\n","  ['DT',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   'VBZ',\n","   'VBN',\n","   'CC',\n","   'VBN',\n","   'VBN',\n","   'IN',\n","   'NN',\n","   'NN',\n","   '.'],\n","  ['DT',\n","   'JJ',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'NN',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NNP',\n","   'NN',\n","   'RB',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'JJ',\n","   'NN',\n","   'NNS',\n","   '.'],\n","  ['JJ',\n","   'NN',\n","   'NNS',\n","   'VBP',\n","   'VBN',\n","   'CC',\n","   'MD',\n","   'VB',\n","   'VBN',\n","   'TO',\n","   'VB',\n","   'NN',\n","   ',',\n","   'VB',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'NNS',\n","   'CC',\n","   'TO',\n","   'VB',\n","   'NN',\n","   'IN',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'CC',\n","   'NN',\n","   'NN',\n","   'NN',\n","   '.'],\n","  ['DT',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NNP',\n","   'NN',\n","   'VBZ',\n","   'VBN',\n","   'VBN',\n","   'CC',\n","   'RB',\n","   'VBN',\n","   'IN',\n","   'DT',\n","   'JJR',\n","   'NN',\n","   '-LRB-',\n","   'JJR',\n","   'NN',\n","   '-RRB-',\n","   'NN',\n","   'NN',\n","   ',',\n","   'NN',\n","   'VBZ',\n","   'TO',\n","   'VB',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'NNP',\n","   'NNS',\n","   '.'],\n","  ['DT',\n","   'NN',\n","   ',',\n","   'NN',\n","   'NN',\n","   'NN',\n","   'NN',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NNS',\n","   'VBP',\n","   'VBG',\n","   'IN',\n","   'IN',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'IN',\n","   'NN',\n","   'NN',\n","   '.'],\n","  ['NNP',\n","   'NNP',\n","   'VBP',\n","   'VBN',\n","   'DT',\n","   'JJ',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   'NN',\n","   'NN',\n","   'VBG',\n","   'NN',\n","   'NN',\n","   ',',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'NN',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NNPS',\n","   'NNS',\n","   '.'],\n","  ['DT',\n","   'VBN',\n","   'NN',\n","   'NN',\n","   'NN',\n","   'MD',\n","   'VB',\n","   'VBN',\n","   'JJ',\n","   'IN',\n","   'NN',\n","   'NN',\n","   'VBG',\n","   'JJ',\n","   'NN',\n","   ',',\n","   'NN',\n","   'NNS',\n","   'CC',\n","   'VBN',\n","   'NNS',\n","   'IN',\n","   'NN',\n","   'CC',\n","   'NNS',\n","   '.'],\n","  ['DT',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   'MD',\n","   'VB',\n","   'JJ',\n","   'IN',\n","   'DT',\n","   'NN',\n","   ',',\n","   'RB',\n","   'NNS',\n","   'VBP',\n","   'VBN',\n","   'VBN',\n","   'TO',\n","   'VB',\n","   'JJ',\n","   'NNP',\n","   ',',\n","   'NNP',\n","   'NNS',\n","   'IN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'CC',\n","   'VBG',\n","   'NN',\n","   'NN',\n","   'NNS',\n","   '.'],\n","  ['NN',\n","   'NNS',\n","   'IN',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   'CC',\n","   'NNS',\n","   'VBP',\n","   'VBN',\n","   'RB',\n","   'VBN',\n","   'CC',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'MD',\n","   'VB',\n","   'JJ',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'VBG',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'CD',\n","   'NNS',\n","   'VBN',\n","   'IN',\n","   'JJ',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NN',\n","   '.'],\n","  ['DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   'MD',\n","   'VB',\n","   'VBN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'NNS',\n","   'VBG',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'NNS',\n","   'IN',\n","   'NN',\n","   'NN',\n","   'CC',\n","   'NN',\n","   'NN'],\n","  ['DT',\n","   'JJ',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   'NN',\n","   'MD',\n","   'VB',\n","   'VBN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'NN',\n","   'WDT',\n","   'VBZ'],\n","  ['DT',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'NNS',\n","   ',',\n","   'CC',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'NNP'],\n","  ['NN',\n","   'IN',\n","   'JJ',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'NNS',\n","   ',',\n","   'IN',\n","   'JJ',\n","   'NN',\n","   'NNS',\n","   ',',\n","   'WRB',\n","   'EX',\n","   'VBZ',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'NNS',\n","   'MD',\n","   'RB',\n","   'VB',\n","   'VBN',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NN'],\n","  ['JJ',\n","   'NNS',\n","   'RB',\n","   'IN',\n","   'NN',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'JJ',\n","   'CC',\n","   'JJ',\n","   'NNS',\n","   'NN',\n","   '-LRB-',\n","   'NN',\n","   'VBG',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   'VBN',\n","   'RP',\n","   'IN',\n","   'DT',\n","   'NNS',\n","   '-RRB-'],\n","  ['JJ', 'NN', 'CC', 'NN', 'IN', 'NN', 'NN', 'NN', 'NNS'],\n","  ['JJ',\n","   'NN',\n","   'IN',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   'NN',\n","   '-LRB-',\n","   'RB',\n","   'VBG',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'WDT',\n","   'PRP',\n","   'VBP',\n","   'NN',\n","   'TO',\n","   'VB',\n","   '-RRB-',\n","   'CC',\n","   'IN',\n","   'NN',\n","   'NNP',\n","   'NN'],\n","  ['DT',\n","   'NN',\n","   'VBN',\n","   'NNS',\n","   'NN',\n","   ',',\n","   'VBG',\n","   'IN',\n","   'NN',\n","   'NN',\n","   ',',\n","   'WRB',\n","   'JJ',\n","   ',',\n","   'CC',\n","   'DT',\n","   'JJ',\n","   'AFX',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   'NNS'],\n","  ['DT',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'NNS',\n","   'IN',\n","   'JJ',\n","   '-LRB-',\n","   'NN',\n","   'NNS',\n","   '-RRB-',\n","   'CC',\n","   'JJ',\n","   'NN',\n","   '-LRB-',\n","   'NNS',\n","   ',',\n","   'NN',\n","   'IN',\n","   'NN',\n","   '-RRB-'],\n","  ['DT', 'JJ', 'NN', 'IN', 'JJ', 'NNS'],\n","  ['DT', 'JJ', 'JJ', 'NN', 'IN', 'NN', 'CC', 'NN', 'NNS'],\n","  ['PRP',\n","   'VBP',\n","   'TO',\n","   'VB',\n","   'JJ',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NNS',\n","   'IN',\n","   'NNP'],\n","  ['IN', 'PRP', 'VBP', 'DT', 'NNS', 'UH', 'VB', 'PRP', 'IN', 'NN'],\n","  ['NNS'],\n","  ['NNP'],\n","  ['PRP',\n","   'VBP',\n","   'VBG',\n","   'DT',\n","   'NN',\n","   ',',\n","   'PRP',\n","   'VBP',\n","   'IN',\n","   'NNP',\n","   'VBZ',\n","   'DT',\n","   'NN',\n","   '.'],\n","  ['NNP'],\n","  ['MD', 'PRP', 'VB', 'IN', 'PRP', 'NN', '.'],\n","  ['PRP', 'VBP', 'IN', 'NN', '.'],\n","  ['PRP',\n","   'VBD',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   'NNP',\n","   ',',\n","   'RB',\n","   'RB',\n","   ',',\n","   'RB',\n","   'TO',\n","   'VB',\n","   'JJ',\n","   'PRP',\n","   'VBZ',\n","   'VBN',\n","   '.'],\n","  ['PRP$', 'NN', 'VBZ', 'DT', 'NN', 'NN', '.'],\n","  ['VBP', 'PRP', 'VB', 'CD', 'NNS', 'NN', '.'],\n","  ['IN', 'RB', ',', 'PRP', 'MD', 'VB', 'TO', 'VB', 'CC', 'VB', '.'],\n","  ['NN', 'DT', 'NN', '.'],\n","  ['PRP', 'MD', 'VB', 'PRP', 'JJ', 'NN', 'IN', 'NNP', '.'],\n","  ['NN', ','],\n","  ['NNP'],\n","  ['NNP',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   ',',\n","   'JJ',\n","   'NNP',\n","   'CD',\n","   '-LRB-',\n","   'CD',\n","   '-RRB-',\n","   'CD',\n","   'NN',\n","   '-LRB-',\n","   'CD',\n","   '-RRB-',\n","   'CD',\n","   'NN'],\n","  ['PRP', 'VBD', 'DT', '.'],\n","  ['PRP', 'VBP', 'DT', 'VBZ', 'CD', 'NNP', 'NNP', '.'],\n","  ['WRB',\n","   ':',\n","   'NNP',\n","   ',',\n","   'NNP',\n","   'CD',\n","   ',',\n","   'CD',\n","   'CD',\n","   'NN',\n","   'SYM',\n","   'CD',\n","   'NN',\n","   '-LRB-',\n","   'NNP',\n","   'SYM',\n","   'CD',\n","   '-RRB-',\n","   'NNP',\n","   'NNP',\n","   '-LRB-',\n","   'NNP',\n","   'CC',\n","   'NNP',\n","   '-RRB-',\n","   ',',\n","   'NNP',\n","   '.'],\n","  ['WRB', ':', 'NN', 'NN'],\n","  ['NFP'],\n","  ['CD', 'SYM', 'CD', 'NNP'],\n","  ['VB', 'HYPH', 'RB', 'NN', ':', 'CD'],\n","  ['NN', ':', 'CD'],\n","  ['RB', 'VBZ', 'DT', 'NN', 'IN', 'NNP', 'NNP', 'POS', 'NN', 'NN', '.'],\n","  ['WP', 'VBP', 'PRP', 'VB', '.'],\n","  ['NNP'],\n","  ['NNP', ',', 'UH', 'VB', '.'],\n","  ['UH',\n","   'VB',\n","   'PRP',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'IN',\n","   'PRP',\n","   'CC',\n","   'NNP',\n","   'NNP',\n","   'VBP',\n","   'JJ',\n","   'IN',\n","   'WP',\n","   'PRP',\n","   'VBZ',\n","   'VBN',\n","   '.'],\n","  ['IN', 'DT', ',', 'WP', 'VBP', 'PRP', 'VB', '.'],\n","  ['NNP'],\n","  ['IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   'NNP',\n","   'PRP',\n","   'RB',\n","   'UH',\n","   'VBP',\n","   'IN',\n","   'NN',\n","   'PRP$',\n","   'NNS',\n","   'IN',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   '.'],\n","  ['UH', 'VB', 'VBN', 'NNP', 'NN'],\n","  ['JJS', 'NNS'],\n","  ['NNP', 'NNP'],\n","  ['UH', 'VB', 'DT', 'VBN', '.'],\n","  ['NNP'],\n","  ['UH',\n","   'VB',\n","   'NNP',\n","   'NNP',\n","   'NNS',\n","   'IN',\n","   'PRP$',\n","   'JJ',\n","   'JJ',\n","   'NNS',\n","   'NN',\n","   'CC',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   '-LRB-',\n","   'VB',\n","   'NNP',\n","   'NN',\n","   ',',\n","   'IN',\n","   'CC',\n","   'IN',\n","   'NN',\n","   '-RRB-',\n","   '.'],\n","  ['NNP'],\n","  ['PRP',\n","   'VBP',\n","   'VBG',\n","   'CD',\n","   'DT',\n","   'NN',\n","   ',',\n","   'CC',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'PRP',\n","   'WRB',\n","   'PRP',\n","   'VBZ',\n","   'JJ',\n","   '.'],\n","  ['NNP'],\n","  ['NN', 'RB', 'RB', '.'],\n","  ['VBP', 'PRP', 'RB', 'VB', 'DT', 'NN', 'PRP', 'MD', 'VB', '.'],\n","  ['NNP'],\n","  ['-LRB-', 'NN', ':', 'NN', '-RRB-', '-LRB-', 'NN', ':', 'NN', '-RRB-'],\n","  ['RB', 'VBP', 'DT', 'NN', 'NNS', '.'],\n","  ['UH', 'VB', 'PRP', 'VB', 'IN', 'PRP', 'VBP', 'NN', 'JJ', '.'],\n","  ['NN', '.'],\n","  ['NNP', 'NNP', 'JJ', 'NN'],\n","  ['PRP',\n","   'VBP',\n","   'RB',\n","   ',',\n","   'CC',\n","   'PRP',\n","   'VBP',\n","   'RB',\n","   'VB',\n","   'PDT',\n","   'DT',\n","   'NNS',\n","   'CC',\n","   'NNS',\n","   'JJ',\n","   '.'],\n","  ['MD', 'EX', 'VB', 'DT', '-LRB-', 'UH', '-RRB-', 'NN', 'IN', 'DT', '.'],\n","  ['MD', 'PRP', 'UH', 'VB', 'IN', 'DT', 'NN', '.'],\n","  ['PRP', 'VBP', 'IN', 'WP', 'DT', 'NN', 'VBZ', 'RB', '.'],\n","  ['PRP',\n","   'VBP',\n","   'NN',\n","   'NNS',\n","   ',',\n","   'CC',\n","   'NN',\n","   '-LRB-',\n","   'JJ',\n","   'NN',\n","   ',',\n","   'RB',\n","   'IN',\n","   'NN',\n","   'NN',\n","   '-RRB-',\n","   '.'],\n","  ['PRP', 'VBP', 'PRP', 'MD', 'VB', 'TO', 'VB', 'IN', 'CD', 'IN', 'DT', '.'],\n","  ['UH',\n","   'VB',\n","   'PRP',\n","   'VB',\n","   'WDT',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'RB',\n","   'IN',\n","   'DT',\n","   'NN',\n","   '.'],\n","  ['NN', '.'],\n","  ['NNP', ','],\n","  ['IN', 'PRP$', 'NN', 'NN', ',', 'UH', 'VB', 'DT', 'NN', 'RB', '.'],\n","  ['PRP',\n","   'MD',\n","   'VB',\n","   'TO',\n","   'VB',\n","   'IN',\n","   'PRP',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   '.'],\n","  ['NN', ','],\n","  ['NNP'],\n","  ['NNP', 'NNP', 'NN', 'NN', 'NN', 'NN', 'CC', 'NN', 'NN'],\n","  ['-LRB-',\n","   'NN',\n","   'NN',\n","   ':',\n","   'NN',\n","   '-LRB-',\n","   'NN',\n","   'JJ',\n","   'NN',\n","   '-RRB-',\n","   '-RRB-'],\n","  ['CD', 'CD', 'NN'],\n","  ['IN', 'WP', 'PRP', 'MD', 'VB', ':'],\n","  ['IN',\n","   'NN',\n","   'CC',\n","   'NNS',\n","   ',',\n","   'PRP',\n","   'VBP',\n","   'RB',\n","   'IN',\n","   'NN',\n","   'NN',\n","   'VBG',\n","   'VBN',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   '.'],\n","  ['PRP', 'VBP', 'RB', 'JJ', 'IN', 'DT', 'NN', '.'],\n","  ['PRP', 'VBP', 'DT', 'VBG', 'NN', 'IN', 'PRP$', 'NN', '.'],\n","  ['IN',\n","   'NNP',\n","   'POS',\n","   'NNS',\n","   'VBP',\n","   'VBN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'NNS',\n","   '-LRB-',\n","   'NN',\n","   'NN',\n","   '-RRB-',\n","   'CC',\n","   'DT',\n","   'NN',\n","   'NN',\n","   ',',\n","   'MD',\n","   'NNP',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'VB',\n","   'DT',\n","   'NNS',\n","   'IN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NNS',\n","   '.'],\n","  ['DT', 'MD', 'VB', 'JJR', 'IN', 'DT', 'NNS', '.'],\n","  ['IN',\n","   'NN',\n","   ',',\n","   'PRP',\n","   'VBP',\n","   'JJ',\n","   'WRB',\n","   'PRP',\n","   'VBP',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'NNS',\n","   'CC',\n","   'PRP',\n","   'VBP',\n","   'TO',\n","   'VB',\n","   'RP',\n","   'PRP$',\n","   'NN',\n","   'NN',\n","   '.'],\n","  ['PRP',\n","   'VBP',\n","   'RB',\n","   'VB',\n","   'JJ',\n","   'RB',\n","   'RB',\n","   'TO',\n","   'VB',\n","   'PRP$',\n","   'NN',\n","   'IN',\n","   'RB',\n","   'JJ',\n","   'NNS',\n","   'IN',\n","   'NNP',\n","   ',',\n","   'RB',\n","   'WRB',\n","   'DT',\n","   'NNS',\n","   'VBP',\n","   'IN',\n","   'JJ',\n","   'HYPH',\n","   'NNS',\n","   '-LRB-',\n","   'NN',\n","   'HYPH',\n","   'NN',\n","   '-RRB-',\n","   '.'],\n","  ['PRP', 'MD', 'VB', 'PRP$', 'NN', 'NN', 'RB', 'IN', 'IN', 'PRP$', 'NN', '.'],\n","  ['UH',\n","   'VB',\n","   'PRP',\n","   'VB',\n","   'WRB',\n","   'PRP$',\n","   'NN',\n","   'MD',\n","   'VB',\n","   'DT',\n","   'NNP',\n","   'NNS',\n","   'VB',\n","   'JJR',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'PRP$',\n","   'NN',\n","   'NN',\n","   '.'],\n","  ['UH', 'VB', 'CC', 'VB', 'IN', 'PRP$', 'NNS', 'IN', 'DT', 'NN', '.'],\n","  ['NN', '.'],\n","  ['NNP'],\n","  ['DT', ','],\n","  ['DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'NNS',\n","   'NN',\n","   'MD',\n","   'VB',\n","   'NN',\n","   'IN',\n","   'RB',\n","   ':'],\n","  ['NNP',\n","   ',',\n","   'NN',\n","   'NNP',\n","   'CD',\n","   'NN',\n","   'SYM',\n","   'CD',\n","   'NN',\n","   '-LRB-',\n","   'NNP',\n","   'CD',\n","   '-RRB-',\n","   '.'],\n","  ['DT', 'NNS', 'WP', 'VBP', 'JJ', 'IN', 'NNS', 'VBP', 'IN', 'VBZ', ':'],\n","  ['NNP', 'NNP'],\n","  ['NNP', 'NNP'],\n","  ['NNP', 'NNP'],\n","  ['NNP', 'NNP'],\n","  ['NNP', 'NNP'],\n","  ['NNP', 'NNP'],\n","  ['NNP', 'NNP'],\n","  ['NNP', 'NNP'],\n","  ['NNP', 'NNP'],\n","  ['NNP', 'NNP'],\n","  ['NNP', 'NNP'],\n","  ['NNP', 'NNPS'],\n","  ['NNP', 'NNP'],\n","  ['NNP', 'NNP'],\n","  ['NNP', 'NNP', 'NNP'],\n","  ['NNP', 'NNP'],\n","  ['NN', 'NNS', 'VBP', 'RB', 'VBN', 'VBN', 'IN', 'DT', 'JJ', '.'],\n","  ['IN',\n","   'NN',\n","   ',',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'IN',\n","   'DT',\n","   'IN',\n","   'PRP',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NNS',\n","   'IN',\n","   'PRP$',\n","   'JJ',\n","   'NN',\n","   '.'],\n","  ['IN',\n","   'NN',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'VBG',\n","   'PRP',\n","   'TO',\n","   'VB',\n","   'PRP$',\n","   'NN',\n","   'IN',\n","   'NNS',\n","   'IN',\n","   'PRP$',\n","   'NN',\n","   '.'],\n","  ['DT',\n","   'WP',\n","   'VBP',\n","   'RB',\n","   'VBN',\n","   'DT',\n","   'NN',\n","   'MD',\n","   'RB',\n","   'VB',\n","   'NNS',\n","   '-LRB-',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'CD',\n","   '-RRB-',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'VBN',\n","   'IN',\n","   'NN',\n","   'IN',\n","   'PRP$',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   '.'],\n","  ['IN',\n","   'NN',\n","   'VBZ',\n","   'DT',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'UH',\n","   'VB',\n","   'PRP',\n","   'VB',\n","   '.'],\n","  ['JJ', 'NNS', ','],\n","  ['NNP', '.', 'NN'],\n","  ['NNP', ',', 'PRP', 'VBD', 'IN', 'NNP', 'NN', 'IN', 'DT', '.'],\n","  ['VB', 'PRP', 'VB', 'NN', '.'],\n","  ['NN', '.'],\n","  ['NNP'],\n","  ['DT', 'VBZ', 'DT', 'NN', 'IN', 'PRP$', 'NN', 'IN', 'NNP', '.'],\n","  ['PRP',\n","   'VBP',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'IN',\n","   'PRP',\n","   'NN',\n","   '.'],\n","  ['NN', 'IN', 'VBG', 'RP', 'IN', 'DT', '.'],\n","  ['NNP'],\n","  ['NNP', ','],\n","  ['PRP', 'VBD', 'RB', 'VB', 'RB', 'IN', 'NNP', 'CC', 'NNP', 'NNP', '.'],\n","  ['MD',\n","   'PRP',\n","   'UH',\n","   'VB',\n","   'NNP',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   'NN',\n","   '.'],\n","  ['NNP',\n","   ',',\n","   'NNP',\n","   'CC',\n","   'PRP',\n","   'VBD',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   'CC',\n","   'PRP',\n","   'VBP',\n","   'RB',\n","   'JJ',\n","   'IN',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'DT',\n","   'NNS',\n","   '.'],\n","  ['PRP',\n","   'VBP',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'CC',\n","   'NNP',\n","   'VBZ',\n","   'IN',\n","   'IN',\n","   'NN',\n","   'CC',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'TO',\n","   'VB',\n","   'JJ',\n","   'IN',\n","   'PRP',\n","   'VBP',\n","   'RP',\n","   'IN',\n","   'PRP',\n","   'CC',\n","   'DT',\n","   'NN',\n","   ',',\n","   'JJ',\n","   'NN',\n","   'WDT',\n","   'MD',\n","   'VB',\n","   '.'],\n","  ['VBP', 'PRP'],\n","  ['NNP'],\n","  ['VB',\n","   'PRP',\n","   'VB',\n","   'RB',\n","   'WP',\n","   'VBZ',\n","   'VBN',\n","   'RB',\n","   ':',\n","   'NN',\n","   ',',\n","   'FW',\n","   '.'],\n","  ['NN', '.'],\n","  ['NNP'],\n","  ['UH', 'PRP', ','],\n","  ['PRP',\n","   'VBD',\n","   'TO',\n","   'VB',\n","   'PRP',\n","   'VB',\n","   'IN',\n","   'DT',\n","   'IN',\n","   'PRP',\n","   'VBP',\n","   'IN',\n","   'PRP$',\n","   'NN',\n","   '.'],\n","  ['VB', 'PRP', 'VB', 'IN', 'PRP', 'VBP', 'DT', 'NNS', '.'],\n","  ['NNS', ','],\n","  ['NNP'],\n","  ['NNP',\n","   'NNP',\n","   'VBD',\n","   'IN',\n","   'PRP',\n","   'VBP',\n","   'PRP',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'NN',\n","   'IN',\n","   ':',\n","   'NNP',\n","   'POS',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   'CC',\n","   'NNS',\n","   ',',\n","   'RB',\n","   'RB',\n","   'IN',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'NN',\n","   '-LRB-',\n","   'NN',\n","   ',',\n","   'NN',\n","   ',',\n","   'JJ',\n","   'NN',\n","   ',',\n","   'NN',\n","   '-RRB-'],\n","  ['NNP',\n","   'NNP',\n","   'VBZ',\n","   'VBN',\n","   'TO',\n","   'VB',\n","   'IN',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   '-LRB-',\n","   'NNP',\n","   '-RRB-',\n","   'IN',\n","   'DT',\n","   'CD',\n","   'HYPH',\n","   'NN',\n","   'NN',\n","   'NN',\n","   'VBN',\n","   '``',\n","   'NNP',\n","   'NNPS',\n","   \"''\",\n","   '.'],\n","  ['NNP',\n","   'MD',\n","   'VB',\n","   'NNP',\n","   'CC',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'JJ',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'CD',\n","   'NNS',\n","   'TO',\n","   'VB',\n","   'WRB',\n","   'PRP',\n","   'VBP',\n","   'IN',\n","   'NN',\n","   'NNS',\n","   'CC',\n","   'TO',\n","   'VB',\n","   'WRB',\n","   'PRP',\n","   'VBP',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   '.'],\n","  ['UH',\n","   'VB',\n","   'PRP',\n","   'VB',\n","   'IN',\n","   'PRP$',\n","   'JJS',\n","   'NN',\n","   'IN',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'PRP',\n","   '.'],\n","  ['NNS', ','],\n","  ['NNP'],\n","  ['UH', 'VB', 'PDT', 'DT', 'IN', 'PRP', '.'],\n","  ['NN', '.'],\n","  ['NNP'],\n","  ['NNP', ','],\n","  ['VB', 'DT', '.'],\n","  ['NNP', 'NNP'],\n","  ['RB', 'IN', ':', 'NNP', 'NN', 'NNS', '.'],\n","  ['NNP'],\n","  ['NNP', ','],\n","  ['CD', 'IN', 'CD', 'NN', '.'],\n","  ['PRP',\n","   'VBP',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NNS',\n","   'VBP',\n","   'RB',\n","   'VBG',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'NNP',\n","   'NNP',\n","   ',',\n","   'NNP',\n","   'NN',\n","   'RB',\n","   'RB',\n","   '.'],\n","  ['PRP$',\n","   'NN',\n","   'NN',\n","   'VBZ',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'CC',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'MD',\n","   'PRP',\n","   'VB',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   '.'],\n","  ['IN',\n","   'DT',\n","   'NN',\n","   ',',\n","   'PRP',\n","   'VBP',\n","   'TO',\n","   'VB',\n","   'RP',\n","   'NNP',\n","   'NNP',\n","   'CC',\n","   'NNP',\n","   'TO',\n","   'VB',\n","   'CC',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   '.'],\n","  ['PRP',\n","   'VBP',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'VBZ',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'PRP',\n","   ',',\n","   'PRP',\n","   ',',\n","   'NNP',\n","   'NNP',\n","   'CC',\n","   'NNP',\n","   'NNP',\n","   '.'],\n","  ['CC',\n","   'RB',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NNS',\n","   'CC',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'RP',\n","   'DT',\n","   'NN',\n","   '.'],\n","  ['NNP',\n","   ',',\n","   'UH',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   ',',\n","   'NNP',\n","   ',',\n","   'NNP',\n","   'NNP',\n","   'CC',\n","   'PRP',\n","   '.'],\n","  ['NN', '.'],\n","  ['NNP', ','],\n","  ['PRP',\n","   'VBP',\n","   'VBN',\n","   'VBN',\n","   'IN',\n","   'PRP$',\n","   'NN',\n","   'NN',\n","   ',',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   'IN',\n","   'IN',\n","   'PRP',\n","   'VBD',\n","   'VBG',\n","   'DT',\n","   'NNP',\n","   'IN',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   'CC',\n","   'NNP',\n","   'NNP',\n","   'VBG',\n","   'PRP$',\n","   'NN',\n","   'NN',\n","   'PRP',\n","   'VBD',\n","   'IN',\n","   'DT',\n","   'NNS',\n","   'VBP',\n","   'VBN',\n","   'IN',\n","   'NN',\n","   'NNS',\n","   'TO',\n","   'VB',\n","   'PRP$',\n","   'NN',\n","   '.'],\n","  ['RB', 'DT', 'NN', 'VBD', 'PRP', 'IN', 'DT', 'NN', 'VBZ', 'VBN', '.'],\n","  ['PRP',\n","   'VBP',\n","   'VBN',\n","   'IN',\n","   'DT',\n","   'NNS',\n","   'VBP',\n","   'VBN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NNP',\n","   'NNP',\n","   'NN',\n","   'NN',\n","   '.'],\n","  ['PRP',\n","   'MD',\n","   'VB',\n","   'JJ',\n","   'JJ',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'PRP',\n","   'IN',\n","   'DT',\n","   'NN',\n","   '.'],\n","  ['NNP',\n","   'NNP',\n","   ',',\n","   'PRP',\n","   'VBP',\n","   'IN',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   'POS',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   'VBZ',\n","   'NNP',\n","   'CD',\n","   ',',\n","   'CD',\n","   '.'],\n","  ['UH',\n","   'VB',\n","   'IN',\n","   'IN',\n","   'WP',\n","   'PRP$',\n","   'NN',\n","   'VBZ',\n","   'CC',\n","   'PRP$',\n","   'NN',\n","   'NN',\n","   '.'],\n","  ['NN', ','],\n","  ['NNP',\n","   'NNP',\n","   'NNP',\n","   'NN',\n","   'NN',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   '-LRB-',\n","   'NNP',\n","   '-RRB-',\n","   'CD',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   ',',\n","   'NNP',\n","   'CD',\n","   'NNP',\n","   'NN',\n","   ':',\n","   'CD',\n","   'NN',\n","   ':',\n","   'CD',\n","   'NN',\n","   ':',\n","   'CD',\n","   'NN',\n","   ':',\n","   '-LRB-',\n","   '-RRB-'],\n","  ['UH', 'PRP', 'VBD', 'VBN', 'IN', 'RB', '.'],\n","  ['PRP',\n","   'VBD',\n","   'TO',\n","   'VB',\n","   'PRP',\n","   'VBD',\n","   'RB',\n","   'RB',\n","   'JJ',\n","   'CC',\n","   'NNP',\n","   'VBD',\n","   'RB',\n","   'VBG',\n","   'DT',\n","   'IN',\n","   'DT',\n","   'NN',\n","   '.'],\n","  ['PRP',\n","   'VBD',\n","   'PRP',\n","   'IN',\n","   'IN',\n","   'NNP',\n","   'CC',\n","   'NNP',\n","   'PRP',\n","   'VBD',\n","   'PRP',\n","   'VBD',\n","   'RB',\n","   'VBG',\n","   '.'],\n","  ['RB',\n","   'PRP',\n","   'VBD',\n","   'PRP',\n","   'PRP',\n","   'VBD',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'JJ',\n","   'TO',\n","   'VB',\n","   'NNP',\n","   'RB',\n","   'RB',\n","   '.'],\n","  ['PRP', 'VBD', 'DT', 'VBD', 'JJ', '.'],\n","  ['VBD',\n","   'PRP',\n","   'VB',\n","   'IN',\n","   'RB',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'PRP',\n","   'VBD',\n","   'DT',\n","   'NN',\n","   ',',\n","   'NNP',\n","   'VBZ',\n","   'TO',\n","   'VB',\n","   'PRP',\n","   'VBP',\n","   'TO',\n","   'VB',\n","   'NN',\n","   ',',\n","   'PRP',\n","   'VBD',\n","   'PRP',\n","   'PRP',\n","   'VBZ',\n","   'JJ',\n","   'TO',\n","   'VB',\n","   'RB',\n","   'RB',\n","   'IN',\n","   'DT',\n","   'NN',\n","   ',',\n","   'RB',\n","   'VB',\n","   'IN',\n","   'NN',\n","   'WRB',\n","   'PRP',\n","   'VBP',\n","   'RB',\n","   'VB',\n","   'PDT',\n","   'DT',\n","   'NNS',\n","   'RB',\n","   'CC',\n","   'VB',\n","   'TO',\n","   'VB',\n","   'RB',\n","   'VBN',\n","   'RP'],\n","  ['NFP', 'NN', 'NN', 'NN', 'NN', 'NFP'],\n","  ['JJ', ',', 'JJ', 'NN', 'MD', 'VB', 'VBN', 'IN', 'DT', 'NN', '.'],\n","  ['IN',\n","   'PRP',\n","   'VBP',\n","   'RB',\n","   'DT',\n","   'NN',\n","   'VBN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   '-LRB-',\n","   'CC',\n","   'JJ',\n","   'IN',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'JJ',\n","   'NN',\n","   '-RRB-',\n","   ',',\n","   'PRP',\n","   'MD',\n","   'RB',\n","   'VB',\n","   'CC',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NN',\n","   '.'],\n","  ['IN',\n","   'JJ',\n","   'NN',\n","   ',',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'CC',\n","   'RB',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'NN',\n","   '.'],\n","  ['UH',\n","   'VB',\n","   'RB',\n","   'IN',\n","   'PRP',\n","   'CC',\n","   'PRP$',\n","   'NN',\n","   'VBP',\n","   'RB',\n","   'VB',\n","   'IN',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NN',\n","   '.'],\n","  ['NNS',\n","   ',',\n","   'NNS',\n","   'CC',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'WDT',\n","   'VBP',\n","   'RB',\n","   'VB',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'PRP$',\n","   'NN',\n","   'MD',\n","   'VB',\n","   'VBN',\n","   'IN',\n","   'CC',\n","   'VBN',\n","   'CC',\n","   'VBN',\n","   'IN',\n","   'PRP',\n","   '.'],\n","  ['NN', 'NN', ':', 'NN'],\n","  ['NN', 'NN', ':', 'NN'],\n","  ['NN', ':', 'NNP', ',', 'NNP', 'NNP'],\n","  ['NN', ':', '$', 'CD', 'SYM', 'CD'],\n","  ['NN', ':'],\n","  ['PRP$',\n","   'NN',\n","   'VBZ',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   'WDT',\n","   'VBZ',\n","   'VBG',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'PRP$',\n","   'NN',\n","   'VBG',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   '.'],\n","  ['PRP',\n","   'VBP',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   'VBG',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   ',',\n","   'JJ',\n","   'NNS',\n","   'NN',\n","   ',',\n","   'CC',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'NNS',\n","   'TO',\n","   'VB',\n","   'IN',\n","   'DT',\n","   'NN',\n","   '.'],\n","  ['NNP'],\n","  ['NNS', ':'],\n","  ['PRP',\n","   'MD',\n","   'VB',\n","   'JJ',\n","   'TO',\n","   'VB',\n","   'PRP$',\n","   'CD',\n","   'SYM',\n","   'CD',\n","   'NNS',\n","   'IN',\n","   'NN',\n","   'IN',\n","   'JJ',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'PRP$',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'IN',\n","   'DT',\n","   'NN',\n","   '.'],\n","  ['NN', ':'],\n","  ['NNP',\n","   'NNPS',\n","   ',',\n","   'NNP',\n","   'CD',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   ',',\n","   'NNP',\n","   'CD',\n","   'NNP',\n","   'NN',\n","   ':',\n","   '-LRB-',\n","   '-RRB-',\n","   'NN',\n","   ':',\n","   'CD',\n","   'NN',\n","   ':',\n","   'CD'],\n","  ['NN'],\n","  ['PRP',\n","   'VBP',\n","   'VBN',\n","   'IN',\n","   'PRP',\n","   'DT',\n","   'JJ',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'JJ',\n","   'NNS',\n","   ',',\n","   'VBD',\n","   'RB',\n","   'VB',\n","   'TO',\n","   'VB',\n","   'IN',\n","   'DT',\n","   'RB',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'PRP$',\n","   'NN',\n","   'NNS',\n","   '.'],\n","  ['PRP',\n","   'VBP',\n","   'VBG',\n","   'DT',\n","   'RB',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NNS',\n","   'PRP',\n","   'VBP',\n","   'IN',\n","   'NNP',\n","   '.'],\n","  ['PRP',\n","   'VBP',\n","   'PRP',\n","   'VBD',\n","   'DT',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'PRP$',\n","   'JJ',\n","   'NN',\n","   '.'],\n","  ['EX',\n","   'MD',\n","   'VB',\n","   'NN',\n","   'CC',\n","   'NN',\n","   'RB',\n","   'RB',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'RB',\n","   '.'],\n","  ['PRP', 'MD', 'VB', 'RB', '.'],\n","  ['PRP',\n","   'VBP',\n","   'VBN',\n","   'DT',\n","   'NNS',\n","   'IN',\n","   'NNP',\n","   'CC',\n","   'NNP',\n","   'IN',\n","   'NN',\n","   'HYPH',\n","   'NN',\n","   ',',\n","   'DT',\n","   'NNP',\n","   '-LRB-',\n","   'NN',\n","   '.',\n","   '-RRB-',\n","   'NNS',\n","   '-LRB-',\n","   'NNP',\n","   'CC',\n","   'NNP',\n","   '.',\n","   'IN',\n","   'JJ',\n","   'NN',\n","   '-RRB-',\n","   'VBD',\n","   'PRP$',\n","   'JJ',\n","   'NN',\n","   'DT',\n","   'NN',\n","   'RB',\n","   ',',\n","   'CC',\n","   'PRP$',\n","   'JJ',\n","   'NN',\n","   'VBZ',\n","   'IN',\n","   'NNP',\n","   'CC',\n","   'VBZ',\n","   'JJ',\n","   'NNS',\n","   'IN',\n","   'JJ',\n","   '-LRB-',\n","   'IN',\n","   'PRP',\n","   'VBP',\n","   'RB',\n","   'JJ',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   '-RRB-',\n","   '.'],\n","  ['VB',\n","   'PRP',\n","   'DT',\n","   'JJ',\n","   'NNS',\n","   ',',\n","   'CC',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'IN',\n","   'NN',\n","   '.'],\n","  ['NNP'],\n","  ['PRP',\n","   'NNS',\n","   'VBP',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'AFX',\n","   'JJ',\n","   'NN',\n","   'NNS',\n","   'WDT',\n","   'VBD',\n","   'PRP$',\n","   'RB',\n","   'RB',\n","   'JJ',\n","   'NN',\n","   'RB',\n","   'CD',\n","   'CD',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'CD',\n","   'NNS',\n","   '.'],\n","  ['RB',\n","   'JJ',\n","   'WRB',\n","   'RB',\n","   'RBR',\n","   'NNP',\n","   'VBZ',\n","   'VBG',\n","   'TO',\n","   'VB',\n","   'RB',\n","   'CC',\n","   'PRP',\n","   'VBP',\n","   'VBG',\n","   'RP',\n","   'PRP$',\n","   'NNS',\n","   '.'],\n","  ['RB',\n","   'JJ',\n","   ',',\n","   'CC',\n","   'PRP',\n","   'VBP',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'VBZ',\n","   'PRP',\n","   '.'],\n","  ['VBZ', 'PRP', 'IN', 'NN', '.'],\n","  ['PRP', 'MD', 'VB', 'TO', 'VB', '.'],\n","  ['PRP', 'MD', 'VB', 'TO', 'VB', 'RB', 'IN', 'PRP', 'RB', '.'],\n","  ['RB', '.'],\n","  ['PRP', 'VBP', 'DT', 'NN', '.'],\n","  ['UH', 'NNP', ':'],\n","  ['VBD', 'IN', 'PRP', 'MD', 'VB', 'JJ', '.'],\n","  ['JJS', ','],\n","  ['NNP'],\n","  ['UH', ',', 'PRP', 'VBD', 'NN', '.'],\n","  ['VBP',\n","   'PRP',\n","   'VBN',\n","   'DT',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'WDT',\n","   'PRP',\n","   'VBD',\n","   'NN',\n","   '.'],\n","  ['PRP',\n","   'VBP',\n","   'DT',\n","   'VBZ',\n","   'RB',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   ',',\n","   'VBZ',\n","   'PRP$',\n","   'NN',\n","   'VB',\n","   'IN',\n","   'DT',\n","   'RB',\n","   'RBR',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'NN',\n","   ',',\n","   'VBZ',\n","   'PRP$',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'RBR',\n","   'JJ',\n","   ',',\n","   'CC',\n","   'VBZ',\n","   'NNP',\n","   'RP',\n","   'IN',\n","   'DT',\n","   'NNP',\n","   'NNP',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'NNP',\n","   'POS',\n","   'JJ',\n","   'NN',\n","   ',',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   '.'],\n","  ['UH', '.'],\n","  ['UH', ',', 'MD', 'RB', 'PRP', 'VB', 'PRP', '.'],\n","  ['PRP',\n","   'VBP',\n","   'RB',\n","   'VBG',\n","   'NN',\n","   ',',\n","   'CC',\n","   'PRP',\n","   'VBP',\n","   'IN',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'RB',\n","   'IN',\n","   'NNP',\n","   '.'],\n","  ['PRP',\n","   'VBP',\n","   'RB',\n","   'JJ',\n","   ',',\n","   'CC',\n","   'PRP',\n","   'VBP',\n","   'IN',\n","   'PRP',\n","   'VBZ',\n","   'VBN',\n","   'NN',\n","   'NN',\n","   ',',\n","   'RB',\n","   '.'],\n","  ['PRP',\n","   'MD',\n","   'VB',\n","   'PRP',\n","   'RP',\n","   'IN',\n","   'NN',\n","   'CC',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'CC',\n","   'VB',\n","   'IN',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'PRP',\n","   'RP',\n","   '.'],\n","  ['``', 'NNP', 'NNP', \"''\", '-LRB-', '-RRB-'],\n","  ['CD', 'CD', 'NN'],\n","  ['DT', ':'],\n","  ['PRP',\n","   'VBZ',\n","   'PRP$',\n","   'NN',\n","   ',',\n","   'IN',\n","   'JJ',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NNP',\n","   'POS',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NNP',\n","   'MD',\n","   'VB',\n","   'NNP',\n","   'NNP',\n","   'TO',\n","   'RB',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'NNS',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'IN',\n","   'JJ',\n","   'NN',\n","   'NNS',\n","   '.'],\n","  ['DT',\n","   'NN',\n","   'IN',\n","   'WDT',\n","   'DT',\n","   'NN',\n","   'VBZ',\n","   'VBG',\n","   'VBZ',\n","   'IN',\n","   'IN',\n","   'PRP',\n","   'RB',\n","   'VBP',\n","   'NN',\n","   'POS',\n","   'NN',\n","   'IN',\n","   'JJ',\n","   'NNS',\n","   'RB',\n","   ',',\n","   'PRP',\n","   'VBZ',\n","   'RP',\n","   'DT',\n","   'NN',\n","   'WDT',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   'MD',\n","   'VB',\n","   'IN',\n","   '.'],\n","  ['IN', 'JJ', 'NNS', 'DT', 'NN', 'VBZ', 'VBN', '.'],\n","  ['VB', 'PRP$', 'NN', 'IN', 'WRB', 'DT', 'NNS', 'VBP', 'VBN', '.'],\n","  ['FW',\n","   'DT',\n","   'NNP',\n","   'NN',\n","   'VBZ',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'VBG',\n","   'TO',\n","   'VB',\n","   'WRB',\n","   'DT',\n","   'CC',\n","   'DT',\n","   'NN',\n","   'MD',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'RB',\n","   'IN',\n","   'VB',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'VBG',\n","   'WRB',\n","   'JJ',\n","   'NN',\n","   'MD',\n","   'VB',\n","   'IN',\n","   'DT',\n","   'NNS',\n","   '.'],\n","  ['PRP',\n","   'RB',\n","   'VBZ',\n","   'DT',\n","   'NN',\n","   'DT',\n","   'RB',\n","   'JJ',\n","   'JJ',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'WP',\n","   'WRB',\n","   'CC',\n","   'WRB',\n","   'JJ',\n","   'NN',\n","   'MD',\n","   'VB',\n","   'IN',\n","   'VBG',\n","   'TO',\n","   'VB',\n","   'IN',\n","   'PRP',\n","   'VBP',\n","   'JJ',\n","   'NN',\n","   '.'],\n","  ['NN', 'VB', 'WRB', 'NN', 'VBZ', '.'],\n","  ['NNP', '-LRB-', '-RRB-'],\n","  ['CD', 'CD', 'NN'],\n","  ['NNS',\n","   ',',\n","   'VBN',\n","   'VBZ',\n","   'DT',\n","   'VBN',\n","   'NN',\n","   'WDT',\n","   'VBZ',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NNS',\n","   'IN',\n","   'CD',\n","   'CC',\n","   'CD',\n","   '.'],\n","  ['DT',\n","   'NN',\n","   'MD',\n","   'RB',\n","   'VB',\n","   'VBN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'RB',\n","   'RB',\n","   'IN',\n","   'JJ',\n","   '.'],\n","  ['VBP',\n","   'PRP',\n","   'IN',\n","   'PRP$',\n","   'NN',\n","   'CC',\n","   'PRP',\n","   'VBP',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'DT',\n","   'JJ',\n","   'NNS',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'NNS',\n","   '.'],\n","  ['NFP', 'NNP', 'NNP', 'JJ', 'NN', 'NN'],\n","  ['-LRB-', 'NN', '-RRB-'],\n","  ['VB',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'VBZ',\n","   'JJ',\n","   ',',\n","   'VBN',\n","   'IN',\n","   'NNP',\n","   'POS',\n","   'NN',\n","   'NNS',\n","   '.'],\n","  ['``', 'NNP', ',', 'NNP', '-LRB-', 'NNP', '-RRB-', \"''\", '-LRB-', '-RRB-'],\n","  ['CD', 'CD', 'NN'],\n","  ['JJ', 'NN', 'NN', 'IN', 'NNP', 'NN', 'CD'],\n","  ['NN', 'NN', 'CD', 'NN', 'NNS', ':'],\n","  ['VBN',\n","   'VBZ',\n","   'NNP',\n","   'POS',\n","   'NN',\n","   'NN',\n","   'CD',\n","   '-LRB-',\n","   'NN',\n","   'CD',\n","   '-RRB-',\n","   'NN',\n","   'NN',\n","   '.'],\n","  ['PRP',\n","   'VBP',\n","   'PRP',\n","   'VBZ',\n","   'JJ',\n","   'IN',\n","   'DT',\n","   'NNS',\n","   'CC',\n","   'NNS',\n","   'PRP',\n","   'VBP',\n","   'VBN',\n","   'IN',\n","   'DT',\n","   'NNS',\n","   '.'],\n","  ['IN',\n","   'DT',\n","   'NN',\n","   ',',\n","   'DT',\n","   'NN',\n","   ':',\n","   'NFP',\n","   'VBZ',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'CD',\n","   'IN',\n","   'CD',\n","   '.',\n","   'NFP'],\n","  ['NFP',\n","   'VBZ',\n","   'NN',\n","   'NN',\n","   'NN',\n","   'NNS',\n","   'IN',\n","   'CD',\n","   'JJR',\n","   'IN',\n","   'JJS',\n","   'NNS',\n","   'IN',\n","   'NNS',\n","   'IN',\n","   'NN',\n","   'NN',\n","   '.',\n","   'NFP'],\n","  ['NFP',\n","   'VBZ',\n","   'IN',\n","   'VBN',\n","   'NN',\n","   'NN',\n","   'NNS',\n","   'IN',\n","   'NN',\n","   'NNS',\n","   '.',\n","   'NFP'],\n","  ['NFP',\n","   'VBZ',\n","   'DT',\n","   'CD',\n","   'NN',\n","   'SYM',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'JJ',\n","   'NNS',\n","   'IN',\n","   'VBG',\n","   'NN',\n","   'NNS',\n","   'IN',\n","   'JJ',\n","   'NNS',\n","   ',',\n","   'VBG',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NNS',\n","   'TO',\n","   'VB',\n","   'TO',\n","   'VB',\n","   'JJ',\n","   'NN',\n","   'NNS',\n","   'CC',\n","   'JJ',\n","   'NNP',\n","   'HYPH',\n","   'VBN',\n","   'NNS',\n","   '.',\n","   'NFP'],\n","  ['NFP',\n","   'VBZ',\n","   'NNS',\n","   'TO',\n","   'VB',\n","   'NN',\n","   'CC',\n","   'VB',\n","   'VB',\n","   'NNS',\n","   'IN',\n","   'NN',\n","   'NN',\n","   'NNS',\n","   ',',\n","   'CC',\n","   'VBZ',\n","   'DT',\n","   'NN',\n","   'NNS',\n","   'VBN',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'CD',\n","   'NN',\n","   '-LRB-',\n","   'CD',\n","   'SYM',\n","   'CD',\n","   '-RRB-',\n","   '.',\n","   'NFP'],\n","  ['NFP',\n","   'VBZ',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'NN',\n","   ',',\n","   'IN',\n","   'DT',\n","   'CD',\n","   'NN',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'CC',\n","   'NN',\n","   'CC',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'VBN',\n","   'NN',\n","   'NNS',\n","   '.'],\n","  ['DT',\n","   'VBN',\n","   'NNS',\n","   'MD',\n","   'VB',\n","   'JJ',\n","   'RB',\n","   'IN',\n","   'JJ',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'CC',\n","   'VBN',\n","   'NNS',\n","   'IN',\n","   'IN',\n","   'JJ',\n","   'NNS',\n","   'CC',\n","   'JJ',\n","   'NNS',\n","   '.',\n","   'NFP'],\n","  ['NFP',\n","   'VBZ',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'CC',\n","   'NN',\n","   'NNS',\n","   ',',\n","   'IN',\n","   'RB',\n","   'JJR',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   '.',\n","   'NFP'],\n","  ['NFP',\n","   'VBZ',\n","   'DT',\n","   'CD',\n","   'HYPH',\n","   'NN',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'NN',\n","   'NNS',\n","   'VBG',\n","   'IN',\n","   'CD',\n","   ',',\n","   'IN',\n","   'NN',\n","   'NNS',\n","   'VBG',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'JJ',\n","   'NN',\n","   '.',\n","   'NFP'],\n","  ['NFP', 'VBZ', 'DT', 'NN', 'NN', 'NN', 'IN', 'DT', 'NNS', '.'],\n","  ['NNP',\n","   'RB',\n","   'VBZ',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'NN',\n","   'NN',\n","   '-LRB-',\n","   'NN',\n","   '-RRB-',\n","   'MD',\n","   'VB',\n","   'JJ',\n","   'IN',\n","   'NN',\n","   'POS',\n","   'NN',\n","   ',',\n","   'CC',\n","   'MD',\n","   'VB',\n","   'DT',\n","   'RB',\n","   'JJR',\n","   'NN',\n","   'NNS',\n","   'VBN',\n","   'TO',\n","   'VB',\n","   'VBN',\n","   'NNS',\n","   'IN',\n","   'NN',\n","   'NN',\n","   'CC',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'CD',\n","   'HYPH',\n","   'NN',\n","   'IN',\n","   'CD',\n","   'HYPH',\n","   'NN',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   '.'],\n","  ['DT',\n","   'RB',\n","   'MD',\n","   'VB',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'DT',\n","   'HYPH',\n","   'NN',\n","   'NN',\n","   'VBZ',\n","   'VBN',\n","   'IN',\n","   'NNP',\n","   'POS',\n","   'NNS',\n","   'IN',\n","   'NNP',\n","   'NNP',\n","   'IN',\n","   'NNP',\n","   'CD',\n","   'CC',\n","   'CD',\n","   ',',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'CC',\n","   'TO',\n","   'VB',\n","   'IN',\n","   'PRP$',\n","   'NNS',\n","   '.'],\n","  ['PRP',\n","   'VBP',\n","   'RB',\n","   'IN',\n","   'VBG',\n","   'PRP$',\n","   'NNS',\n","   'CC',\n","   'VBG',\n","   'PRP$',\n","   'NN',\n","   '.'],\n","  ['DT',\n","   'VBN',\n","   'NNS',\n","   'VBP',\n","   'DT',\n","   'NN',\n","   'CD',\n","   'NN',\n","   'NN',\n","   ',',\n","   'DT',\n","   'NN',\n","   '-LRB-',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   'POS',\n","   'VBN',\n","   'NN',\n","   'NN',\n","   'CD',\n","   '-RRB-',\n","   ',',\n","   'CC',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'VBG',\n","   'NNS',\n","   '.'],\n","  ['RB',\n","   ',',\n","   'UH',\n","   'VB',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'CC',\n","   'DT',\n","   'NN',\n","   'VBP',\n","   'IN',\n","   '``',\n","   'NNP',\n","   'CD',\n","   \"''\",\n","   'NN',\n","   '.'],\n","  ['PRP',\n","   'MD',\n","   'VB',\n","   'JJ',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'JJ',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   ',',\n","   'IN',\n","   'NN',\n","   'IN',\n","   'JJ',\n","   'NNS',\n","   '.'],\n","  ['PRP',\n","   'VBP',\n","   'RB',\n","   'IN',\n","   'VBG',\n","   'PRP',\n","   'IN',\n","   'NNP',\n","   'CD',\n","   'SYM',\n","   'CD',\n","   '.'],\n","  ['IN',\n","   'DT',\n","   'NN',\n","   ',',\n","   'PRP',\n","   'VBP',\n","   'PRP$',\n","   'JJS',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'CC',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   '.'],\n","  ['NNP',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   '-LRB-',\n","   'CD',\n","   '-RRB-',\n","   'CD',\n","   '-LRB-',\n","   'CD',\n","   '-RRB-',\n","   'CD'],\n","  ['-LRB-', 'NN', '-RRB-', '-LRB-', 'NN', '-RRB-', '-LRB-', 'NN', '-RRB-'],\n","  ['NNS', 'NNP', 'NNP', ':'],\n","  ['DT',\n","   'VBZ',\n","   'TO',\n","   'VB',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   'NNP',\n","   'MD',\n","   'VB',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'NN',\n","   'NN',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'POS',\n","   'NNS',\n","   'VBN',\n","   'IN',\n","   'NNP',\n","   'NN',\n","   'CC',\n","   'NN',\n","   '.'],\n","  ['VBP', 'PRP', '.'],\n","  ['RB', ','],\n","  ['NNP', 'NNP', 'NN', ',', 'NNP', 'NNP'],\n","  ['VBN',\n","   'VBZ',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'POS',\n","   'NNS',\n","   '.'],\n","  ['JJ', 'NNS', ':'],\n","  ['PRP$',\n","   'NN',\n","   'VBZ',\n","   'RB',\n","   'TO',\n","   'VB',\n","   'VBN',\n","   'IN',\n","   'CD',\n","   'SYM',\n","   'CD',\n","   'NNS',\n","   '.'],\n","  ['NNP',\n","   'NNP',\n","   ',',\n","   'PRP$',\n","   'JJ',\n","   'NN',\n","   ',',\n","   'MD',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'PRP$',\n","   'NN',\n","   '.'],\n","  ['NNP',\n","   'NNP',\n","   'VBZ',\n","   'VBG',\n","   'RP',\n","   'DT',\n","   'JJ',\n","   'NNS',\n","   'IN',\n","   'PRP$',\n","   'NN',\n","   'CC',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'DT',\n","   'RB',\n","   'IN',\n","   'NNS',\n","   'NN',\n","   'RB',\n","   'NN',\n","   '.'],\n","  ['NNS',\n","   'MD',\n","   'VB',\n","   'VBN',\n","   'IN',\n","   'PRP',\n","   'IN',\n","   'NN',\n","   ',',\n","   'NN',\n","   '-LRB-',\n","   'CD',\n","   '-RRB-',\n","   ',',\n","   'NN',\n","   '-LRB-',\n","   'CD',\n","   '-RRB-',\n","   ',',\n","   'CC',\n","   'NN',\n","   '-LRB-',\n","   'CD',\n","   '-RRB-',\n","   '.'],\n","  ['PRP',\n","   'MD',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'NNS',\n","   'IN',\n","   'NN',\n","   'POS',\n","   'JJ',\n","   'NN',\n","   '-LRB-',\n","   'CD',\n","   'NN',\n","   'NNP',\n","   '-RRB-',\n","   '.'],\n","  ['DT', 'VB', 'RP', 'NN', 'VBZ', 'CD', '.'],\n","  ['NN', 'VBZ', 'CD', '.'],\n","  ['DT',\n","   'NN',\n","   'POS',\n","   'NNS',\n","   'VBP',\n","   'NN',\n","   'IN',\n","   'CD',\n","   'NN',\n","   '-LRB-',\n","   'NNP',\n","   '-RRB-',\n","   '.'],\n","  ['NNP', 'NNP'],\n","  ['VBN', 'IN', ':', 'NNP', 'NNP'],\n","  ['CD', 'CD', 'NN'],\n","  ['VBN',\n","   'VBZ',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'POS',\n","   'NNS',\n","   '.'],\n","  ['JJ', 'NNS', ':'],\n","  ['PRP$',\n","   'NN',\n","   'VBZ',\n","   'RB',\n","   'TO',\n","   'VB',\n","   'VBN',\n","   'IN',\n","   'CD',\n","   'SYM',\n","   'CD',\n","   'NNS',\n","   '.'],\n","  ['NNP',\n","   'NNP',\n","   ',',\n","   'PRP$',\n","   'JJ',\n","   'NN',\n","   ',',\n","   'MD',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'PRP$',\n","   'NN',\n","   '.'],\n","  ['NNP',\n","   'NNP',\n","   'VBZ',\n","   'VBG',\n","   'RP',\n","   'DT',\n","   'JJ',\n","   'NNS',\n","   'IN',\n","   'PRP$',\n","   'NN',\n","   'CC',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'DT',\n","   'RB',\n","   'IN',\n","   'NNS',\n","   'NN',\n","   'RB',\n","   'NN',\n","   '.'],\n","  ['NNS',\n","   'MD',\n","   'VB',\n","   'VBN',\n","   'IN',\n","   'PRP',\n","   'IN',\n","   'NN',\n","   ',',\n","   'NN',\n","   '-LRB-',\n","   'CD',\n","   '-RRB-',\n","   ',',\n","   'NN',\n","   '-LRB-',\n","   'CD',\n","   '-RRB-',\n","   ',',\n","   'CC',\n","   'NN',\n","   '-LRB-',\n","   'CD',\n","   '-RRB-',\n","   '.'],\n","  ['PRP',\n","   'MD',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'NNS',\n","   'IN',\n","   'NN',\n","   'POS',\n","   'JJ',\n","   'NN',\n","   '-LRB-',\n","   'CD',\n","   'NN',\n","   'NNP',\n","   '-RRB-',\n","   '.'],\n","  ['DT', 'VB', 'RP', 'NN', 'VBZ', 'CD', '.'],\n","  ['NN', 'VBZ', 'CD', '.'],\n","  ['DT',\n","   'NN',\n","   'POS',\n","   'NNS',\n","   'VBP',\n","   'NN',\n","   'IN',\n","   'CD',\n","   'NN',\n","   '-LRB-',\n","   'NNP',\n","   '-RRB-',\n","   '.'],\n","  ['JJ', 'NN', '.'],\n","  ['VBG', 'TO', 'VB', 'DT', 'JJ', 'NN', '.'],\n","  ['DT', 'VBZ', 'DT', 'RB', 'JJ', 'NN', '.'],\n","  ['PRP', 'MD', 'VB', 'DT', 'NN', '.'],\n","  ['JJS', ','],\n","  ['NNP'],\n","  ['NNP', 'NNP'],\n","  ['CD', 'CD', 'NN'],\n","  ['NNP', ','],\n","  ['IN',\n","   'IN',\n","   'VBG',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   ',',\n","   'CD',\n","   'CC',\n","   'CD',\n","   'NN',\n","   ',',\n","   'PRP',\n","   'VBP',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'IN',\n","   'DT',\n","   '``',\n","   'JJ',\n","   \"''\",\n","   'NN',\n","   'MD',\n","   'VB',\n","   'JJ',\n","   'CC',\n","   'MD',\n","   'IN',\n","   'NN',\n","   'VB',\n","   'JJ',\n","   ',',\n","   'CC',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'MD',\n","   'VB',\n","   'JJ',\n","   'CC',\n","   'JJ',\n","   'IN',\n","   'RB',\n","   'VBN',\n","   'RP',\n","   'NN',\n","   'CC',\n","   'NNS',\n","   ',',\n","   'CC',\n","   'RB',\n","   'VBN',\n","   'IN',\n","   'NN',\n","   '.'],\n","  ['IN',\n","   'JJ',\n","   ',',\n","   'PRP',\n","   'MD',\n","   'RB',\n","   'VB',\n","   'RB',\n","   'JJ',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'CC',\n","   'PRP',\n","   'VBP',\n","   'PRP',\n","   'VBP',\n","   'IN',\n","   'DT',\n","   '.'],\n","  ['RB', ',', 'PRP', 'VBP', 'PRP', 'VBP', 'VBN', 'DT', 'NNS', 'RB', '.'],\n","  ['PRP',\n","   'VBP',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'VBG',\n","   'DT',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'PRP',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'JJ',\n","   'NNS',\n","   '.'],\n","  ['CC',\n","   'IN',\n","   'DT',\n","   '-LRB-',\n","   'RB',\n","   'JJ',\n","   '-RRB-',\n","   'NNS',\n","   'VBP',\n","   'RB',\n","   'JJ',\n","   'IN',\n","   'PRP$',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NNS',\n","   'IN',\n","   'NNP',\n","   'CC',\n","   'NNP',\n","   ',',\n","   'PRP',\n","   'VBD',\n","   'TO',\n","   'VB',\n","   'RB',\n","   'DT',\n","   'NNS',\n","   'IN',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NNS',\n","   ',',\n","   'NNS',\n","   'RB',\n","   '.'],\n","  ['NN',\n","   ':',\n","   'DT',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'NN',\n","   'IN',\n","   '``',\n","   'NN',\n","   'NN',\n","   \"''\",\n","   'VBZ',\n","   'VBG',\n","   '.'],\n","  ['DT',\n","   'NN',\n","   'VBZ',\n","   'NN',\n","   'JJ',\n","   'IN',\n","   'VBG',\n","   'DT',\n","   '``',\n","   'NN',\n","   'NN',\n","   '.',\n","   \"''\"],\n","  ['DT',\n","   'NN',\n","   'NNS',\n","   'VBP',\n","   'JJ',\n","   'JJ',\n","   'NNS',\n","   'IN',\n","   'NNP',\n","   'CC',\n","   'PRP',\n","   'CC',\n","   'PRP$',\n","   'NNS',\n","   'VBP',\n","   'CC',\n","   'VBP',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'RB',\n","   '.'],\n","  ['PRP$',\n","   'NN',\n","   'NN',\n","   'VBG',\n","   'DT',\n","   'NN',\n","   'VBD',\n","   'DT',\n","   'NN',\n","   'IN',\n","   '``',\n","   'NNS',\n","   '.',\n","   \"''\"],\n","  ['IN',\n","   'PRP$',\n","   'NN',\n","   ',',\n","   'NNP',\n","   'NNP',\n","   'VBD',\n","   'NNP',\n","   'CC',\n","   'NNP',\n","   'TO',\n","   'VB',\n","   'PRP',\n","   'IN',\n","   'DT',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NNS',\n","   'PRP',\n","   'VBD',\n","   'TO',\n","   'VB',\n","   'PRP$',\n","   'NN',\n","   'RB',\n","   'IN',\n","   'NNS',\n","   '.'],\n","  ['CC', 'NNP', 'NNP', 'POS', 'NNS', 'VBD', 'JJ', '.'],\n","  ['IN',\n","   'DT',\n","   'NNP',\n","   'NN',\n","   ',',\n","   'DT',\n","   'JJ',\n","   'NNP',\n","   '-LRB-',\n","   'NNP',\n","   '-RRB-',\n","   'CC',\n","   'DT',\n","   'JJ',\n","   'NNP',\n","   '-LRB-',\n","   'NNP',\n","   '-RRB-',\n","   'VBD',\n","   'NNS',\n","   'IN',\n","   'VBG',\n","   'IN',\n","   'NNS',\n","   '.'],\n","  ['NNP', 'VBD', 'DT', '``', 'NN', \"''\", 'NN', 'NN', '.'],\n","  ['DT',\n","   'NNS',\n","   'RB',\n","   'VBD',\n","   'IN',\n","   'NNP',\n","   'TO',\n","   'VB',\n","   'DT',\n","   '``',\n","   'JJ',\n","   \"''\",\n","   'NN',\n","   ',',\n","   'IN',\n","   'NNS',\n","   ',',\n","   'NN',\n","   ',',\n","   'NN',\n","   'NN',\n","   ',',\n","   'DT',\n","   'NNS',\n","   '.'],\n","  ['IN',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   ',',\n","   'DT',\n","   'NNP',\n","   'NNS',\n","   'VBD',\n","   'NNP',\n","   ',',\n","   'PRP$',\n","   'NN',\n","   ',',\n","   'CC',\n","   'PRP$',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NN',\n","   '.'],\n","  ['NNP',\n","   'VBD',\n","   'RB',\n","   'RB',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   'POS',\n","   'NN',\n","   'NN',\n","   'VBZ',\n","   'PRP',\n","   'JJ',\n","   'TO',\n","   'VB',\n","   'RP',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   '.'],\n","  ['PRP',\n","   'RB',\n","   'VBD',\n","   'IN',\n","   'RB',\n","   'NN',\n","   'VBZ',\n","   'RB',\n","   'VBG',\n","   'IN',\n","   'PRP$',\n","   'JJ',\n","   'NN',\n","   'HYPH',\n","   'NN',\n","   ',',\n","   'VBG',\n","   'IN',\n","   'DT',\n","   'VBN',\n","   'NNS',\n","   'VBN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   '.'],\n","  ['NN',\n","   ':',\n","   'PRP',\n","   'VBZ',\n","   'JJ',\n","   'IN',\n","   'NNP',\n","   'TO',\n","   'VB',\n","   'RBR',\n","   'PRP$',\n","   'NNS',\n","   'IN',\n","   'VBG',\n","   'VBN',\n","   '.'],\n","  ['IN',\n","   'DT',\n","   'JJS',\n","   'NN',\n","   ',',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   '``',\n","   'NN',\n","   \"''\",\n","   'VBZ',\n","   '.'],\n","  ['IN',\n","   'WDT',\n","   'NN',\n","   ',',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   'VBZ',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'VBN',\n","   'TO',\n","   'VB',\n","   'RBR',\n","   'DT',\n","   'NNS',\n","   'IN',\n","   'VBG',\n","   'VBN',\n","   '.'],\n","  ['IN',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   ',',\n","   'NNS',\n","   'VBP',\n","   'IN',\n","   'NNP',\n","   '-LRB-',\n","   'IN',\n","   'NNS',\n","   '-RRB-',\n","   '``',\n","   'VBD',\n","   'IN',\n","   'DT',\n","   'NNS',\n","   ',',\n","   \"''\",\n","   'CC',\n","   'DT',\n","   'NNS',\n","   'VBD',\n","   ',',\n","   'CC',\n","   'NNP',\n","   'VBD',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   'NNS',\n","   '.'],\n","  ['PRP', 'VBP', 'JJ', ',', 'NNP', '.'],\n","  ['NNS',\n","   'MD',\n","   'RB',\n","   'VB',\n","   'RB',\n","   'IN',\n","   'VBG',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'RB',\n","   'IN',\n","   'DT',\n","   'NN',\n","   ',',\n","   'VBG',\n","   'TO',\n","   'VB',\n","   'PRP',\n","   '.'],\n","  ['NN', 'RB', 'RB', 'IN', 'DT', 'NNS', '.'],\n","  ['NNP',\n","   'RB',\n","   'VBD',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   ',',\n","   'VB',\n","   'RB',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'PRP$',\n","   'NNS',\n","   ',',\n","   'RB',\n","   'VB',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'VBZ',\n","   'TO',\n","   'VB',\n","   'RB',\n","   'HYPH',\n","   'VBN',\n","   'CC',\n","   'VBN',\n","   'IN',\n","   'NNS',\n","   'CC',\n","   'NN',\n","   '.'],\n","  ['MD', 'VB', 'DT', 'NN', '.'],\n","  ['``', 'NNP', 'NNP', \"''\", '-LRB-', '-RRB-'],\n","  ['CD', 'CD', 'NN'],\n","  ['UH', 'VB', 'IN', 'NNP'],\n","  ['NNS', ':'],\n","  ['NNP',\n","   'MD',\n","   'VB',\n","   'VBG',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   'IN',\n","   'NNP',\n","   ',',\n","   'NNP',\n","   'CD',\n","   ',',\n","   'CD',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   'IN',\n","   'NNP',\n","   '.'],\n","  ['PRP',\n","   'MD',\n","   'VB',\n","   'VBG',\n","   'TO',\n","   'VB',\n","   'RB',\n","   'RBS',\n","   '$',\n","   'CD',\n","   'RB',\n","   'NN',\n","   'NNS',\n","   'MD',\n","   'VB',\n","   'IN',\n","   '$',\n","   'CD',\n","   'SYM',\n","   '$',\n","   'CD',\n","   'IN',\n","   'NN',\n","   '-LRB-',\n","   '$',\n","   'CD',\n","   'CD',\n","   'NN',\n","   'IN',\n","   'NN',\n","   '-RRB-',\n","   'VBG',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NNS',\n","   '.'],\n","  ['PRP', 'VBP', 'RB', 'VBN', 'JJ', 'NNS', 'IN', 'CD', 'NNS', '.'],\n","  ['IN',\n","   'PRP',\n","   'VBP',\n","   'JJ',\n","   'IN',\n","   'VBG',\n","   'UH',\n","   'VB',\n","   'PRP',\n","   'RB',\n","   'RB',\n","   'IN',\n","   'JJ',\n","   '.'],\n","  ['DT', 'JJ', 'NN', 'MD', 'VB', 'IN', 'DT', 'WP', 'VBP', '.'],\n","  ['PRP',\n","   'VBP',\n","   'NNS',\n","   'CC',\n","   'NN',\n","   'IN',\n","   'RB',\n","   'RBR',\n","   'IN',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   ',',\n","   'NNP',\n","   'CD',\n","   ',',\n","   'CD',\n","   '.'],\n","  ['UH', 'VB', 'PRP', 'IN', 'DT', 'NNS', '.'],\n","  ['VBP', 'PRP', ','],\n","  ['NNP', 'NNP', 'NN', 'IN', 'NN', 'NNP', '-LRB-', 'CD', '-RRB-', 'CD'],\n","  ['NNS', '.'],\n","  ['NN', 'VBZ', 'RB', 'JJ', 'IN', 'PRP', 'VBP', 'VBG', '.'],\n","  ['JJS', 'IN', 'NN', 'CC', 'RB', 'RB', 'VBG', 'RB', 'IN', 'VBG', 'RB', '.'],\n","  ['JJS', ','],\n","  ['NNP'],\n","  ['PRP', 'MD', 'VB', 'PRP', 'WRB', 'PRP', 'VBP', 'PRP', '.'],\n","  ['VBZ',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   'CC',\n","   'NNP',\n","   'RB',\n","   'IN',\n","   'IN',\n","   'NNP',\n","   'CD',\n","   '.'],\n","  ['NN', '.'],\n","  ['PRP',\n","   'VBP',\n","   'JJ',\n","   'PRP',\n","   'VBP',\n","   'TO',\n","   'VB',\n","   'HYPH',\n","   'RP',\n","   'IN',\n","   'NNP',\n","   '-LRB-',\n","   'PRP',\n","   'VBP',\n","   'VBN',\n","   'VBG',\n","   'PRP',\n","   '-RRB-',\n","   'CC',\n","   'PRP',\n","   'VBP',\n","   'VBN',\n","   'DT',\n","   'NN',\n","   'HYPH',\n","   'NN',\n","   'RB',\n","   'RB',\n","   'VBN',\n","   'IN',\n","   'NNS',\n","   'PRP',\n","   'VBD',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   'IN',\n","   'NNS',\n","   'RB',\n","   '.'],\n","  ['VB', 'PRP', 'VB', 'IN', 'NNP', '.'],\n","  ['PRP', 'MD', 'VB', 'IN', 'NNP', 'CC', 'MD', 'VB', 'PRP', '.'],\n","  ['JJS', ','],\n","  ['NNP'],\n","  ['NNP', 'NNP', '-LRB-', '-RRB-'],\n","  ['CD', 'CD', 'NN'],\n","  ['NNP', ':'],\n","  ['RB',\n","   ',',\n","   'PRP',\n","   'VBD',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   'IN',\n","   'NNP',\n","   'CC',\n","   'NNP',\n","   'FW',\n","   'FW',\n","   '.'],\n","  ['PRP',\n","   'VBD',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'NNP',\n","   'POS',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   '.'],\n","  ['PRP',\n","   'VBP',\n","   'VBG',\n","   'RP',\n","   'IN',\n","   'NNP',\n","   'CC',\n","   'NNP',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'JJ',\n","   'NNS',\n","   ',',\n","   'NN',\n","   'NN',\n","   'CC',\n","   'NNP',\n","   'NN',\n","   'HYPH',\n","   'NN',\n","   'NN',\n","   ',',\n","   'CC',\n","   'VB',\n","   'PRP',\n","   'VB',\n","   'IN',\n","   'PRP',\n","   'VBP',\n","   'JJ',\n","   'NNS',\n","   '.'],\n","  ['PRP',\n","   'VBP',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   'CC',\n","   'MD',\n","   'RB',\n","   'VB',\n","   'IN',\n","   'DT',\n","   'NNP',\n","   '.'],\n","  ['VB', 'PRP', 'VB', 'WDT', 'NN', 'VBZ', 'IN', 'PRP', '.'],\n","  ['RB',\n","   ',',\n","   'MD',\n","   'PRP',\n","   'VB',\n","   'DT',\n","   'JJ',\n","   'NNS',\n","   ',',\n","   'NN',\n","   'NNS',\n","   ',',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NNS',\n","   'IN',\n","   'NNP',\n","   'POS',\n","   'NN',\n","   ':',\n","   'NNP',\n","   'NNP',\n","   ',',\n","   'NNP',\n","   ',',\n","   'NNP',\n","   'NNP',\n","   '.'],\n","  ['NN', '.'],\n","  ['NNP', 'NNP', 'NNP', 'CC', 'NNP'],\n","  ['VBN',\n","   'IN',\n","   'PRP$',\n","   'NN',\n","   'VBP',\n","   'NN',\n","   'NN',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NNP',\n","   'NNP',\n","   'NNPS',\n","   'NN',\n","   'PRP',\n","   'VBP',\n","   'VBG',\n","   'IN',\n","   'IN',\n","   'NNP',\n","   'IN',\n","   'NNP',\n","   '.'],\n","  ['DT', 'NNS', ',', 'NNS', ',', 'FW', 'VBP', 'VBN', '.'],\n","  ['NN', '.'],\n","  ['UH', ',', 'PRP', 'MD', 'VB', 'TO', 'VB', '.'],\n","  ['NN', '.'],\n","  ['NN', 'DT', 'CD', '.'],\n","  ['VB', 'IN', 'PRP', 'RB', '.'],\n","  ['CD', 'CD', 'NN'],\n","  ['RB', 'VBZ', 'DT', 'NN', 'IN', 'VBG', 'RB', ',', 'NN', '.'],\n","  ['NNP'],\n","  ['NNP', 'NNP'],\n","  ['CD', 'CD', 'NN'],\n","  ['DT',\n","   'VB',\n","   'HYPH',\n","   'RB',\n","   'NN',\n","   'CC',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'CD',\n","   'CD',\n","   'NN',\n","   'NN',\n","   'VBP',\n","   'IN',\n","   'VBZ',\n","   ':'],\n","  ['NN', 'MD', 'VB', 'DT', 'NN', 'JJ', 'NN', 'CD', '.'],\n","  ['PDT',\n","   'DT',\n","   'JJ',\n","   'NNS',\n","   'MD',\n","   'VB',\n","   'VBN',\n","   'TO',\n","   'VB',\n","   'PRP$',\n","   'NN',\n","   'NN',\n","   ',',\n","   'WDT',\n","   'VBZ',\n","   'CD',\n","   '.'],\n","  ['NNP',\n","   ',',\n","   'PRP$',\n","   'NN',\n","   'NN',\n","   '-LRB-',\n","   'NN',\n","   'CD',\n","   '-RRB-',\n","   'IN',\n","   'VBG',\n","   'DT',\n","   'NN',\n","   'JJ',\n","   'NN',\n","   'MD',\n","   'VB',\n","   'CD',\n","   '.'],\n","  ['PRP',\n","   'VBP',\n","   'VBN',\n","   'IN',\n","   'CD',\n","   'JJ',\n","   'NNS',\n","   'CC',\n","   'MD',\n","   'NN',\n","   'JJ',\n","   'VB',\n","   'TO',\n","   'VB',\n","   'RB',\n","   ',',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'RB',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'CC',\n","   'IN',\n","   'NN',\n","   'NN',\n","   '.'],\n","  ['DT', 'NN', 'IN', 'DT', 'NN', 'VBZ', 'CD', 'NNS', '.'],\n","  ['DT', 'NN', 'MD', 'VB', 'IN', 'NN', 'VBZ', 'VBN', 'RP', '.'],\n","  ['UH', 'VB', 'PRP', 'VB', 'IN', 'DT', 'IN', 'PRP', 'VBP', 'JJ', 'NN', '.'],\n","  ['NN', '.'],\n","  ['NNP', 'NNP', 'NNP', ',', 'NNP', 'NN'],\n","  ['VBN',\n","   'IN',\n","   'PRP$',\n","   'NN',\n","   'VBP',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NNS',\n","   'WDT',\n","   'VBD',\n","   'VBN',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   ',',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   'NN',\n","   ',',\n","   'VBG',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'WDT',\n","   'VBZ',\n","   'VBN',\n","   'IN',\n","   'CD',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   ',',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   'PRP',\n","   ',',\n","   'CC',\n","   'DT',\n","   'JJ',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NN',\n","   '.'],\n","  ['IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NNS',\n","   'CC',\n","   'NN',\n","   'NNS',\n","   'VBP',\n","   'RB',\n","   'RB',\n","   'JJ',\n","   'RB',\n","   ',',\n","   'PRP',\n","   'VBP',\n","   'RB',\n","   'VBN',\n","   'VBN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   '.'],\n","  ['JJ',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   ',',\n","   'VBG',\n","   'DT',\n","   'NNS',\n","   'CC',\n","   'NN',\n","   'NNS',\n","   ',',\n","   'VBP',\n","   'VBG',\n","   'VBN',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   '.'],\n","  ['JJ',\n","   'VBN',\n","   'NNS',\n","   'MD',\n","   'VB',\n","   'JJ',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'CC',\n","   'RB',\n","   'CC',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'PRP',\n","   'JJ',\n","   'IN',\n","   'DT',\n","   'IN',\n","   'PRP',\n","   ',',\n","   'RB',\n","   'VB',\n","   'PRP',\n","   'VB',\n","   'WRB',\n","   'JJ',\n","   'NNS',\n","   'PRP',\n","   'VBP',\n","   '.'],\n","  ['PRP',\n","   'MD',\n","   'VB',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'IN',\n","   'DT',\n","   'NNS',\n","   'WP',\n","   'VBD',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   '.'],\n","  ['PRP',\n","   'VBP',\n","   'RB',\n","   'VBN',\n","   'JJ',\n","   'NN',\n","   ',',\n","   'NNS',\n","   'CC',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   ',',\n","   'CC',\n","   'PRP',\n","   'VBZ',\n","   '.'],\n","  ['PRP',\n","   'RB',\n","   'VBP',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'WDT',\n","   'VBZ',\n","   'NN',\n","   'NNS',\n","   ',',\n","   'JJ',\n","   'CC',\n","   'JJ',\n","   'NNS',\n","   ',',\n","   'JJ',\n","   'NNS',\n","   ',',\n","   'NNS',\n","   ',',\n","   'NNS',\n","   ',',\n","   'JJ',\n","   'NN',\n","   'NNS',\n","   ',',\n","   'NN',\n","   'NNS',\n","   ',',\n","   'NNS',\n","   ',',\n","   'NNS',\n","   ',',\n","   'NNS',\n","   ',',\n","   'NN',\n","   'NNS',\n","   ',',\n","   'JJ',\n","   'NNS',\n","   ',',\n","   'NNS',\n","   ',',\n","   'CC',\n","   'NN',\n","   'JJ',\n","   'NNS',\n","   ',',\n","   'IN',\n","   'NNS',\n","   '.'],\n","  ['IN',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'JJ',\n","   'IN',\n","   'PRP$',\n","   'NN',\n","   ',',\n","   'PRP',\n","   'RB',\n","   'MD',\n","   'VB',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'VBG',\n","   'PRP$',\n","   'NN',\n","   'JJ',\n","   'IN',\n","   'NNP',\n","   'CD',\n","   'NN',\n","   '.'],\n","  ['NNS',\n","   'VBP',\n","   'RB',\n","   'VBN',\n","   'VBN',\n","   'CC',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'RB',\n","   'DT',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'JJ',\n","   'NNS',\n","   '.'],\n","  ['RB', 'RB', 'IN', 'VBG', 'IN', 'PRP$', 'NNS', '.'],\n","  ['RB', 'RB', ',', 'VBP', 'PRP', 'DT', 'IN', 'DT', 'JJ', 'NN', '.'],\n","  ['-LRB-',\n","   'NN',\n","   '-RRB-',\n","   '-LRB-',\n","   'NN',\n","   '-RRB-',\n","   '.',\n","   '-LRB-',\n","   'NN',\n","   '-RRB-',\n","   '-LRB-',\n","   'NN',\n","   '-RRB-',\n","   '-LRB-',\n","   'NN',\n","   '-RRB-',\n","   '-LRB-',\n","   'NN',\n","   '-RRB-',\n","   '-LRB-',\n","   'NN',\n","   '-RRB-',\n","   '-LRB-',\n","   'NN',\n","   '-RRB-',\n","   '-LRB-',\n","   'NN',\n","   '-RRB-',\n","   '-LRB-',\n","   'NN',\n","   '-RRB-',\n","   '-LRB-',\n","   'NN',\n","   '-RRB-'],\n","  ['NFP', 'NN'],\n","  ['NFP', 'NN'],\n","  ['NFP', 'NN'],\n","  ['NFP', 'NN'],\n","  ['NFP', 'NN'],\n","  ['NFP', 'NN'],\n","  ['NFP', 'NN'],\n","  ['NFP', 'NN'],\n","  ['NFP', 'NN'],\n","  ['NFP', 'NN'],\n","  ['NFP', 'NN'],\n","  ['NNP', 'NNP'],\n","  ['NNP',\n","   'NNP',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'NN',\n","   'CC',\n","   'NN',\n","   'NN',\n","   'NN',\n","   'NNP',\n","   'NNP',\n","   'IN',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   'IN',\n","   'NNP',\n","   'CD',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   ',',\n","   'NNP',\n","   'CD',\n","   'NNP',\n","   ',',\n","   'NNP',\n","   'CD',\n","   '-LRB-',\n","   'NN',\n","   '-RRB-',\n","   'CD',\n","   '-LRB-',\n","   'NN',\n","   '-RRB-',\n","   'CD',\n","   '-LRB-',\n","   'NN',\n","   '-RRB-',\n","   'CD',\n","   'NN',\n","   ':',\n","   'NN',\n","   ':'],\n","  ['VBN',\n","   'VBZ',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'PRP$',\n","   'NN',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'IN',\n","   'IN',\n","   'DT',\n","   'NNP',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   'IN',\n","   'NNP',\n","   'NN',\n","   '.'],\n","  ['VBP',\n","   'VBN',\n","   'IN',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   '-LRB-',\n","   'CC',\n","   'NNP',\n","   '-RRB-',\n","   'IN',\n","   'NN',\n","   'CC',\n","   'VBD',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'DT',\n","   ',',\n","   'RB',\n","   '.'],\n","  ['NN', 'IN', 'NN', ',', '``', 'NN', 'NNS', '.', \"''\"],\n","  ['NN',\n","   'VBZ',\n","   'TO',\n","   '-LRB-',\n","   'RB',\n","   '.',\n","   '-RRB-',\n","   'VB',\n","   'NNP',\n","   'NNP',\n","   'POS',\n","   'CC',\n","   'NNP',\n","   'NNPS',\n","   'POS',\n","   'VBN',\n","   'NNS',\n","   'IN',\n","   'LS',\n","   '-RRB-',\n","   'NNP',\n","   'POS',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'VBD',\n","   'VBN',\n","   'RB',\n","   'IN',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'CC',\n","   'LS',\n","   '-RRB-',\n","   'DT',\n","   'NN',\n","   'VBZ',\n","   'TO',\n","   'VB',\n","   'RP',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'VB',\n","   'HYPH',\n","   'CC',\n","   'HYPH',\n","   'VB',\n","   'NN',\n","   '.'],\n","  ['DT', 'NNP', 'NN', 'NN', 'VBZ', 'JJ', 'TO', 'VB', 'DT', 'NNS', 'RB', '.'],\n","  ['NNS', 'VBP', 'RB', 'VBN', '.'],\n","  ['JJS', ','],\n","  ['NNP'],\n","  ['NNP', ':'],\n","  ['IN',\n","   'PRP',\n","   'VBD',\n","   'NN',\n","   ',',\n","   'NNP',\n","   'CC',\n","   'PRP',\n","   'VBD',\n","   'CC',\n","   'PRP',\n","   'VBP',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'VBZ',\n","   'JJ',\n","   'TO',\n","   'VB',\n","   'IN',\n","   'NNP',\n","   '.'],\n","  ['PRP',\n","   'MD',\n","   'VB',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'PRP',\n","   'VBD',\n","   'IN',\n","   'NNP',\n","   'JJ',\n","   'NN',\n","   '.'],\n","  ['PRP',\n","   'VBD',\n","   'VBN',\n","   'IN',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'VBN',\n","   'NN',\n","   '.'],\n","  ['PRP', 'RB', 'VBG', 'PRP', '.'],\n","  ['VB',\n","   'PRP',\n","   'VB',\n","   'CC',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'PRP',\n","   ',',\n","   'CC',\n","   'VB',\n","   'DT',\n","   'JJ',\n","   'NNS',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'TO',\n","   'VB',\n","   'IN',\n","   'DT',\n","   'NN',\n","   '.'],\n","  ['PRP$', 'NN', 'VBZ', 'IN', 'NNP', 'IN', 'IN', 'CD', 'IN', 'NNP', '.'],\n","  ['JJS', ','],\n","  ['NNP'],\n","  ['NNP',\n","   'VBZ',\n","   'PRP',\n","   'VBZ',\n","   'RB',\n","   'VBG',\n","   'IN',\n","   'CD',\n","   'NN',\n","   'CC',\n","   'PRP',\n","   'VBZ',\n","   'JJ',\n","   'HYPH',\n","   'VBN',\n","   '.'],\n","  ['VBG',\n","   'IN',\n","   'DT',\n","   'NNP',\n","   'NN',\n","   'IN',\n","   'NNS',\n","   'NNP',\n","   'VBZ',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   '-LRB-',\n","   '``',\n","   'JJ',\n","   'NN',\n","   \"''\",\n","   'NN',\n","   '-RRB-',\n","   'RB',\n","   'IN',\n","   'NN',\n","   'CD',\n","   '.'],\n","  ['PRP$',\n","   'NN',\n","   'VBZ',\n","   'IN',\n","   'IN',\n","   'RB',\n","   'CC',\n","   'RB',\n","   'NNP',\n","   ',',\n","   'DT',\n","   'NN',\n","   'VBP',\n","   'DT',\n","   'NN',\n","   'CC',\n","   'NNS',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NN',\n","   ',',\n","   'WDT',\n","   'MD',\n","   'VB',\n","   'JJ',\n","   'IN',\n","   'NNS',\n","   ',',\n","   'NNS',\n","   'POS',\n","   'NNS',\n","   '.'],\n","  ['NNS',\n","   'VBP',\n","   'VBG',\n","   'WP',\n","   'NNP',\n","   'VBZ',\n","   'IN',\n","   'NNS',\n","   'CC',\n","   'NNS',\n","   ',',\n","   'VBG',\n","   'IN',\n","   'NNS',\n","   'IN',\n","   'JJ',\n","   ',',\n","   'CC',\n","   'NNP',\n","   'VBZ',\n","   'NN',\n","   'HYPH',\n","   'VBG',\n","   'DT',\n","   'NNS',\n","   '.'],\n","  ['JJ', '.'],\n","  ['VBD', 'PRP', 'VBD', 'VBN', 'PRP', ',', 'CC', 'VBD', 'TO', 'VB', 'JJ', '.'],\n","  ['PRP', 'VBP', 'WRB', 'DT', 'NN', 'IN', 'NNS', 'MD', 'VB', '.'],\n","  ['PRP',\n","   'VBP',\n","   ',',\n","   'PRP',\n","   'VBP',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'CC',\n","   'VBP',\n","   'RB',\n","   'VBN',\n","   'WRB',\n","   'DT',\n","   'MD',\n","   'VB',\n","   '.'],\n","  ['PRP', 'VBP', 'VBG', 'IN', 'PRP', 'MD', 'VB', 'TO', 'VB', '.'],\n","  ['NN', '.'],\n","  ['JJS', ','],\n","  ['NNP'],\n","  ['NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   ',',\n","   'DT',\n","   'JJ',\n","   'NNS',\n","   'IN',\n","   'PRP$',\n","   'NN',\n","   'MD',\n","   'VB',\n","   'IN',\n","   'NN',\n","   '.'],\n","  ['IN',\n","   'PRP',\n","   'VBP',\n","   'RB',\n","   'VBN',\n","   ',',\n","   'NNP',\n","   'VBZ',\n","   'VBN',\n","   'PRP$',\n","   'VBG',\n","   'NNS',\n","   'IN',\n","   'NNS',\n","   '.'],\n","  ['PRP',\n","   'VBP',\n","   'VBG',\n","   '``',\n","   'NNS',\n","   \"''\",\n","   'IN',\n","   'WRB',\n","   'PRP',\n","   'MD',\n","   'RB',\n","   'VB',\n","   'RB',\n","   '.'],\n","  ['PRP', 'MD', 'VB', 'PRP', 'DT', 'NN', '.'],\n","  ['JJS', ','],\n","  ['NNP'],\n","  ['VBG', 'DT', '``', 'NN', 'NN', \"''\"],\n","  ['NN',\n","   ':',\n","   'DT',\n","   'NN',\n","   'VBZ',\n","   'IN',\n","   'NN',\n","   'NNS',\n","   'CC',\n","   'DT',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NNP',\n","   'NNP',\n","   '.'],\n","  ['NNP', 'CD', ',', 'CD'],\n","  ['IN', 'NNP', 'NNP'],\n","  ['DT', 'NNP', 'NNP', 'NNP'],\n","  ['NNP'],\n","  ['DT',\n","   'NN',\n","   'NNP',\n","   'NN',\n","   'VBZ',\n","   'VBN',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'VBG',\n","   'CD',\n","   'NNS',\n","   'IN',\n","   'NN',\n","   'NNS',\n","   'CC',\n","   'NNS',\n","   'WP',\n","   'VBP',\n","   'NNP',\n","   'POS',\n","   'NN',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'IN',\n","   'PRP',\n","   'VBD',\n","   'IN',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'NN',\n","   'NNS',\n","   '.'],\n","  ['DT',\n","   'JJ',\n","   'NN',\n","   ',',\n","   'VBN',\n","   'IN',\n","   'NN',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   ',',\n","   'NNP',\n","   ',',\n","   'NNP',\n","   'NNP',\n","   ',',\n","   'VBZ',\n","   'VBG',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NNS',\n","   'JJ',\n","   'NN',\n","   'VBN',\n","   'IN',\n","   'JJ',\n","   'JJ',\n","   'NN',\n","   'NNS',\n","   'CC',\n","   'NN',\n","   'IN',\n","   'PRP',\n","   'VBZ',\n","   'VBN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NNP',\n","   ':',\n","   '``',\n","   'DT',\n","   'NN',\n","   'NN',\n","   '.',\n","   \"''\"],\n","  ['NNS',\n","   'CC',\n","   'NN',\n","   'NNS',\n","   'VBP',\n","   'IN',\n","   'DT',\n","   'NNS',\n","   ',',\n","   'VBN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'WP',\n","   'VBZ',\n","   'DT',\n","   'NN',\n","   'POS',\n","   'NN',\n","   'NN',\n","   ',',\n","   'VBD',\n","   'DT',\n","   'NNP',\n","   'NN',\n","   'NN',\n","   ',',\n","   'VBD',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'HYPH',\n","   'VBG',\n","   'NN',\n","   'CC',\n","   'VBD',\n","   'VB',\n","   'NNS',\n","   'IN',\n","   'NNS',\n","   'IN',\n","   'NN',\n","   'NNS',\n","   '.'],\n","  ['DT',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'VBZ',\n","   'IN',\n","   'NNP',\n","   'NNP',\n","   ',',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   ',',\n","   'VBD',\n","   'RB',\n","   'WRB',\n","   'PRP',\n","   'VBD',\n","   'NNS',\n","   'TO',\n","   'VB',\n","   'JJ',\n","   'NN',\n","   'NNS',\n","   'VBN',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'NNS',\n","   'MD',\n","   'VB',\n","   '.'],\n","  ['NNP',\n","   'VBD',\n","   'PRP$',\n","   'JJ',\n","   'NN',\n","   'CC',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   'WRB',\n","   'PRP',\n","   'VBD',\n","   'DT',\n","   'CD',\n","   'HYPH',\n","   'NN',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'NNS',\n","   ',',\n","   'NNS',\n","   'CC',\n","   'NNS',\n","   'VBP',\n","   '.'],\n","  ['``',\n","   'PRP',\n","   'VBP',\n","   'RB',\n","   'VB',\n","   'WRB',\n","   'DT',\n","   'NNS',\n","   'MD',\n","   'VB',\n","   'VBN',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   ',',\n","   \"''\",\n","   'VBD',\n","   'NNP',\n","   '.'],\n","  ['DT',\n","   'NNS',\n","   'MD',\n","   'VB',\n","   'DT',\n","   'VBN',\n","   ',',\n","   'VBG',\n","   'NNP',\n","   ',',\n","   'TO',\n","   'VB',\n","   'VBN',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NN',\n","   ',',\n","   'CC',\n","   'TO',\n","   'VB',\n","   'RP',\n","   'NNS',\n","   ',',\n","   'JJ',\n","   'NNS',\n","   'CC',\n","   'NNS',\n","   '.'],\n","  ['NNP',\n","   'NN',\n","   'NNP',\n","   'NNP',\n","   'VBD',\n","   'DT',\n","   'NNP',\n","   'VBD',\n","   '``',\n","   'JJ',\n","   \"''\",\n","   'IN',\n","   'DT',\n","   'NNS',\n","   'IN',\n","   'NNP',\n","   '.'],\n","  ['``',\n","   'DT',\n","   'NNP',\n","   'VBZ',\n","   'PRP',\n","   'VBD',\n","   'DT',\n","   'VBG',\n","   'NN',\n","   ',',\n","   'WRB',\n","   'WP',\n","   'VBD',\n","   'DT',\n","   'VBG',\n","   'NN',\n","   'VBD',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   ',',\n","   \"''\",\n","   'NNP',\n","   'VBD',\n","   '.'],\n","  ['NNP',\n","   'VBD',\n","   'NN',\n","   ',',\n","   'VBG',\n","   'DT',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NNS',\n","   'NN',\n","   '.'],\n","  ['NNP',\n","   'NN',\n","   'NNP',\n","   'NNP',\n","   'VBD',\n","   'NNP',\n","   'POS',\n","   'NN',\n","   'MD',\n","   'VB',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   '.'],\n","  ['DT',\n","   'NN',\n","   'VBD',\n","   'VBN',\n","   'IN',\n","   'NNP',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'CD',\n","   'NN',\n","   'IN',\n","   'NN',\n","   ':',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'NNS',\n","   'RB',\n","   '.'],\n","  ['IN',\n","   'DT',\n","   'NN',\n","   ',',\n","   'NNS',\n","   'VBD',\n","   'VBG',\n","   'TO',\n","   'VB',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   'IN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NNS',\n","   '.'],\n","  ['``', 'PRP', 'VBD', 'DT', 'NN', ',', \"''\", 'NNP', 'VBD', '.'],\n","  ['``', 'PRP', 'VBD', 'TO', 'VB', 'NN', '.', \"''\"],\n","  ['WP',\n","   'VBD',\n","   'JJ',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'VBD',\n","   'IN',\n","   'NNP',\n","   'CD',\n","   'WRB',\n","   'NNP',\n","   'NN',\n","   'NNS',\n","   'VBD',\n","   'IN',\n","   'JJ',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'NN',\n","   'NNS',\n","   'MD',\n","   'VB',\n","   'IN',\n","   'NN',\n","   '.'],\n","  ['DT',\n","   'NNS',\n","   'MD',\n","   'VB',\n","   'NNS',\n","   'RB',\n","   'JJ',\n","   'IN',\n","   '$',\n","   'CD',\n","   'IN',\n","   'NN',\n","   ',',\n","   'RB',\n","   'CD',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   '$',\n","   'CD',\n","   'IN',\n","   'NN',\n","   'NNS',\n","   'IN',\n","   'CD',\n","   'NNS',\n","   'RBR',\n","   '.'],\n","  ['``',\n","   'PRP',\n","   '-LRB-',\n","   'NN',\n","   'NNS',\n","   '-RRB-',\n","   'VBD',\n","   'CC',\n","   'VBD',\n","   'DT',\n","   '$',\n","   'CD',\n","   'NN',\n","   'NN',\n","   ',',\n","   'CC',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   'VBD',\n","   'RB',\n","   'JJ',\n","   ',',\n","   \"''\",\n","   'VBD',\n","   'NNP',\n","   ',',\n","   'WP$',\n","   'NN',\n","   'VBZ',\n","   'VBN',\n","   'VBG',\n","   'IN',\n","   'NNP',\n","   '.'],\n","  ['``', 'DT', 'NN', 'VBD', 'RB', '.', \"''\"],\n","  ['NNS',\n","   'VBP',\n","   'IN',\n","   'IN',\n","   'NNP',\n","   'CD',\n","   ',',\n","   'NN',\n","   'NNS',\n","   'CC',\n","   'NN',\n","   'NNS',\n","   'VBD',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   ',',\n","   'VBG',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'VB',\n","   'VBN',\n","   '.'],\n","  ['DT',\n","   'NNS',\n","   ',',\n","   'CD',\n","   'IN',\n","   'DT',\n","   ',',\n","   'VBD',\n","   'VBN',\n","   'IN',\n","   'CD',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'CC',\n","   'VBD',\n","   'NNS',\n","   'IN',\n","   'NN',\n","   'NNS',\n","   '.'],\n","  ['``',\n","   'IN',\n","   'RB',\n","   'VBN',\n","   'RB',\n","   ',',\n","   'DT',\n","   '-LRB-',\n","   'NNP',\n","   '-RRB-',\n","   'NN',\n","   'NN',\n","   'MD',\n","   'VB',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   ',',\n","   'VB',\n","   'NN',\n","   'CC',\n","   'VB',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'NN',\n","   ',',\n","   \"''\",\n","   'VBD',\n","   'CD',\n","   'NN',\n","   'VBN',\n","   'IN',\n","   'NNP',\n","   'NNP',\n","   'NN',\n","   'NN',\n","   'NNP',\n","   'NNP',\n","   'CD',\n","   '.'],\n","  ['IN',\n","   'EX',\n","   'VBZ',\n","   'NN',\n","   'JJ',\n","   'IN',\n","   'DT',\n","   'NNS',\n","   'VBG',\n","   'RB',\n","   'TO',\n","   'VB',\n","   'IN',\n","   'NN',\n","   'NNS',\n","   ',',\n","   'NNP',\n","   'VBZ',\n","   'DT',\n","   'NNS',\n","   'CC',\n","   'JJ',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'VBD',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'NNS',\n","   '.'],\n","  ['PRP',\n","   'VBD',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NNS',\n","   'MD',\n","   'VB',\n","   'TO',\n","   'VB',\n","   'IN',\n","   'NN',\n","   'VBD',\n","   'TO',\n","   '``',\n","   'VB',\n","   \"''\",\n","   'NNS',\n","   ',',\n","   'WDT',\n","   'MD',\n","   'VB',\n","   'JJ',\n","   'NN',\n","   'NNS',\n","   '.'],\n","  ['IN',\n","   'DT',\n","   'NNP',\n","   'CD',\n","   'NNS',\n","   ',',\n","   'NN',\n","   'NNS',\n","   'VBD',\n","   'JJ',\n","   'NNS',\n","   'IN',\n","   'IN',\n","   'NN',\n","   'NNS',\n","   'VBD',\n","   'RB',\n","   'VBN',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   '.'],\n","  ['DT', 'NNS', 'VBD', 'PRP$', 'NN', '.'],\n","  ['DT',\n","   'JJ',\n","   'NN',\n","   ',',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'VBD',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   '.'],\n","  ['WP',\n","   'VBD',\n","   'VBN',\n","   'IN',\n","   'NN',\n","   'VBD',\n","   'DT',\n","   '$',\n","   'CD',\n","   'NN',\n","   'NN',\n","   'VBN',\n","   'CD',\n","   'NNS',\n","   'RBR',\n","   '.'],\n","  ['NN',\n","   'NNS',\n","   'RB',\n","   'VBD',\n","   'PRP$',\n","   'NN',\n","   'IN',\n","   'VBG',\n","   'DT',\n","   'NN',\n","   ',',\n","   'VBG',\n","   'PRP',\n","   'MD',\n","   'RB',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'RB',\n","   'IN',\n","   'DT',\n","   'NNS',\n","   '.'],\n","  ['PRP',\n","   'VBD',\n","   'TO',\n","   'VB',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   ',',\n","   'CC',\n","   'IN',\n","   'NNP',\n","   'CD',\n","   'DT',\n","   'NNP',\n","   'VBD',\n","   'PRP$',\n","   'JJ',\n","   'NN',\n","   'CD',\n","   'NN',\n","   'CC',\n","   'VBD',\n","   'IN',\n","   'NNS',\n","   ',',\n","   'WDT',\n","   'VBD',\n","   'RB',\n","   'VBN',\n","   '.'],\n","  ['WP',\n","   'VBD',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'VBZ',\n","   'VBN',\n","   'IN',\n","   'DT',\n","   'NNP',\n","   'CC',\n","   'NNP',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   '.'],\n","  ['NNP',\n","   ',',\n","   'WP',\n","   'IN',\n","   'PRP$',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'CC',\n","   'JJ',\n","   'VBG',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NNP',\n","   ',',\n","   'VBD',\n","   'DT',\n","   'CD',\n","   'HYPH',\n","   'NN',\n","   'NN',\n","   'NN',\n","   ',',\n","   'VBG',\n","   'JJ',\n","   'NNS',\n","   'TO',\n","   'VB',\n","   'DT',\n","   '$',\n","   'CD',\n","   'NN',\n","   'NN',\n","   '.'],\n","  ['JJ', 'NN', 'IN', 'VBG', 'DT', 'NN', 'VBD', 'IN', 'DT', 'JJ', 'NN', '.'],\n","  ['CC',\n","   'DT',\n","   'NNP',\n","   'NN',\n","   ',',\n","   'WDT',\n","   'VBD',\n","   'VBN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   ',',\n","   'CC',\n","   'DT',\n","   'NN',\n","   'VBD',\n","   'IN',\n","   'NNP',\n","   'POS',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'VBD',\n","   'VBN',\n","   'VBN',\n","   '.'],\n","  ['IN',\n","   'NN',\n","   ',',\n","   'DT',\n","   'NN',\n","   'WP',\n","   'VBD',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'NN',\n","   ',',\n","   'NNP',\n","   'NNP',\n","   ',',\n","   'VBD',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NNP',\n","   'CC',\n","   'NNP',\n","   'NN',\n","   'NNS',\n","   'RB',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'VBD',\n","   'VBN',\n","   '.'],\n","  ['PRP', 'VBD', 'RB', 'VB', 'NN', 'IN', 'PRP', '.'],\n","  ['``',\n","   'IN',\n","   'NN',\n","   ',',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'VBN',\n","   'PRP',\n","   ',',\n","   \"''\",\n","   'NNP',\n","   'VBD',\n","   '.'],\n","  ['IN',\n","   'DT',\n","   'NN',\n","   'NNS',\n","   'JJ',\n","   ',',\n","   'DT',\n","   'NNS',\n","   'VBD',\n","   'NN',\n","   'IN',\n","   'JJ',\n","   'NNS',\n","   'VBG',\n","   'JJR',\n","   'NNS',\n","   '.'],\n","  ['``',\n","   'DT',\n","   'NNP',\n","   'NN',\n","   'VBD',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'POS',\n","   'JJ',\n","   'NN',\n","   'NNS',\n","   'IN',\n","   'NN',\n","   'NNS',\n","   ',',\n","   'RB',\n","   'VBG',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'WDT',\n","   'VBD',\n","   'VBG',\n","   'RP',\n","   'IN',\n","   'DT',\n","   'RB',\n","   'JJ',\n","   'NN',\n","   ',',\n","   \"''\",\n","   'NNP',\n","   'VBD',\n","   '.'],\n","  ['``',\n","   'PRP',\n","   'VBD',\n","   'IN',\n","   'NN',\n","   'IN',\n","   'PRP',\n","   'VBD',\n","   'TO',\n","   'VB',\n","   'NN',\n","   'RB',\n","   'JJ',\n","   '.'],\n","  ['DT',\n","   'NN',\n","   'VBD',\n","   'DT',\n","   'NNS',\n","   'POS',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'CC',\n","   'VBD',\n","   'DT',\n","   'NNP',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'HYPH',\n","   'VBG',\n","   'NN',\n","   '.',\n","   \"''\"],\n","  ['NNS',\n","   'IN',\n","   'NN',\n","   'VBD',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   '$',\n","   'CD',\n","   'DT',\n","   'NN',\n","   'IN',\n","   '$',\n","   'CD',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'CD',\n","   'NNS',\n","   ',',\n","   'NNP',\n","   'NNS',\n","   'VBP',\n","   '.'],\n","  ['NNP', 'VBZ', 'DT', 'VBG', 'NNS', 'IN', 'NN', 'VBD', '$', 'CD', 'CD', '.'],\n","  ['NNP',\n","   'VBD',\n","   'DT',\n","   'NN',\n","   ',',\n","   'VBN',\n","   'CD',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NN',\n","   ',',\n","   'VBD',\n","   'IN',\n","   'IN',\n","   'VBD',\n","   'NNPS',\n","   '.'],\n","  ['NNS', ',', 'PRP', 'VBD', ',', 'VBD', 'RB', 'VB', 'IN', 'DT', 'NN', '.'],\n","  ['RB',\n","   'PRP',\n","   'VBD',\n","   'DT',\n","   'VBG',\n","   'NN',\n","   'IN',\n","   'JJ',\n","   'NN',\n","   ',',\n","   'WDT',\n","   'VBZ',\n","   'VBN',\n","   'TO',\n","   'VB',\n","   'NN',\n","   'NNS',\n","   'TO',\n","   'VB',\n","   'NN',\n","   '.'],\n","  ['NNP',\n","   'VBD',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'VBD',\n","   'DT',\n","   'NNP',\n","   'TO',\n","   'VB',\n","   'NNS',\n","   'MD',\n","   'NNS',\n","   'IN',\n","   'NN',\n","   'VB',\n","   'VBN',\n","   'IN',\n","   'JJ',\n","   'NNS',\n","   '.'],\n","  ['``',\n","   'PRP',\n","   'VBP',\n","   'DT',\n","   'NN',\n","   'PRP',\n","   'VBD',\n","   'VBD',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   ',',\n","   \"''\",\n","   'NNP',\n","   'VBD',\n","   '.'],\n","  ['``',\n","   'IN',\n","   'PRP$',\n","   'NN',\n","   ',',\n","   'PRP',\n","   'VBD',\n","   'RB',\n","   'VB',\n","   'PRP',\n","   'VBD',\n","   'CC',\n","   'VBD',\n","   'JJR',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   '.'],\n","  ['PRP',\n","   'VBD',\n","   'PRP',\n","   'VBD',\n","   'PRP',\n","   'JJR',\n","   'IN',\n","   'PRP',\n","   'VBD',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NN',\n","   'CC',\n","   'NN',\n","   '.',\n","   \"''\"],\n","  ['NNP',\n","   'NNP',\n","   'HYPH',\n","   'NNP',\n","   ',',\n","   'WP',\n","   'VBD',\n","   'DT',\n","   'NNP',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'CC',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'WDT',\n","   'VBZ',\n","   'NN',\n","   'NNS',\n","   ',',\n","   'VBD',\n","   'NNP',\n","   'VBD',\n","   'RB',\n","   'VB',\n","   'PRP',\n","   'IN',\n","   'VBG',\n","   'DT',\n","   'NN',\n","   'NN',\n","   '.'],\n","  ['NNP',\n","   'HYPH',\n","   'NNP',\n","   'RB',\n","   'VBD',\n","   'PRP',\n","   'VBD',\n","   'JJ',\n","   'IN',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'HYPH',\n","   'NN',\n","   'NN',\n","   'VBG',\n","   'VBN',\n","   '.'],\n","  ['``',\n","   'NNP',\n","   'VBD',\n","   'DT',\n","   'IN',\n","   'PRP',\n","   ',',\n","   \"''\",\n","   'VBD',\n","   'NNP',\n","   'HYPH',\n","   'NNP',\n","   ',',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NNP',\n","   'NNP',\n","   'NNPS',\n","   '.'],\n","  ['``',\n","   'PRP',\n","   'VBD',\n","   'WP',\n","   'PRP',\n","   'VBD',\n","   'VBD',\n","   'TO',\n","   'VB',\n","   'VBN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'VBG',\n","   '.',\n","   \"''\"],\n","  ['DT',\n","   'NNP',\n","   'NN',\n","   'VBD',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'VBG',\n","   'NNP',\n","   'VB',\n","   'PRP$',\n","   'NNS',\n","   '.'],\n","  ['DT',\n","   'NN',\n","   'NNS',\n","   'VBD',\n","   'TO',\n","   'VB',\n","   'NNP',\n","   'VBN',\n","   ',',\n","   'CC',\n","   'EX',\n","   'VBD',\n","   'NNS',\n","   'JJ',\n","   'NN',\n","   'MD',\n","   'VB',\n","   'IN',\n","   'JJR',\n","   'NN',\n","   ',',\n","   'DT',\n","   'NNP',\n","   'POS',\n","   'NN',\n","   'NNP',\n","   'VBD',\n","   '.'],\n","  ['NNP',\n","   'NNP',\n","   'NNP',\n","   ',',\n","   'DT',\n","   'JJ',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   'NN',\n","   ',',\n","   'VBD',\n","   'VBG',\n","   'DT',\n","   'NNP',\n","   'NN',\n","   'CC',\n","   'RB',\n","   'VBD',\n","   'NNP',\n","   '.'],\n","  ['``',\n","   'PRP',\n","   'VBD',\n","   'DT',\n","   'NN',\n","   'NN',\n","   ',',\n","   'CC',\n","   'PRP',\n","   'VBD',\n","   'RB',\n","   'RB',\n","   'TO',\n","   'VB',\n","   'NNP',\n","   'VB',\n","   'JJ',\n","   ',',\n","   \"''\",\n","   'NNP',\n","   'VBD',\n","   '.'],\n","  ['``',\n","   'PRP',\n","   '-LRB-',\n","   'NNP',\n","   'NN',\n","   '-RRB-',\n","   'VBD',\n","   'WP',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   'MD',\n","   'VB',\n","   '.',\n","   \"''\"],\n","  ['WP',\n","   'NNP',\n","   'POS',\n","   'NN',\n","   'VBZ',\n","   'TO',\n","   'VB',\n","   'VBZ',\n","   'WRB',\n","   'PDT',\n","   'DT',\n","   'NNS',\n","   'VBD',\n","   '.'],\n","  ['PRP',\n","   'VBZ',\n","   'NNS',\n","   'CC',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   'POS',\n","   'NNP',\n","   'CD',\n","   'NNS',\n","   'MD',\n","   'VB',\n","   'JJ',\n","   'NNS',\n","   '.'],\n","  ['``',\n","   'PRP',\n","   'VBP',\n","   'RB',\n","   'VB',\n","   'WRB',\n","   'PRP',\n","   'VBD',\n","   'WP',\n","   'PRP',\n","   'VBD',\n","   ',',\n","   'CC',\n","   'PRP',\n","   'VBP',\n","   'JJ',\n","   'TO',\n","   'VB',\n","   'RP',\n","   ',',\n","   \"''\",\n","   'NNP',\n","   'VBD',\n","   '.'],\n","  ['``',\n","   'NNP',\n","   'VBD',\n","   'PRP',\n","   'VBD',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NNPS',\n","   ',',\n","   'CC',\n","   'PRP',\n","   'VBP',\n","   'DT',\n","   'NN',\n","   'VBZ',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NN',\n","   '.',\n","   \"''\"],\n","  ['PRP',\n","   'MD',\n","   'VB',\n","   'NNP',\n","   'NNP',\n","   'POS',\n","   'NN',\n","   'CC',\n","   'VB',\n","   'PRP',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'VBG',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   '.'],\n","  ['PRP', 'MD', 'VB', 'PRP', 'RP', 'IN', 'PRP', 'MD', 'VB', '.'],\n","  ['NNP', 'CC', 'NNP', ','],\n","  ['PRP',\n","   'VBP',\n","   'VBG',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   'CC',\n","   'NNP',\n","   'NNP',\n","   'IN',\n","   'NNP',\n","   'TO',\n","   'VB',\n","   'PRP$',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'PRP$',\n","   'JJ',\n","   'NNS',\n","   'IN',\n","   'NNP',\n","   '-LRB-',\n","   'IN',\n","   'NNS',\n","   'RB',\n","   'IN',\n","   'NN',\n","   '-RRB-',\n","   '.'],\n","  ['MD', 'PRP', 'VB', 'DT', 'NN', 'CC', 'RB', 'RB', '.'],\n","  ['PRP$',\n","   'NN',\n","   'VBZ',\n","   'IN',\n","   'DT',\n","   'NNS',\n","   'MD',\n","   'VB',\n","   'JJ',\n","   'IN',\n","   'DT',\n","   '-LRB-',\n","   'RB',\n","   '.',\n","   '-RRB-',\n","   'CC',\n","   'PRP$',\n","   'NN',\n","   'CD',\n","   'NN',\n","   'VBZ',\n","   'TO',\n","   'VB',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'NNP',\n","   'NN',\n","   'VBN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   '.'],\n","  ['DT', 'NN', 'IN', 'WRB', 'NNP', 'CC', 'NNP', 'MD', 'VB', 'RB', '.'],\n","  ['NN', '.'],\n","  ['VBZ', 'JJ', '.'],\n","  ['PRP',\n","   'VBP',\n","   'DT',\n","   '``',\n","   'JJ',\n","   'NN',\n","   \"''\",\n","   'IN',\n","   'DT',\n","   'NNS',\n","   ',',\n","   'JJS',\n","   'NN',\n","   'CC',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   ',',\n","   'CC',\n","   'IN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   ',',\n","   'DT',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'VBG',\n","   'NN',\n","   'IN',\n","   'CD',\n","   'NN',\n","   '.'],\n","  ['VBZ', 'EX', 'DT', 'NN', '.'],\n","  ['PRP', 'MD', 'VB', 'IN', 'NNP', 'TO', 'VB', 'DT', 'NN', '.'],\n","  ['IN',\n","   'PRP',\n","   'VBP',\n","   ',',\n","   'NNP',\n","   ',',\n","   'NNP',\n","   'CC',\n","   'PRP',\n","   'RB',\n","   'VBP',\n","   'RP',\n","   'CD',\n","   'NN',\n","   ',',\n","   'CC',\n","   'PRP',\n","   'VBP',\n","   'JJ',\n","   'TO',\n","   'VB',\n","   'RP',\n","   'DT',\n","   'NN',\n","   '.'],\n","  ['JJS', ','],\n","  ['NNP'],\n","  ['VBP', 'PRP', 'VBG', 'NN', '.'],\n","  ['CC', 'IN', 'UH', ',', 'WP', 'VBZ', 'DT', 'NN', 'CC', 'NN', '.'],\n","  ['NNP'],\n","  ['JJ', 'TO', 'VB', 'DT', 'VBZ', 'JJ', '.'],\n","  ['PRP',\n","   'VBD',\n","   'TO',\n","   'VB',\n","   'IN',\n","   'PRP',\n","   'VBD',\n","   'DT',\n","   'NNS',\n","   'VBN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'MD',\n","   'VB',\n","   'PRP$',\n","   'NNS',\n","   'IN',\n","   'IN',\n","   'PRP$',\n","   'NN',\n","   'JJ',\n","   'NNS',\n","   '.'],\n","  ['PRP', 'VBZ', 'RB', 'IN', 'VBG', 'DT', 'NN', 'IN', 'NN', 'IN', 'NN', '.'],\n","  ['PRP', 'VBZ', 'RB', 'IN', 'DT', 'NN', '.'],\n","  ['VB', 'RB', '.'],\n","  ['VB', 'NN', '.'],\n","  ['VB', 'JJ', '.'],\n","  ['NNS', 'IN', 'PRP', 'VBP', 'JJ', '.'],\n","  ['VBG',\n","   'RB',\n","   'IN',\n","   'NNP',\n","   'IN',\n","   'RB',\n","   'DT',\n","   'NN',\n","   'WDT',\n","   'VBZ',\n","   'DT',\n","   'JJ',\n","   'JJR',\n","   'IN',\n","   'PRP',\n","   'VBD',\n","   'PRP',\n","   'MD',\n","   'VB',\n","   'VBG',\n","   'RB',\n","   'CC',\n","   'WRB',\n","   'NN',\n","   'VBZ',\n","   'PRP',\n","   'VBD',\n","   'TO',\n","   'VB',\n","   '.'],\n","  ['VB', 'NN', '.'],\n","  ['PRP',\n","   'VBP',\n","   'RB',\n","   'VB',\n","   'IN',\n","   'PRP',\n","   'IN',\n","   'NNS',\n","   'CC',\n","   'RB',\n","   'PRP',\n","   'VBP',\n","   'PRP',\n","   'IN',\n","   'PDT',\n","   'DT',\n","   'NN',\n","   'VBG',\n","   ',',\n","   'NN',\n","   'VBG',\n","   'NN',\n","   '.'],\n","  ['NN', 'IN', 'VBG', 'IN', 'PRP', 'TO', 'VB', 'PRP', 'IN', '.'],\n","  ['PRP', 'RB', 'VBD', 'VBG', 'PRP', '.'],\n","  ['PRP', 'RB', 'VBP', 'IN', 'JJ', 'NNS', 'IN', 'DT', 'NN', '.'],\n","  ['EX', 'VBP', 'DT', 'JJ', 'NN', 'NNS', 'IN', 'DT', 'WDT', 'VBG', 'RB', '.'],\n","  ['PRP', 'VBZ', 'RB', 'JJ', 'NN', '.'],\n","  ['WRB', 'VBP', 'NNS', 'VBG', 'IN', 'PRP', '.'],\n","  ['VBP', 'PRP', 'VBG', 'NNP', '.'],\n","  ['NNP', 'VBZ', 'VBN', 'JJ', '.'],\n","  ['VBG', 'IN', 'RB', 'VBZ', 'VBN', 'RB', 'JJ', '.'],\n","  ['NNS',\n","   'IN',\n","   'RB',\n","   'VBP',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'JJR',\n","   'NN',\n","   'IN',\n","   'JJ',\n","   'NNS',\n","   '.'],\n","  ['NNP',\n","   'VBZ',\n","   'JJ',\n","   'CC',\n","   'VBZ',\n","   'VBN',\n","   'PRP',\n","   'DT',\n","   'RB',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'NN',\n","   '.'],\n","  ['VB', 'IN', 'NN', ','],\n","  ['NNP'],\n","  ['NNP', 'NNP', 'NNP'],\n","  ['NFP'],\n","  ['VB', 'PRP$', 'JJ', 'NN', 'IN', 'NNP', 'NNP', 'IN'],\n","  ['IN',\n","   'PRP',\n","   'PRP',\n","   'VBZ',\n","   'RB',\n","   'IN',\n","   'NN',\n","   'CC',\n","   'VBG',\n","   'PRP$',\n","   'NN',\n","   'POS',\n","   'NN',\n","   'IN',\n","   'PRP$',\n","   'NN',\n","   '.'],\n","  ['PRP', 'VBZ', 'RB', 'IN', 'DT', 'NN', '.'],\n","  ['VB', 'RB', 'CC', 'VB', 'RB', '.'],\n","  ['NNS'],\n","  ['NNP'],\n","  ['NN', 'PRP', 'VBP', 'VBG', 'RB', 'IN', 'NNP', 'IN', 'RB', 'DT', 'NN', '.'],\n","  ['NNP', 'VBZ', 'TO', 'VB', 'JJ', 'TO', 'VB', 'PRP', 'RB', 'IN', 'NN', '.'],\n","  ['PRP', 'VBP', 'RB', 'RB', 'VBG', 'RB', 'IN', 'PRP', '.'],\n","  ['VB', 'PRP', 'VB', 'JJ', 'NN', 'PRP', 'VBP', 'NNP', 'NNPS', 'RB', '.'],\n","  ['NNP', 'NNP'],\n","  ['CD', 'CD', 'NN'],\n","  ['IN', 'PRP$', 'NN', ','],\n","  ['-LRB-', 'VB', 'VBN', 'NN', ':', 'NN', '-RRB-'],\n","  ['NFP', 'NN', 'NFP'],\n","  ['DT',\n","   'NN',\n","   'CC',\n","   ',',\n","   'CC',\n","   'NNS',\n","   'MD',\n","   'VB',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'HYPH',\n","   'NN',\n","   'NN',\n","   'CC',\n","   'MD',\n","   'RB',\n","   'VB',\n","   'JJ',\n","   'CC',\n","   'JJ',\n","   '.'],\n","  ['IN',\n","   'PRP',\n","   'VBP',\n","   'RB',\n","   'DT',\n","   'VBN',\n","   'NN',\n","   ',',\n","   'PRP',\n","   'VBP',\n","   'RB',\n","   'VBN',\n","   'IN',\n","   'PRP',\n","   'VBP',\n","   'VBN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NN',\n","   ',',\n","   'DT',\n","   'NN',\n","   ',',\n","   'NN',\n","   ',',\n","   'NN',\n","   'CC',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'VBZ',\n","   'RB',\n","   'VBN',\n","   '.'],\n","  ['IN',\n","   'PRP',\n","   'VBP',\n","   'VBN',\n","   'DT',\n","   'NN',\n","   'CC',\n","   ',',\n","   'CC',\n","   'NNS',\n","   'IN',\n","   'NN',\n","   ',',\n","   'UH',\n","   'VB',\n","   'PRP',\n","   'RB',\n","   'IN',\n","   'NN',\n","   'CC',\n","   'IN',\n","   'NN',\n","   '-LRB-',\n","   'VB',\n","   'PRP',\n","   'RB',\n","   'IN',\n","   'CD',\n","   'CD',\n","   '-RRB-',\n","   'CC',\n","   'RB',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'CC',\n","   'PDT',\n","   'PRP$',\n","   'NNS',\n","   '.'],\n","  ['VBP', 'PRP', '.'],\n","  ['NFP', 'NN', '-LRB-', 'NN', ':', 'NN', '-RRB-'],\n","  ['PRP', 'VBD', 'VBG', 'IN', 'VBG', 'PRP', 'IN', 'DT', 'NN', 'NN', '.'],\n","  ['PRP',\n","   'MD',\n","   'RB',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'CC',\n","   'VB',\n","   'PRP',\n","   'TO',\n","   'VB',\n","   'PRP',\n","   'RB',\n","   'DT',\n","   'NN',\n","   '.'],\n","  ['WRB',\n","   'IN',\n","   'NN',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'CC',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NN',\n","   '.'],\n","  ['NNP', 'NNP', 'CD', '.'],\n","  ['RB',\n","   'JJ',\n","   'IN',\n","   'PRP',\n","   'VBP',\n","   'VBG',\n","   'TO',\n","   'VB',\n","   'CD',\n","   'NN',\n","   'CC',\n","   'CD',\n","   'NN',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NN',\n","   '.'],\n","  ['NN', '.'],\n","  ['NNP', 'POS', 'NN', 'VBZ', 'NN', '.'],\n","  ['WP', 'VBP', 'PRP', 'VBG', 'TO', 'VB', 'PRP', '.'],\n","  ['NNP'],\n","  ['DT', 'VBZ', 'DT', 'JJ', 'NN', '.'],\n","  ['PRP', 'VBP', 'PRP', 'VBP', 'VBG', 'PRP$', 'NN', 'RB', '.'],\n","  ['VBP', 'RB', 'IN', 'VBG', 'DT', 'JJ', 'NNS', '.'],\n","  ['NNP'],\n","  ['NNP', 'NNP', '-LRB-', '-RRB-', 'IN', 'CD', 'CD', 'NN'],\n","  ['PRP$', 'NN', 'VBZ', 'RB', 'JJ', '.'],\n","  ['PRP$',\n","   'NN',\n","   'VBZ',\n","   'RB',\n","   'JJ',\n","   ':',\n","   'WRB',\n","   'PRP',\n","   'VBZ',\n","   'NN',\n","   'PRP',\n","   'VBZ',\n","   'TO',\n","   'VB',\n","   'CD',\n","   'NNS',\n","   '.'],\n","  ['WRB', 'PRP', 'VBZ', 'PRP', 'VBZ', 'DT', 'NN', 'VB', '.'],\n","  ['WRB',\n","   'PRP',\n","   'VBD',\n","   'VBN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'VBG',\n","   'NN',\n","   'DT',\n","   'NN',\n","   'VBD',\n","   'PRP',\n","   'CD',\n","   'NNS',\n","   'TO',\n","   'VB',\n","   '.'],\n","  ['PRP',\n","   'VBZ',\n","   'NN',\n","   'IN',\n","   'NN',\n","   '.',\n","   '-LRB-',\n","   'NFP',\n","   'RB',\n","   'DT',\n","   'NN',\n","   '-RRB-'],\n","  ['PRP$', 'NN', 'NN', 'VBD', 'IN', 'DT', 'NN', '.'],\n","  ['WRB',\n","   'PRP',\n","   'VBZ',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'DT',\n","   'NNS',\n","   'VBP',\n","   'PRP',\n","   'NNS',\n","   '.'],\n","  ['PRP$', 'JJ', 'NN', 'NN', 'NN', 'VBD', 'DT', 'JJ', 'NN', '.'],\n","  ['PRP$',\n","   'NN',\n","   'POS',\n","   'NN',\n","   'VBZ',\n","   '``',\n","   'NN',\n","   'VBN',\n","   'IN',\n","   'JJ',\n","   'NN',\n","   '.',\n","   \"''\"],\n","  ['PRP', 'VBZ', 'TO', 'VB', 'PRP$', 'NNS', 'IN', 'DT', 'NN', '.'],\n","  ['DT',\n","   'NN',\n","   'IN',\n","   'PRP$',\n","   'NN',\n","   'VBZ',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'JJ',\n","   'NNS',\n","   '.'],\n","  ['PRP$',\n","   'NN',\n","   'VBZ',\n","   'RB',\n","   'JJ',\n","   ',',\n","   'PDT',\n","   'DT',\n","   'NNS',\n","   'IN',\n","   'NN',\n","   'VBP',\n","   'NNS',\n","   'WDT',\n","   'VBP',\n","   ':',\n","   '``',\n","   'JJ',\n","   'NN',\n","   ':',\n","   'CD',\n","   'NNS',\n","   'CC',\n","   'PRP$',\n","   'NN',\n","   \"''\",\n","   'PRP$',\n","   'NN',\n","   'VBZ',\n","   'RB',\n","   'JJ',\n","   ',',\n","   'WRB',\n","   'PRP',\n","   'VBD',\n","   'RB',\n","   ',',\n","   'PRP',\n","   'VBD',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'CD',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   '.'],\n","  ['PRP$',\n","   'NN',\n","   'VBZ',\n","   'RB',\n","   'JJ',\n","   ',',\n","   'RB',\n","   'IN',\n","   'NNPS',\n","   'CD',\n","   'NNS',\n","   ',',\n","   'PRP',\n","   'VBZ',\n","   'NNPS',\n","   'NNS',\n","   '.'],\n","  ['PRP$',\n","   'NN',\n","   'VBZ',\n","   'RB',\n","   'JJ',\n","   ',',\n","   'WRB',\n","   'PRP',\n","   'VBZ',\n","   'IN',\n","   'DT',\n","   'NN',\n","   ',',\n","   'PRP',\n","   'VBZ',\n","   'TO',\n","   'VB',\n","   'RB',\n","   '.'],\n","  ['PRP$',\n","   'NN',\n","   'VBZ',\n","   'RB',\n","   'JJ',\n","   ',',\n","   'PRP',\n","   'VBD',\n","   'VBN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'PRP$',\n","   'NN',\n","   '.'],\n","  ['PRP$',\n","   'NN',\n","   'VBZ',\n","   'RB',\n","   'JJ',\n","   ',',\n","   'PRP',\n","   'VBZ',\n","   'VBN',\n","   'JJR',\n","   'JJ',\n","   'NNS',\n","   'VBG',\n","   'IN',\n","   'PRP',\n","   '.'],\n","  ['PRP$', 'NN', 'VBZ', 'RB', 'JJ', ',', 'PRP', 'MD', 'VB', 'NN', '.'],\n","  ['PRP', 'MD', 'VB', 'TO', 'VB', 'CC', 'VB', 'NFP'],\n","  ['JJ', '.'],\n","  ['VB', 'DT', 'NN', 'IN', 'NNP', 'NN', '.'],\n","  ['NNP'],\n","  ['WP', 'VBP', 'DT', 'JJ', 'NN', 'NNS', '.'],\n","  ['VB', 'PRP$', 'NNS', '.'],\n","  ['NNP'],\n","  ['PRP',\n","   'VBD',\n","   'NNP',\n","   'IN',\n","   'PRP',\n","   'VBD',\n","   'PRP',\n","   'NN',\n","   'RB',\n","   'RB',\n","   'IN',\n","   'PRP',\n","   'VBD',\n","   'RB',\n","   'VB',\n","   'TO',\n","   'VB',\n","   'PRP$',\n","   'NN',\n","   'IN',\n","   'PRP',\n","   'VBD',\n","   'NNS',\n","   'VBN',\n","   'IN',\n","   'NN',\n","   '.'],\n","  ['PRP',\n","   'VBD',\n","   'PRP',\n","   'PRP',\n","   'VBD',\n","   'PRP',\n","   'TO',\n","   'VB',\n","   'PRP',\n","   'RP',\n","   'CC',\n","   'RB',\n","   'RBS',\n","   'VB',\n","   'WP',\n","   'PRP',\n","   'VBZ',\n","   'TO',\n","   'VB',\n","   '.'],\n","  ['PRP',\n","   'VBD',\n","   'PRP',\n","   'VBP',\n","   'VBG',\n","   'IN',\n","   'NNS',\n","   'CC',\n","   'VBN',\n","   'IN',\n","   'WP',\n","   'PRP',\n","   'VBD',\n","   'PRP',\n","   'DT',\n","   'NN',\n","   'VBD',\n","   'DT',\n","   'NN',\n","   '.'],\n","  ['NNP'],\n","  ['VBZ', 'DT', 'NN', 'WDT', 'PRP', 'VBD', 'NNP', 'RB', 'JJ', '.'],\n","  ['PDT',\n","   'DT',\n","   'NNS',\n","   'IN',\n","   'NN',\n","   'VBP',\n","   'VBG',\n","   'PRP',\n","   'MD',\n","   'RB',\n","   'VB',\n","   'VBG',\n","   'PRP',\n","   'VBN',\n","   'PRP',\n","   'MD',\n","   'RB',\n","   'VB',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   '.'],\n","  ['NNP'],\n","  ['NNP', 'NNP', 'CD'],\n","  ['PRP', 'MD', 'RB', 'VB', 'IN', 'DT', 'NN', '.'],\n","  ['VBP',\n","   'PRP',\n","   'VB',\n","   'TO',\n","   'NN',\n","   'VB',\n","   'DT',\n","   'NNS',\n","   'IN',\n","   'PRP$',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NNS',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'CC',\n","   'VBD',\n","   'PRP',\n","   'RB',\n","   'VB',\n","   'DT',\n","   '.'],\n","  ['NNP'],\n","  ['NNP', ','],\n","  ['VBP', 'RB', 'VB', 'DT', 'NN', 'RP', 'IN', 'PRP', 'VBP', 'IN', 'PRP', '.'],\n","  ['PRP',\n","   'VBP',\n","   'PRP',\n","   'VBZ',\n","   'PRP',\n","   'CC',\n","   'PRP',\n","   'VBD',\n","   'TO',\n","   'VB',\n","   'PRP',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   '-LRB-',\n","   'PRP',\n","   'RB',\n","   'VBD',\n","   'PRP',\n","   'IN',\n","   'PRP$',\n","   'JJ',\n","   'NN',\n","   '-RRB-',\n","   '.'],\n","  ['NN', ','],\n","  ['NNP'],\n","  ['RB', 'DT', 'NN', 'TO', 'VB', 'PRP', 'DT', 'NN', 'NN', '.'],\n","  ['NN', ','],\n","  ['NNP'],\n","  ['NNP', 'VBD', 'PRP', 'NN', '.'],\n","  ['PRP',\n","   'MD',\n","   'VB',\n","   'IN',\n","   'NNP',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NNS',\n","   'CC',\n","   'MD',\n","   'VB',\n","   'PRP',\n","   'RB',\n","   '.'],\n","  ['NNP'],\n","  ['PRP', 'MD', 'VB', 'RB', '.'],\n","  ['VB', 'RB', 'VB', 'NNP', 'CC', 'NNP', 'VB', '.'],\n","  ['NNP'],\n","  ['PRP', 'VBD', 'RB', 'VB', 'DT', 'NN', 'TO', 'VB', 'IN', 'NNP', 'NN', '.'],\n","  ['VB', 'PRP', 'DT', 'NN', 'NN', '.'],\n","  ['NNP'],\n","  ['MD',\n","   'PRP',\n","   'UH',\n","   'VB',\n","   'DT',\n","   'NNP',\n","   'NN',\n","   ',',\n","   'NN',\n","   'IN',\n","   'PRP$',\n","   'NN',\n","   '.'],\n","  ['NNP'],\n","  ['WRB', 'IN', 'VBG', 'IN', 'CD', 'CC', 'CD', '.'],\n","  ['PRP', 'VBP', 'IN', 'DT', 'NN', 'RB', 'VB', 'PRP', 'DT', 'NN', '.'],\n","  ['NNP', 'CD'],\n","  ['DT', 'NN', 'VBZ', 'JJ', '.'],\n","  ['NNP'],\n","  ['VB', 'VBN', 'NN', 'CC', 'NN', 'NN', '.'],\n","  ['RB', 'PRP', 'VBD', 'RB', 'VB', 'NN', 'RB', '.'],\n","  ['NNP', 'VBZ', 'RB', 'JJ', 'CC', 'DT', 'JJ', 'NN', '.'],\n","  ['PRP', 'VBP', 'PRP', 'MD', 'VB', 'DT', 'JJ', 'NN', '.'],\n","  ['VB',\n","   'PRP',\n","   'DT',\n","   'NN',\n","   'NNP',\n","   'NN',\n","   'TO',\n","   'VB',\n","   '-LRB-',\n","   'VBN',\n","   'IN',\n","   'NNP',\n","   'VBG',\n","   'IN',\n","   'DT',\n","   'NN',\n","   '-RRB-',\n","   '.'],\n","  ['NNS', ','],\n","  ['NNP'],\n","  ['PRP', 'VBP', 'RB', 'VBN', 'DT', 'NN', 'TO', 'VB', 'PRP', 'RB', '.'],\n","  ['NNP',\n","   'VBZ',\n","   'IN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'RB',\n","   'PRP',\n","   'VBP',\n","   'RB',\n","   'VBN',\n","   'DT',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'IN',\n","   'PRP',\n","   '.'],\n","  ['PRP',\n","   'MD',\n","   'VB',\n","   'PRP',\n","   'RB',\n","   'RB',\n","   'IN',\n","   'PRP',\n","   'VBP',\n","   'IN',\n","   'PRP',\n","   'MD',\n","   'CC',\n","   'RB',\n","   '.'],\n","  ['NNP'],\n","  ['VBP', 'PRP', 'NNS', 'RB', 'VBG', 'IN', 'DT', 'NN', '.'],\n","  ['MD', 'PRP', 'VB', 'DT', 'NN', 'IN', 'NNP', 'CC', 'PRP', 'RB', '.'],\n","  ['NNP',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   'NN',\n","   'CD',\n","   ',',\n","   'CD',\n","   'NNP',\n","   'NNP',\n","   'NNP',\n","   ',',\n","   'NNP',\n","   'NN',\n","   'NN',\n","   'CD'],\n","  ['NNP', 'NNP', ',', 'NN', 'CD'],\n","  ['NNP', 'NNP', ',', 'NN', 'CD'],\n","  ['VBN',\n","   'VBZ',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   '-LRB-',\n","   'NN',\n","   'CC',\n","   'NN',\n","   '-RRB-',\n","   '.'],\n","  ['PRP',\n","   'MD',\n","   'VB',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'TO',\n","   'VB',\n","   'RB',\n","   'RB',\n","   'IN',\n","   'PRP',\n","   'MD',\n","   '.'],\n","  ['NNP'],\n","  ['VB', 'PRP', 'RB', '.'],\n","  ['NNP'],\n","  ['NN', 'NN', '.'],\n","  ['NNP', 'NNP', 'VBZ', 'UH', '.'],\n","  ['NNP'],\n","  ['PRP', 'MD', 'VB', 'JJ', 'TO', 'VB', '.'],\n","  ['NNP'],\n","  ['PRP', 'VBP', 'TO', 'VB', 'NN', 'IN', 'CD', 'POS', 'CD', 'NN', 'NN', '.'],\n","  ['WP', 'VBZ', 'DT', 'CD', 'NN', 'NN', 'NN', 'IN', 'CD', '.'],\n","  ['NNP'],\n","  ['NNP', 'NNP'],\n","  ['CD', 'CD', 'NN'],\n","  ['-LRB-', 'VBN', 'NN', '-LRB-', 'NN', 'JJ', 'NN', '-RRB-', '-RRB-'],\n","  ['PRP',\n","   'VBP',\n","   'IN',\n","   'DT',\n","   'VBZ',\n","   'IN',\n","   'PRP',\n","   'IN',\n","   'PRP',\n","   'VBP',\n","   'RB',\n","   'VB',\n","   'DT',\n","   'IN',\n","   'DT',\n","   'NNS',\n","   '.'],\n","  ['WP', ':', 'NNP'],\n","  ['WP', ':', 'JJ', 'NN', 'IN', 'NNP', 'NNP'],\n","  ['WRB', ':', 'NN', 'IN', 'CD', 'NN'],\n","  ['WRB',\n","   ':',\n","   'DT',\n","   'NNP',\n","   'NNP',\n","   'CD',\n","   'NNP',\n","   'NNP',\n","   '-LRB-',\n","   'CD',\n","   '-RRB-',\n","   'CD'],\n","  ['WRB', ':', 'NN', 'VBZ', 'NNP', 'POS', 'JJ', 'NN', 'IN', 'NNP', '.'],\n","  ['DT', 'VBZ', 'RB', 'DT', 'NNP', 'HYPH', 'VBN', 'NN', '.'],\n","  ['WRB', 'VBP', 'PRP', 'VB', 'IN', 'VBG', 'RP', 'DT', 'NN', '.'],\n","  ['NNP',\n","   'CC',\n","   'NNP',\n","   'VBP',\n","   'VBN',\n","   'VBG',\n","   'NN',\n","   'CD',\n","   'IN',\n","   'PRP$',\n","   'NN',\n","   '-LRB-',\n","   'VB',\n","   'RB',\n","   '-RRB-',\n","   '.'],\n","  ['VBP', 'PRP', 'VB', '.'],\n","  ['UH', 'VB', 'PRP', 'VB', 'NNP', 'NN', '.'],\n","  ['NNS', ','],\n","  ['NNP'],\n","  ['IN',\n","   'PRP',\n","   'VBP',\n","   'RB',\n","   'RB',\n","   'VBN',\n","   'DT',\n","   'NNS',\n","   ',',\n","   'NNP',\n","   'POS',\n","   'NN',\n","   'MD',\n","   'VB',\n","   'JJ',\n","   '.'],\n","  ['NNP', 'NNP', 'JJ', 'NN', 'NN', 'NNP', 'CD'],\n","  ['UH', 'VB', 'PRP$', 'NNS', 'IN', 'JJ', 'RB', '.'],\n","  ['NNP'],\n","  ['NNP', ','],\n","  ['MD',\n","   'PRP',\n","   'VB',\n","   'WRB',\n","   'DT',\n","   'NNS',\n","   'DT',\n","   'VBP',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   '.'],\n","  ['IN',\n","   'JJ',\n","   ',',\n","   'MD',\n","   'PRP',\n","   'RB',\n","   'VB',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   ',',\n","   'CD',\n","   'IN',\n","   'CD',\n","   '.'],\n","  ['NN', ','],\n","  ['NNP'],\n","  ['PRP',\n","   'VBP',\n","   'DT',\n","   'JJ',\n","   'NNS',\n","   'WDT',\n","   'MD',\n","   'VB',\n","   'TO',\n","   'VB',\n","   'NNS',\n","   'CC',\n","   'VB',\n","   'VBN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   '.'],\n","  ['NN', ',', 'NNP', 'NNP', 'NNPS', 'NNP'],\n","  ['DT', 'NN', 'VBZ', 'RB', 'IN', 'NNP', ',', 'NNP', ',', 'CC', 'NNP', '.'],\n","  ['DT',\n","   'CD',\n","   'NN',\n","   'NN',\n","   'VBZ',\n","   'DT',\n","   'NN',\n","   ',',\n","   'NNS',\n","   ',',\n","   'CC',\n","   'NNS',\n","   '.'],\n","  ['EX',\n","   'VBZ',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   ',',\n","   'CC',\n","   'DT',\n","   'NN',\n","   'VBZ',\n","   'TO',\n","   'VB',\n","   'VBN',\n","   'JJ',\n","   'IN',\n","   'PRP',\n","   'VBZ',\n","   'NN',\n","   '.'],\n","  ['NN', ',', 'NNP', 'NNP', 'NNPS', 'NNP'],\n","  ['IN',\n","   'DT',\n","   'NN',\n","   ',',\n","   'DT',\n","   'NN',\n","   'VBZ',\n","   'TO',\n","   'VB',\n","   'DT',\n","   'NNP',\n","   'NN',\n","   '.'],\n","  ['IN',\n","   'NNP',\n","   'NNS',\n","   ',',\n","   'DT',\n","   'NN',\n","   'VBZ',\n","   'RB',\n","   '$',\n","   'CD',\n","   'CD',\n","   'IN',\n","   'NNP',\n","   'CC',\n","   'RB',\n","   '$',\n","   'CD',\n","   'CD',\n","   'IN',\n","   'NNS',\n","   ',',\n","   'NN',\n","   'JJ',\n","   '.'],\n","  ['DT',\n","   'JJ',\n","   'CD',\n","   'NNS',\n","   'VBD',\n","   'PRP$',\n","   'NN',\n","   'IN',\n","   'IN',\n","   'NNP',\n","   ',',\n","   'CC',\n","   'VBD',\n","   'RB',\n","   'VB',\n","   'VBN',\n","   'IN',\n","   'DT',\n","   'NN',\n","   '.'],\n","  ['NN', ',', 'NNP', 'NNP', 'NNP', ',', 'NNP', '.'],\n","  ['DT',\n","   'NN',\n","   'VBD',\n","   'VBN',\n","   'IN',\n","   'CD',\n","   'IN',\n","   'DT',\n","   'NN',\n","   'IN',\n","   'NNP',\n","   'NNPS',\n","   '-LRB-',\n","   'RB',\n","   'NNP',\n","   'NNP',\n","   'NNPS',\n","   ',',\n","   'NNP',\n","   'NN',\n","   '-RRB-',\n","   ',',\n","   'CC',\n","   'RB',\n","   'VBN',\n","   'IN',\n","   'NN',\n","   'IN',\n","   'NN',\n","   '.'],\n","  ['NN',\n","   'VBZ',\n","   'RB',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'IN',\n","   'NNS',\n","   'CC',\n","   'NNS',\n","   ',',\n","   'CC',\n","   'DT',\n","   'NN',\n","   'NNS',\n","   '.'],\n","  ['NN', 'VBZ', 'PRP$', 'NN', '.'],\n","  ['PRP', 'VBP', 'DT', 'NN', 'MD', 'VB', 'IN', 'NN', '.'],\n","  ['RB', 'PRP', 'VBP', 'PRP', 'VB', 'VBN', 'IN', 'NNP', '.'],\n","  ['PRP', 'MD', 'VB', 'CD', ',', 'JJ', '.'],\n","  ['CD', ',', 'NNP', 'NNP', 'NNP', 'NN', 'IN', 'NN', '.'],\n","  ['DT', 'NN', 'MD', 'RB', 'VB', 'VBN', 'IN', 'NNS', 'CC', 'NNS', 'NN', '.'],\n","  ['RB', 'RB', 'IN', 'PRP$', 'NN', 'IN', 'NNS', '.'],\n","  ['PRP',\n","   'VBP',\n","   'DT',\n","   'MD',\n","   'VB',\n","   'IN',\n","   'DT',\n","   'NN',\n","   ',',\n","   'JJ',\n","   'NNS',\n","   '-LRB-',\n","   'JJ',\n","   'IN',\n","   'NN',\n","   '-RRB-',\n","   'CC',\n","   'NN',\n","   'CC',\n","   'NNS',\n","   '-LRB-',\n","   'NNP',\n","   '-RRB-',\n","   '.'],\n","  ['CD', ',', 'JJ', '.'],\n","  ['CD', ',', 'NNP', ',', 'NNP', 'NNP'],\n","  ['VBN', 'RP', 'JJ', 'NN', 'TO', 'VB', 'NN', 'NN', 'NNS', '.'],\n","  ['VBD', 'RP', 'DT', 'NNS', 'IN', 'CD', '.'],\n","  ['DT',\n","   'JJ',\n","   'NN',\n","   '-LRB-',\n","   'CD',\n","   '-RRB-',\n","   'VBD',\n","   'VBN',\n","   'IN',\n","   'NN',\n","   'CC',\n","   'NN',\n","   '-LRB-',\n","   'NNP',\n","   'NNP',\n","   'CC',\n","   'NNP',\n","   'NNP',\n","   '-RRB-',\n","   'RB',\n","   'DT',\n","   'NN',\n","   'MD',\n","   'VB',\n","   'VBN',\n","   'IN',\n","   'PRP',\n","   'RB',\n","   'RB',\n","   '.'],\n","  ['CD', ',', 'JJ', '.'],\n","  ['CD', ',', 'NNP', ',', 'NNP', ',', 'NNP'],\n","  ['VBZ', 'IN', 'IN', 'NNP', 'NNP', 'NNP', ',', 'DT', 'NN', '.'],\n","  ['NNP',\n","   'NNP',\n","   'NNP',\n","   'VBZ',\n","   'VBN',\n","   'IN',\n","   'NNP',\n","   'NNP',\n","   '-LRB-',\n","   'NNP',\n","   'NNP',\n","   'CC',\n","   'NNP',\n","   'NNP',\n","   '-RRB-',\n","   '.'],\n","  ['RB',\n","   'DT',\n","   'NN',\n","   'MD',\n","   'RB',\n","   'VB',\n","   'IN',\n","   'PRP',\n","   'IN',\n","   'DT',\n","   'JJ',\n","   'NN',\n","   'WDT',\n","   'MD',\n","   'VB',\n","   'TO',\n","   'VB',\n","   'VBN',\n","   'MD',\n","   'VB',\n","   'JJ',\n","   'NN',\n","   '.'],\n","  ['CD', ',', 'JJ', '.'],\n","  ['CD', ',', 'NNP', ',', 'NNP', 'NNPS', ',', 'NNP'],\n","  ['VBN', 'RP', 'JJ', 'NN', 'TO', 'VB', 'NN', 'NN', 'NNS', '.'],\n","  ['VBD', 'RP', 'DT', 'NNS', 'IN', 'CD', '.'],\n","  ['JJ', 'IN', 'CD', '.'],\n","  ['PRP',\n","   'MD',\n","   'VB',\n","   'VBN',\n","   'IN',\n","   'NNP',\n","   'NNP',\n","   '-LRB-',\n","   'NNP',\n","   'NNP',\n","   'CC',\n","   'NNP',\n","   'NNP',\n","   '-RRB-',\n","   '.'],\n","  ['CD', ',', 'JJ', '.'],\n","  ['VB', 'PRP', 'VB', 'IN', 'PRP', 'VBP', 'DT', 'NNS', '.'],\n","  ['NNP',\n","   'NNP',\n","   'JJ',\n","   'NN',\n","   'NN',\n","   'NNS',\n","   'CC',\n","   'NNS',\n","   '-LRB-',\n","   'CD',\n","   '-RRB-',\n","   'CD',\n","   'NN'],\n","  ['DT', 'NN', 'IN', 'VBG', 'NN', 'CD', 'RB'],\n","  ['PRP',\n","   'VBP',\n","   'IN',\n","   'PRP',\n","   'VBZ',\n","   'DT',\n","   'CD',\n","   ',',\n","   'RB',\n","   'DT',\n","   'MD',\n","   'VB',\n","   'DT',\n","   'NN',\n","   '.'],\n","  ['WRB', 'VBP', 'PRP', 'VB', 'IN', 'VBG', 'RP', 'DT', 'NN', '.'],\n","  ...],\n"," <torch.utils.data.dataloader.DataLoader at 0x7f5d7a8ad3d0>,\n"," [0.7945300660402925],\n"," [0.8005920263509698],\n"," [0.779434223557162])"]},"metadata":{},"execution_count":60}]},{"cell_type":"code","source":["# domain = \"emails\"\n","# domain_dir = os.path.join(data_dir, \"pos_fine\", f\"{domain}\")\n","# domain_dev_file = os.path.join(domain_dir, f\"gweb-{domain}-dev.conll\")\n","# domain_test_file = os.path.join(domain_dir, f\"gweb-{domain}-test.conll\")"],"metadata":{"id":"fwvivWyzEHOi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# domain_dev_word_lst, domain_dev_tag_lst, domain_dev_tag_set = read_data(domain_dev_file)\n","# domain_test_word_lst, domain_test_tag_lst, domain_test_tag_set = read_data(domain_test_file)\n","# domain_dev_word_lst, domain_dev_tag_lst = filter_tag(domain_dev_word_lst, domain_dev_tag_lst)  \n","# domain_test_word_lst, domain_test_tag_lst = filter_tag(domain_test_word_lst, domain_test_tag_lst)"],"metadata":{"id":"UHAOs-fdEHMO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# domain_precision_value_lst = []\n","# domain_recall_value_lst = []\n","# domain_f1_value_lst = []"],"metadata":{"id":"3JGnpmRNHHmz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# domain_test_dataset = PosDataset(domain_test_word_lst, domain_test_tag_lst)\n","\n","# domain_test_iter = data.DataLoader(dataset=domain_test_dataset,\n","#                              batch_size=8,\n","#                              shuffle=False,\n","#                              num_workers=1,\n","#                              collate_fn=pad)\n","\n","# domain_precision_value, domain_recall_value, domain_f1_value = eval(model, domain_test_iter)\n","\n","# domain_precision_value_lst.append(domain_precision_value)\n","# domain_recall_value_lst.append(domain_recall_value)\n","# domain_f1_value_lst.append(domain_f1_value)"],"metadata":{"id":"cHb8ZM-VjG-7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class PosDataset_new(data.Dataset):\n","    def __init__(self, word_lst, tag_lst):\n","        self.word_lst, self.tag_lst = word_lst, tag_lst\n","\n","    def __len__(self):\n","      return len(self.word_lst)\n","\n","    def __getitem__(self, idx):\n","      words, tags = self.word_lst[idx], self.tag_lst[idx] # words, tags: string list\n","      assert len(words)==len(tags)\n","        # seqlen\n","      seqlen = len(words)\n","\n","      return words, tags, seqlen\n","\n","def pad_new(batch):\n","    '''Pads to the longest sample'''\n","    f = lambda x: [sample[x] for sample in batch]\n","    words = f(0)\n","    tags = f(1)\n","    seqlens = f(-1)\n","    maxlen = np.array(seqlens).max()\n","\n","    f = lambda x, seqlen: [sample[x] + [0] * (seqlen - len(sample[x])) for sample in batch] # 0: <pad>\n","    x = f(0, maxlen)\n","    y = f(1, maxlen)\n","\n","    f = torch.LongTensor\n","\n","    return f(x), f(y), seqlens\n","\n","def train_new(model, iterator, optimizer, criterion):\n","    model.train()\n","    for i, batch in enumerate(iterator):\n","        x, y, seqlens = batch\n","        \n","        optimizer.zero_grad()\n","        logits, y, _ = model(x, y) # logits: (N, T, VOCAB), y: (N, T)\n","\n","        logits = logits.view(-1, logits.shape[-1]) # (N*T, VOCAB)\n","        y = y.view(-1)  # (N*T,)\n","\n","        loss = criterion(logits, y)\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        if i%10==0: # monitoring\n","            print(\"step: {}, loss: {}\".format(i, loss.item()))"],"metadata":{"id":"S1HrHo0LEhWN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def gen_pseudo_data(model, domain_dev_iter, topn=300, initial=True):\n","  model.eval()\n","\n","  LLD = []\n","  MEAN_PROB = []\n","  new_x_lst = []\n","  new_y_lst = []\n","\n","  if initial:\n","    with torch.no_grad():\n","        for i, batch in enumerate(domain_dev_iter):\n","\n","          _, x, _, _, y, _ = batch\n","          sen_len = y.bool().sum(axis=1)\n","\n","          logits, _, y_hat = model(x, y)  # y_hat: (N, T)\n","\n","          # Save prediction as new training dataset\n","          softmax_value = torch.softmax(logits, dim=2)\n","          max_prob = torch.amax(softmax_value, dim=2)\n","          \n","          # Rank by LLD\n","          # lld = torch.prod(max_prob, 1)\n","          # LLD.extend(lld)\n","\n","          # Rank by mean probability\n","          res_prob = y.bool().to(device) * max_prob.to(device)\n","          sum_prob = res_prob.sum(axis=1)\n","          mean_prob = sum_prob / sen_len.to(device)\n","          MEAN_PROB.extend(mean_prob)\n","          \n","          new_x_lst.extend(x.tolist())\n","          new_y_lst.extend(y_hat.tolist())\n","  else:\n","    with torch.no_grad():\n","        for i, batch in enumerate(domain_dev_iter):\n","\n","          x, y, seqlens = batch\n","          sen_len = y.bool().sum(axis=1)\n","\n","          logits, _, y_hat = model(x, y)  # y_hat: (N, T)\n","\n","          # Save prediction as new training dataset\n","          softmax_value = torch.softmax(logits, dim=2)\n","          max_prob = torch.amax(softmax_value, dim=2)\n","\n","          # Rank by mean probability\n","          res_prob = y.bool().to(device) * max_prob.to(device)\n","          sum_prob = res_prob.sum(axis=1)\n","          mean_prob = sum_prob / sen_len.to(device)\n","          MEAN_PROB.extend(mean_prob)\n","          \n","          new_x_lst.extend(x.tolist())\n","          new_y_lst.extend(y_hat.tolist())\n","\n","  ind = list(range(len(MEAN_PROB)))\n","  ind = [x for _, x in sorted(zip(MEAN_PROB, ind), reverse=True)]\n","\n","  select_ind = ind[: topn]\n","  not_select_ind = ind[topn: ]\n","\n","  new_train_x = [new_x_lst[i] for i in select_ind]\n","  new_train_y = [new_y_lst[i] for i in select_ind]\n","\n","  remain_train_x = [new_x_lst[i] for i in not_select_ind]\n","  remain_train_y = [new_y_lst[i] for i in not_select_ind]\n","\n","  return new_train_x, new_train_y, remain_train_x, remain_train_y"],"metadata":{"id":"vzWOF5sCGjgC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def self_train(domain, topn_ratio, threshold_ratio):\n","  model, domain_dev_word_lst, domain_dev_tag_lst, domain_test_iter, domain_precision_value_lst, domain_recall_value_lst, domain_f1_value_lst = prepare_for_domain(\"emails\")\n","  i = 0\n","  last_top_sen = set()\n","  topn = int(topn_ratio * len(domain_dev_word_lst))\n","  top_words = domain_dev_word_lst[:topn]\n","  new_top_sen = set([tuple(sen) for sen in top_words])\n","  while len(new_top_sen.difference(last_top_sen)) > threshold_ratio * topn:\n","    i += 1\n","    print(\"\\nLoop\", i)\n","\n","    domain_dev_dataset = PosDataset(domain_dev_word_lst, domain_dev_tag_lst)\n","\n","    domain_dev_iter = data.DataLoader(dataset=domain_dev_dataset,\n","                                batch_size=8,\n","                                shuffle=False,\n","                                num_workers=1,\n","                                collate_fn=pad)\n","\n","    if i == 1:\n","      last_top_sen = set()\n","    else:\n","      last_top_sen = new_top_sen\n","\n","    top_words, top_tags, remain_words, remain_tags = gen_pseudo_data(model, domain_dev_iter, topn)\n","    new_top_sen = set([tuple(sen) for sen in top_words])\n","\n","    new_train_dataset = PosDataset_new(top_words, top_tags)\n","    new_train_iter = data.DataLoader(dataset=new_train_dataset,\n","                                batch_size=8,\n","                                shuffle=True,\n","                                num_workers=1,\n","                                collate_fn=pad_new)\n","\n","    optimizer = optim.Adam(model.parameters(), lr = 0.0001)\n","    criterion = nn.CrossEntropyLoss(ignore_index=0)\n","\n","    train_new(model, new_train_iter, optimizer, criterion)\n","\n","    domain_precision_value, domain_recall_value, domain_f1_value = eval(model, domain_test_iter)\n","    domain_precision_value_lst.append(domain_precision_value)\n","    domain_recall_value_lst.append(domain_recall_value)\n","    domain_f1_value_lst.append(domain_f1_value)\n","\n","    print(\"Difference\", len(new_top_sen.difference(last_top_sen)))\n","  return model, domain_precision_value_lst, domain_recall_value_lst, domain_f1_value_lst"],"metadata":{"id":"l7CNcMkasIGY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def save_model(model, model_name, model_dir):\n","  # new_model_suffix = f\"online_nonfixed_self_learned_{domain}_{topn}.pt\"\n","  # save the model only if we have not self train the model before\n","  if model_name not in os.listdir(model_dir):\n","    model_full_path = os.path.join(model_dir, model_name)\n","    torch.save(model.state_dict(), model_full_path)"],"metadata":{"id":"EKUV5wBD9BUS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def save_metric(metric, metric_name, metric_dir):\n","  # pass\n","  metric_full_path = os.path.join(metric_dir, metric_name)\n","  metric.to_csv(metric_full_path)"],"metadata":{"id":"SCjlwTcYEAwc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","import plotly\n","import plotly.express as px\n","import plotly.graph_objects as go"],"metadata":{"id":"YZPfqW6Q5bkN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["threshold_ratio = 0.2\n","topn_ratio = 0.1\n","for domain in file_name_lst:\n","  model, domain_precision_value_lst, domain_recall_value_lst, domain_f1_value_lst = self_train(domain, topn_ratio, threshold_ratio)\n","  # plot\n","  test_metric = pd.DataFrame({\n","    \"Loop\": list(range(len(domain_precision_value_lst))) * 3,\n","    \"metric\": [\"precision\"]*len(domain_precision_value_lst) + [\"recall\"]*len(domain_precision_value_lst) + [\"f1\"]*len(domain_precision_value_lst),\n","    \"value\": domain_precision_value_lst + domain_recall_value_lst + domain_f1_value_lst\n","    })\n","  # save the metrics\n","  save_metric(test_metric, f\"online_nonfixed_{domain}_{topn_ratio}_{threshold_ratio}.csv\", os.path.join(metrics_dir, \"online_nonfixed\"))\n","  fig = px.line(test_metric, x=\"Loop\", y=\"value\", color='metric', markers=True)\n","  fig.show()\n","  # save interactive version\n","  fig.write_html(f\"{plot_dir}/online_nonfixed/online_nonfixed_metric_{domain}_{topn_ratio}_{threshold_ratio}.html\")\n","  fig.write_image(f\"{plot_dir}/online_nonfixed/online_nonfixed_metric_{domain}_{topn_ratio}_{threshold_ratio}.png\")\n","  # save model\n","  save_model(model, f\"online_nonfixed_self_learned_{domain}_{topn_ratio}_{threshold_ratio}.pt\", os.path.join(model_dir, \"online_nonfixed\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"pSLV_IoewG8q","executionInfo":{"status":"ok","timestamp":1669688840686,"user_tz":300,"elapsed":725187,"user":{"displayName":"Zheng Wu","userId":"01190949623920087412"}},"outputId":"cd6745b4-27bb-45d8-ab0a-50bf7c65b2aa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["preparing domain dir and files...\n","reading data for domain dev and test...\n","The number of samples: 2450\n","The number of tags 49\n","The number of samples: 2450\n","The number of tags 48\n","after filter tag 2427\n","after filter tag 2402\n","preparing evaluation placeholder for prevision, recall and f1...\n","prepare base model for domain emails...\n","evaluating prevision, recall and f1 for base model...\n","acc=0.91\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.79      0.94      0.86        35\n","           2       0.87      0.52      0.65        77\n","           3       1.00      0.79      0.88      1030\n","           4       1.00      0.84      0.91       291\n","           5       0.91      0.84      0.87       294\n","           6       0.99      0.98      0.99      1570\n","           7       0.61      0.94      0.74       186\n","           8       0.00      0.00      0.00        11\n","           9       0.99      0.98      0.98       689\n","          10       0.93      0.98      0.96       901\n","          11       0.96      1.00      0.98      2111\n","          12       0.98      0.96      0.97        47\n","          13       0.60      0.46      0.52        13\n","          14       0.28      1.00      0.44        43\n","          15       0.93      0.98      0.95      2778\n","          16       0.90      0.80      0.85      1151\n","          17       0.91      0.95      0.93        41\n","          18       0.94      1.00      0.97        32\n","          19       0.68      0.57      0.62        40\n","          20       1.00      0.96      0.98       584\n","          21       0.00      0.00      0.00        52\n","          22       0.93      0.75      0.83      4175\n","          23       0.73      0.95      0.83      2253\n","          24       0.37      0.68      0.48        44\n","          25       0.87      0.92      0.89       888\n","          26       1.00      0.78      0.88         9\n","          27       0.71      0.99      0.82        69\n","          28       1.00      1.00      1.00      1864\n","          29       1.00      0.99      0.99       344\n","          30       0.81      0.86      0.83      1136\n","          31       0.55      0.63      0.59        19\n","          32       1.00      0.75      0.86         8\n","          33       0.75      0.97      0.84        86\n","          34       0.19      0.38      0.25        32\n","          35       0.97      1.00      0.98       474\n","          36       1.00      0.14      0.24       182\n","          37       0.89      0.96      0.92      1592\n","          38       0.98      0.96      0.97       404\n","          39       0.97      0.93      0.95       485\n","          40       0.90      0.98      0.94       573\n","          41       0.93      0.94      0.94       841\n","          42       0.98      0.99      0.99       575\n","          43       0.94      0.89      0.92       152\n","          44       0.87      0.92      0.90        75\n","          46       0.96      0.99      0.98        82\n","          48       0.00      0.00      0.00        79\n","\n","    accuracy                           0.91     28417\n","   macro avg       0.79      0.80      0.78     28417\n","weighted avg       0.91      0.91      0.90     28417\n","\n","\n","Loop 1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.5751357078552246\n","step: 10, loss: 0.0012157262535765767\n","step: 20, loss: 0.03217334300279617\n","step: 30, loss: 0.48562318086624146\n","acc=0.90\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.71      0.97      0.82        35\n","           2       0.90      0.45      0.60        77\n","           3       1.00      0.79      0.88      1030\n","           4       1.00      0.85      0.92       291\n","           5       0.96      0.82      0.88       294\n","           6       0.98      0.97      0.98      1570\n","           7       0.50      0.95      0.66       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.88      0.98      0.93       901\n","          11       0.98      1.00      0.99      2111\n","          12       0.96      0.96      0.96        47\n","          13       0.67      0.31      0.42        13\n","          14       0.32      0.98      0.48        43\n","          15       0.96      0.98      0.97      2778\n","          16       0.92      0.79      0.85      1151\n","          17       0.95      0.95      0.95        41\n","          18       0.94      0.97      0.95        32\n","          19       0.55      0.28      0.37        40\n","          20       1.00      0.97      0.98       584\n","          21       0.00      0.00      0.00        52\n","          22       0.95      0.71      0.81      4175\n","          23       0.70      0.98      0.81      2253\n","          24       0.35      0.59      0.44        44\n","          25       0.87      0.91      0.89       888\n","          26       0.88      0.78      0.82         9\n","          27       0.82      0.99      0.89        69\n","          28       0.99      1.00      1.00      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.91      0.86      0.89      1136\n","          31       0.52      0.63      0.57        19\n","          32       0.86      0.75      0.80         8\n","          33       0.72      0.98      0.83        86\n","          34       0.22      0.50      0.31        32\n","          35       0.98      0.99      0.98       474\n","          36       0.94      0.08      0.15       182\n","          37       0.89      0.96      0.92      1592\n","          38       0.97      0.97      0.97       404\n","          39       0.97      0.94      0.95       485\n","          40       0.89      0.97      0.93       573\n","          41       0.93      0.94      0.94       841\n","          42       0.98      0.98      0.98       575\n","          43       0.94      0.89      0.92       152\n","          44       0.87      0.92      0.90        75\n","          46       0.99      0.99      0.99        82\n","          48       0.15      0.49      0.23        79\n","\n","    accuracy                           0.90     28417\n","   macro avg       0.79      0.80      0.77     28417\n","weighted avg       0.92      0.90      0.90     28417\n","\n","Difference 238\n","\n","Loop 2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0015834557125344872\n","step: 10, loss: 8.665349741932005e-05\n","step: 20, loss: 0.0010089462157338858\n","step: 30, loss: 0.00032222390291281044\n","acc=0.89\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.77      0.86      0.81        35\n","           2       0.67      0.05      0.10        77\n","           3       1.00      0.79      0.88      1030\n","           4       1.00      0.84      0.91       291\n","           5       0.98      0.82      0.89       294\n","           6       0.99      0.97      0.98      1570\n","           7       0.54      0.95      0.69       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.93      0.97      0.95       901\n","          11       0.99      1.00      0.99      2111\n","          12       0.98      0.96      0.97        47\n","          13       1.00      0.15      0.27        13\n","          14       0.31      0.98      0.47        43\n","          15       0.94      0.98      0.96      2778\n","          16       0.90      0.79      0.84      1151\n","          17       0.93      0.95      0.94        41\n","          18       0.94      1.00      0.97        32\n","          19       0.86      0.15      0.26        40\n","          20       1.00      0.98      0.99       584\n","          21       0.00      0.00      0.00        52\n","          22       0.95      0.69      0.80      4175\n","          23       0.62      0.99      0.76      2253\n","          24       0.35      0.50      0.42        44\n","          25       0.86      0.89      0.88       888\n","          26       1.00      1.00      1.00         9\n","          27       0.36      1.00      0.53        69\n","          28       1.00      1.00      1.00      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.88      0.85      0.86      1136\n","          31       0.65      0.58      0.61        19\n","          32       1.00      0.75      0.86         8\n","          33       0.76      0.90      0.82        86\n","          34       0.08      0.16      0.11        32\n","          35       0.98      0.99      0.98       474\n","          36       1.00      0.04      0.07       182\n","          37       0.90      0.94      0.92      1592\n","          38       0.98      0.96      0.97       404\n","          39       0.98      0.93      0.95       485\n","          40       0.88      0.98      0.92       573\n","          41       0.94      0.93      0.94       841\n","          42       0.98      0.97      0.98       575\n","          43       0.94      0.89      0.91       152\n","          44       0.87      0.92      0.90        75\n","          46       1.00      0.99      0.99        82\n","          48       0.11      0.11      0.11        79\n","\n","    accuracy                           0.89     28417\n","   macro avg       0.80      0.76      0.74     28417\n","weighted avg       0.91      0.89      0.89     28417\n","\n","Difference 97\n","\n","Loop 3\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0007214852375909686\n","step: 10, loss: 0.005437876097857952\n","step: 20, loss: 0.00023386652173940092\n","step: 30, loss: 0.000317742902552709\n","acc=0.89\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.86      0.86      0.86        35\n","           2       0.67      0.05      0.10        77\n","           3       1.00      0.79      0.88      1030\n","           4       1.00      0.84      0.91       291\n","           5       0.94      0.84      0.89       294\n","           6       0.99      0.97      0.98      1570\n","           7       0.54      0.94      0.68       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.99      0.99       689\n","          10       0.83      0.98      0.90       901\n","          11       0.99      1.00      0.99      2111\n","          12       0.98      0.87      0.92        47\n","          13       1.00      0.15      0.27        13\n","          14       0.31      0.98      0.47        43\n","          15       0.95      0.98      0.97      2778\n","          16       0.92      0.77      0.84      1151\n","          17       0.97      0.95      0.96        41\n","          18       0.94      0.97      0.95        32\n","          19       1.00      0.12      0.22        40\n","          20       1.00      0.99      1.00       584\n","          21       0.00      0.00      0.00        52\n","          22       0.98      0.65      0.78      4175\n","          23       0.59      0.99      0.74      2253\n","          24       0.50      0.02      0.04        44\n","          25       0.84      0.89      0.87       888\n","          26       1.00      1.00      1.00         9\n","          27       0.48      1.00      0.65        69\n","          28       1.00      0.99      1.00      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.79      0.89      0.83      1136\n","          31       0.72      0.68      0.70        19\n","          32       1.00      0.75      0.86         8\n","          33       0.75      0.86      0.80        86\n","          34       0.17      0.34      0.23        32\n","          35       0.98      0.99      0.98       474\n","          36       1.00      0.04      0.08       182\n","          37       0.95      0.93      0.94      1592\n","          38       0.98      0.97      0.97       404\n","          39       0.96      0.93      0.95       485\n","          40       0.86      0.98      0.92       573\n","          41       0.95      0.93      0.94       841\n","          42       0.98      0.98      0.98       575\n","          43       0.93      0.91      0.92       152\n","          44       0.87      0.92      0.90        75\n","          46       1.00      0.98      0.99        82\n","          48       0.02      0.03      0.02        79\n","\n","    accuracy                           0.89     28417\n","   macro avg       0.81      0.75      0.74     28417\n","weighted avg       0.91      0.89      0.88     28417\n","\n","Difference 126\n","\n","Loop 4\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 8.162688027368858e-05\n","step: 10, loss: 3.18175480060745e-05\n","step: 20, loss: 0.07878604531288147\n","step: 30, loss: 3.901132458850043e-06\n","acc=0.88\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.86      0.86      0.86        35\n","           2       0.66      0.25      0.36        77\n","           3       1.00      0.79      0.89      1030\n","           4       1.00      0.66      0.80       291\n","           5       0.94      0.81      0.87       294\n","           6       0.99      0.98      0.99      1570\n","           7       0.42      0.97      0.59       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.92      0.97      0.95       901\n","          11       0.98      1.00      0.99      2111\n","          12       0.98      0.87      0.92        47\n","          13       0.00      0.00      0.00        13\n","          14       0.85      0.95      0.90        43\n","          15       0.96      0.97      0.96      2778\n","          16       0.92      0.75      0.83      1151\n","          17       0.97      0.95      0.96        41\n","          18       0.94      0.97      0.95        32\n","          19       1.00      0.10      0.18        40\n","          20       1.00      0.99      0.99       584\n","          21       0.00      0.00      0.00        52\n","          22       0.98      0.64      0.77      4175\n","          23       0.55      0.99      0.71      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.86      0.87      0.86       888\n","          26       1.00      1.00      1.00         9\n","          27       0.64      1.00      0.78        69\n","          28       1.00      0.99      0.99      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.73      0.91      0.81      1136\n","          31       0.72      0.68      0.70        19\n","          32       1.00      0.62      0.77         8\n","          33       0.82      0.67      0.74        86\n","          34       0.16      0.31      0.21        32\n","          35       0.98      0.98      0.98       474\n","          36       1.00      0.01      0.02       182\n","          37       0.92      0.94      0.93      1592\n","          38       0.99      0.91      0.95       404\n","          39       0.98      0.91      0.94       485\n","          40       0.81      0.98      0.89       573\n","          41       0.97      0.86      0.91       841\n","          42       0.99      0.97      0.98       575\n","          43       0.85      0.92      0.89       152\n","          44       0.87      0.92      0.90        75\n","          46       1.00      0.96      0.98        82\n","          48       0.00      0.00      0.00        79\n","\n","    accuracy                           0.88     28417\n","   macro avg       0.79      0.74      0.73     28417\n","weighted avg       0.91      0.88      0.88     28417\n","\n","Difference 83\n","\n","Loop 5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 4.227106273901882e-06\n","step: 10, loss: 1.7374159142491408e-06\n","step: 20, loss: 1.5545831502095098e-06\n","step: 30, loss: 3.8299120319607027e-07\n","acc=0.86\n","classification_report               precision    recall  f1-score   support\n","\n","           1       1.00      0.71      0.83        35\n","           2       0.68      0.22      0.33        77\n","           3       1.00      0.79      0.89      1030\n","           4       1.00      0.49      0.66       291\n","           5       0.97      0.63      0.76       294\n","           6       0.99      0.98      0.99      1570\n","           7       0.44      0.92      0.60       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.92      0.97      0.94       901\n","          11       0.98      0.99      0.99      2111\n","          12       0.97      0.83      0.90        47\n","          13       0.00      0.00      0.00        13\n","          14       0.75      0.95      0.84        43\n","          15       0.97      0.97      0.97      2778\n","          16       0.94      0.73      0.82      1151\n","          17       0.97      0.95      0.96        41\n","          18       0.93      0.81      0.87        32\n","          19       0.00      0.00      0.00        40\n","          20       1.00      0.99      0.99       584\n","          21       0.00      0.00      0.00        52\n","          22       0.97      0.59      0.73      4175\n","          23       0.46      1.00      0.63      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.87      0.86      0.86       888\n","          26       1.00      1.00      1.00         9\n","          27       0.73      1.00      0.84        69\n","          28       1.00      0.98      0.99      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.81      0.89      0.85      1136\n","          31       0.71      0.63      0.67        19\n","          32       1.00      0.62      0.77         8\n","          33       0.84      0.65      0.73        86\n","          34       0.20      0.31      0.24        32\n","          35       0.98      0.98      0.98       474\n","          36       0.00      0.00      0.00       182\n","          37       0.93      0.93      0.93      1592\n","          38       0.98      0.92      0.95       404\n","          39       0.98      0.90      0.94       485\n","          40       0.84      0.95      0.89       573\n","          41       0.97      0.84      0.90       841\n","          42       0.99      0.97      0.98       575\n","          43       0.85      0.93      0.89       152\n","          44       0.87      0.91      0.89        75\n","          46       1.00      0.96      0.98        82\n","          48       0.00      0.00      0.00        79\n","\n","    accuracy                           0.86     28417\n","   macro avg       0.75      0.71      0.72     28417\n","weighted avg       0.90      0.86      0.86     28417\n","\n","Difference 80\n","\n","Loop 6\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 8.616645459369465e-07\n","step: 10, loss: 0.013029592111706734\n","step: 20, loss: 0.0019655993673950434\n","step: 30, loss: 1.0006774573412258e-06\n","acc=0.88\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.81      0.86      0.83        35\n","           2       0.70      0.30      0.42        77\n","           3       0.99      0.79      0.88      1030\n","           4       1.00      0.84      0.91       291\n","           5       0.99      0.83      0.91       294\n","           6       0.99      0.98      0.99      1570\n","           7       0.44      0.97      0.60       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.89      0.98      0.93       901\n","          11       0.98      1.00      0.99      2111\n","          12       0.98      0.89      0.93        47\n","          13       0.00      0.00      0.00        13\n","          14       0.82      0.95      0.88        43\n","          15       0.97      0.97      0.97      2778\n","          16       0.92      0.76      0.83      1151\n","          17       1.00      0.95      0.97        41\n","          18       0.94      0.97      0.95        32\n","          19       1.00      0.10      0.18        40\n","          20       0.98      1.00      0.99       584\n","          21       0.00      0.00      0.00        52\n","          22       0.97      0.65      0.78      4175\n","          23       0.57      0.99      0.73      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.86      0.87      0.86       888\n","          26       1.00      0.78      0.88         9\n","          27       0.58      1.00      0.74        69\n","          28       1.00      0.99      1.00      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.83      0.90      0.87      1136\n","          31       0.74      0.74      0.74        19\n","          32       1.00      0.75      0.86         8\n","          33       0.87      0.77      0.81        86\n","          34       0.17      0.34      0.23        32\n","          35       0.97      0.99      0.98       474\n","          36       0.00      0.00      0.00       182\n","          37       0.88      0.95      0.91      1592\n","          38       0.97      0.94      0.95       404\n","          39       0.97      0.94      0.96       485\n","          40       0.82      0.97      0.89       573\n","          41       0.96      0.85      0.90       841\n","          42       0.97      0.98      0.97       575\n","          43       0.90      0.92      0.91       152\n","          44       0.87      0.92      0.90        75\n","          46       1.00      0.98      0.99        82\n","          48       0.13      0.08      0.10        79\n","\n","    accuracy                           0.88     28417\n","   macro avg       0.77      0.75      0.74     28417\n","weighted avg       0.90      0.88      0.88     28417\n","\n","Difference 38\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"54afadbc-e9f4-4876-a5fb-f652938f199c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"54afadbc-e9f4-4876-a5fb-f652938f199c\")) {                    Plotly.newPlot(                        \"54afadbc-e9f4-4876-a5fb-f652938f199c\",                        [{\"hovertemplate\":\"metric=precision<br>Loop=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"precision\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"markers+lines\",\"name\":\"precision\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6],\"xaxis\":\"x\",\"y\":[0.7945300660402925,0.7924782014643649,0.7995439548205665,0.8082175576683908,0.7869148018682478,0.7498729746845363,0.7706664293371144],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"metric=recall<br>Loop=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"recall\",\"line\":{\"color\":\"#EF553B\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"markers+lines\",\"name\":\"recall\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6],\"xaxis\":\"x\",\"y\":[0.8005920263509698,0.7987389285299002,0.7631800827913177,0.7539160449727377,0.736607419397628,0.7114722386565415,0.748262982703677],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"metric=f1<br>Loop=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"f1\",\"line\":{\"color\":\"#00cc96\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"markers+lines\",\"name\":\"f1\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6],\"xaxis\":\"x\",\"y\":[0.779434223557162,0.7718021476987659,0.742201996221519,0.7361311475123817,0.7321259536112813,0.7164136015295623,0.7416584548712343],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Loop\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"metric\"},\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('54afadbc-e9f4-4876-a5fb-f652938f199c');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                            </script>        </div>\n","</body>\n","</html>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["preparing domain dir and files...\n","reading data for domain dev and test...\n","The number of samples: 2450\n","The number of tags 49\n","The number of samples: 2450\n","The number of tags 48\n","after filter tag 2427\n","after filter tag 2402\n","preparing evaluation placeholder for prevision, recall and f1...\n","prepare base model for domain emails...\n","evaluating prevision, recall and f1 for base model...\n","acc=0.91\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.79      0.94      0.86        35\n","           2       0.87      0.52      0.65        77\n","           3       1.00      0.79      0.88      1030\n","           4       1.00      0.84      0.91       291\n","           5       0.91      0.84      0.87       294\n","           6       0.99      0.98      0.99      1570\n","           7       0.61      0.94      0.74       186\n","           8       0.00      0.00      0.00        11\n","           9       0.99      0.98      0.98       689\n","          10       0.93      0.98      0.96       901\n","          11       0.96      1.00      0.98      2111\n","          12       0.98      0.96      0.97        47\n","          13       0.60      0.46      0.52        13\n","          14       0.28      1.00      0.44        43\n","          15       0.93      0.98      0.95      2778\n","          16       0.90      0.80      0.85      1151\n","          17       0.91      0.95      0.93        41\n","          18       0.94      1.00      0.97        32\n","          19       0.68      0.57      0.62        40\n","          20       1.00      0.96      0.98       584\n","          21       0.00      0.00      0.00        52\n","          22       0.93      0.75      0.83      4175\n","          23       0.73      0.95      0.83      2253\n","          24       0.37      0.68      0.48        44\n","          25       0.87      0.92      0.89       888\n","          26       1.00      0.78      0.88         9\n","          27       0.71      0.99      0.82        69\n","          28       1.00      1.00      1.00      1864\n","          29       1.00      0.99      0.99       344\n","          30       0.81      0.86      0.83      1136\n","          31       0.55      0.63      0.59        19\n","          32       1.00      0.75      0.86         8\n","          33       0.75      0.97      0.84        86\n","          34       0.19      0.38      0.25        32\n","          35       0.97      1.00      0.98       474\n","          36       1.00      0.14      0.24       182\n","          37       0.89      0.96      0.92      1592\n","          38       0.98      0.96      0.97       404\n","          39       0.97      0.93      0.95       485\n","          40       0.90      0.98      0.94       573\n","          41       0.93      0.94      0.94       841\n","          42       0.98      0.99      0.99       575\n","          43       0.94      0.89      0.92       152\n","          44       0.87      0.92      0.90        75\n","          46       0.96      0.99      0.98        82\n","          48       0.00      0.00      0.00        79\n","\n","    accuracy                           0.91     28417\n","   macro avg       0.79      0.80      0.78     28417\n","weighted avg       0.91      0.91      0.90     28417\n","\n","\n","Loop 1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.3602069914340973\n","step: 10, loss: 0.0678258091211319\n","step: 20, loss: 0.02126944251358509\n","step: 30, loss: 0.0019958456978201866\n","acc=0.90\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.79      0.94      0.86        35\n","           2       0.85      0.29      0.43        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.98      0.85      0.91       291\n","           5       0.97      0.78      0.86       294\n","           6       0.99      0.97      0.98      1570\n","           7       0.52      0.94      0.67       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.82      0.98      0.90       901\n","          11       0.98      1.00      0.99      2111\n","          12       0.96      0.98      0.97        47\n","          13       0.00      0.00      0.00        13\n","          14       0.22      1.00      0.36        43\n","          15       0.97      0.98      0.97      2778\n","          16       0.92      0.79      0.85      1151\n","          17       0.91      0.98      0.94        41\n","          18       0.91      0.91      0.91        32\n","          19       0.86      0.15      0.26        40\n","          20       1.00      0.91      0.95       584\n","          21       0.00      0.00      0.00        52\n","          22       0.93      0.72      0.81      4175\n","          23       0.65      0.97      0.78      2253\n","          24       0.28      0.45      0.35        44\n","          25       0.87      0.90      0.88       888\n","          26       1.00      1.00      1.00         9\n","          27       0.72      1.00      0.84        69\n","          28       1.00      1.00      1.00      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.92      0.86      0.89      1136\n","          31       0.58      0.58      0.58        19\n","          32       1.00      0.62      0.77         8\n","          33       0.69      0.98      0.81        86\n","          34       0.19      0.41      0.26        32\n","          35       0.98      0.99      0.98       474\n","          36       1.00      0.05      0.09       182\n","          37       0.90      0.94      0.92      1592\n","          38       0.97      0.95      0.96       404\n","          39       0.97      0.93      0.95       485\n","          40       0.89      0.97      0.93       573\n","          41       0.89      0.94      0.92       841\n","          42       0.98      0.98      0.98       575\n","          43       0.93      0.91      0.92       152\n","          44       0.87      0.92      0.90        75\n","          46       1.00      0.98      0.99        82\n","          48       0.38      0.27      0.31        79\n","\n","    accuracy                           0.90     28417\n","   macro avg       0.79      0.77      0.75     28417\n","weighted avg       0.91      0.90      0.89     28417\n","\n","Difference 238\n","\n","Loop 2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0008091909694485366\n","step: 10, loss: 0.008597355335950851\n","step: 20, loss: 0.04618065059185028\n","step: 30, loss: 0.00030198419699445367\n","acc=0.88\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.81      0.86      0.83        35\n","           2       0.88      0.18      0.30        77\n","           3       1.00      0.79      0.89      1030\n","           4       1.00      0.47      0.64       291\n","           5       0.94      0.21      0.34       294\n","           6       0.99      0.98      0.98      1570\n","           7       0.60      0.94      0.73       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.93      0.97      0.95       901\n","          11       0.98      1.00      0.99      2111\n","          12       0.98      0.98      0.98        47\n","          13       0.00      0.00      0.00        13\n","          14       0.08      0.98      0.15        43\n","          15       0.96      0.98      0.97      2778\n","          16       0.90      0.81      0.85      1151\n","          17       0.91      0.98      0.94        41\n","          18       0.94      0.97      0.95        32\n","          19       1.00      0.07      0.14        40\n","          20       1.00      0.80      0.89       584\n","          21       0.00      0.00      0.00        52\n","          22       0.92      0.70      0.80      4175\n","          23       0.62      0.98      0.76      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.82      0.90      0.86       888\n","          26       1.00      1.00      1.00         9\n","          27       0.53      1.00      0.70        69\n","          28       1.00      0.99      1.00      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.94      0.86      0.89      1136\n","          31       0.61      0.58      0.59        19\n","          32       1.00      0.75      0.86         8\n","          33       0.72      0.94      0.82        86\n","          34       0.23      0.50      0.31        32\n","          35       0.98      0.99      0.98       474\n","          36       1.00      0.02      0.04       182\n","          37       0.91      0.90      0.91      1592\n","          38       0.97      0.96      0.96       404\n","          39       0.98      0.93      0.95       485\n","          40       0.89      0.95      0.92       573\n","          41       0.89      0.92      0.91       841\n","          42       0.85      0.97      0.91       575\n","          43       0.92      0.89      0.90       152\n","          44       0.87      0.92      0.90        75\n","          46       1.00      0.98      0.99        82\n","          48       0.42      0.46      0.44        79\n","\n","    accuracy                           0.88     28417\n","   macro avg       0.78      0.74      0.72     28417\n","weighted avg       0.91      0.88      0.88     28417\n","\n","Difference 64\n","\n","Loop 3\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0005015079514123499\n","step: 10, loss: 0.0004418235912453383\n","step: 20, loss: 0.00046597389155067503\n","step: 30, loss: 0.00021405152801889926\n","acc=0.87\n","classification_report               precision    recall  f1-score   support\n","\n","           1       1.00      0.77      0.87        35\n","           2       0.67      0.05      0.10        77\n","           3       1.00      0.79      0.89      1030\n","           4       1.00      0.46      0.63       291\n","           5       1.00      0.27      0.42       294\n","           6       0.99      0.98      0.99      1570\n","           7       0.64      0.94      0.76       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.94      0.97      0.95       901\n","          11       0.99      0.99      0.99      2111\n","          12       0.98      0.98      0.98        47\n","          13       0.00      0.00      0.00        13\n","          14       0.09      0.98      0.16        43\n","          15       0.96      0.98      0.97      2778\n","          16       0.94      0.74      0.83      1151\n","          17       0.91      0.98      0.94        41\n","          18       0.94      0.97      0.95        32\n","          19       1.00      0.03      0.05        40\n","          20       1.00      0.88      0.94       584\n","          21       0.00      0.00      0.00        52\n","          22       0.91      0.69      0.79      4175\n","          23       0.56      0.99      0.72      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.80      0.88      0.84       888\n","          26       1.00      1.00      1.00         9\n","          27       0.43      1.00      0.60        69\n","          28       1.00      0.99      1.00      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.94      0.85      0.89      1136\n","          31       0.69      0.58      0.63        19\n","          32       1.00      0.75      0.86         8\n","          33       0.81      0.86      0.84        86\n","          34       0.05      0.09      0.07        32\n","          35       0.98      0.98      0.98       474\n","          36       1.00      0.02      0.03       182\n","          37       0.94      0.90      0.92      1592\n","          38       0.96      0.95      0.95       404\n","          39       0.99      0.90      0.94       485\n","          40       0.91      0.89      0.90       573\n","          41       0.90      0.92      0.91       841\n","          42       0.97      0.90      0.93       575\n","          43       0.91      0.90      0.91       152\n","          44       0.87      0.92      0.90        75\n","          46       1.00      0.96      0.98        82\n","          48       0.20      0.51      0.29        79\n","\n","    accuracy                           0.87     28417\n","   macro avg       0.78      0.72      0.70     28417\n","weighted avg       0.91      0.87      0.87     28417\n","\n","Difference 97\n","\n","Loop 4\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.09355998784303665\n","step: 10, loss: 0.24163568019866943\n","step: 20, loss: 0.10680580884218216\n","step: 30, loss: 0.0013890875270590186\n","acc=0.86\n","classification_report               precision    recall  f1-score   support\n","\n","           1       1.00      0.63      0.77        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       1.00      0.41      0.58       291\n","           5       1.00      0.16      0.27       294\n","           6       0.99      0.98      0.99      1570\n","           7       0.50      0.34      0.40       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.94      0.96      0.95       901\n","          11       0.98      0.99      0.99      2111\n","          12       0.98      0.98      0.98        47\n","          13       0.00      0.00      0.00        13\n","          14       0.08      1.00      0.15        43\n","          15       0.96      0.97      0.97      2778\n","          16       0.95      0.71      0.82      1151\n","          17       0.91      0.98      0.94        41\n","          18       0.94      0.91      0.92        32\n","          19       0.00      0.00      0.00        40\n","          20       1.00      0.88      0.94       584\n","          21       0.00      0.00      0.00        52\n","          22       0.92      0.69      0.79      4175\n","          23       0.55      0.99      0.71      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.77      0.88      0.82       888\n","          26       1.00      1.00      1.00         9\n","          27       0.78      1.00      0.88        69\n","          28       1.00      0.99      0.99      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.94      0.83      0.88      1136\n","          31       0.67      0.53      0.59        19\n","          32       1.00      0.75      0.86         8\n","          33       0.79      0.88      0.84        86\n","          34       0.05      0.09      0.07        32\n","          35       0.98      0.98      0.98       474\n","          36       0.00      0.00      0.00       182\n","          37       0.96      0.89      0.92      1592\n","          38       0.95      0.95      0.95       404\n","          39       0.99      0.89      0.93       485\n","          40       0.90      0.88      0.89       573\n","          41       0.89      0.92      0.91       841\n","          42       0.99      0.89      0.94       575\n","          43       0.90      0.91      0.91       152\n","          44       0.87      0.92      0.90        75\n","          46       1.00      0.96      0.98        82\n","          48       0.17      0.96      0.29        79\n","\n","    accuracy                           0.86     28417\n","   macro avg       0.72      0.71      0.69     28417\n","weighted avg       0.90      0.86      0.86     28417\n","\n","Difference 107\n","\n","Loop 5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.001876474590972066\n","step: 10, loss: 0.014075862243771553\n","step: 20, loss: 0.02277323789894581\n","step: 30, loss: 0.00032612303039059043\n","acc=0.85\n","classification_report               precision    recall  f1-score   support\n","\n","           1       1.00      0.83      0.91        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.88      1030\n","           4       1.00      0.32      0.49       291\n","           5       1.00      0.22      0.37       294\n","           6       0.97      0.98      0.97      1570\n","           7       0.61      0.94      0.74       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.92      0.97      0.95       901\n","          11       0.98      0.99      0.99      2111\n","          12       0.98      0.98      0.98        47\n","          13       0.00      0.00      0.00        13\n","          14       0.08      1.00      0.15        43\n","          15       0.95      0.98      0.96      2778\n","          16       0.95      0.62      0.75      1151\n","          17       0.91      0.98      0.94        41\n","          18       0.93      0.88      0.90        32\n","          19       0.00      0.00      0.00        40\n","          20       1.00      0.90      0.95       584\n","          21       0.00      0.00      0.00        52\n","          22       0.96      0.62      0.76      4175\n","          23       0.48      0.99      0.65      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.81      0.87      0.84       888\n","          26       1.00      1.00      1.00         9\n","          27       0.70      1.00      0.82        69\n","          28       1.00      0.99      0.99      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.95      0.82      0.88      1136\n","          31       0.69      0.58      0.63        19\n","          32       1.00      0.75      0.86         8\n","          33       0.81      0.86      0.84        86\n","          34       0.05      0.09      0.07        32\n","          35       0.98      0.97      0.98       474\n","          36       1.00      0.02      0.04       182\n","          37       0.94      0.90      0.92      1592\n","          38       0.95      0.96      0.95       404\n","          39       0.98      0.91      0.94       485\n","          40       0.89      0.89      0.89       573\n","          41       0.90      0.92      0.91       841\n","          42       0.99      0.92      0.95       575\n","          43       0.92      0.89      0.90       152\n","          44       0.87      0.92      0.90        75\n","          46       1.00      0.96      0.98        82\n","          48       0.05      0.08      0.06        79\n","\n","    accuracy                           0.85     28417\n","   macro avg       0.74      0.70      0.69     28417\n","weighted avg       0.90      0.85      0.86     28417\n","\n","Difference 71\n","\n","Loop 6\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 9.069738007383421e-05\n","step: 10, loss: 0.00018286457634530962\n","step: 20, loss: 0.00021267561533022672\n","step: 30, loss: 5.9215766668785363e-05\n","acc=0.86\n","classification_report               precision    recall  f1-score   support\n","\n","           1       1.00      0.71      0.83        35\n","           2       1.00      0.01      0.03        77\n","           3       1.00      0.79      0.88      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.99      0.99      0.99      1570\n","           7       0.91      0.93      0.92       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.89      0.98      0.93       901\n","          11       0.98      1.00      0.99      2111\n","          12       0.98      0.94      0.96        47\n","          13       0.00      0.00      0.00        13\n","          14       0.05      1.00      0.10        43\n","          15       0.94      0.98      0.96      2778\n","          16       0.93      0.72      0.81      1151\n","          17       0.91      0.98      0.94        41\n","          18       0.94      0.97      0.95        32\n","          19       0.00      0.00      0.00        40\n","          20       1.00      0.93      0.97       584\n","          21       0.00      0.00      0.00        52\n","          22       0.92      0.68      0.78      4175\n","          23       0.57      0.98      0.72      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.78      0.92      0.84       888\n","          26       0.90      1.00      0.95         9\n","          27       0.64      1.00      0.78        69\n","          28       1.00      0.99      0.99      1864\n","          29       0.98      0.99      0.99       344\n","          30       0.94      0.79      0.86      1136\n","          31       0.58      0.58      0.58        19\n","          32       1.00      0.75      0.86         8\n","          33       0.86      0.86      0.86        86\n","          34       0.05      0.09      0.07        32\n","          35       0.98      0.98      0.98       474\n","          36       0.00      0.00      0.00       182\n","          37       0.94      0.89      0.91      1592\n","          38       0.94      0.93      0.94       404\n","          39       0.97      0.91      0.94       485\n","          40       0.87      0.89      0.88       573\n","          41       0.92      0.91      0.92       841\n","          42       0.98      0.87      0.92       575\n","          43       0.91      0.89      0.90       152\n","          44       0.87      0.92      0.90        75\n","          46       1.00      0.96      0.98        82\n","          48       0.11      0.34      0.17        79\n","\n","    accuracy                           0.86     28417\n","   macro avg       0.70      0.70      0.67     28417\n","weighted avg       0.88      0.86      0.86     28417\n","\n","Difference 66\n","\n","Loop 7\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 7.816570723662153e-05\n","step: 10, loss: 5.720879016735125e-06\n","step: 20, loss: 1.997297840716783e-05\n","step: 30, loss: 1.539405457151588e-05\n","acc=0.86\n","classification_report               precision    recall  f1-score   support\n","\n","           1       1.00      0.60      0.75        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.88      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      0.99      0.98      1570\n","           7       0.81      0.94      0.87       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.90      0.97      0.94       901\n","          11       0.98      1.00      0.99      2111\n","          12       0.98      0.94      0.96        47\n","          13       0.00      0.00      0.00        13\n","          14       0.06      1.00      0.11        43\n","          15       0.94      0.98      0.96      2778\n","          16       0.93      0.71      0.81      1151\n","          17       0.91      0.98      0.94        41\n","          18       0.94      0.97      0.95        32\n","          19       0.00      0.00      0.00        40\n","          20       1.00      0.89      0.94       584\n","          21       0.00      0.00      0.00        52\n","          22       0.94      0.68      0.79      4175\n","          23       0.55      0.98      0.71      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.78      0.93      0.85       888\n","          26       0.82      1.00      0.90         9\n","          27       0.72      1.00      0.84        69\n","          28       1.00      0.99      0.99      1864\n","          29       0.98      0.99      0.99       344\n","          30       0.94      0.80      0.87      1136\n","          31       0.69      0.58      0.63        19\n","          32       1.00      0.75      0.86         8\n","          33       0.85      0.86      0.86        86\n","          34       0.05      0.09      0.07        32\n","          35       0.98      0.98      0.98       474\n","          36       0.00      0.00      0.00       182\n","          37       0.92      0.92      0.92      1592\n","          38       0.96      0.94      0.95       404\n","          39       0.92      0.96      0.94       485\n","          40       0.88      0.90      0.89       573\n","          41       0.91      0.90      0.91       841\n","          42       0.99      0.87      0.93       575\n","          43       0.93      0.89      0.91       152\n","          44       0.87      0.92      0.90        75\n","          46       1.00      0.96      0.98        82\n","          48       0.07      0.15      0.10        79\n","\n","    accuracy                           0.86     28417\n","   macro avg       0.68      0.69      0.67     28417\n","weighted avg       0.88      0.86      0.86     28417\n","\n","Difference 39\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"4e6bf425-df4d-4d48-b391-3afd20afc517\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4e6bf425-df4d-4d48-b391-3afd20afc517\")) {                    Plotly.newPlot(                        \"4e6bf425-df4d-4d48-b391-3afd20afc517\",                        [{\"hovertemplate\":\"metric=precision<br>Loop=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"precision\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"markers+lines\",\"name\":\"precision\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7],\"xaxis\":\"x\",\"y\":[0.7945300660402925,0.7876671136001746,0.7818006526301862,0.7795200303164952,0.7239460122329717,0.7437316065486216,0.700864379531687,0.6780235672761125],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"metric=recall<br>Loop=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"recall\",\"line\":{\"color\":\"#EF553B\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"markers+lines\",\"name\":\"recall\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7],\"xaxis\":\"x\",\"y\":[0.8005920263509698,0.7719821525703626,0.7397033139653909,0.7204307629500459,0.7054579827805617,0.7013291627867003,0.696328459923132,0.6908589014823535],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"metric=f1<br>Loop=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"f1\",\"line\":{\"color\":\"#00cc96\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"markers+lines\",\"name\":\"f1\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7],\"xaxis\":\"x\",\"y\":[0.779434223557162,0.7496955297691588,0.7154651542015292,0.7011535891621522,0.6857751576548681,0.6884567461634498,0.673124372054221,0.6697306580940221],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Loop\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"metric\"},\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('4e6bf425-df4d-4d48-b391-3afd20afc517');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                            </script>        </div>\n","</body>\n","</html>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["preparing domain dir and files...\n","reading data for domain dev and test...\n","The number of samples: 2450\n","The number of tags 49\n","The number of samples: 2450\n","The number of tags 48\n","after filter tag 2427\n","after filter tag 2402\n","preparing evaluation placeholder for prevision, recall and f1...\n","prepare base model for domain emails...\n","evaluating prevision, recall and f1 for base model...\n","acc=0.91\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.79      0.94      0.86        35\n","           2       0.87      0.52      0.65        77\n","           3       1.00      0.79      0.88      1030\n","           4       1.00      0.84      0.91       291\n","           5       0.91      0.84      0.87       294\n","           6       0.99      0.98      0.99      1570\n","           7       0.61      0.94      0.74       186\n","           8       0.00      0.00      0.00        11\n","           9       0.99      0.98      0.98       689\n","          10       0.93      0.98      0.96       901\n","          11       0.96      1.00      0.98      2111\n","          12       0.98      0.96      0.97        47\n","          13       0.60      0.46      0.52        13\n","          14       0.28      1.00      0.44        43\n","          15       0.93      0.98      0.95      2778\n","          16       0.90      0.80      0.85      1151\n","          17       0.91      0.95      0.93        41\n","          18       0.94      1.00      0.97        32\n","          19       0.68      0.57      0.62        40\n","          20       1.00      0.96      0.98       584\n","          21       0.00      0.00      0.00        52\n","          22       0.93      0.75      0.83      4175\n","          23       0.73      0.95      0.83      2253\n","          24       0.37      0.68      0.48        44\n","          25       0.87      0.92      0.89       888\n","          26       1.00      0.78      0.88         9\n","          27       0.71      0.99      0.82        69\n","          28       1.00      1.00      1.00      1864\n","          29       1.00      0.99      0.99       344\n","          30       0.81      0.86      0.83      1136\n","          31       0.55      0.63      0.59        19\n","          32       1.00      0.75      0.86         8\n","          33       0.75      0.97      0.84        86\n","          34       0.19      0.38      0.25        32\n","          35       0.97      1.00      0.98       474\n","          36       1.00      0.14      0.24       182\n","          37       0.89      0.96      0.92      1592\n","          38       0.98      0.96      0.97       404\n","          39       0.97      0.93      0.95       485\n","          40       0.90      0.98      0.94       573\n","          41       0.93      0.94      0.94       841\n","          42       0.98      0.99      0.99       575\n","          43       0.94      0.89      0.92       152\n","          44       0.87      0.92      0.90        75\n","          46       0.96      0.99      0.98        82\n","          48       0.00      0.00      0.00        79\n","\n","    accuracy                           0.91     28417\n","   macro avg       0.79      0.80      0.78     28417\n","weighted avg       0.91      0.91      0.90     28417\n","\n","\n","Loop 1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.4181363880634308\n","step: 10, loss: 0.027540048584342003\n","step: 20, loss: 0.0045406147837638855\n","step: 30, loss: 0.0005323390359990299\n","acc=0.90\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.82      0.89      0.85        35\n","           2       0.86      0.48      0.62        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.97      0.85      0.90       291\n","           5       0.95      0.84      0.89       294\n","           6       0.99      0.98      0.98      1570\n","           7       0.57      0.94      0.71       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.83      0.98      0.90       901\n","          11       0.98      1.00      0.99      2111\n","          12       0.98      0.98      0.98        47\n","          13       0.55      0.46      0.50        13\n","          14       0.28      0.98      0.43        43\n","          15       0.97      0.98      0.97      2778\n","          16       0.91      0.79      0.85      1151\n","          17       0.91      0.98      0.94        41\n","          18       0.93      0.81      0.87        32\n","          19       0.85      0.28      0.42        40\n","          20       1.00      0.95      0.97       584\n","          21       0.00      0.00      0.00        52\n","          22       0.93      0.72      0.81      4175\n","          23       0.66      0.97      0.79      2253\n","          24       0.33      0.39      0.35        44\n","          25       0.87      0.90      0.89       888\n","          26       0.90      1.00      0.95         9\n","          27       0.70      1.00      0.82        69\n","          28       1.00      0.99      1.00      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.93      0.86      0.89      1136\n","          31       0.61      0.58      0.59        19\n","          32       1.00      0.75      0.86         8\n","          33       0.70      0.98      0.82        86\n","          34       0.24      0.50      0.32        32\n","          35       0.98      0.99      0.99       474\n","          36       0.93      0.07      0.13       182\n","          37       0.89      0.95      0.92      1592\n","          38       0.97      0.96      0.97       404\n","          39       0.98      0.94      0.96       485\n","          40       0.90      0.97      0.93       573\n","          41       0.93      0.94      0.93       841\n","          42       0.98      0.98      0.98       575\n","          43       0.93      0.91      0.92       152\n","          44       0.87      0.92      0.90        75\n","          46       1.00      0.99      0.99        82\n","          48       0.35      0.42      0.38        79\n","\n","    accuracy                           0.90     28417\n","   macro avg       0.80      0.80      0.78     28417\n","weighted avg       0.91      0.90      0.90     28417\n","\n","Difference 238\n","\n","Loop 2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.03205116465687752\n","step: 10, loss: 0.026732493191957474\n","step: 20, loss: 0.05142906308174133\n","step: 30, loss: 0.004440591670572758\n","acc=0.90\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.78      0.89      0.83        35\n","           2       0.91      0.42      0.57        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.97      0.84      0.90       291\n","           5       0.78      0.82      0.80       294\n","           6       0.99      0.97      0.98      1570\n","           7       0.51      0.92      0.65       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.89      0.98      0.94       901\n","          11       0.98      1.00      0.99      2111\n","          12       0.98      0.96      0.97        47\n","          13       0.50      0.08      0.13        13\n","          14       0.69      0.98      0.81        43\n","          15       0.96      0.98      0.97      2778\n","          16       0.91      0.79      0.85      1151\n","          17       0.91      0.98      0.94        41\n","          18       0.94      1.00      0.97        32\n","          19       0.40      0.20      0.27        40\n","          20       1.00      0.95      0.97       584\n","          21       0.00      0.00      0.00        52\n","          22       0.93      0.72      0.81      4175\n","          23       0.66      0.97      0.79      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.85      0.92      0.89       888\n","          26       1.00      1.00      1.00         9\n","          27       0.70      0.99      0.82        69\n","          28       1.00      1.00      1.00      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.93      0.86      0.89      1136\n","          31       0.67      0.53      0.59        19\n","          32       1.00      0.75      0.86         8\n","          33       0.77      0.95      0.85        86\n","          34       0.24      0.66      0.35        32\n","          35       0.99      0.99      0.99       474\n","          36       0.95      0.10      0.18       182\n","          37       0.90      0.91      0.91      1592\n","          38       0.98      0.95      0.97       404\n","          39       0.98      0.92      0.95       485\n","          40       0.88      0.98      0.93       573\n","          41       0.88      0.95      0.91       841\n","          42       0.98      0.98      0.98       575\n","          43       0.93      0.91      0.92       152\n","          44       0.87      0.92      0.90        75\n","          46       0.99      0.98      0.98        82\n","          48       0.20      0.66      0.31        79\n","\n","    accuracy                           0.90     28417\n","   macro avg       0.79      0.78      0.76     28417\n","weighted avg       0.91      0.90      0.90     28417\n","\n","Difference 44\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"e1be7ecd-1b63-4313-8743-8f38489a6fa4\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e1be7ecd-1b63-4313-8743-8f38489a6fa4\")) {                    Plotly.newPlot(                        \"e1be7ecd-1b63-4313-8743-8f38489a6fa4\",                        [{\"hovertemplate\":\"metric=precision<br>Loop=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"precision\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"markers+lines\",\"name\":\"precision\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2],\"xaxis\":\"x\",\"y\":[0.7945300660402925,0.8022078236234284,0.7907399908882837],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"metric=recall<br>Loop=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"recall\",\"line\":{\"color\":\"#EF553B\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"markers+lines\",\"name\":\"recall\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2],\"xaxis\":\"x\",\"y\":[0.8005920263509698,0.7957487463509204,0.784253337985919],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"metric=f1<br>Loop=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"f1\",\"line\":{\"color\":\"#00cc96\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"markers+lines\",\"name\":\"f1\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2],\"xaxis\":\"x\",\"y\":[0.779434223557162,0.7768514708115201,0.7641240178511717],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Loop\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"metric\"},\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('e1be7ecd-1b63-4313-8743-8f38489a6fa4');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                            </script>        </div>\n","</body>\n","</html>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["preparing domain dir and files...\n","reading data for domain dev and test...\n","The number of samples: 2450\n","The number of tags 49\n","The number of samples: 2450\n","The number of tags 48\n","after filter tag 2427\n","after filter tag 2402\n","preparing evaluation placeholder for prevision, recall and f1...\n","prepare base model for domain emails...\n","evaluating prevision, recall and f1 for base model...\n","acc=0.91\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.79      0.94      0.86        35\n","           2       0.87      0.52      0.65        77\n","           3       1.00      0.79      0.88      1030\n","           4       1.00      0.84      0.91       291\n","           5       0.91      0.84      0.87       294\n","           6       0.99      0.98      0.99      1570\n","           7       0.61      0.94      0.74       186\n","           8       0.00      0.00      0.00        11\n","           9       0.99      0.98      0.98       689\n","          10       0.93      0.98      0.96       901\n","          11       0.96      1.00      0.98      2111\n","          12       0.98      0.96      0.97        47\n","          13       0.60      0.46      0.52        13\n","          14       0.28      1.00      0.44        43\n","          15       0.93      0.98      0.95      2778\n","          16       0.90      0.80      0.85      1151\n","          17       0.91      0.95      0.93        41\n","          18       0.94      1.00      0.97        32\n","          19       0.68      0.57      0.62        40\n","          20       1.00      0.96      0.98       584\n","          21       0.00      0.00      0.00        52\n","          22       0.93      0.75      0.83      4175\n","          23       0.73      0.95      0.83      2253\n","          24       0.37      0.68      0.48        44\n","          25       0.87      0.92      0.89       888\n","          26       1.00      0.78      0.88         9\n","          27       0.71      0.99      0.82        69\n","          28       1.00      1.00      1.00      1864\n","          29       1.00      0.99      0.99       344\n","          30       0.81      0.86      0.83      1136\n","          31       0.55      0.63      0.59        19\n","          32       1.00      0.75      0.86         8\n","          33       0.75      0.97      0.84        86\n","          34       0.19      0.38      0.25        32\n","          35       0.97      1.00      0.98       474\n","          36       1.00      0.14      0.24       182\n","          37       0.89      0.96      0.92      1592\n","          38       0.98      0.96      0.97       404\n","          39       0.97      0.93      0.95       485\n","          40       0.90      0.98      0.94       573\n","          41       0.93      0.94      0.94       841\n","          42       0.98      0.99      0.99       575\n","          43       0.94      0.89      0.92       152\n","          44       0.87      0.92      0.90        75\n","          46       0.96      0.99      0.98        82\n","          48       0.00      0.00      0.00        79\n","\n","    accuracy                           0.91     28417\n","   macro avg       0.79      0.80      0.78     28417\n","weighted avg       0.91      0.91      0.90     28417\n","\n","\n","Loop 1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.5218360424041748\n","step: 10, loss: 0.0011203880421817303\n","step: 20, loss: 0.008928264491260052\n","step: 30, loss: 0.0007937285117805004\n","acc=0.90\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.77      0.97      0.86        35\n","           2       0.86      0.64      0.73        77\n","           3       1.00      0.79      0.88      1030\n","           4       0.98      0.85      0.91       291\n","           5       0.95      0.84      0.89       294\n","           6       0.98      0.98      0.98      1570\n","           7       0.54      0.94      0.69       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.91      0.98      0.94       901\n","          11       0.98      1.00      0.99      2111\n","          12       0.98      0.98      0.98        47\n","          13       0.29      0.31      0.30        13\n","          14       0.31      0.98      0.47        43\n","          15       0.96      0.98      0.97      2778\n","          16       0.91      0.79      0.85      1151\n","          17       0.93      0.95      0.94        41\n","          18       0.94      0.97      0.95        32\n","          19       0.75      0.38      0.50        40\n","          20       1.00      0.95      0.98       584\n","          21       0.00      0.00      0.00        52\n","          22       0.94      0.74      0.83      4175\n","          23       0.70      0.97      0.81      2253\n","          24       0.34      0.61      0.44        44\n","          25       0.87      0.91      0.89       888\n","          26       1.00      1.00      1.00         9\n","          27       0.65      1.00      0.79        69\n","          28       1.00      1.00      1.00      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.92      0.86      0.89      1136\n","          31       0.50      0.58      0.54        19\n","          32       0.86      0.75      0.80         8\n","          33       0.73      0.98      0.84        86\n","          34       0.26      0.62      0.36        32\n","          35       0.98      0.99      0.99       474\n","          36       1.00      0.08      0.14       182\n","          37       0.89      0.95      0.92      1592\n","          38       0.97      0.98      0.97       404\n","          39       0.97      0.94      0.95       485\n","          40       0.90      0.97      0.93       573\n","          41       0.91      0.94      0.93       841\n","          42       0.98      0.98      0.98       575\n","          43       0.94      0.89      0.92       152\n","          44       0.87      0.92      0.90        75\n","          46       0.96      0.99      0.98        82\n","          48       0.23      0.44      0.30        79\n","\n","    accuracy                           0.90     28417\n","   macro avg       0.79      0.81      0.78     28417\n","weighted avg       0.92      0.90      0.90     28417\n","\n","Difference 238\n","\n","Loop 2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.04334018751978874\n","step: 10, loss: 0.0009265763219445944\n","step: 20, loss: 0.00576825812458992\n","step: 30, loss: 0.0022637408692389727\n","acc=0.90\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.80      0.94      0.87        35\n","           2       0.94      0.38      0.54        77\n","           3       1.00      0.79      0.88      1030\n","           4       0.97      0.84      0.90       291\n","           5       0.95      0.73      0.82       294\n","           6       0.97      1.00      0.98      1570\n","           7       0.76      0.94      0.84       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.91      0.98      0.94       901\n","          11       0.98      1.00      0.99      2111\n","          12       0.98      0.91      0.95        47\n","          13       0.75      0.23      0.35        13\n","          14       0.31      1.00      0.48        43\n","          15       0.94      0.98      0.96      2778\n","          16       0.93      0.78      0.85      1151\n","          17       0.95      0.95      0.95        41\n","          18       0.94      1.00      0.97        32\n","          19       0.74      0.35      0.47        40\n","          20       1.00      1.00      1.00       584\n","          21       0.00      0.00      0.00        52\n","          22       0.93      0.74      0.82      4175\n","          23       0.68      0.98      0.80      2253\n","          24       0.17      0.02      0.04        44\n","          25       0.86      0.91      0.89       888\n","          26       1.00      1.00      1.00         9\n","          27       0.72      0.99      0.83        69\n","          28       1.00      1.00      1.00      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.87      0.87      0.87      1136\n","          31       0.67      0.63      0.65        19\n","          32       1.00      0.75      0.86         8\n","          33       0.76      0.90      0.82        86\n","          34       0.22      0.75      0.34        32\n","          35       0.98      0.99      0.99       474\n","          36       1.00      0.07      0.12       182\n","          37       0.91      0.95      0.93      1592\n","          38       0.97      0.97      0.97       404\n","          39       0.97      0.92      0.95       485\n","          40       0.89      0.97      0.93       573\n","          41       0.96      0.93      0.95       841\n","          42       0.98      0.99      0.98       575\n","          43       0.95      0.87      0.91       152\n","          44       0.87      0.92      0.90        75\n","          46       0.99      0.99      0.99        82\n","          48       0.13      0.25      0.17        79\n","\n","    accuracy                           0.90     28417\n","   macro avg       0.81      0.78      0.77     28417\n","weighted avg       0.92      0.90      0.90     28417\n","\n","Difference 51\n","\n","Loop 3\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0008582202717661858\n","step: 10, loss: 0.0003330935724079609\n","step: 20, loss: 0.00034241421963088214\n","step: 30, loss: 0.00012318584776949137\n","acc=0.89\n","classification_report               precision    recall  f1-score   support\n","\n","           1       1.00      0.89      0.94        35\n","           2       0.87      0.44      0.59        77\n","           3       1.00      0.79      0.88      1030\n","           4       0.92      0.85      0.88       291\n","           5       0.94      0.70      0.80       294\n","           6       0.98      0.99      0.98      1570\n","           7       0.58      0.94      0.72       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.91      0.98      0.94       901\n","          11       0.98      1.00      0.99      2111\n","          12       0.97      0.83      0.90        47\n","          13       0.50      0.08      0.13        13\n","          14       0.36      1.00      0.53        43\n","          15       0.92      0.98      0.95      2778\n","          16       0.93      0.78      0.85      1151\n","          17       0.95      0.95      0.95        41\n","          18       0.94      0.91      0.92        32\n","          19       0.50      0.12      0.20        40\n","          20       1.00      1.00      1.00       584\n","          21       0.00      0.00      0.00        52\n","          22       0.95      0.70      0.81      4175\n","          23       0.66      0.98      0.79      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.87      0.90      0.89       888\n","          26       1.00      0.78      0.88         9\n","          27       0.71      1.00      0.83        69\n","          28       1.00      0.99      0.99      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.68      0.89      0.77      1136\n","          31       0.71      0.63      0.67        19\n","          32       0.71      0.62      0.67         8\n","          33       0.86      0.86      0.86        86\n","          34       0.24      0.66      0.35        32\n","          35       0.98      0.99      0.98       474\n","          36       1.00      0.02      0.04       182\n","          37       0.95      0.95      0.95      1592\n","          38       0.96      0.95      0.96       404\n","          39       0.97      0.94      0.95       485\n","          40       0.89      0.97      0.93       573\n","          41       0.95      0.93      0.94       841\n","          42       0.99      0.99      0.99       575\n","          43       0.94      0.88      0.91       152\n","          44       0.87      0.92      0.90        75\n","          46       0.99      0.98      0.98        82\n","          48       0.50      0.01      0.02        79\n","\n","    accuracy                           0.89     28417\n","   macro avg       0.80      0.75      0.74     28417\n","weighted avg       0.91      0.89      0.89     28417\n","\n","Difference 33\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"41597780-fcdd-478c-9a49-bcf9a1fbc68c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"41597780-fcdd-478c-9a49-bcf9a1fbc68c\")) {                    Plotly.newPlot(                        \"41597780-fcdd-478c-9a49-bcf9a1fbc68c\",                        [{\"hovertemplate\":\"metric=precision<br>Loop=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"precision\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"markers+lines\",\"name\":\"precision\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3],\"xaxis\":\"x\",\"y\":[0.7945300660402925,0.7913415145781945,0.8103141500887557,0.7960954567186834],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"metric=recall<br>Loop=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"recall\",\"line\":{\"color\":\"#EF553B\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"markers+lines\",\"name\":\"recall\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3],\"xaxis\":\"x\",\"y\":[0.8005920263509698,0.8117535504397775,0.7849285857504311,0.7549545503055906],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"metric=f1<br>Loop=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"f1\",\"line\":{\"color\":\"#00cc96\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"markers+lines\",\"name\":\"f1\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3],\"xaxis\":\"x\",\"y\":[0.779434223557162,0.7799952562232442,0.7698372069363606,0.7432335021844365],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Loop\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"metric\"},\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('41597780-fcdd-478c-9a49-bcf9a1fbc68c');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                            </script>        </div>\n","</body>\n","</html>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["preparing domain dir and files...\n","reading data for domain dev and test...\n","The number of samples: 2450\n","The number of tags 49\n","The number of samples: 2450\n","The number of tags 48\n","after filter tag 2427\n","after filter tag 2402\n","preparing evaluation placeholder for prevision, recall and f1...\n","prepare base model for domain emails...\n","evaluating prevision, recall and f1 for base model...\n","acc=0.91\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.79      0.94      0.86        35\n","           2       0.87      0.52      0.65        77\n","           3       1.00      0.79      0.88      1030\n","           4       1.00      0.84      0.91       291\n","           5       0.91      0.84      0.87       294\n","           6       0.99      0.98      0.99      1570\n","           7       0.61      0.94      0.74       186\n","           8       0.00      0.00      0.00        11\n","           9       0.99      0.98      0.98       689\n","          10       0.93      0.98      0.96       901\n","          11       0.96      1.00      0.98      2111\n","          12       0.98      0.96      0.97        47\n","          13       0.60      0.46      0.52        13\n","          14       0.28      1.00      0.44        43\n","          15       0.93      0.98      0.95      2778\n","          16       0.90      0.80      0.85      1151\n","          17       0.91      0.95      0.93        41\n","          18       0.94      1.00      0.97        32\n","          19       0.68      0.57      0.62        40\n","          20       1.00      0.96      0.98       584\n","          21       0.00      0.00      0.00        52\n","          22       0.93      0.75      0.83      4175\n","          23       0.73      0.95      0.83      2253\n","          24       0.37      0.68      0.48        44\n","          25       0.87      0.92      0.89       888\n","          26       1.00      0.78      0.88         9\n","          27       0.71      0.99      0.82        69\n","          28       1.00      1.00      1.00      1864\n","          29       1.00      0.99      0.99       344\n","          30       0.81      0.86      0.83      1136\n","          31       0.55      0.63      0.59        19\n","          32       1.00      0.75      0.86         8\n","          33       0.75      0.97      0.84        86\n","          34       0.19      0.38      0.25        32\n","          35       0.97      1.00      0.98       474\n","          36       1.00      0.14      0.24       182\n","          37       0.89      0.96      0.92      1592\n","          38       0.98      0.96      0.97       404\n","          39       0.97      0.93      0.95       485\n","          40       0.90      0.98      0.94       573\n","          41       0.93      0.94      0.94       841\n","          42       0.98      0.99      0.99       575\n","          43       0.94      0.89      0.92       152\n","          44       0.87      0.92      0.90        75\n","          46       0.96      0.99      0.98        82\n","          48       0.00      0.00      0.00        79\n","\n","    accuracy                           0.91     28417\n","   macro avg       0.79      0.80      0.78     28417\n","weighted avg       0.91      0.91      0.90     28417\n","\n","\n","Loop 1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.37422797083854675\n","step: 10, loss: 0.08911372721195221\n","step: 20, loss: 0.0009938867297023535\n","step: 30, loss: 0.005641952622681856\n","acc=0.90\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.78      0.91      0.84        35\n","           2       0.86      0.42      0.56        77\n","           3       1.00      0.79      0.88      1030\n","           4       1.00      0.85      0.92       291\n","           5       0.96      0.83      0.89       294\n","           6       0.99      0.98      0.98      1570\n","           7       0.57      0.94      0.71       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.88      0.98      0.93       901\n","          11       0.99      1.00      0.99      2111\n","          12       0.98      0.96      0.97        47\n","          13       0.57      0.31      0.40        13\n","          14       0.28      1.00      0.44        43\n","          15       0.96      0.98      0.97      2778\n","          16       0.91      0.79      0.85      1151\n","          17       0.91      0.95      0.93        41\n","          18       0.94      1.00      0.97        32\n","          19       0.83      0.12      0.22        40\n","          20       1.00      0.96      0.98       584\n","          21       0.00      0.00      0.00        52\n","          22       0.93      0.72      0.81      4175\n","          23       0.65      0.98      0.78      2253\n","          24       0.23      0.11      0.15        44\n","          25       0.86      0.91      0.88       888\n","          26       1.00      1.00      1.00         9\n","          27       0.63      0.99      0.77        69\n","          28       1.00      1.00      1.00      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.91      0.86      0.89      1136\n","          31       0.52      0.58      0.55        19\n","          32       1.00      0.75      0.86         8\n","          33       0.72      0.98      0.83        86\n","          34       0.25      0.53      0.34        32\n","          35       0.98      0.99      0.98       474\n","          36       1.00      0.06      0.11       182\n","          37       0.89      0.94      0.92      1592\n","          38       0.96      0.97      0.97       404\n","          39       0.98      0.94      0.96       485\n","          40       0.90      0.95      0.93       573\n","          41       0.92      0.94      0.93       841\n","          42       0.99      0.97      0.98       575\n","          43       0.94      0.90      0.92       152\n","          44       0.87      0.92      0.90        75\n","          46       1.00      0.96      0.98        82\n","          48       0.25      0.41      0.31        79\n","\n","    accuracy                           0.90     28417\n","   macro avg       0.80      0.78      0.76     28417\n","weighted avg       0.91      0.90      0.90     28417\n","\n","Difference 238\n","\n","Loop 2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.005025522317737341\n","step: 10, loss: 0.0003447239869274199\n","step: 20, loss: 0.06364671885967255\n","step: 30, loss: 0.23154635727405548\n","acc=0.88\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.81      0.86      0.83        35\n","           2       0.90      0.56      0.69        77\n","           3       1.00      0.79      0.88      1030\n","           4       1.00      0.84      0.91       291\n","           5       0.96      0.82      0.88       294\n","           6       0.99      0.98      0.99      1570\n","           7       0.55      0.95      0.70       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.91      0.98      0.94       901\n","          11       0.99      1.00      0.99      2111\n","          12       0.98      0.87      0.92        47\n","          13       0.00      0.00      0.00        13\n","          14       0.38      0.98      0.55        43\n","          15       0.96      0.98      0.97      2778\n","          16       0.98      0.46      0.62      1151\n","          17       0.93      0.95      0.94        41\n","          18       0.88      0.94      0.91        32\n","          19       0.75      0.15      0.25        40\n","          20       1.00      0.97      0.98       584\n","          21       0.00      0.00      0.00        52\n","          22       0.96      0.69      0.80      4175\n","          23       0.64      0.98      0.78      2253\n","          24       1.00      0.05      0.09        44\n","          25       0.87      0.89      0.88       888\n","          26       1.00      0.78      0.88         9\n","          27       0.58      1.00      0.73        69\n","          28       1.00      0.99      0.99      1864\n","          29       1.00      0.99      0.99       344\n","          30       0.85      0.87      0.86      1136\n","          31       0.65      0.58      0.61        19\n","          32       0.86      0.75      0.80         8\n","          33       0.78      0.93      0.85        86\n","          34       0.24      0.75      0.36        32\n","          35       0.99      0.98      0.98       474\n","          36       1.00      0.07      0.12       182\n","          37       0.91      0.96      0.93      1592\n","          38       0.94      0.98      0.96       404\n","          39       0.97      0.93      0.95       485\n","          40       0.89      0.94      0.91       573\n","          41       0.94      0.93      0.94       841\n","          42       0.98      0.98      0.98       575\n","          43       0.94      0.91      0.92       152\n","          44       0.87      0.92      0.90        75\n","          46       1.00      0.98      0.99        82\n","          48       0.05      0.52      0.10        79\n","\n","    accuracy                           0.88     28417\n","   macro avg       0.80      0.77      0.74     28417\n","weighted avg       0.92      0.88      0.89     28417\n","\n","Difference 79\n","\n","Loop 3\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.001972367288544774\n","step: 10, loss: 0.00037169590359553695\n","step: 20, loss: 0.001246006926521659\n","step: 30, loss: 0.00012372180935926735\n","acc=0.87\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.80      0.91      0.85        35\n","           2       0.50      0.01      0.03        77\n","           3       1.00      0.79      0.89      1030\n","           4       1.00      0.83      0.91       291\n","           5       1.00      0.80      0.89       294\n","           6       0.99      0.97      0.98      1570\n","           7       0.34      0.97      0.50       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.90      0.98      0.94       901\n","          11       0.99      0.99      0.99      2111\n","          12       0.98      0.98      0.98        47\n","          13       0.00      0.00      0.00        13\n","          14       0.59      0.95      0.73        43\n","          15       0.95      0.98      0.97      2778\n","          16       0.96      0.46      0.62      1151\n","          17       0.89      0.98      0.93        41\n","          18       0.89      0.97      0.93        32\n","          19       0.50      0.10      0.17        40\n","          20       1.00      0.99      0.99       584\n","          21       0.00      0.00      0.00        52\n","          22       0.96      0.67      0.79      4175\n","          23       0.62      0.99      0.76      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.86      0.86      0.86       888\n","          26       1.00      0.78      0.88         9\n","          27       0.55      1.00      0.71        69\n","          28       1.00      0.99      1.00      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.92      0.83      0.87      1136\n","          31       0.65      0.58      0.61        19\n","          32       1.00      0.75      0.86         8\n","          33       0.79      0.92      0.85        86\n","          34       0.25      0.59      0.35        32\n","          35       0.99      0.97      0.98       474\n","          36       1.00      0.03      0.05       182\n","          37       0.91      0.94      0.93      1592\n","          38       0.94      0.98      0.96       404\n","          39       0.97      0.86      0.91       485\n","          40       0.90      0.94      0.92       573\n","          41       0.95      0.94      0.95       841\n","          42       0.99      0.98      0.98       575\n","          43       0.94      0.89      0.92       152\n","          44       0.87      0.92      0.90        75\n","          46       1.00      0.99      0.99        82\n","          48       0.04      0.37      0.06        79\n","\n","    accuracy                           0.87     28417\n","   macro avg       0.77      0.75      0.72     28417\n","weighted avg       0.92      0.87      0.88     28417\n","\n","Difference 102\n","\n","Loop 4\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0005105959135107696\n","step: 10, loss: 4.067292684339918e-05\n","step: 20, loss: 0.0006337219965644181\n","step: 30, loss: 0.05988315865397453\n","acc=0.88\n","classification_report               precision    recall  f1-score   support\n","\n","           1       1.00      0.89      0.94        35\n","           2       0.33      0.01      0.03        77\n","           3       1.00      0.79      0.89      1030\n","           4       1.00      0.83      0.91       291\n","           5       1.00      0.82      0.90       294\n","           6       0.97      0.98      0.98      1570\n","           7       0.56      0.94      0.71       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.89      0.98      0.93       901\n","          11       0.98      1.00      0.99      2111\n","          12       0.98      0.98      0.98        47\n","          13       0.00      0.00      0.00        13\n","          14       0.28      1.00      0.44        43\n","          15       0.96      0.98      0.97      2778\n","          16       0.95      0.57      0.71      1151\n","          17       0.93      0.98      0.95        41\n","          18       0.94      0.94      0.94        32\n","          19       0.00      0.00      0.00        40\n","          20       0.97      1.00      0.99       584\n","          21       0.00      0.00      0.00        52\n","          22       0.96      0.69      0.80      4175\n","          23       0.65      0.98      0.78      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.79      0.95      0.86       888\n","          26       1.00      1.00      1.00         9\n","          27       0.44      1.00      0.61        69\n","          28       1.00      0.99      1.00      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.87      0.84      0.85      1136\n","          31       0.69      0.58      0.63        19\n","          32       0.86      0.75      0.80         8\n","          33       0.81      0.90      0.85        86\n","          34       0.21      0.62      0.31        32\n","          35       0.98      0.99      0.98       474\n","          36       0.00      0.00      0.00       182\n","          37       0.95      0.94      0.95      1592\n","          38       0.94      0.98      0.96       404\n","          39       0.98      0.91      0.94       485\n","          40       0.89      0.95      0.91       573\n","          41       0.96      0.93      0.95       841\n","          42       0.98      0.96      0.97       575\n","          43       0.92      0.91      0.91       152\n","          44       0.87      0.92      0.90        75\n","          46       0.99      0.99      0.99        82\n","          48       0.05      0.38      0.08        79\n","\n","    accuracy                           0.88     28417\n","   macro avg       0.73      0.76      0.72     28417\n","weighted avg       0.91      0.88      0.88     28417\n","\n","Difference 67\n","\n","Loop 5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 7.470721902791411e-05\n","step: 10, loss: 2.8444850613595918e-05\n","step: 20, loss: 0.0004122018290217966\n","step: 30, loss: 5.7672616094350815e-05\n","acc=0.88\n","classification_report               precision    recall  f1-score   support\n","\n","           1       1.00      0.86      0.92        35\n","           2       1.00      0.03      0.05        77\n","           3       1.00      0.79      0.88      1030\n","           4       1.00      0.64      0.78       291\n","           5       1.00      0.21      0.35       294\n","           6       1.00      0.97      0.98      1570\n","           7       0.46      0.97      0.63       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.92      0.98      0.95       901\n","          11       0.98      1.00      0.99      2111\n","          12       0.98      0.89      0.93        47\n","          13       0.00      0.00      0.00        13\n","          14       0.51      0.95      0.66        43\n","          15       0.97      0.98      0.97      2778\n","          16       0.95      0.54      0.69      1151\n","          17       0.91      0.98      0.94        41\n","          18       0.94      0.97      0.95        32\n","          19       0.00      0.00      0.00        40\n","          20       0.91      1.00      0.95       584\n","          21       0.00      0.00      0.00        52\n","          22       0.93      0.73      0.82      4175\n","          23       0.66      0.98      0.79      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.83      0.94      0.88       888\n","          26       1.00      0.78      0.88         9\n","          27       0.81      0.99      0.89        69\n","          28       1.00      0.99      1.00      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.81      0.89      0.85      1136\n","          31       0.69      0.58      0.63        19\n","          32       1.00      0.75      0.86         8\n","          33       0.84      0.86      0.85        86\n","          34       0.23      0.62      0.34        32\n","          35       0.99      0.98      0.98       474\n","          36       0.00      0.00      0.00       182\n","          37       0.94      0.94      0.94      1592\n","          38       0.95      0.97      0.96       404\n","          39       0.98      0.90      0.94       485\n","          40       0.90      0.94      0.92       573\n","          41       0.97      0.84      0.90       841\n","          42       0.99      0.96      0.98       575\n","          43       0.94      0.89      0.91       152\n","          44       0.87      0.92      0.90        75\n","          46       0.99      0.96      0.98        82\n","          48       0.09      0.90      0.16        79\n","\n","    accuracy                           0.88     28417\n","   macro avg       0.76      0.74      0.72     28417\n","weighted avg       0.91      0.88      0.88     28417\n","\n","Difference 91\n","\n","Loop 6\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 5.988438715576194e-05\n","step: 10, loss: 6.788776772737037e-06\n","step: 20, loss: 1.2790463188139256e-05\n","step: 30, loss: 0.043998077511787415\n","acc=0.87\n","classification_report               precision    recall  f1-score   support\n","\n","           1       1.00      0.86      0.92        35\n","           2       1.00      0.10      0.19        77\n","           3       0.99      0.79      0.88      1030\n","           4       1.00      0.61      0.76       291\n","           5       1.00      0.39      0.56       294\n","           6       0.99      0.98      0.98      1570\n","           7       0.47      0.97      0.63       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.94      0.97      0.95       901\n","          11       0.98      1.00      0.99      2111\n","          12       0.98      0.96      0.97        47\n","          13       0.00      0.00      0.00        13\n","          14       0.55      0.95      0.69        43\n","          15       0.95      0.98      0.96      2778\n","          16       0.95      0.61      0.74      1151\n","          17       0.91      0.95      0.93        41\n","          18       0.94      0.97      0.95        32\n","          19       0.00      0.00      0.00        40\n","          20       0.93      1.00      0.97       584\n","          21       0.00      0.00      0.00        52\n","          22       0.93      0.70      0.80      4175\n","          23       0.62      0.99      0.76      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.86      0.88      0.87       888\n","          26       1.00      0.78      0.88         9\n","          27       0.74      0.99      0.84        69\n","          28       1.00      0.99      1.00      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.92      0.83      0.88      1136\n","          31       0.65      0.58      0.61        19\n","          32       1.00      0.75      0.86         8\n","          33       0.88      0.87      0.88        86\n","          34       0.21      0.69      0.32        32\n","          35       0.99      0.97      0.98       474\n","          36       0.00      0.00      0.00       182\n","          37       0.94      0.93      0.94      1592\n","          38       0.95      0.96      0.96       404\n","          39       0.98      0.88      0.93       485\n","          40       0.89      0.91      0.90       573\n","          41       0.97      0.86      0.91       841\n","          42       0.99      0.96      0.98       575\n","          43       0.94      0.86      0.90       152\n","          44       0.87      0.92      0.90        75\n","          46       0.99      0.96      0.98        82\n","          48       0.07      0.86      0.14        79\n","\n","    accuracy                           0.87     28417\n","   macro avg       0.76      0.74      0.72     28417\n","weighted avg       0.91      0.87      0.88     28417\n","\n","Difference 67\n","\n","Loop 7\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.002213776344433427\n","step: 10, loss: 0.0051923817954957485\n","step: 20, loss: 1.7635540643823333e-05\n","step: 30, loss: 1.7157102774945088e-05\n","acc=0.74\n","classification_report               precision    recall  f1-score   support\n","\n","           1       1.00      0.43      0.60        35\n","           2       1.00      0.08      0.14        77\n","           3       1.00      0.79      0.89      1030\n","           4       1.00      0.51      0.67       291\n","           5       1.00      0.05      0.09       294\n","           6       0.99      0.98      0.99      1570\n","           7       0.72      0.94      0.81       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.94      0.98      0.96       901\n","          11       0.98      0.99      0.99      2111\n","          12       0.98      0.94      0.96        47\n","          13       0.00      0.00      0.00        13\n","          14       0.48      0.95      0.64        43\n","          15       0.97      0.95      0.96      2778\n","          16       1.00      0.01      0.02      1151\n","          17       0.95      0.88      0.91        41\n","          18       0.94      0.94      0.94        32\n","          19       0.00      0.00      0.00        40\n","          20       0.91      1.00      0.95       584\n","          21       0.00      0.00      0.00        52\n","          22       1.00      0.34      0.50      4175\n","          23       0.74      0.89      0.81      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.87      0.81      0.84       888\n","          26       1.00      0.67      0.80         9\n","          27       0.93      0.99      0.96        69\n","          28       1.00      0.99      0.99      1864\n","          29       1.00      0.99      0.99       344\n","          30       0.93      0.82      0.87      1136\n","          31       0.78      0.37      0.50        19\n","          32       1.00      0.75      0.86         8\n","          33       0.89      0.78      0.83        86\n","          34       0.24      0.69      0.36        32\n","          35       0.98      0.98      0.98       474\n","          36       0.00      0.00      0.00       182\n","          37       0.98      0.77      0.86      1592\n","          38       0.95      0.92      0.93       404\n","          39       1.00      0.04      0.08       485\n","          40       0.97      0.44      0.60       573\n","          41       0.98      0.77      0.86       841\n","          42       0.99      0.88      0.93       575\n","          43       0.98      0.86      0.92       152\n","          44       0.89      0.84      0.86        75\n","          46       1.00      0.93      0.96        82\n","          48       0.01      0.99      0.03        79\n","\n","    accuracy                           0.74     28417\n","   macro avg       0.78      0.65      0.65     28417\n","weighted avg       0.94      0.74      0.78     28417\n","\n","Difference 85\n","\n","Loop 8\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 1.699314270808827e-05\n","step: 10, loss: 0.023608649149537086\n","step: 20, loss: 0.057979900389909744\n","step: 30, loss: 1.5268067727447487e-05\n","acc=0.70\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.88      1030\n","           4       1.00      0.21      0.35       291\n","           5       0.00      0.00      0.00       294\n","           6       0.99      0.95      0.97      1570\n","           7       0.68      0.48      0.57       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.94      0.97       689\n","          10       0.94      0.97      0.95       901\n","          11       0.99      0.99      0.99      2111\n","          12       0.98      0.87      0.92        47\n","          13       0.00      0.00      0.00        13\n","          14       0.00      0.00      0.00        43\n","          15       0.97      0.93      0.95      2778\n","          16       0.00      0.00      0.00      1151\n","          17       0.96      0.66      0.78        41\n","          18       0.93      0.78      0.85        32\n","          19       0.00      0.00      0.00        40\n","          20       0.93      0.99      0.96       584\n","          21       0.00      0.00      0.00        52\n","          22       1.00      0.24      0.39      4175\n","          23       0.75      0.86      0.80      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.87      0.87      0.87       888\n","          26       1.00      0.44      0.62         9\n","          27       1.00      0.97      0.99        69\n","          28       1.00      0.98      0.99      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.94      0.81      0.87      1136\n","          31       0.00      0.00      0.00        19\n","          32       1.00      0.12      0.22         8\n","          33       0.89      0.81      0.85        86\n","          34       0.10      0.53      0.17        32\n","          35       0.99      0.98      0.99       474\n","          36       0.00      0.00      0.00       182\n","          37       0.97      0.84      0.90      1592\n","          38       0.96      0.85      0.90       404\n","          39       1.00      0.00      0.00       485\n","          40       0.97      0.44      0.61       573\n","          41       0.99      0.75      0.85       841\n","          42       1.00      0.68      0.81       575\n","          43       0.97      0.84      0.90       152\n","          44       1.00      0.08      0.15        75\n","          46       1.00      0.67      0.80        82\n","          48       0.01      1.00      0.02        79\n","\n","    accuracy                           0.70     28417\n","   macro avg       0.67      0.53      0.54     28417\n","weighted avg       0.89      0.70      0.74     28417\n","\n","Difference 42\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"85a6461a-0d91-44c6-92b9-e9a95fc4a159\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"85a6461a-0d91-44c6-92b9-e9a95fc4a159\")) {                    Plotly.newPlot(                        \"85a6461a-0d91-44c6-92b9-e9a95fc4a159\",                        [{\"hovertemplate\":\"metric=precision<br>Loop=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"precision\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"markers+lines\",\"name\":\"precision\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8],\"xaxis\":\"x\",\"y\":[0.7945300660402925,0.7998818330151092,0.8012743608537035,0.7687605281470813,0.728769078917913,0.7586441819206889,0.7599536286005018,0.7818712894075538,0.6686477105955914],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"metric=recall<br>Loop=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"recall\",\"line\":{\"color\":\"#EF553B\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"markers+lines\",\"name\":\"recall\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8],\"xaxis\":\"x\",\"y\":[0.8005920263509698,0.784411461588853,0.7690392273542316,0.7479625868811712,0.7563326127909258,0.7401586299271193,0.7429475633359404,0.6493525744807234,0.5290434261582826],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"metric=f1<br>Loop=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"f1\",\"line\":{\"color\":\"#00cc96\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"markers+lines\",\"name\":\"f1\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8],\"xaxis\":\"x\",\"y\":[0.779434223557162,0.7639704754777361,0.7448315505009656,0.7249131706496705,0.7229488899445726,0.7162521378893879,0.7227127536264014,0.6487461191419287,0.5396198407884716],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Loop\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"metric\"},\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('85a6461a-0d91-44c6-92b9-e9a95fc4a159');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                            </script>        </div>\n","</body>\n","</html>"]},"metadata":{}}]},{"cell_type":"code","source":["topn = 1000\n","threshold_ratio = 0.1\n","for domain in file_name_lst:\n","  model, domain_precision_value_lst, domain_recall_value_lst, domain_f1_value_lst = self_train(domain, topn, threshold_ratio)\n","  # plot\n","  test_metric = pd.DataFrame({\n","    \"Loop\": list(range(len(domain_precision_value_lst))) * 3,\n","    \"metric\": [\"precision\"]*len(domain_precision_value_lst) + [\"recall\"]*len(domain_precision_value_lst) + [\"f1\"]*len(domain_precision_value_lst),\n","    \"value\": domain_precision_value_lst + domain_recall_value_lst + domain_f1_value_lst\n","    })\n","  fig = px.line(test_metric, x=\"Loop\", y=\"value\", color='metric', markers=True)\n","  fig.show()\n","  # save interactive version\n","  fig.write_html(f\"{plot_dir}/online_nonfixed/online_nonfixed_metric_{domain}_{topn}_{threshold_ratio}.html\")\n","  fig.write_image(f\"{plot_dir}/online_nonfixed/online_nonfixed_metric_{domain}_{topn}_{threshold_ratio}.png\")\n","  # save model\n","  save_model(model, f\"online_nonfixed_self_learned_{domain}_{topn}.pt\", os.path.join(model_dir, \"online_nonfixed\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"8305IQIt_DAg","executionInfo":{"status":"error","timestamp":1669686777101,"user_tz":300,"elapsed":2865120,"user":{"displayName":"Zheng Wu","userId":"01190949623920087412"}},"outputId":"15cc4959-b6d0-4e52-c4d7-7affe3e4fbd2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["preparing domain dir and files...\n","reading data for domain dev and test...\n","The number of samples: 2450\n","The number of tags 49\n","The number of samples: 2450\n","The number of tags 48\n","after filter tag 2427\n","after filter tag 2402\n","preparing evaluation placeholder for prevision, recall and f1...\n","prepare base model for domain emails...\n","evaluating prevision, recall and f1 for base model...\n","acc=0.91\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.79      0.94      0.86        35\n","           2       0.87      0.52      0.65        77\n","           3       1.00      0.79      0.88      1030\n","           4       1.00      0.84      0.91       291\n","           5       0.91      0.84      0.87       294\n","           6       0.99      0.98      0.99      1570\n","           7       0.61      0.94      0.74       186\n","           8       0.00      0.00      0.00        11\n","           9       0.99      0.98      0.98       689\n","          10       0.93      0.98      0.96       901\n","          11       0.96      1.00      0.98      2111\n","          12       0.98      0.96      0.97        47\n","          13       0.60      0.46      0.52        13\n","          14       0.28      1.00      0.44        43\n","          15       0.93      0.98      0.95      2778\n","          16       0.90      0.80      0.85      1151\n","          17       0.91      0.95      0.93        41\n","          18       0.94      1.00      0.97        32\n","          19       0.68      0.57      0.62        40\n","          20       1.00      0.96      0.98       584\n","          21       0.00      0.00      0.00        52\n","          22       0.93      0.75      0.83      4175\n","          23       0.73      0.95      0.83      2253\n","          24       0.37      0.68      0.48        44\n","          25       0.87      0.92      0.89       888\n","          26       1.00      0.78      0.88         9\n","          27       0.71      0.99      0.82        69\n","          28       1.00      1.00      1.00      1864\n","          29       1.00      0.99      0.99       344\n","          30       0.81      0.86      0.83      1136\n","          31       0.55      0.63      0.59        19\n","          32       1.00      0.75      0.86         8\n","          33       0.75      0.97      0.84        86\n","          34       0.19      0.38      0.25        32\n","          35       0.97      1.00      0.98       474\n","          36       1.00      0.14      0.24       182\n","          37       0.89      0.96      0.92      1592\n","          38       0.98      0.96      0.97       404\n","          39       0.97      0.93      0.95       485\n","          40       0.90      0.98      0.94       573\n","          41       0.93      0.94      0.94       841\n","          42       0.98      0.99      0.99       575\n","          43       0.94      0.89      0.92       152\n","          44       0.87      0.92      0.90        75\n","          46       0.96      0.99      0.98        82\n","          48       0.00      0.00      0.00        79\n","\n","    accuracy                           0.91     28417\n","   macro avg       0.79      0.80      0.78     28417\n","weighted avg       0.91      0.91      0.90     28417\n","\n","\n","Loop 1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.3302593231201172\n","step: 10, loss: 0.041297201067209244\n","step: 20, loss: 0.03154778480529785\n","step: 30, loss: 0.017508449032902718\n","step: 40, loss: 0.012712319381535053\n","step: 50, loss: 0.0021119515877217054\n","step: 60, loss: 0.0074520595371723175\n","step: 70, loss: 0.05965064465999603\n","step: 80, loss: 0.09388625621795654\n","step: 90, loss: 0.007818343117833138\n","step: 100, loss: 0.04228316992521286\n","step: 110, loss: 0.022680068388581276\n","step: 120, loss: 0.025902127847075462\n","acc=0.90\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.68      0.97      0.80        35\n","           2       0.82      0.12      0.20        77\n","           3       1.00      0.79      0.88      1030\n","           4       0.98      0.85      0.91       291\n","           5       0.94      0.84      0.88       294\n","           6       0.99      0.98      0.98      1570\n","           7       0.57      0.91      0.70       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.97      0.99       689\n","          10       0.95      0.98      0.96       901\n","          11       0.98      1.00      0.99      2111\n","          12       0.96      0.98      0.97        47\n","          13       0.33      0.15      0.21        13\n","          14       0.23      1.00      0.38        43\n","          15       0.96      0.98      0.97      2778\n","          16       0.91      0.80      0.85      1151\n","          17       0.91      0.95      0.93        41\n","          18       0.94      0.94      0.94        32\n","          19       1.00      0.55      0.71        40\n","          20       0.98      0.93      0.96       584\n","          21       0.00      0.00      0.00        52\n","          22       0.94      0.75      0.83      4175\n","          23       0.69      0.97      0.80      2253\n","          24       0.32      0.59      0.42        44\n","          25       0.87      0.89      0.88       888\n","          26       1.00      1.00      1.00         9\n","          27       0.80      0.99      0.88        69\n","          28       1.00      0.99      1.00      1864\n","          29       1.00      0.99      0.99       344\n","          30       0.89      0.88      0.88      1136\n","          31       0.58      0.58      0.58        19\n","          32       0.86      0.75      0.80         8\n","          33       0.79      0.91      0.84        86\n","          34       0.21      0.47      0.29        32\n","          35       0.97      0.99      0.98       474\n","          36       0.94      0.09      0.17       182\n","          37       0.89      0.96      0.92      1592\n","          38       0.98      0.93      0.95       404\n","          39       0.98      0.94      0.96       485\n","          40       0.90      0.94      0.92       573\n","          41       0.89      0.93      0.91       841\n","          42       0.96      0.99      0.97       575\n","          43       0.95      0.89      0.92       152\n","          44       0.87      0.92      0.90        75\n","          46       0.99      0.99      0.99        82\n","          48       0.11      0.19      0.14        79\n","\n","    accuracy                           0.90     28417\n","   macro avg       0.79      0.79      0.76     28417\n","weighted avg       0.92      0.90      0.90     28417\n","\n","Difference 968\n","\n","Loop 2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0029620188288390636\n","step: 10, loss: 0.0010195043869316578\n","step: 20, loss: 0.0013814721023663878\n","step: 30, loss: 0.0044435784220695496\n","step: 40, loss: 0.008691382594406605\n","step: 50, loss: 0.0018372961785644293\n","step: 60, loss: 0.0015657746698707342\n","step: 70, loss: 0.018120620399713516\n","step: 80, loss: 0.0014300367329269648\n","step: 90, loss: 0.00629816297441721\n","step: 100, loss: 0.05914205685257912\n","step: 110, loss: 0.05668140947818756\n","step: 120, loss: 0.0009716561762616038\n","acc=0.89\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.79      0.97      0.87        35\n","           2       0.83      0.06      0.12        77\n","           3       1.00      0.79      0.88      1030\n","           4       1.00      0.76      0.86       291\n","           5       0.80      0.84      0.82       294\n","           6       0.99      0.98      0.99      1570\n","           7       0.45      0.94      0.61       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.92      0.98      0.95       901\n","          11       0.99      1.00      0.99      2111\n","          12       0.98      0.98      0.98        47\n","          13       0.00      0.00      0.00        13\n","          14       0.27      1.00      0.43        43\n","          15       0.94      0.98      0.96      2778\n","          16       0.94      0.79      0.86      1151\n","          17       0.89      0.98      0.93        41\n","          18       0.94      0.94      0.94        32\n","          19       1.00      0.25      0.40        40\n","          20       0.99      0.92      0.95       584\n","          21       0.00      0.00      0.00        52\n","          22       0.91      0.73      0.81      4175\n","          23       0.66      0.96      0.78      2253\n","          24       0.33      0.09      0.14        44\n","          25       0.87      0.93      0.90       888\n","          26       1.00      0.78      0.88         9\n","          27       0.91      0.97      0.94        69\n","          28       1.00      0.99      1.00      1864\n","          29       1.00      0.99      0.99       344\n","          30       0.90      0.84      0.87      1136\n","          31       0.58      0.58      0.58        19\n","          32       0.86      0.75      0.80         8\n","          33       0.82      0.92      0.87        86\n","          34       0.07      0.12      0.09        32\n","          35       0.98      0.99      0.98       474\n","          36       1.00      0.10      0.18       182\n","          37       0.88      0.95      0.92      1592\n","          38       0.97      0.92      0.95       404\n","          39       0.97      0.93      0.95       485\n","          40       0.89      0.93      0.91       573\n","          41       0.89      0.93      0.91       841\n","          42       0.98      0.99      0.98       575\n","          43       0.94      0.89      0.92       152\n","          44       0.87      0.92      0.90        75\n","          46       0.99      0.98      0.98        82\n","          48       0.05      0.01      0.02        79\n","\n","    accuracy                           0.89     28417\n","   macro avg       0.78      0.75      0.73     28417\n","weighted avg       0.91      0.89      0.89     28417\n","\n","Difference 213\n","\n","Loop 3\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0006671412847936153\n","step: 10, loss: 0.002867874689400196\n","step: 20, loss: 0.005295696202665567\n","step: 30, loss: 0.0002461642143316567\n","step: 40, loss: 0.0007268518675118685\n","step: 50, loss: 0.00010392857802798972\n","step: 60, loss: 0.07065409421920776\n","step: 70, loss: 0.002613552613183856\n","step: 80, loss: 0.021902233362197876\n","step: 90, loss: 0.0028801639564335346\n","step: 100, loss: 0.0005526513559743762\n","step: 110, loss: 0.00022967242693994194\n","step: 120, loss: 0.03793174773454666\n","acc=0.88\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.70      1.00      0.82        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.88      1030\n","           4       1.00      0.72      0.84       291\n","           5       0.79      0.23      0.36       294\n","           6       0.99      0.98      0.98      1570\n","           7       0.51      0.92      0.66       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.93      0.97      0.95       901\n","          11       0.98      1.00      0.99      2111\n","          12       0.98      0.89      0.93        47\n","          13       0.00      0.00      0.00        13\n","          14       0.13      1.00      0.24        43\n","          15       0.93      0.98      0.96      2778\n","          16       0.94      0.77      0.85      1151\n","          17       0.73      0.98      0.83        41\n","          18       0.91      0.97      0.94        32\n","          19       1.00      0.10      0.18        40\n","          20       0.99      0.94      0.96       584\n","          21       0.00      0.00      0.00        52\n","          22       0.93      0.72      0.81      4175\n","          23       0.65      0.98      0.78      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.82      0.94      0.88       888\n","          26       1.00      0.67      0.80         9\n","          27       0.88      0.99      0.93        69\n","          28       1.00      0.99      0.99      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.92      0.83      0.87      1136\n","          31       0.73      0.42      0.53        19\n","          32       1.00      0.62      0.77         8\n","          33       0.84      0.80      0.82        86\n","          34       0.08      0.56      0.15        32\n","          35       0.98      0.98      0.98       474\n","          36       1.00      0.09      0.17       182\n","          37       0.84      0.97      0.90      1592\n","          38       0.93      0.92      0.92       404\n","          39       0.96      0.94      0.95       485\n","          40       0.89      0.87      0.88       573\n","          41       0.90      0.89      0.90       841\n","          42       1.00      0.94      0.97       575\n","          43       0.96      0.88      0.92       152\n","          44       0.87      0.92      0.90        75\n","          46       0.99      0.99      0.99        82\n","          48       0.17      0.14      0.15        79\n","\n","    accuracy                           0.88     28417\n","   macro avg       0.76      0.72      0.70     28417\n","weighted avg       0.90      0.88      0.88     28417\n","\n","Difference 172\n","\n","Loop 4\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.00024264950479846448\n","step: 10, loss: 7.552797615062445e-05\n","step: 20, loss: 0.0036883947905153036\n","step: 30, loss: 5.62767636438366e-05\n","step: 40, loss: 0.0004106873238924891\n","step: 50, loss: 0.0039128512144088745\n","step: 60, loss: 0.0017428428400307894\n","step: 70, loss: 0.00011097175593022257\n","step: 80, loss: 0.00019147992134094238\n","step: 90, loss: 0.0003730605822056532\n","step: 100, loss: 0.0005514483200386167\n","step: 110, loss: 0.04370416700839996\n","step: 120, loss: 0.013890632428228855\n","acc=0.87\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.88      1030\n","           4       1.00      0.56      0.72       291\n","           5       1.00      0.01      0.01       294\n","           6       1.00      0.98      0.99      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.97      0.99       689\n","          10       0.93      0.96      0.95       901\n","          11       0.98      0.99      0.99      2111\n","          12       0.98      0.98      0.98        47\n","          13       0.00      0.00      0.00        13\n","          14       0.16      1.00      0.27        43\n","          15       0.86      0.98      0.92      2778\n","          16       0.91      0.79      0.85      1151\n","          17       0.80      0.98      0.88        41\n","          18       0.91      0.97      0.94        32\n","          19       0.00      0.00      0.00        40\n","          20       0.97      0.93      0.95       584\n","          21       0.00      0.00      0.00        52\n","          22       0.94      0.69      0.80      4175\n","          23       0.66      0.97      0.79      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.83      0.93      0.88       888\n","          26       0.00      0.00      0.00         9\n","          27       0.94      0.97      0.96        69\n","          28       1.00      0.99      0.99      1864\n","          29       1.00      0.99      0.99       344\n","          30       0.93      0.82      0.87      1136\n","          31       0.82      0.47      0.60        19\n","          32       1.00      0.25      0.40         8\n","          33       0.88      0.76      0.81        86\n","          34       0.00      0.00      0.00        32\n","          35       0.97      0.99      0.98       474\n","          36       1.00      0.01      0.01       182\n","          37       0.87      0.93      0.90      1592\n","          38       0.94      0.90      0.92       404\n","          39       0.91      0.95      0.93       485\n","          40       0.87      0.90      0.88       573\n","          41       0.85      0.90      0.87       841\n","          42       1.00      0.94      0.97       575\n","          43       0.94      0.90      0.92       152\n","          44       0.88      0.95      0.91        75\n","          46       1.00      0.93      0.96        82\n","          48       0.07      0.78      0.13        79\n","\n","    accuracy                           0.87     28417\n","   macro avg       0.69      0.65      0.63     28417\n","weighted avg       0.89      0.87      0.86     28417\n","\n","Difference 201\n","\n","Loop 5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.002786237746477127\n","step: 10, loss: 0.0001398171007167548\n","step: 20, loss: 0.00012132264964748174\n","step: 30, loss: 0.04102654755115509\n","step: 40, loss: 0.0016467943787574768\n","step: 50, loss: 0.00026111514307558537\n","step: 60, loss: 0.00021374203788582236\n","step: 70, loss: 0.00021491771622095257\n","step: 80, loss: 0.0034225599374622107\n","step: 90, loss: 0.0005307051469571888\n","step: 100, loss: 0.005748183932155371\n","step: 110, loss: 0.04121913015842438\n","step: 120, loss: 0.004542349837720394\n","acc=0.86\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.88      1030\n","           4       0.99      0.72      0.83       291\n","           5       0.00      0.00      0.00       294\n","           6       0.99      0.98      0.99      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.93      0.97      0.95       901\n","          11       0.98      1.00      0.99      2111\n","          12       0.92      0.98      0.95        47\n","          13       0.00      0.00      0.00        13\n","          14       0.27      1.00      0.43        43\n","          15       0.94      0.98      0.96      2778\n","          16       0.93      0.76      0.84      1151\n","          17       0.78      0.98      0.87        41\n","          18       0.86      0.97      0.91        32\n","          19       0.00      0.00      0.00        40\n","          20       0.91      0.92      0.92       584\n","          21       0.00      0.00      0.00        52\n","          22       0.95      0.68      0.80      4175\n","          23       0.67      0.97      0.79      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.80      0.95      0.87       888\n","          26       0.00      0.00      0.00         9\n","          27       0.94      0.96      0.95        69\n","          28       1.00      0.99      0.99      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.91      0.85      0.88      1136\n","          31       0.88      0.37      0.52        19\n","          32       1.00      0.25      0.40         8\n","          33       0.86      0.77      0.81        86\n","          34       0.00      0.00      0.00        32\n","          35       0.95      1.00      0.97       474\n","          36       1.00      0.02      0.03       182\n","          37       0.84      0.95      0.89      1592\n","          38       0.93      0.85      0.89       404\n","          39       0.83      0.98      0.90       485\n","          40       0.81      0.91      0.86       573\n","          41       0.85      0.79      0.82       841\n","          42       0.99      0.96      0.97       575\n","          43       0.95      0.88      0.91       152\n","          44       0.87      0.92      0.90        75\n","          46       0.99      0.96      0.98        82\n","          48       0.07      0.94      0.12        79\n","\n","    accuracy                           0.86     28417\n","   macro avg       0.66      0.65      0.62     28417\n","weighted avg       0.89      0.86      0.86     28417\n","\n","Difference 186\n","\n","Loop 6\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0004384311323519796\n","step: 10, loss: 4.412944326759316e-05\n","step: 20, loss: 0.053712114691734314\n","step: 30, loss: 0.00034358460106886923\n","step: 40, loss: 0.05337861180305481\n","step: 50, loss: 8.331886056112126e-05\n","step: 60, loss: 3.1573355954606086e-05\n","step: 70, loss: 0.00013227005547378212\n","step: 80, loss: 0.0012055692495778203\n","step: 90, loss: 0.008412439376115799\n","step: 100, loss: 0.000348907575244084\n","step: 110, loss: 0.016299797222018242\n","step: 120, loss: 0.00010368088260293007\n","acc=0.86\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.88      1030\n","           4       1.00      0.72      0.83       291\n","           5       0.00      0.00      0.00       294\n","           6       0.99      0.98      0.99      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.92      0.97      0.95       901\n","          11       0.98      1.00      0.99      2111\n","          12       0.96      0.98      0.97        47\n","          13       0.00      0.00      0.00        13\n","          14       0.22      1.00      0.36        43\n","          15       0.93      0.98      0.95      2778\n","          16       0.91      0.73      0.81      1151\n","          17       0.75      0.98      0.85        41\n","          18       0.86      0.94      0.90        32\n","          19       0.00      0.00      0.00        40\n","          20       0.95      0.92      0.93       584\n","          21       0.00      0.00      0.00        52\n","          22       0.95      0.68      0.80      4175\n","          23       0.64      0.98      0.78      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.84      0.92      0.88       888\n","          26       0.00      0.00      0.00         9\n","          27       0.87      0.99      0.93        69\n","          28       1.00      0.99      1.00      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.91      0.83      0.87      1136\n","          31       0.75      0.32      0.44        19\n","          32       1.00      0.25      0.40         8\n","          33       0.86      0.73      0.79        86\n","          34       0.00      0.00      0.00        32\n","          35       0.98      0.99      0.98       474\n","          36       0.00      0.00      0.00       182\n","          37       0.83      0.95      0.89      1592\n","          38       0.94      0.85      0.89       404\n","          39       0.92      0.96      0.94       485\n","          40       0.76      0.91      0.83       573\n","          41       0.88      0.78      0.83       841\n","          42       0.99      0.96      0.98       575\n","          43       0.92      0.88      0.90       152\n","          44       0.87      0.92      0.90        75\n","          46       1.00      0.98      0.99        82\n","          48       0.06      0.73      0.10        79\n","\n","    accuracy                           0.86     28417\n","   macro avg       0.64      0.64      0.62     28417\n","weighted avg       0.88      0.86      0.86     28417\n","\n","Difference 163\n","\n","Loop 7\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.01288007851690054\n","step: 10, loss: 0.0033406848087906837\n","step: 20, loss: 3.158374966005795e-05\n","step: 30, loss: 0.00016751234943512827\n","step: 40, loss: 0.0046752640046179295\n","step: 50, loss: 0.09927809238433838\n","step: 60, loss: 0.13674765825271606\n","step: 70, loss: 0.0009355974034406245\n","step: 80, loss: 0.00043639334035106003\n","step: 90, loss: 0.0446750782430172\n","step: 100, loss: 0.001670563011430204\n","step: 110, loss: 0.0001867580140242353\n","step: 120, loss: 0.004686173517256975\n","acc=0.86\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       0.99      0.79      0.88      1030\n","           4       0.99      0.60      0.75       291\n","           5       1.00      0.00      0.01       294\n","           6       0.99      0.99      0.99      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.92      0.97      0.95       901\n","          11       0.97      1.00      0.98      2111\n","          12       0.92      0.98      0.95        47\n","          13       0.00      0.00      0.00        13\n","          14       0.17      1.00      0.28        43\n","          15       0.93      0.98      0.95      2778\n","          16       0.92      0.77      0.84      1151\n","          17       0.78      0.98      0.87        41\n","          18       0.91      0.94      0.92        32\n","          19       0.00      0.00      0.00        40\n","          20       0.95      0.92      0.94       584\n","          21       0.00      0.00      0.00        52\n","          22       0.92      0.71      0.80      4175\n","          23       0.64      0.98      0.77      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.86      0.92      0.89       888\n","          26       0.00      0.00      0.00         9\n","          27       0.82      1.00      0.90        69\n","          28       1.00      0.99      0.99      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.92      0.83      0.87      1136\n","          31       0.00      0.00      0.00        19\n","          32       1.00      0.25      0.40         8\n","          33       0.87      0.77      0.81        86\n","          34       0.00      0.00      0.00        32\n","          35       0.98      0.99      0.98       474\n","          36       0.00      0.00      0.00       182\n","          37       0.84      0.94      0.89      1592\n","          38       0.95      0.80      0.87       404\n","          39       0.95      0.94      0.95       485\n","          40       0.79      0.91      0.85       573\n","          41       0.88      0.79      0.83       841\n","          42       0.99      0.95      0.97       575\n","          43       0.96      0.83      0.89       152\n","          44       0.87      0.96      0.91        75\n","          46       1.00      0.83      0.91        82\n","          48       0.04      0.48      0.08        79\n","\n","    accuracy                           0.86     28417\n","   macro avg       0.65      0.62      0.61     28417\n","weighted avg       0.89      0.86      0.86     28417\n","\n","Difference 217\n","\n","Loop 8\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 7.005775842117146e-05\n","step: 10, loss: 6.129374378360808e-05\n","step: 20, loss: 3.727125658770092e-05\n","step: 30, loss: 0.02159970998764038\n","step: 40, loss: 0.008177393116056919\n","step: 50, loss: 0.00010428632231196389\n","step: 60, loss: 0.0063184890896081924\n","step: 70, loss: 9.119021706283092e-05\n","step: 80, loss: 0.005546248517930508\n","step: 90, loss: 0.0429849810898304\n","step: 100, loss: 0.043083276599645615\n","step: 110, loss: 9.020606375997886e-05\n","step: 120, loss: 0.0009807964088395238\n","acc=0.86\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       1.00      0.17      0.29       291\n","           5       0.00      0.00      0.00       294\n","           6       0.99      0.99      0.99      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.97      0.99       689\n","          10       0.91      0.97      0.94       901\n","          11       0.98      0.99      0.99      2111\n","          12       0.94      0.98      0.96        47\n","          13       0.00      0.00      0.00        13\n","          14       0.24      1.00      0.38        43\n","          15       0.95      0.98      0.96      2778\n","          16       0.92      0.78      0.85      1151\n","          17       0.91      0.98      0.94        41\n","          18       0.91      0.94      0.92        32\n","          19       0.00      0.00      0.00        40\n","          20       0.96      0.91      0.94       584\n","          21       0.00      0.00      0.00        52\n","          22       0.91      0.72      0.80      4175\n","          23       0.68      0.97      0.80      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.80      0.95      0.87       888\n","          26       0.00      0.00      0.00         9\n","          27       0.88      0.99      0.93        69\n","          28       1.00      0.99      0.99      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.90      0.84      0.87      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.89      0.72      0.79        86\n","          34       0.00      0.00      0.00        32\n","          35       0.97      0.98      0.98       474\n","          36       0.00      0.00      0.00       182\n","          37       0.84      0.92      0.88      1592\n","          38       0.94      0.75      0.83       404\n","          39       0.85      0.95      0.90       485\n","          40       0.79      0.87      0.83       573\n","          41       0.86      0.79      0.82       841\n","          42       0.98      0.97      0.97       575\n","          43       0.97      0.78      0.86       152\n","          44       0.88      0.93      0.90        75\n","          46       1.00      0.98      0.99        82\n","          48       0.05      0.81      0.10        79\n","\n","    accuracy                           0.86     28417\n","   macro avg       0.61      0.62      0.59     28417\n","weighted avg       0.87      0.86      0.86     28417\n","\n","Difference 199\n","\n","Loop 9\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0006437322590500116\n","step: 10, loss: 0.006539014168083668\n","step: 20, loss: 0.0026684687472879887\n","step: 30, loss: 0.0005093180807307363\n","step: 40, loss: 0.011883357539772987\n","step: 50, loss: 0.0005255999276414514\n","step: 60, loss: 0.04246338829398155\n","step: 70, loss: 0.02012515813112259\n","step: 80, loss: 0.003696138272061944\n","step: 90, loss: 0.010045746341347694\n","step: 100, loss: 0.00046873182873241603\n","step: 110, loss: 0.0006112471455708146\n","step: 120, loss: 0.00024133591796271503\n","acc=0.86\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       0.96      0.80      0.87      1030\n","           4       1.00      0.39      0.56       291\n","           5       0.00      0.00      0.00       294\n","           6       0.98      0.99      0.98      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.87      0.98      0.92       901\n","          11       0.98      1.00      0.99      2111\n","          12       0.96      0.98      0.97        47\n","          13       0.00      0.00      0.00        13\n","          14       0.25      1.00      0.39        43\n","          15       0.94      0.97      0.95      2778\n","          16       0.85      0.86      0.85      1151\n","          17       0.81      0.95      0.88        41\n","          18       0.84      0.97      0.90        32\n","          19       0.00      0.00      0.00        40\n","          20       0.91      0.90      0.91       584\n","          21       0.00      0.00      0.00        52\n","          22       0.93      0.70      0.80      4175\n","          23       0.67      0.96      0.79      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.83      0.96      0.89       888\n","          26       0.00      0.00      0.00         9\n","          27       0.79      1.00      0.88        69\n","          28       1.00      0.99      0.99      1864\n","          29       1.00      0.99      0.99       344\n","          30       0.92      0.84      0.88      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.77      0.85      0.81        86\n","          34       0.00      0.00      0.00        32\n","          35       0.96      0.98      0.97       474\n","          36       0.00      0.00      0.00       182\n","          37       0.87      0.91      0.89      1592\n","          38       0.91      0.83      0.87       404\n","          39       0.96      0.94      0.95       485\n","          40       0.83      0.90      0.86       573\n","          41       0.81      0.83      0.82       841\n","          42       0.99      0.97      0.98       575\n","          43       0.83      0.84      0.83       152\n","          44       0.86      0.93      0.90        75\n","          46       1.00      0.96      0.98        82\n","          48       0.03      0.30      0.05        79\n","\n","    accuracy                           0.86     28417\n","   macro avg       0.59      0.62      0.59     28417\n","weighted avg       0.87      0.86      0.86     28417\n","\n","Difference 219\n","\n","Loop 10\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0006261775270104408\n","step: 10, loss: 3.840659337583929e-05\n","step: 20, loss: 0.00019369457731954753\n","step: 30, loss: 0.00013866432709619403\n","step: 40, loss: 0.024018816649913788\n","step: 50, loss: 0.036593105643987656\n","step: 60, loss: 0.0012546437792479992\n","step: 70, loss: 0.005698682740330696\n","step: 80, loss: 0.017379777505993843\n","step: 90, loss: 0.001304372912272811\n","step: 100, loss: 6.196214962983504e-05\n","step: 110, loss: 0.00035701910383068025\n","step: 120, loss: 0.0004892965662293136\n","acc=0.86\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       1.00      0.03      0.05       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      0.99      0.98      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.92      0.97      0.94       901\n","          11       0.99      0.99      0.99      2111\n","          12       0.96      0.98      0.97        47\n","          13       0.00      0.00      0.00        13\n","          14       0.13      1.00      0.23        43\n","          15       0.90      0.98      0.94      2778\n","          16       0.88      0.83      0.85      1151\n","          17       0.87      0.95      0.91        41\n","          18       0.91      0.94      0.92        32\n","          19       0.00      0.00      0.00        40\n","          20       0.89      0.90      0.90       584\n","          21       0.00      0.00      0.00        52\n","          22       0.89      0.72      0.79      4175\n","          23       0.68      0.96      0.79      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.83      0.96      0.89       888\n","          26       0.00      0.00      0.00         9\n","          27       0.71      1.00      0.83        69\n","          28       1.00      0.99      0.99      1864\n","          29       1.00      0.99      0.99       344\n","          30       0.94      0.82      0.88      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.81      0.78      0.79        86\n","          34       0.00      0.00      0.00        32\n","          35       0.98      0.97      0.98       474\n","          36       0.00      0.00      0.00       182\n","          37       0.86      0.92      0.89      1592\n","          38       0.92      0.80      0.86       404\n","          39       0.93      0.90      0.92       485\n","          40       0.79      0.91      0.85       573\n","          41       0.86      0.80      0.83       841\n","          42       0.95      0.98      0.97       575\n","          43       0.95      0.80      0.87       152\n","          44       0.86      0.93      0.90        75\n","          46       1.00      0.95      0.97        82\n","          48       0.01      0.09      0.02        79\n","\n","    accuracy                           0.86     28417\n","   macro avg       0.60      0.60      0.58     28417\n","weighted avg       0.87      0.86      0.85     28417\n","\n","Difference 194\n","\n","Loop 11\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.00021959921286907047\n","step: 10, loss: 0.005614729598164558\n","step: 20, loss: 0.02651635743677616\n","step: 30, loss: 0.0017297161975875497\n","step: 40, loss: 0.005712923128157854\n","step: 50, loss: 0.0001255462266271934\n","step: 60, loss: 0.08488281071186066\n","step: 70, loss: 0.00016207070439122617\n","step: 80, loss: 0.007028949912637472\n","step: 90, loss: 0.00027809699531644583\n","step: 100, loss: 0.020717762410640717\n","step: 110, loss: 0.05563567578792572\n","step: 120, loss: 0.0002116790128638968\n","acc=0.85\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       0.97      0.80      0.88      1030\n","           4       1.00      0.09      0.17       291\n","           5       0.00      0.00      0.00       294\n","           6       0.98      0.99      0.99      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.97      0.99       689\n","          10       0.89      0.97      0.93       901\n","          11       0.98      0.99      0.99      2111\n","          12       0.96      0.98      0.97        47\n","          13       0.00      0.00      0.00        13\n","          14       0.13      1.00      0.23        43\n","          15       0.92      0.98      0.95      2778\n","          16       0.91      0.79      0.85      1151\n","          17       0.67      0.98      0.79        41\n","          18       0.84      0.97      0.90        32\n","          19       0.00      0.00      0.00        40\n","          20       0.91      0.91      0.91       584\n","          21       0.00      0.00      0.00        52\n","          22       0.91      0.69      0.79      4175\n","          23       0.63      0.97      0.77      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.83      0.94      0.88       888\n","          26       0.00      0.00      0.00         9\n","          27       0.64      1.00      0.78        69\n","          28       1.00      0.99      0.99      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.95      0.81      0.88      1136\n","          31       0.00      0.00      0.00        19\n","          32       1.00      0.12      0.22         8\n","          33       0.80      0.83      0.81        86\n","          34       0.00      0.00      0.00        32\n","          35       0.98      0.97      0.97       474\n","          36       0.00      0.00      0.00       182\n","          37       0.85      0.89      0.87      1592\n","          38       0.87      0.76      0.81       404\n","          39       0.84      0.91      0.87       485\n","          40       0.77      0.87      0.82       573\n","          41       0.87      0.75      0.80       841\n","          42       0.91      0.96      0.94       575\n","          43       0.92      0.86      0.89       152\n","          44       0.86      0.92      0.89        75\n","          46       1.00      0.95      0.97        82\n","          48       0.02      0.19      0.03        79\n","\n","    accuracy                           0.85     28417\n","   macro avg       0.60      0.60      0.58     28417\n","weighted avg       0.86      0.85      0.85     28417\n","\n","Difference 227\n","\n","Loop 12\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.00037330284249037504\n","step: 10, loss: 0.027861658483743668\n","step: 20, loss: 0.04358552396297455\n","step: 30, loss: 0.00017531815683469176\n","step: 40, loss: 0.015108716674149036\n","step: 50, loss: 0.021507494151592255\n","step: 60, loss: 0.001467155641876161\n","step: 70, loss: 0.03474794328212738\n","step: 80, loss: 0.00413693068549037\n","step: 90, loss: 0.000535197148565203\n","step: 100, loss: 0.020547710359096527\n","step: 110, loss: 0.00012293322652112693\n","step: 120, loss: 0.002789716934785247\n","acc=0.85\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       0.92      0.80      0.85      1030\n","           4       1.00      0.08      0.15       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      1.00      0.98      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.90      0.97      0.93       901\n","          11       0.98      0.98      0.98      2111\n","          12       0.70      0.98      0.81        47\n","          13       0.00      0.00      0.00        13\n","          14       0.21      1.00      0.34        43\n","          15       0.88      0.98      0.93      2778\n","          16       0.92      0.79      0.85      1151\n","          17       0.61      0.98      0.75        41\n","          18       0.79      0.97      0.87        32\n","          19       0.00      0.00      0.00        40\n","          20       0.87      0.91      0.89       584\n","          21       0.00      0.00      0.00        52\n","          22       0.91      0.69      0.79      4175\n","          23       0.62      0.97      0.76      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.81      0.94      0.87       888\n","          26       0.00      0.00      0.00         9\n","          27       0.76      0.87      0.81        69\n","          28       0.99      0.99      0.99      1864\n","          29       1.00      0.99      0.99       344\n","          30       0.94      0.80      0.86      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.80      0.74      0.77        86\n","          34       0.00      0.00      0.00        32\n","          35       0.98      0.93      0.96       474\n","          36       0.00      0.00      0.00       182\n","          37       0.85      0.90      0.87      1592\n","          38       0.91      0.73      0.81       404\n","          39       0.95      0.87      0.91       485\n","          40       0.77      0.90      0.83       573\n","          41       0.86      0.78      0.82       841\n","          42       0.89      0.97      0.93       575\n","          43       0.95      0.80      0.87       152\n","          44       0.87      0.92      0.90        75\n","          46       1.00      0.96      0.98        82\n","          48       0.00      0.03      0.00        79\n","\n","    accuracy                           0.85     28417\n","   macro avg       0.58      0.59      0.57     28417\n","weighted avg       0.86      0.85      0.84     28417\n","\n","Difference 326\n","\n","Loop 13\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0001646589080337435\n","step: 10, loss: 7.639774412382394e-05\n","step: 20, loss: 2.713267349463422e-05\n","step: 30, loss: 0.050293613225221634\n","step: 40, loss: 0.00023402959050145\n","step: 50, loss: 0.012991102412343025\n","step: 60, loss: 0.020793966948986053\n","step: 70, loss: 0.0017364292871206999\n","step: 80, loss: 0.006439143791794777\n","step: 90, loss: 0.03609148785471916\n","step: 100, loss: 0.00018086838827002794\n","step: 110, loss: 0.0001320612063864246\n","step: 120, loss: 0.00048324454110115767\n","acc=0.83\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.88      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      1.00      0.99      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.91      0.96      0.94       901\n","          11       0.98      0.99      0.98      2111\n","          12       0.79      0.98      0.88        47\n","          13       0.00      0.00      0.00        13\n","          14       0.08      1.00      0.14        43\n","          15       0.93      0.98      0.95      2778\n","          16       0.91      0.76      0.83      1151\n","          17       0.66      0.95      0.78        41\n","          18       0.86      0.97      0.91        32\n","          19       0.00      0.00      0.00        40\n","          20       0.94      0.90      0.92       584\n","          21       0.00      0.00      0.00        52\n","          22       0.96      0.63      0.76      4175\n","          23       0.54      0.99      0.70      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.86      0.88      0.87       888\n","          26       0.00      0.00      0.00         9\n","          27       0.76      1.00      0.86        69\n","          28       0.99      0.99      0.99      1864\n","          29       0.98      0.99      0.99       344\n","          30       0.91      0.81      0.86      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.74      0.85      0.79        86\n","          34       0.00      0.00      0.00        32\n","          35       0.97      0.97      0.97       474\n","          36       0.00      0.00      0.00       182\n","          37       0.77      0.93      0.84      1592\n","          38       0.88      0.85      0.87       404\n","          39       0.93      0.91      0.92       485\n","          40       0.88      0.76      0.81       573\n","          41       0.86      0.61      0.72       841\n","          42       0.87      0.98      0.92       575\n","          43       0.94      0.79      0.86       152\n","          44       0.87      0.92      0.90        75\n","          46       1.00      0.96      0.98        82\n","          48       0.00      0.00      0.00        79\n","\n","    accuracy                           0.83     28417\n","   macro avg       0.56      0.59      0.56     28417\n","weighted avg       0.85      0.83      0.83     28417\n","\n","Difference 276\n","\n","Loop 14\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.00012636868632398546\n","step: 10, loss: 5.044651697971858e-05\n","step: 20, loss: 0.0269578006118536\n","step: 30, loss: 0.010919441469013691\n","step: 40, loss: 0.009644071571528912\n","step: 50, loss: 0.0012398798717185855\n","step: 60, loss: 0.06309185922145844\n","step: 70, loss: 0.0008858396322466433\n","step: 80, loss: 0.00011826974514406174\n","step: 90, loss: 0.003908609040081501\n","step: 100, loss: 0.001997136976569891\n","step: 110, loss: 0.0007898092735558748\n","step: 120, loss: 0.0003237948112655431\n","acc=0.83\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      1.00      0.99      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.91      0.97      0.94       901\n","          11       0.97      0.99      0.98      2111\n","          12       0.79      0.98      0.88        47\n","          13       0.00      0.00      0.00        13\n","          14       0.07      1.00      0.13        43\n","          15       0.92      0.98      0.95      2778\n","          16       0.88      0.79      0.84      1151\n","          17       0.61      0.98      0.75        41\n","          18       0.83      0.94      0.88        32\n","          19       0.00      0.00      0.00        40\n","          20       0.92      0.93      0.92       584\n","          21       0.00      0.00      0.00        52\n","          22       0.98      0.60      0.74      4175\n","          23       0.56      0.98      0.71      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.80      0.89      0.84       888\n","          26       0.00      0.00      0.00         9\n","          27       0.84      0.91      0.87        69\n","          28       1.00      0.99      0.99      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.94      0.80      0.86      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.63      0.90      0.74        86\n","          34       0.00      0.00      0.00        32\n","          35       0.97      0.99      0.98       474\n","          36       0.00      0.00      0.00       182\n","          37       0.83      0.87      0.85      1592\n","          38       0.89      0.87      0.88       404\n","          39       0.83      0.96      0.89       485\n","          40       0.85      0.85      0.85       573\n","          41       0.86      0.73      0.79       841\n","          42       0.74      0.98      0.84       575\n","          43       0.96      0.74      0.84       152\n","          44       0.87      0.92      0.90        75\n","          46       1.00      0.94      0.97        82\n","          48       0.01      0.09      0.02        79\n","\n","    accuracy                           0.83     28417\n","   macro avg       0.55      0.59      0.56     28417\n","weighted avg       0.85      0.83      0.83     28417\n","\n","Difference 222\n","\n","Loop 15\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0001497054472565651\n","step: 10, loss: 0.031052730977535248\n","step: 20, loss: 4.0839850043994375e-06\n","step: 30, loss: 0.0016109736170619726\n","step: 40, loss: 5.4991473007248715e-05\n","step: 50, loss: 6.918674625921994e-05\n","step: 60, loss: 0.01828151009976864\n","step: 70, loss: 0.03668607398867607\n","step: 80, loss: 0.005197489634156227\n","step: 90, loss: 0.06080636754631996\n","step: 100, loss: 0.0034708641469478607\n","step: 110, loss: 0.03037036955356598\n","step: 120, loss: 0.00048692463315092027\n","acc=0.83\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      1.00      0.99      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.97      0.98       689\n","          10       0.89      0.97      0.93       901\n","          11       0.98      0.99      0.98      2111\n","          12       0.84      0.98      0.90        47\n","          13       0.00      0.00      0.00        13\n","          14       0.24      0.77      0.37        43\n","          15       0.84      0.97      0.90      2778\n","          16       0.81      0.80      0.81      1151\n","          17       0.65      0.98      0.78        41\n","          18       0.79      0.94      0.86        32\n","          19       0.00      0.00      0.00        40\n","          20       0.87      0.95      0.91       584\n","          21       0.00      0.00      0.00        52\n","          22       0.96      0.62      0.75      4175\n","          23       0.60      0.99      0.75      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.82      0.92      0.87       888\n","          26       0.00      0.00      0.00         9\n","          27       1.00      0.74      0.85        69\n","          28       0.97      0.99      0.98      1864\n","          29       1.00      0.82      0.90       344\n","          30       0.84      0.84      0.84      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.65      0.86      0.74        86\n","          34       0.00      0.00      0.00        32\n","          35       0.99      0.84      0.91       474\n","          36       0.00      0.00      0.00       182\n","          37       0.84      0.85      0.85      1592\n","          38       0.93      0.75      0.83       404\n","          39       0.85      0.96      0.90       485\n","          40       0.79      0.88      0.84       573\n","          41       0.84      0.78      0.81       841\n","          42       0.93      0.95      0.94       575\n","          43       0.95      0.51      0.66       152\n","          44       0.86      0.85      0.86        75\n","          46       1.00      0.71      0.83        82\n","          48       0.00      0.00      0.00        79\n","\n","    accuracy                           0.83     28417\n","   macro avg       0.56      0.56      0.55     28417\n","weighted avg       0.84      0.83      0.82     28417\n","\n","Difference 113\n","\n","Loop 16\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0016666474984958768\n","step: 10, loss: 0.06249064952135086\n","step: 20, loss: 0.00044318888103589416\n","step: 30, loss: 0.0629659965634346\n","step: 40, loss: 0.00021170142281334847\n","step: 50, loss: 0.00013896837481297553\n","step: 60, loss: 0.1115490198135376\n","step: 70, loss: 0.032708410173654556\n","step: 80, loss: 0.005714721977710724\n","step: 90, loss: 0.0008054430363699794\n","step: 100, loss: 3.1159997888607904e-05\n","step: 110, loss: 0.004047492053359747\n","step: 120, loss: 0.0016648853197693825\n","acc=0.83\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      1.00      0.99      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.90      0.97      0.93       901\n","          11       0.97      1.00      0.98      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       0.45      0.74      0.56        43\n","          15       0.90      0.97      0.94      2778\n","          16       0.88      0.81      0.84      1151\n","          17       0.63      0.98      0.77        41\n","          18       0.84      0.97      0.90        32\n","          19       0.00      0.00      0.00        40\n","          20       0.81      0.91      0.86       584\n","          21       0.00      0.00      0.00        52\n","          22       0.98      0.61      0.75      4175\n","          23       0.61      0.96      0.74      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.75      0.95      0.84       888\n","          26       0.00      0.00      0.00         9\n","          27       0.85      0.67      0.75        69\n","          28       0.97      0.99      0.98      1864\n","          29       0.99      0.97      0.98       344\n","          30       0.93      0.80      0.86      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.68      0.88      0.77        86\n","          34       0.00      0.00      0.00        32\n","          35       0.98      0.94      0.96       474\n","          36       0.00      0.00      0.00       182\n","          37       0.82      0.88      0.85      1592\n","          38       0.94      0.78      0.85       404\n","          39       0.82      0.95      0.88       485\n","          40       0.84      0.85      0.85       573\n","          41       0.70      0.84      0.77       841\n","          42       0.89      0.95      0.92       575\n","          43       0.93      0.81      0.87       152\n","          44       0.88      0.93      0.90        75\n","          46       1.00      0.96      0.98        82\n","          48       0.00      0.01      0.00        79\n","\n","    accuracy                           0.83     28417\n","   macro avg       0.54      0.56      0.55     28417\n","weighted avg       0.85      0.83      0.83     28417\n","\n","Difference 148\n","\n","Loop 17\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0009293692419305444\n","step: 10, loss: 2.189229599025566e-05\n","step: 20, loss: 3.0611456168117e-05\n","step: 30, loss: 0.0026125945150852203\n","step: 40, loss: 6.0927533922949806e-05\n","step: 50, loss: 0.00022720647393725812\n","step: 60, loss: 6.253958417801186e-05\n","step: 70, loss: 0.003352127969264984\n","step: 80, loss: 0.002206692937761545\n","step: 90, loss: 0.0023397430777549744\n","step: 100, loss: 0.0021750156302005053\n","step: 110, loss: 0.0019040514016523957\n","step: 120, loss: 0.0009790799813345075\n","acc=0.84\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       0.99      0.79      0.88      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      1.00      0.99      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       0.99      0.98      0.99       689\n","          10       0.89      0.97      0.93       901\n","          11       0.97      0.99      0.98      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       1.00      0.09      0.17        43\n","          15       0.89      0.97      0.93      2778\n","          16       0.90      0.78      0.84      1151\n","          17       0.66      0.98      0.78        41\n","          18       0.82      0.97      0.89        32\n","          19       0.00      0.00      0.00        40\n","          20       0.89      0.91      0.90       584\n","          21       0.00      0.00      0.00        52\n","          22       0.97      0.64      0.77      4175\n","          23       0.61      0.98      0.75      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.81      0.94      0.87       888\n","          26       0.00      0.00      0.00         9\n","          27       0.94      0.94      0.94        69\n","          28       0.99      0.99      0.99      1864\n","          29       1.00      0.98      0.99       344\n","          30       0.90      0.83      0.86      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.64      0.90      0.75        86\n","          34       0.00      0.00      0.00        32\n","          35       0.92      0.99      0.95       474\n","          36       0.00      0.00      0.00       182\n","          37       0.84      0.89      0.87      1592\n","          38       0.96      0.69      0.80       404\n","          39       0.85      0.95      0.90       485\n","          40       0.78      0.88      0.83       573\n","          41       0.76      0.83      0.79       841\n","          42       0.95      0.93      0.94       575\n","          43       0.97      0.67      0.79       152\n","          44       0.86      0.93      0.90        75\n","          46       1.00      0.96      0.98        82\n","          48       0.01      0.08      0.01        79\n","\n","    accuracy                           0.84     28417\n","   macro avg       0.56      0.55      0.54     28417\n","weighted avg       0.85      0.84      0.83     28417\n","\n","Difference 159\n","\n","Loop 18\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.004030194599181414\n","step: 10, loss: 0.0005740292835980654\n","step: 20, loss: 0.00013478845357894897\n","step: 30, loss: 0.015730779618024826\n","step: 40, loss: 0.04364337399601936\n","step: 50, loss: 0.010412878356873989\n","step: 60, loss: 0.0002275819715578109\n","step: 70, loss: 0.0003668071876745671\n","step: 80, loss: 0.0006102941115386784\n","step: 90, loss: 0.000260411441558972\n","step: 100, loss: 0.002005462534725666\n","step: 110, loss: 0.000201511662453413\n","step: 120, loss: 0.0003223518724553287\n","acc=0.83\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      1.00      0.99      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.91      0.96      0.94       901\n","          11       0.97      0.99      0.98      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       0.89      0.74      0.81        43\n","          15       0.90      0.97      0.93      2778\n","          16       0.90      0.78      0.83      1151\n","          17       0.77      0.98      0.86        41\n","          18       0.88      0.94      0.91        32\n","          19       0.00      0.00      0.00        40\n","          20       0.90      0.92      0.91       584\n","          21       0.00      0.00      0.00        52\n","          22       0.97      0.60      0.74      4175\n","          23       0.61      0.99      0.75      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.84      0.90      0.86       888\n","          26       0.00      0.00      0.00         9\n","          27       1.00      0.48      0.65        69\n","          28       0.99      0.99      0.99      1864\n","          29       0.97      0.96      0.96       344\n","          30       0.89      0.83      0.86      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.66      0.88      0.75        86\n","          34       0.00      0.00      0.00        32\n","          35       0.94      0.99      0.96       474\n","          36       0.00      0.00      0.00       182\n","          37       0.78      0.92      0.85      1592\n","          38       0.95      0.69      0.79       404\n","          39       0.77      0.95      0.85       485\n","          40       0.75      0.88      0.81       573\n","          41       0.82      0.77      0.79       841\n","          42       0.97      0.94      0.96       575\n","          43       0.96      0.62      0.75       152\n","          44       0.87      0.92      0.90        75\n","          46       1.00      0.93      0.96        82\n","          48       0.02      0.37      0.04        79\n","\n","    accuracy                           0.83     28417\n","   macro avg       0.56      0.56      0.55     28417\n","weighted avg       0.85      0.83      0.83     28417\n","\n","Difference 203\n","\n","Loop 19\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.00016696681268513203\n","step: 10, loss: 0.07628989964723587\n","step: 20, loss: 0.0003715071070473641\n","step: 30, loss: 0.06509479135274887\n","step: 40, loss: 0.0198611281812191\n","step: 50, loss: 0.001280387630686164\n","step: 60, loss: 0.05062206834554672\n","step: 70, loss: 0.03756757453083992\n","step: 80, loss: 0.00010448932880535722\n","step: 90, loss: 0.00013387418584898114\n","step: 100, loss: 0.00024877808755263686\n","step: 110, loss: 0.00013393057452049106\n","step: 120, loss: 5.656931534758769e-05\n","acc=0.83\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      1.00      0.99      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.97      0.99       689\n","          10       0.91      0.97      0.94       901\n","          11       0.96      1.00      0.98      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       0.84      0.60      0.70        43\n","          15       0.87      0.97      0.92      2778\n","          16       0.89      0.78      0.83      1151\n","          17       0.70      0.98      0.82        41\n","          18       0.91      0.91      0.91        32\n","          19       0.00      0.00      0.00        40\n","          20       0.91      0.91      0.91       584\n","          21       0.00      0.00      0.00        52\n","          22       0.96      0.62      0.75      4175\n","          23       0.62      0.98      0.76      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.84      0.89      0.86       888\n","          26       0.00      0.00      0.00         9\n","          27       0.98      0.65      0.78        69\n","          28       0.99      0.99      0.99      1864\n","          29       0.99      0.95      0.97       344\n","          30       0.93      0.78      0.85      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.58      0.90      0.71        86\n","          34       0.00      0.00      0.00        32\n","          35       0.95      0.98      0.96       474\n","          36       0.00      0.00      0.00       182\n","          37       0.81      0.90      0.85      1592\n","          38       0.92      0.79      0.85       404\n","          39       0.61      0.98      0.75       485\n","          40       0.81      0.86      0.84       573\n","          41       0.82      0.77      0.80       841\n","          42       0.98      0.95      0.97       575\n","          43       1.00      0.52      0.68       152\n","          44       0.83      0.97      0.90        75\n","          46       1.00      0.96      0.98        82\n","          48       0.01      0.14      0.02        79\n","\n","    accuracy                           0.83     28417\n","   macro avg       0.56      0.55      0.55     28417\n","weighted avg       0.85      0.83      0.83     28417\n","\n","Difference 145\n","\n","Loop 20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 7.695012027397752e-05\n","step: 10, loss: 0.000133228357299231\n","step: 20, loss: 4.4088883441872895e-05\n","step: 30, loss: 0.000140313888550736\n","step: 40, loss: 0.00013180731912143528\n","step: 50, loss: 3.409590135561302e-05\n","step: 60, loss: 0.012751124799251556\n","step: 70, loss: 0.000230561156058684\n","step: 80, loss: 9.108640369959176e-05\n","step: 90, loss: 4.790543607668951e-05\n","step: 100, loss: 8.350204734597355e-05\n","step: 110, loss: 9.742654947331175e-05\n","step: 120, loss: 0.000410392734920606\n","acc=0.83\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      1.00      0.99      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       0.76      0.98      0.86       689\n","          10       0.89      0.97      0.93       901\n","          11       0.94      1.00      0.97      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       0.37      0.84      0.51        43\n","          15       0.93      0.96      0.94      2778\n","          16       0.90      0.77      0.83      1151\n","          17       0.62      0.88      0.73        41\n","          18       0.88      0.91      0.89        32\n","          19       0.00      0.00      0.00        40\n","          20       0.88      0.93      0.91       584\n","          21       0.00      0.00      0.00        52\n","          22       0.95      0.65      0.77      4175\n","          23       0.61      0.96      0.74      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.77      0.93      0.84       888\n","          26       0.00      0.00      0.00         9\n","          27       0.97      0.93      0.95        69\n","          28       0.97      0.99      0.98      1864\n","          29       1.00      0.95      0.97       344\n","          30       0.94      0.80      0.86      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.61      0.91      0.73        86\n","          34       0.00      0.00      0.00        32\n","          35       0.92      0.93      0.92       474\n","          36       0.00      0.00      0.00       182\n","          37       0.84      0.86      0.85      1592\n","          38       0.93      0.80      0.86       404\n","          39       0.79      0.96      0.87       485\n","          40       0.81      0.86      0.83       573\n","          41       0.80      0.81      0.81       841\n","          42       0.98      0.94      0.96       575\n","          43       1.00      0.20      0.34       152\n","          44       0.87      0.91      0.89        75\n","          46       1.00      0.96      0.98        82\n","          48       0.00      0.00      0.00        79\n","\n","    accuracy                           0.83     28417\n","   macro avg       0.54      0.55      0.53     28417\n","weighted avg       0.84      0.83      0.83     28417\n","\n","Difference 173\n","\n","Loop 21\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.00012771149340551347\n","step: 10, loss: 0.04359814152121544\n","step: 20, loss: 2.1380339603638276e-05\n","step: 30, loss: 5.754365702159703e-05\n","step: 40, loss: 0.027481984347105026\n","step: 50, loss: 0.014780169352889061\n","step: 60, loss: 0.000633584859315306\n","step: 70, loss: 0.05564573407173157\n","step: 80, loss: 0.00734503660351038\n","step: 90, loss: 0.00012934303958900273\n","step: 100, loss: 0.0003612961736507714\n","step: 110, loss: 0.010777922347187996\n","step: 120, loss: 0.005252791568636894\n","acc=0.83\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      1.00      0.99      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       0.74      0.98      0.84       689\n","          10       0.90      0.97      0.93       901\n","          11       0.89      0.99      0.94      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       0.45      0.88      0.60        43\n","          15       0.96      0.87      0.91      2778\n","          16       0.88      0.80      0.84      1151\n","          17       0.65      0.88      0.75        41\n","          18       0.88      0.91      0.89        32\n","          19       0.00      0.00      0.00        40\n","          20       0.90      0.95      0.92       584\n","          21       0.00      0.00      0.00        52\n","          22       0.97      0.61      0.75      4175\n","          23       0.58      0.98      0.73      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.82      0.93      0.87       888\n","          26       0.00      0.00      0.00         9\n","          27       0.97      0.81      0.88        69\n","          28       0.99      0.99      0.99      1864\n","          29       0.96      0.99      0.97       344\n","          30       0.92      0.80      0.86      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.55      0.94      0.70        86\n","          34       0.00      0.00      0.00        32\n","          35       0.95      0.98      0.97       474\n","          36       0.00      0.00      0.00       182\n","          37       0.85      0.87      0.86      1592\n","          38       0.93      0.84      0.88       404\n","          39       0.82      0.95      0.88       485\n","          40       0.83      0.87      0.85       573\n","          41       0.79      0.82      0.81       841\n","          42       0.94      0.97      0.96       575\n","          43       1.00      0.32      0.49       152\n","          44       0.76      0.97      0.85        75\n","          46       0.51      0.96      0.67        82\n","          48       0.00      0.00      0.00        79\n","\n","    accuracy                           0.83     28417\n","   macro avg       0.53      0.56      0.53     28417\n","weighted avg       0.84      0.83      0.82     28417\n","\n","Difference 192\n","\n","Loop 22\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 6.097574805608019e-05\n","step: 10, loss: 2.0253310140105896e-06\n","step: 20, loss: 4.049572453368455e-06\n","step: 30, loss: 3.2600819395156577e-06\n","step: 40, loss: 0.0022217058576643467\n","step: 50, loss: 3.681192174553871e-05\n","step: 60, loss: 0.009782860986888409\n","step: 70, loss: 0.0002503448922652751\n","step: 80, loss: 0.00364194018766284\n","step: 90, loss: 0.0002144711761502549\n","step: 100, loss: 0.0003803771687671542\n","step: 110, loss: 0.009948736988008022\n","step: 120, loss: 0.02352428250014782\n","acc=0.81\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      1.00      0.99      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       0.88      0.98      0.92       689\n","          10       0.89      0.97      0.93       901\n","          11       0.86      1.00      0.92      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       0.52      0.60      0.56        43\n","          15       0.94      0.85      0.89      2778\n","          16       0.90      0.75      0.82      1151\n","          17       0.78      0.71      0.74        41\n","          18       0.83      0.94      0.88        32\n","          19       0.00      0.00      0.00        40\n","          20       0.86      0.95      0.90       584\n","          21       0.00      0.00      0.00        52\n","          22       0.98      0.56      0.71      4175\n","          23       0.56      0.98      0.71      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.82      0.92      0.87       888\n","          26       0.00      0.00      0.00         9\n","          27       0.95      0.87      0.91        69\n","          28       0.98      0.99      0.99      1864\n","          29       0.99      0.97      0.98       344\n","          30       0.86      0.82      0.84      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.40      0.97      0.57        86\n","          34       0.00      0.00      0.00        32\n","          35       0.98      0.86      0.92       474\n","          36       0.00      0.00      0.00       182\n","          37       0.82      0.89      0.85      1592\n","          38       0.61      0.95      0.74       404\n","          39       0.77      0.96      0.86       485\n","          40       0.88      0.58      0.70       573\n","          41       0.71      0.81      0.76       841\n","          42       0.96      0.95      0.96       575\n","          43       1.00      0.09      0.17       152\n","          44       0.68      0.93      0.79        75\n","          46       0.82      0.96      0.89        82\n","          48       0.00      0.06      0.01        79\n","\n","    accuracy                           0.81     28417\n","   macro avg       0.53      0.54      0.51     28417\n","weighted avg       0.83      0.81      0.80     28417\n","\n","Difference 243\n","\n","Loop 23\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.002588835544884205\n","step: 10, loss: 4.719668595498661e-06\n","step: 20, loss: 0.044648364186286926\n","step: 30, loss: 3.538269447744824e-05\n","step: 40, loss: 2.7220676201977767e-05\n","step: 50, loss: 0.000640183687210083\n","step: 60, loss: 0.05347023904323578\n","step: 70, loss: 0.0002508933248464018\n","step: 80, loss: 0.012110426090657711\n","step: 90, loss: 3.472076787147671e-05\n","step: 100, loss: 0.01140228658914566\n","step: 110, loss: 0.0008890607859939337\n","step: 120, loss: 0.007142007350921631\n","acc=0.80\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      1.00      0.99      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       0.95      0.98      0.96       689\n","          10       0.89      0.96      0.93       901\n","          11       0.92      0.99      0.96      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       0.30      0.58      0.40        43\n","          15       0.88      0.90      0.89      2778\n","          16       0.89      0.75      0.82      1151\n","          17       0.80      0.20      0.31        41\n","          18       0.87      0.84      0.86        32\n","          19       0.00      0.00      0.00        40\n","          20       0.91      0.93      0.92       584\n","          21       0.00      0.00      0.00        52\n","          22       0.96      0.60      0.74      4175\n","          23       0.56      0.98      0.71      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.83      0.91      0.87       888\n","          26       0.00      0.00      0.00         9\n","          27       0.67      0.64      0.65        69\n","          28       0.98      0.99      0.99      1864\n","          29       1.00      0.95      0.97       344\n","          30       0.88      0.80      0.84      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.73      0.57      0.64        86\n","          34       0.00      0.00      0.00        32\n","          35       0.94      0.92      0.93       474\n","          36       0.00      0.00      0.00       182\n","          37       0.68      0.89      0.77      1592\n","          38       0.42      0.93      0.58       404\n","          39       0.83      0.94      0.88       485\n","          40       0.81      0.08      0.14       573\n","          41       0.83      0.65      0.73       841\n","          42       0.96      0.95      0.95       575\n","          43       0.00      0.00      0.00       152\n","          44       0.58      0.92      0.72        75\n","          46       0.93      0.96      0.95        82\n","          48       0.00      0.01      0.00        79\n","\n","    accuracy                           0.80     28417\n","   macro avg       0.50      0.49      0.48     28417\n","weighted avg       0.82      0.80      0.79     28417\n","\n","Difference 139\n","\n","Loop 24\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 2.808736462611705e-05\n","step: 10, loss: 8.372331649297848e-06\n","step: 20, loss: 0.1125328317284584\n","step: 30, loss: 1.4434473087021615e-05\n","step: 40, loss: 0.0008652799879200757\n","step: 50, loss: 0.02739684097468853\n","step: 60, loss: 7.39458337193355e-05\n","step: 70, loss: 0.00025299680419266224\n","step: 80, loss: 4.071823786944151e-05\n","step: 90, loss: 6.801390554755926e-05\n","step: 100, loss: 0.08117905259132385\n","step: 110, loss: 0.0021431792993098497\n","step: 120, loss: 0.0033632470294833183\n","acc=0.78\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      1.00      0.99      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       0.96      0.98      0.97       689\n","          10       0.90      0.97      0.93       901\n","          11       0.88      1.00      0.93      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       1.00      0.02      0.05        43\n","          15       0.95      0.85      0.90      2778\n","          16       0.88      0.76      0.82      1151\n","          17       0.76      0.46      0.58        41\n","          18       0.79      0.59      0.68        32\n","          19       0.00      0.00      0.00        40\n","          20       0.96      0.91      0.93       584\n","          21       0.00      0.00      0.00        52\n","          22       0.98      0.53      0.68      4175\n","          23       0.57      0.98      0.72      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.84      0.89      0.87       888\n","          26       0.00      0.00      0.00         9\n","          27       0.49      0.94      0.64        69\n","          28       0.99      0.99      0.99      1864\n","          29       1.00      0.96      0.98       344\n","          30       0.86      0.82      0.84      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.67      0.76      0.71        86\n","          34       0.00      0.00      0.00        32\n","          35       0.89      0.99      0.94       474\n","          36       0.00      0.00      0.00       182\n","          37       0.56      0.91      0.70      1592\n","          38       0.40      0.94      0.56       404\n","          39       0.91      0.89      0.90       485\n","          40       1.00      0.00      0.00       573\n","          41       0.84      0.62      0.72       841\n","          42       0.94      0.96      0.95       575\n","          43       0.00      0.00      0.00       152\n","          44       1.00      0.01      0.03        75\n","          46       0.36      0.96      0.53        82\n","          48       0.02      0.28      0.03        79\n","\n","    accuracy                           0.78     28417\n","   macro avg       0.51      0.47      0.44     28417\n","weighted avg       0.82      0.78      0.77     28417\n","\n","Difference 139\n","\n","Loop 25\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0011624058242887259\n","step: 10, loss: 6.671127630397677e-05\n","step: 20, loss: 4.9849983042804524e-05\n","step: 30, loss: 0.05717119947075844\n","step: 40, loss: 0.0008442467078566551\n","step: 50, loss: 0.0026740613393485546\n","step: 60, loss: 0.0005660908063873649\n","step: 70, loss: 0.1222725510597229\n","step: 80, loss: 0.025577645748853683\n","step: 90, loss: 0.0013700395356863737\n","step: 100, loss: 0.03978383541107178\n","step: 110, loss: 0.00022597148199565709\n","step: 120, loss: 0.04940183460712433\n","acc=0.79\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      1.00      0.99      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       0.95      0.98      0.96       689\n","          10       0.90      0.97      0.93       901\n","          11       0.86      1.00      0.92      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       0.14      0.02      0.04        43\n","          15       0.95      0.85      0.90      2778\n","          16       0.88      0.77      0.82      1151\n","          17       0.84      0.63      0.72        41\n","          18       0.81      0.91      0.85        32\n","          19       0.00      0.00      0.00        40\n","          20       0.90      0.93      0.92       584\n","          21       0.00      0.00      0.00        52\n","          22       0.96      0.60      0.74      4175\n","          23       0.56      0.98      0.71      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.83      0.90      0.87       888\n","          26       0.00      0.00      0.00         9\n","          27       0.63      0.97      0.77        69\n","          28       0.98      0.99      0.99      1864\n","          29       0.99      0.95      0.97       344\n","          30       0.83      0.82      0.82      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.66      0.85      0.74        86\n","          34       0.00      0.00      0.00        32\n","          35       0.95      0.96      0.96       474\n","          36       0.00      0.00      0.00       182\n","          37       0.74      0.91      0.81      1592\n","          38       0.39      0.94      0.55       404\n","          39       0.89      0.89      0.89       485\n","          40       0.00      0.00      0.00       573\n","          41       0.84      0.63      0.72       841\n","          42       0.95      0.94      0.95       575\n","          43       0.00      0.00      0.00       152\n","          44       0.00      0.00      0.00        75\n","          46       0.24      0.96      0.39        82\n","          48       0.00      0.03      0.00        79\n","\n","    accuracy                           0.79     28417\n","   macro avg       0.45      0.48      0.45     28417\n","weighted avg       0.80      0.79      0.78     28417\n","\n","Difference 143\n","\n","Loop 26\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0004977917997166514\n","step: 10, loss: 0.02954634465277195\n","step: 20, loss: 4.209235339658335e-05\n","step: 30, loss: 0.033331483602523804\n","step: 40, loss: 0.002945945831015706\n","step: 50, loss: 0.0008201319142244756\n","step: 60, loss: 0.009333676658570766\n","step: 70, loss: 0.002306651324033737\n","step: 80, loss: 0.00029179040575399995\n","step: 90, loss: 0.007328691892325878\n","step: 100, loss: 0.0002389443980064243\n","step: 110, loss: 0.0002876444486901164\n","step: 120, loss: 0.0324653796851635\n","acc=0.79\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      1.00      0.99      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       0.97      0.98      0.97       689\n","          10       0.90      0.97      0.93       901\n","          11       0.83      1.00      0.91      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       0.00      0.00      0.00        43\n","          15       0.90      0.86      0.88      2778\n","          16       0.87      0.77      0.82      1151\n","          17       0.76      0.46      0.58        41\n","          18       0.80      0.88      0.84        32\n","          19       0.00      0.00      0.00        40\n","          20       0.91      0.92      0.92       584\n","          21       0.00      0.00      0.00        52\n","          22       0.93      0.62      0.75      4175\n","          23       0.56      0.99      0.72      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.83      0.91      0.87       888\n","          26       0.00      0.00      0.00         9\n","          27       0.35      0.97      0.51        69\n","          28       0.99      0.99      0.99      1864\n","          29       0.99      0.97      0.98       344\n","          30       0.87      0.82      0.84      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.65      0.84      0.73        86\n","          34       0.00      0.00      0.00        32\n","          35       0.99      0.64      0.77       474\n","          36       0.00      0.00      0.00       182\n","          37       0.82      0.85      0.84      1592\n","          38       0.39      0.95      0.55       404\n","          39       0.92      0.89      0.90       485\n","          40       0.00      0.00      0.00       573\n","          41       0.85      0.69      0.76       841\n","          42       0.97      0.94      0.96       575\n","          43       0.00      0.00      0.00       152\n","          44       0.00      0.00      0.00        75\n","          46       0.24      0.96      0.39        82\n","          48       0.00      0.00      0.00        79\n","\n","    accuracy                           0.79     28417\n","   macro avg       0.44      0.47      0.44     28417\n","weighted avg       0.80      0.79      0.78     28417\n","\n","Difference 153\n","\n","Loop 27\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0005177974235266447\n","step: 10, loss: 0.03319662809371948\n","step: 20, loss: 3.329127503093332e-05\n","step: 30, loss: 0.2377188801765442\n","step: 40, loss: 0.0006608421099372208\n","step: 50, loss: 0.015576423145830631\n","step: 60, loss: 0.04358535259962082\n","step: 70, loss: 0.05708160996437073\n","step: 80, loss: 0.0025829218793660402\n","step: 90, loss: 0.04733771085739136\n","step: 100, loss: 0.02090931124985218\n","step: 110, loss: 0.0302644781768322\n","step: 120, loss: 0.009249347262084484\n","acc=0.79\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      1.00      0.99      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.89      0.96      0.93       901\n","          11       0.87      1.00      0.93      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       0.00      0.00      0.00        43\n","          15       0.92      0.86      0.89      2778\n","          16       0.89      0.76      0.82      1151\n","          17       0.96      0.63      0.76        41\n","          18       0.85      0.88      0.86        32\n","          19       0.00      0.00      0.00        40\n","          20       0.81      0.92      0.86       584\n","          21       0.00      0.00      0.00        52\n","          22       0.96      0.59      0.73      4175\n","          23       0.53      0.99      0.69      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.85      0.87      0.86       888\n","          26       0.00      0.00      0.00         9\n","          27       0.41      0.96      0.57        69\n","          28       0.99      0.99      0.99      1864\n","          29       0.99      0.97      0.98       344\n","          30       0.78      0.85      0.81      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.65      0.88      0.75        86\n","          34       0.00      0.00      0.00        32\n","          35       0.99      0.77      0.87       474\n","          36       0.00      0.00      0.00       182\n","          37       0.79      0.89      0.84      1592\n","          38       0.37      0.94      0.53       404\n","          39       0.90      0.90      0.90       485\n","          40       0.00      0.00      0.00       573\n","          41       0.86      0.65      0.74       841\n","          42       0.97      0.96      0.97       575\n","          43       0.00      0.00      0.00       152\n","          44       0.00      0.00      0.00        75\n","          46       0.33      0.96      0.49        82\n","          48       0.00      0.00      0.00        79\n","\n","    accuracy                           0.79     28417\n","   macro avg       0.45      0.48      0.45     28417\n","weighted avg       0.80      0.79      0.78     28417\n","\n","Difference 203\n","\n","Loop 28\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0010071409633383155\n","step: 10, loss: 0.0070516993291676044\n","step: 20, loss: 0.00011799923231592402\n","step: 30, loss: 0.08241922408342361\n","step: 40, loss: 0.013484875671565533\n","step: 50, loss: 0.000510869431309402\n","step: 60, loss: 0.00036850059404969215\n","step: 70, loss: 0.0025830038357526064\n","step: 80, loss: 0.020567690953612328\n","step: 90, loss: 0.10950694233179092\n","step: 100, loss: 0.22172577679157257\n","step: 110, loss: 0.04021845757961273\n","step: 120, loss: 0.0026199757121503353\n","acc=0.77\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      1.00      0.99      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.87      0.97      0.92       901\n","          11       0.87      1.00      0.93      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       0.00      0.00      0.00        43\n","          15       0.89      0.86      0.87      2778\n","          16       0.90      0.68      0.78      1151\n","          17       0.86      0.29      0.44        41\n","          18       0.82      0.88      0.85        32\n","          19       0.00      0.00      0.00        40\n","          20       0.88      0.92      0.90       584\n","          21       0.00      0.00      0.00        52\n","          22       0.96      0.53      0.68      4175\n","          23       0.46      0.99      0.63      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.86      0.84      0.85       888\n","          26       0.00      0.00      0.00         9\n","          27       0.59      0.88      0.71        69\n","          28       0.99      0.99      0.99      1864\n","          29       0.99      0.97      0.98       344\n","          30       0.81      0.82      0.82      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.62      0.88      0.73        86\n","          34       0.00      0.00      0.00        32\n","          35       0.99      0.63      0.77       474\n","          36       0.00      0.00      0.00       182\n","          37       0.83      0.82      0.83      1592\n","          38       0.38      0.96      0.54       404\n","          39       0.96      0.85      0.90       485\n","          40       0.00      0.00      0.00       573\n","          41       0.83      0.78      0.80       841\n","          42       0.93      0.97      0.95       575\n","          43       0.00      0.00      0.00       152\n","          44       0.00      0.00      0.00        75\n","          46       0.29      0.96      0.45        82\n","          48       0.01      0.20      0.03        79\n","\n","    accuracy                           0.77     28417\n","   macro avg       0.45      0.47      0.44     28417\n","weighted avg       0.80      0.77      0.76     28417\n","\n","Difference 111\n","\n","Loop 29\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.016575973480939865\n","step: 10, loss: 0.032702282071113586\n","step: 20, loss: 0.0004798737063538283\n","step: 30, loss: 0.0016858256421983242\n","step: 40, loss: 0.014789010398089886\n","step: 50, loss: 0.011650783009827137\n","step: 60, loss: 0.0027567606884986162\n","step: 70, loss: 0.006160615012049675\n","step: 80, loss: 0.006921173073351383\n","step: 90, loss: 0.13318081200122833\n","step: 100, loss: 0.013841073028743267\n","step: 110, loss: 0.04211258515715599\n","step: 120, loss: 0.0037905878853052855\n","acc=0.78\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.88      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      1.00      0.99      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.90      0.96      0.93       901\n","          11       0.88      1.00      0.93      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       0.00      0.00      0.00        43\n","          15       0.88      0.85      0.87      2778\n","          16       0.89      0.75      0.81      1151\n","          17       0.43      0.98      0.60        41\n","          18       0.00      0.00      0.00        32\n","          19       0.00      0.00      0.00        40\n","          20       0.55      0.96      0.70       584\n","          21       0.00      0.00      0.00        52\n","          22       0.93      0.62      0.74      4175\n","          23       0.56      0.98      0.72      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.83      0.90      0.86       888\n","          26       0.00      0.00      0.00         9\n","          27       0.92      0.51      0.65        69\n","          28       0.99      0.97      0.98      1864\n","          29       0.99      0.96      0.98       344\n","          30       0.86      0.78      0.81      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.58      0.88      0.70        86\n","          34       0.00      0.00      0.00        32\n","          35       0.99      0.28      0.44       474\n","          36       0.00      0.00      0.00       182\n","          37       0.84      0.74      0.79      1592\n","          38       0.40      0.88      0.55       404\n","          39       0.95      0.89      0.92       485\n","          40       0.00      0.00      0.00       573\n","          41       0.74      0.81      0.78       841\n","          42       0.94      0.96      0.95       575\n","          43       0.00      0.00      0.00       152\n","          44       0.00      0.00      0.00        75\n","          46       0.33      0.96      0.49        82\n","          48       0.05      0.94      0.09        79\n","\n","    accuracy                           0.78     28417\n","   macro avg       0.42      0.46      0.42     28417\n","weighted avg       0.79      0.78      0.77     28417\n","\n","Difference 380\n","\n","Loop 30\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0013657439267262816\n","step: 10, loss: 0.0020326757803559303\n","step: 20, loss: 0.00018439849372953176\n","step: 30, loss: 0.0003227913985028863\n","step: 40, loss: 0.025022298097610474\n","step: 50, loss: 0.046384770423173904\n","step: 60, loss: 0.00027418817626312375\n","step: 70, loss: 0.0018380747642368078\n","step: 80, loss: 0.002300563035532832\n","step: 90, loss: 0.027200017124414444\n","step: 100, loss: 0.0012902687303721905\n","step: 110, loss: 0.0003346318262629211\n","step: 120, loss: 0.00948044378310442\n","acc=0.77\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      1.00      0.99      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.91      0.96      0.93       901\n","          11       0.88      1.00      0.93      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       0.00      0.00      0.00        43\n","          15       0.91      0.84      0.88      2778\n","          16       0.90      0.73      0.81      1151\n","          17       0.50      0.98      0.66        41\n","          18       0.83      0.16      0.26        32\n","          19       0.00      0.00      0.00        40\n","          20       0.59      0.98      0.74       584\n","          21       0.00      0.00      0.00        52\n","          22       0.90      0.63      0.74      4175\n","          23       0.56      0.98      0.71      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.85      0.84      0.84       888\n","          26       0.00      0.00      0.00         9\n","          27       0.73      0.67      0.70        69\n","          28       0.99      0.99      0.99      1864\n","          29       0.99      0.96      0.98       344\n","          30       0.87      0.77      0.82      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.55      0.88      0.68        86\n","          34       0.00      0.00      0.00        32\n","          35       0.00      0.00      0.00       474\n","          36       0.00      0.00      0.00       182\n","          37       0.85      0.72      0.78      1592\n","          38       0.39      0.93      0.55       404\n","          39       0.95      0.90      0.92       485\n","          40       0.00      0.00      0.00       573\n","          41       0.80      0.73      0.76       841\n","          42       0.95      0.96      0.96       575\n","          43       0.00      0.00      0.00       152\n","          44       0.00      0.00      0.00        75\n","          46       0.26      0.96      0.41        82\n","          48       0.04      0.95      0.08        79\n","\n","    accuracy                           0.77     28417\n","   macro avg       0.42      0.46      0.41     28417\n","weighted avg       0.78      0.77      0.76     28417\n","\n","Difference 379\n","\n","Loop 31\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0028152037411928177\n","step: 10, loss: 0.0017519494285807014\n","step: 20, loss: 0.01880670338869095\n","step: 30, loss: 0.0005599940777756274\n","step: 40, loss: 0.0005414332845248282\n","step: 50, loss: 0.0548265315592289\n","step: 60, loss: 0.0036892134230583906\n","step: 70, loss: 0.003410660196095705\n","step: 80, loss: 0.002557694911956787\n","step: 90, loss: 0.00022828906367067248\n","step: 100, loss: 0.0003519410383887589\n","step: 110, loss: 0.002024466870352626\n","step: 120, loss: 0.04587556794285774\n","acc=0.77\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      1.00      0.99      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.97      0.99       689\n","          10       0.90      0.96      0.93       901\n","          11       0.87      1.00      0.93      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       0.00      0.00      0.00        43\n","          15       0.84      0.88      0.86      2778\n","          16       0.85      0.75      0.80      1151\n","          17       0.46      0.93      0.61        41\n","          18       1.00      0.16      0.27        32\n","          19       0.00      0.00      0.00        40\n","          20       0.66      0.91      0.77       584\n","          21       0.00      0.00      0.00        52\n","          22       0.88      0.62      0.73      4175\n","          23       0.55      0.99      0.71      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.84      0.83      0.84       888\n","          26       0.00      0.00      0.00         9\n","          27       0.40      0.96      0.56        69\n","          28       0.99      0.99      0.99      1864\n","          29       0.99      0.97      0.98       344\n","          30       0.81      0.83      0.82      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.64      0.88      0.75        86\n","          34       0.00      0.00      0.00        32\n","          35       0.00      0.00      0.00       474\n","          36       0.00      0.00      0.00       182\n","          37       0.83      0.74      0.78      1592\n","          38       0.40      0.92      0.55       404\n","          39       0.98      0.80      0.88       485\n","          40       0.00      0.00      0.00       573\n","          41       0.81      0.73      0.76       841\n","          42       0.97      0.88      0.92       575\n","          43       0.00      0.00      0.00       152\n","          44       0.00      0.00      0.00        75\n","          46       0.30      0.96      0.46        82\n","          48       0.06      0.92      0.10        79\n","\n","    accuracy                           0.77     28417\n","   macro avg       0.41      0.46      0.41     28417\n","weighted avg       0.76      0.77      0.75     28417\n","\n","Difference 266\n","\n","Loop 32\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.000545468763448298\n","step: 10, loss: 0.0001142449546023272\n","step: 20, loss: 0.0015717378119006753\n","step: 30, loss: 0.004404098726809025\n","step: 40, loss: 0.007321551442146301\n","step: 50, loss: 0.0005920419935137033\n","step: 60, loss: 0.003070944221690297\n","step: 70, loss: 0.0001709163043415174\n","step: 80, loss: 4.392644405015744e-05\n","step: 90, loss: 0.023758869618177414\n","step: 100, loss: 0.00016968592535704374\n","step: 110, loss: 0.00023351078561972827\n","step: 120, loss: 6.86427520122379e-05\n","acc=0.77\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      1.00      0.99      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.91      0.97      0.94       901\n","          11       0.87      1.00      0.93      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       0.00      0.00      0.00        43\n","          15       0.81      0.88      0.84      2778\n","          16       0.82      0.77      0.80      1151\n","          17       0.42      0.98      0.58        41\n","          18       0.00      0.00      0.00        32\n","          19       0.00      0.00      0.00        40\n","          20       0.89      0.92      0.91       584\n","          21       0.00      0.00      0.00        52\n","          22       0.84      0.64      0.72      4175\n","          23       0.58      0.98      0.73      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.83      0.85      0.84       888\n","          26       0.00      0.00      0.00         9\n","          27       0.41      0.96      0.57        69\n","          28       0.97      0.99      0.98      1864\n","          29       0.99      0.90      0.94       344\n","          30       0.82      0.83      0.82      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.64      0.88      0.74        86\n","          34       0.00      0.00      0.00        32\n","          35       0.00      0.00      0.00       474\n","          36       0.00      0.00      0.00       182\n","          37       0.83      0.69      0.75      1592\n","          38       0.40      0.94      0.56       404\n","          39       0.97      0.82      0.89       485\n","          40       0.00      0.00      0.00       573\n","          41       0.81      0.77      0.79       841\n","          42       0.96      0.89      0.92       575\n","          43       0.00      0.00      0.00       152\n","          44       0.00      0.00      0.00        75\n","          46       0.31      0.96      0.46        82\n","          48       0.06      0.95      0.10        79\n","\n","    accuracy                           0.77     28417\n","   macro avg       0.39      0.46      0.41     28417\n","weighted avg       0.76      0.77      0.76     28417\n","\n","Difference 235\n","\n","Loop 33\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.00015272837481461465\n","step: 10, loss: 0.04839107394218445\n","step: 20, loss: 0.0011774919694289565\n","step: 30, loss: 0.004344264045357704\n","step: 40, loss: 0.0012028469936922193\n","step: 50, loss: 0.0005115706590004265\n","step: 60, loss: 0.020032644271850586\n","step: 70, loss: 8.057302329689264e-05\n","step: 80, loss: 0.0038571993354707956\n","step: 90, loss: 0.0004929816350340843\n","step: 100, loss: 0.02424832247197628\n","step: 110, loss: 0.0032581898849457502\n","step: 120, loss: 0.00020929283346049488\n","acc=0.77\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      1.00      0.99      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.89      0.96      0.93       901\n","          11       0.80      1.00      0.89      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       0.00      0.00      0.00        43\n","          15       0.79      0.87      0.83      2778\n","          16       0.84      0.76      0.80      1151\n","          17       0.43      0.98      0.60        41\n","          18       0.00      0.00      0.00        32\n","          19       0.00      0.00      0.00        40\n","          20       0.84      0.93      0.88       584\n","          21       0.00      0.00      0.00        52\n","          22       0.87      0.65      0.75      4175\n","          23       0.64      0.90      0.75      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.77      0.86      0.81       888\n","          26       0.00      0.00      0.00         9\n","          27       0.40      0.96      0.56        69\n","          28       0.94      0.99      0.97      1864\n","          29       0.99      0.95      0.97       344\n","          30       0.80      0.82      0.81      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.62      0.88      0.73        86\n","          34       0.00      0.00      0.00        32\n","          35       0.00      0.00      0.00       474\n","          36       0.00      0.00      0.00       182\n","          37       0.82      0.71      0.76      1592\n","          38       0.39      0.95      0.55       404\n","          39       0.95      0.88      0.91       485\n","          40       0.00      0.00      0.00       573\n","          41       0.74      0.79      0.76       841\n","          42       0.96      0.90      0.93       575\n","          43       0.00      0.00      0.00       152\n","          44       0.00      0.00      0.00        75\n","          46       0.33      0.96      0.49        82\n","          48       0.06      0.94      0.11        79\n","\n","    accuracy                           0.77     28417\n","   macro avg       0.39      0.47      0.41     28417\n","weighted avg       0.75      0.77      0.75     28417\n","\n","Difference 137\n","\n","Loop 34\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0008139641140587628\n","step: 10, loss: 0.0008636076818220317\n","step: 20, loss: 1.494229945819825e-05\n","step: 30, loss: 9.86256345640868e-05\n","step: 40, loss: 0.009432358667254448\n","step: 50, loss: 0.00017093453789129853\n","step: 60, loss: 0.008728325366973877\n","step: 70, loss: 0.06149570271372795\n","step: 80, loss: 0.0053320336155593395\n","step: 90, loss: 0.0003853078233078122\n","step: 100, loss: 0.0006039075087755919\n","step: 110, loss: 0.0006465945043601096\n","step: 120, loss: 0.000697391398716718\n","acc=0.71\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      1.00      0.99      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.87      0.97      0.92       901\n","          11       0.87      0.99      0.93      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       0.00      0.00      0.00        43\n","          15       0.81      0.86      0.83      2778\n","          16       0.84      0.76      0.80      1151\n","          17       0.42      0.93      0.58        41\n","          18       0.00      0.00      0.00        32\n","          19       0.00      0.00      0.00        40\n","          20       0.79      0.92      0.85       584\n","          21       0.00      0.00      0.00        52\n","          22       0.73      0.29      0.42      4175\n","          23       0.59      0.95      0.73      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.28      0.91      0.43       888\n","          26       0.00      0.00      0.00         9\n","          27       0.39      0.96      0.55        69\n","          28       0.98      0.99      0.98      1864\n","          29       0.99      0.94      0.97       344\n","          30       0.81      0.81      0.81      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.63      0.88      0.73        86\n","          34       0.00      0.00      0.00        32\n","          35       0.00      0.00      0.00       474\n","          36       0.00      0.00      0.00       182\n","          37       0.82      0.55      0.66      1592\n","          38       0.37      0.96      0.53       404\n","          39       0.99      0.74      0.85       485\n","          40       0.00      0.00      0.00       573\n","          41       0.78      0.73      0.76       841\n","          42       0.97      0.87      0.92       575\n","          43       0.00      0.00      0.00       152\n","          44       0.00      0.00      0.00        75\n","          46       0.32      0.96      0.48        82\n","          48       0.06      0.91      0.11        79\n","\n","    accuracy                           0.71     28417\n","   macro avg       0.38      0.45      0.38     28417\n","weighted avg       0.72      0.71      0.69     28417\n","\n","Difference 179\n","\n","Loop 35\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0007345068152062595\n","step: 10, loss: 0.00010018319881055504\n","step: 20, loss: 0.04650156944990158\n","step: 30, loss: 0.0013556343037635088\n","step: 40, loss: 0.0085433479398489\n","step: 50, loss: 0.00036880202242173254\n","step: 60, loss: 0.004844686482101679\n","step: 70, loss: 0.0119352200999856\n","step: 80, loss: 0.0020556466188281775\n","step: 90, loss: 0.0002638873993419111\n","step: 100, loss: 0.004106494598090649\n","step: 110, loss: 0.024753311648964882\n","step: 120, loss: 0.0026578272227197886\n","acc=0.72\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.88      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      1.00      0.99      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.97      0.98       689\n","          10       0.87      0.97      0.92       901\n","          11       0.87      1.00      0.93      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       0.00      0.00      0.00        43\n","          15       0.86      0.86      0.86      2778\n","          16       0.87      0.72      0.79      1151\n","          17       0.39      0.98      0.56        41\n","          18       0.00      0.00      0.00        32\n","          19       0.00      0.00      0.00        40\n","          20       0.67      0.95      0.79       584\n","          21       0.00      0.00      0.00        52\n","          22       0.80      0.45      0.58      4175\n","          23       0.62      0.96      0.76      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.39      0.90      0.54       888\n","          26       0.00      0.00      0.00         9\n","          27       0.41      0.96      0.58        69\n","          28       0.97      0.99      0.98      1864\n","          29       0.99      0.95      0.97       344\n","          30       0.80      0.83      0.81      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.63      0.88      0.74        86\n","          34       0.00      0.00      0.00        32\n","          35       0.00      0.00      0.00       474\n","          36       0.00      0.00      0.00       182\n","          37       0.76      0.33      0.46      1592\n","          38       0.24      0.95      0.39       404\n","          39       0.97      0.72      0.83       485\n","          40       0.00      0.00      0.00       573\n","          41       0.77      0.76      0.76       841\n","          42       0.88      0.89      0.88       575\n","          43       0.00      0.00      0.00       152\n","          44       0.00      0.00      0.00        75\n","          46       0.28      0.96      0.43        82\n","          48       0.06      0.94      0.11        79\n","\n","    accuracy                           0.72     28417\n","   macro avg       0.37      0.45      0.38     28417\n","weighted avg       0.73      0.72      0.70     28417\n","\n","Difference 129\n","\n","Loop 36\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0007292320369742811\n","step: 10, loss: 7.214045035652816e-05\n","step: 20, loss: 0.0006482275784946978\n","step: 30, loss: 0.027215808629989624\n","step: 40, loss: 0.00043669965816661716\n","step: 50, loss: 0.06777026504278183\n","step: 60, loss: 0.00976582057774067\n","step: 70, loss: 0.0003402070142328739\n","step: 80, loss: 0.000653656548820436\n","step: 90, loss: 0.00029606505995616317\n","step: 100, loss: 0.0528004914522171\n","step: 110, loss: 0.0002899453102145344\n","step: 120, loss: 0.011384857818484306\n","acc=0.71\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      1.00      0.99      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.91      0.97      0.94       901\n","          11       0.87      1.00      0.93      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       0.00      0.00      0.00        43\n","          15       0.89      0.86      0.87      2778\n","          16       0.86      0.74      0.80      1151\n","          17       0.40      0.93      0.56        41\n","          18       0.00      0.00      0.00        32\n","          19       0.00      0.00      0.00        40\n","          20       0.55      0.95      0.70       584\n","          21       0.00      0.00      0.00        52\n","          22       0.94      0.30      0.46      4175\n","          23       0.57      0.90      0.70      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.39      0.87      0.54       888\n","          26       0.00      0.00      0.00         9\n","          27       0.42      0.96      0.58        69\n","          28       0.96      0.99      0.97      1864\n","          29       0.99      0.96      0.97       344\n","          30       0.79      0.82      0.80      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.64      0.88      0.74        86\n","          34       0.00      0.00      0.00        32\n","          35       0.00      0.00      0.00       474\n","          36       0.00      0.00      0.00       182\n","          37       0.81      0.43      0.57      1592\n","          38       0.23      0.95      0.37       404\n","          39       0.89      0.89      0.89       485\n","          40       0.00      0.00      0.00       573\n","          41       0.59      0.82      0.68       841\n","          42       0.65      0.89      0.75       575\n","          43       0.00      0.00      0.00       152\n","          44       0.00      0.00      0.00        75\n","          46       0.27      0.96      0.43        82\n","          48       0.05      0.85      0.10        79\n","\n","    accuracy                           0.71     28417\n","   macro avg       0.36      0.45      0.37     28417\n","weighted avg       0.74      0.71      0.68     28417\n","\n","Difference 156\n","\n","Loop 37\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.02135167084634304\n","step: 10, loss: 0.0016375420382246375\n","step: 20, loss: 0.0003332053602207452\n","step: 30, loss: 0.0008371360599994659\n","step: 40, loss: 0.0048938835971057415\n","step: 50, loss: 8.492212509736419e-05\n","step: 60, loss: 0.015706395730376244\n","step: 70, loss: 0.00027823742129839957\n","step: 80, loss: 0.0009819823317229748\n","step: 90, loss: 0.021717093884944916\n","step: 100, loss: 0.0448467880487442\n","step: 110, loss: 0.011304287239909172\n","step: 120, loss: 0.001026290818117559\n","acc=0.67\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      1.00      0.99      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.88      0.97      0.92       901\n","          11       0.87      1.00      0.93      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       0.00      0.00      0.00        43\n","          15       0.85      0.87      0.86      2778\n","          16       0.88      0.67      0.76      1151\n","          17       0.37      0.73      0.49        41\n","          18       0.00      0.00      0.00        32\n","          19       0.00      0.00      0.00        40\n","          20       0.64      0.95      0.77       584\n","          21       0.00      0.00      0.00        52\n","          22       0.93      0.10      0.18      4175\n","          23       0.59      0.94      0.73      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.25      0.89      0.39       888\n","          26       0.00      0.00      0.00         9\n","          27       0.45      0.96      0.61        69\n","          28       0.92      0.99      0.95      1864\n","          29       0.99      0.80      0.89       344\n","          30       0.79      0.80      0.79      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.62      0.88      0.73        86\n","          34       0.00      0.00      0.00        32\n","          35       0.00      0.00      0.00       474\n","          36       0.00      0.00      0.00       182\n","          37       0.81      0.50      0.62      1592\n","          38       0.20      0.96      0.33       404\n","          39       0.92      0.75      0.83       485\n","          40       0.00      0.00      0.00       573\n","          41       0.68      0.78      0.73       841\n","          42       0.95      0.85      0.90       575\n","          43       0.00      0.00      0.00       152\n","          44       0.00      0.00      0.00        75\n","          46       0.32      0.96      0.48        82\n","          48       0.05      0.72      0.09        79\n","\n","    accuracy                           0.67     28417\n","   macro avg       0.37      0.43      0.37     28417\n","weighted avg       0.74      0.67      0.64     28417\n","\n","Difference 115\n","\n","Loop 38\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.00010754972754511982\n","step: 10, loss: 8.942324348026887e-05\n","step: 20, loss: 0.03460247442126274\n","step: 30, loss: 0.03405620530247688\n","step: 40, loss: 0.005569367669522762\n","step: 50, loss: 0.002901526400819421\n","step: 60, loss: 0.001123642548918724\n","step: 70, loss: 0.0006395744276233017\n","step: 80, loss: 0.0004826091171707958\n","step: 90, loss: 0.017116356641054153\n","step: 100, loss: 0.00046189597924239933\n","step: 110, loss: 0.0010726653272286057\n","step: 120, loss: 0.0002635673154145479\n","acc=0.64\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.78      0.88      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      1.00      0.99      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.90      0.97      0.93       901\n","          11       0.86      1.00      0.92      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       0.00      0.00      0.00        43\n","          15       0.86      0.87      0.87      2778\n","          16       0.87      0.64      0.74      1151\n","          17       0.34      0.63      0.44        41\n","          18       0.00      0.00      0.00        32\n","          19       0.00      0.00      0.00        40\n","          20       0.64      0.94      0.76       584\n","          21       0.00      0.00      0.00        52\n","          22       0.95      0.05      0.10      4175\n","          23       0.64      0.90      0.75      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.23      0.89      0.36       888\n","          26       0.00      0.00      0.00         9\n","          27       0.43      0.96      0.59        69\n","          28       0.97      0.99      0.98      1864\n","          29       0.99      0.95      0.97       344\n","          30       0.73      0.82      0.77      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.63      0.88      0.74        86\n","          34       0.00      0.00      0.00        32\n","          35       0.00      0.00      0.00       474\n","          36       0.00      0.00      0.00       182\n","          37       0.74      0.26      0.39      1592\n","          38       0.14      0.96      0.25       404\n","          39       0.90      0.19      0.31       485\n","          40       0.00      0.00      0.00       573\n","          41       0.60      0.82      0.69       841\n","          42       0.97      0.86      0.91       575\n","          43       0.00      0.00      0.00       152\n","          44       0.00      0.00      0.00        75\n","          46       0.31      0.96      0.47        82\n","          48       0.06      0.95      0.11        79\n","\n","    accuracy                           0.64     28417\n","   macro avg       0.36      0.42      0.35     28417\n","weighted avg       0.74      0.64      0.61     28417\n","\n","Difference 117\n","\n","Loop 39\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.00044969026930630207\n","step: 10, loss: 5.198235157877207e-05\n","step: 20, loss: 0.04548604041337967\n","step: 30, loss: 4.0741459088167176e-05\n","step: 40, loss: 2.1745177946286276e-05\n","step: 50, loss: 0.015780162066221237\n","step: 60, loss: 0.004085850436240435\n","step: 70, loss: 0.00015892232477199286\n","step: 80, loss: 0.00025628379080444574\n","step: 90, loss: 0.00040370746864937246\n","step: 100, loss: 0.0002908848109655082\n","step: 110, loss: 0.0014689781237393618\n","step: 120, loss: 0.0005480772233568132\n","acc=0.66\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      1.00      0.99      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.90      0.96      0.93       901\n","          11       0.86      1.00      0.92      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       0.00      0.00      0.00        43\n","          15       0.86      0.87      0.87      2778\n","          16       0.89      0.65      0.75      1151\n","          17       0.40      0.93      0.56        41\n","          18       0.00      0.00      0.00        32\n","          19       0.00      0.00      0.00        40\n","          20       0.62      0.94      0.75       584\n","          21       0.00      0.00      0.00        52\n","          22       0.85      0.04      0.07      4175\n","          23       0.58      0.97      0.73      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.21      0.89      0.35       888\n","          26       0.00      0.00      0.00         9\n","          27       0.42      0.99      0.59        69\n","          28       0.96      0.99      0.97      1864\n","          29       0.99      0.95      0.97       344\n","          30       0.78      0.80      0.79      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.62      0.88      0.73        86\n","          34       0.00      0.00      0.00        32\n","          35       0.00      0.00      0.00       474\n","          36       0.00      0.00      0.00       182\n","          37       0.72      0.21      0.33      1592\n","          38       0.23      0.94      0.37       404\n","          39       0.95      0.83      0.88       485\n","          40       0.00      0.00      0.00       573\n","          41       0.53      0.85      0.65       841\n","          42       0.96      0.88      0.92       575\n","          43       0.00      0.00      0.00       152\n","          44       0.00      0.00      0.00        75\n","          46       0.32      0.96      0.48        82\n","          48       0.06      0.95      0.11        79\n","\n","    accuracy                           0.66     28417\n","   macro avg       0.36      0.44      0.36     28417\n","weighted avg       0.72      0.66      0.61     28417\n","\n","Difference 107\n","\n","Loop 40\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.018151281401515007\n","step: 10, loss: 0.03217441216111183\n","step: 20, loss: 6.275939813349396e-05\n","step: 30, loss: 8.578232518630102e-05\n","step: 40, loss: 0.0006847789045423269\n","step: 50, loss: 0.042631711810827255\n","step: 60, loss: 0.0854063481092453\n","step: 70, loss: 0.00038552412297576666\n","step: 80, loss: 0.08459026366472244\n","step: 90, loss: 0.037283364683389664\n","step: 100, loss: 0.0014226383063942194\n","step: 110, loss: 0.029169246554374695\n","step: 120, loss: 0.018296828493475914\n","acc=0.65\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      1.00      0.99      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.90      0.97      0.93       901\n","          11       0.85      1.00      0.92      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       0.00      0.00      0.00        43\n","          15       0.88      0.86      0.87      2778\n","          16       0.88      0.59      0.71      1151\n","          17       0.28      0.95      0.44        41\n","          18       0.00      0.00      0.00        32\n","          19       0.00      0.00      0.00        40\n","          20       0.61      0.96      0.74       584\n","          21       0.00      0.00      0.00        52\n","          22       0.85      0.02      0.03      4175\n","          23       0.61      0.96      0.75      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.19      0.88      0.32       888\n","          26       0.00      0.00      0.00         9\n","          27       0.49      0.96      0.65        69\n","          28       0.97      0.99      0.98      1864\n","          29       0.98      0.99      0.98       344\n","          30       0.79      0.81      0.80      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.62      0.88      0.73        86\n","          34       0.00      0.00      0.00        32\n","          35       0.00      0.00      0.00       474\n","          36       0.00      0.00      0.00       182\n","          37       0.65      0.16      0.25      1592\n","          38       0.22      0.95      0.36       404\n","          39       0.95      0.78      0.86       485\n","          40       0.00      0.00      0.00       573\n","          41       0.52      0.81      0.63       841\n","          42       0.96      0.88      0.92       575\n","          43       0.00      0.00      0.00       152\n","          44       0.00      0.00      0.00        75\n","          46       0.28      0.96      0.43        82\n","          48       0.06      0.95      0.11        79\n","\n","    accuracy                           0.65     28417\n","   macro avg       0.36      0.44      0.35     28417\n","weighted avg       0.72      0.65      0.60     28417\n","\n","Difference 233\n","\n","Loop 41\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0013775428524240851\n","step: 10, loss: 0.0016021758783608675\n","step: 20, loss: 6.121214391896501e-05\n","step: 30, loss: 4.582287510856986e-05\n","step: 40, loss: 0.00015014098607935011\n","step: 50, loss: 0.0007945807301439345\n","step: 60, loss: 0.0013509126147255301\n","step: 70, loss: 0.0007146587013266981\n","step: 80, loss: 0.11031518131494522\n","step: 90, loss: 0.004089838825166225\n","step: 100, loss: 0.010153373703360558\n","step: 110, loss: 0.0047484044916927814\n","step: 120, loss: 0.0005022898549214005\n","acc=0.64\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      1.00      0.99      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.97      0.99       689\n","          10       0.86      0.97      0.91       901\n","          11       0.84      1.00      0.91      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       0.00      0.00      0.00        43\n","          15       0.88      0.85      0.86      2778\n","          16       0.90      0.47      0.62      1151\n","          17       0.40      0.98      0.56        41\n","          18       0.00      0.00      0.00        32\n","          19       0.00      0.00      0.00        40\n","          20       0.61      0.96      0.74       584\n","          21       0.00      0.00      0.00        52\n","          22       0.94      0.01      0.02      4175\n","          23       0.60      0.95      0.74      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.19      0.91      0.32       888\n","          26       0.00      0.00      0.00         9\n","          27       0.47      0.97      0.64        69\n","          28       0.97      0.99      0.98      1864\n","          29       0.99      0.94      0.97       344\n","          30       0.77      0.80      0.79      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.64      0.88      0.74        86\n","          34       0.00      0.00      0.00        32\n","          35       0.00      0.00      0.00       474\n","          36       0.00      0.00      0.00       182\n","          37       0.68      0.18      0.28      1592\n","          38       0.28      0.94      0.43       404\n","          39       0.81      0.86      0.84       485\n","          40       0.00      0.00      0.00       573\n","          41       0.51      0.82      0.63       841\n","          42       0.87      0.89      0.88       575\n","          43       0.00      0.00      0.00       152\n","          44       0.00      0.00      0.00        75\n","          46       0.25      0.96      0.39        82\n","          48       0.05      0.94      0.10        79\n","\n","    accuracy                           0.64     28417\n","   macro avg       0.36      0.44      0.35     28417\n","weighted avg       0.73      0.64      0.59     28417\n","\n","Difference 197\n","\n","Loop 42\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.00020372147264424711\n","step: 10, loss: 5.3386629588203505e-05\n","step: 20, loss: 0.00010221704724244773\n","step: 30, loss: 6.036189734004438e-05\n","step: 40, loss: 0.012513005174696445\n","step: 50, loss: 6.817427492933348e-05\n","step: 60, loss: 0.00051276502199471\n","step: 70, loss: 0.036204561591148376\n","step: 80, loss: 0.0002435876667732373\n","step: 90, loss: 0.0002445752325002104\n","step: 100, loss: 0.0019979234784841537\n","step: 110, loss: 0.0004963456885889173\n","step: 120, loss: 0.0007622101693414152\n","acc=0.65\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      1.00      0.99      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.82      0.96      0.88       901\n","          11       0.86      1.00      0.92      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       0.00      0.00      0.00        43\n","          15       0.80      0.86      0.83      2778\n","          16       0.88      0.68      0.77      1151\n","          17       0.39      0.98      0.56        41\n","          18       0.00      0.00      0.00        32\n","          19       0.00      0.00      0.00        40\n","          20       0.80      0.91      0.85       584\n","          21       0.00      0.00      0.00        52\n","          22       0.87      0.01      0.03      4175\n","          23       0.58      0.95      0.72      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.21      0.90      0.35       888\n","          26       0.00      0.00      0.00         9\n","          27       0.29      0.90      0.44        69\n","          28       0.91      0.99      0.95      1864\n","          29       0.99      0.94      0.97       344\n","          30       0.73      0.82      0.77      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.63      0.88      0.74        86\n","          34       0.00      0.00      0.00        32\n","          35       0.00      0.00      0.00       474\n","          36       0.00      0.00      0.00       182\n","          37       0.61      0.14      0.22      1592\n","          38       0.29      0.94      0.44       404\n","          39       0.67      0.89      0.76       485\n","          40       0.00      0.00      0.00       573\n","          41       0.57      0.81      0.67       841\n","          42       0.95      0.89      0.92       575\n","          43       0.00      0.00      0.00       152\n","          44       0.00      0.00      0.00        75\n","          46       0.25      0.96      0.40        82\n","          48       0.06      0.94      0.11        79\n","\n","    accuracy                           0.65     28417\n","   macro avg       0.35      0.44      0.35     28417\n","weighted avg       0.71      0.65      0.59     28417\n","\n","Difference 104\n","\n","Loop 43\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.00025159725919365883\n","step: 10, loss: 1.1688079212035518e-05\n","step: 20, loss: 4.8261052143061534e-05\n","step: 30, loss: 0.0004045948153361678\n","step: 40, loss: 0.006188448518514633\n","step: 50, loss: 0.036935124546289444\n","step: 60, loss: 0.00029545417055487633\n","step: 70, loss: 0.026730908080935478\n","step: 80, loss: 0.0006995463627390563\n","step: 90, loss: 0.00011618118151091039\n","step: 100, loss: 2.6908781364909373e-05\n","step: 110, loss: 0.0010555385379120708\n","step: 120, loss: 0.01751183532178402\n","acc=0.64\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       0.99      0.79      0.88      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      1.00      0.99      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.87      0.97      0.92       901\n","          11       0.87      1.00      0.93      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       0.00      0.00      0.00        43\n","          15       0.81      0.87      0.84      2778\n","          16       0.83      0.74      0.78      1151\n","          17       0.38      0.98      0.55        41\n","          18       0.00      0.00      0.00        32\n","          19       0.00      0.00      0.00        40\n","          20       0.84      0.91      0.87       584\n","          21       0.00      0.00      0.00        52\n","          22       0.84      0.01      0.01      4175\n","          23       0.59      0.97      0.73      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.19      0.84      0.30       888\n","          26       0.00      0.00      0.00         9\n","          27       0.31      0.94      0.47        69\n","          28       0.96      0.91      0.94      1864\n","          29       1.00      0.88      0.94       344\n","          30       0.82      0.78      0.80      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.58      0.88      0.70        86\n","          34       0.00      0.00      0.00        32\n","          35       0.00      0.00      0.00       474\n","          36       0.00      0.00      0.00       182\n","          37       0.63      0.15      0.24      1592\n","          38       0.26      0.94      0.40       404\n","          39       0.87      0.86      0.87       485\n","          40       0.00      0.00      0.00       573\n","          41       0.56      0.81      0.66       841\n","          42       0.94      0.88      0.91       575\n","          43       0.00      0.00      0.00       152\n","          44       0.00      0.00      0.00        75\n","          46       0.16      0.96      0.28        82\n","          48       0.06      0.94      0.11        79\n","\n","    accuracy                           0.64     28417\n","   macro avg       0.35      0.43      0.35     28417\n","weighted avg       0.71      0.64      0.59     28417\n","\n","Difference 178\n","\n","Loop 44\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.00014983098662924021\n","step: 10, loss: 1.6711026546545327e-05\n","step: 20, loss: 0.0007905129459686577\n","step: 30, loss: 4.0686907595954835e-05\n","step: 40, loss: 0.002909769769757986\n","step: 50, loss: 0.00031888525700196624\n","step: 60, loss: 0.0019175660563632846\n","step: 70, loss: 0.035877808928489685\n","step: 80, loss: 0.0699293315410614\n","step: 90, loss: 0.004882485140115023\n","step: 100, loss: 0.05677679181098938\n","step: 110, loss: 0.07088552415370941\n","step: 120, loss: 0.005639518611133099\n","acc=0.62\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      1.00      0.99      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.86      0.96      0.91       901\n","          11       0.87      1.00      0.93      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       0.00      0.00      0.00        43\n","          15       0.81      0.87      0.84      2778\n","          16       0.86      0.70      0.77      1151\n","          17       0.40      0.98      0.56        41\n","          18       0.00      0.00      0.00        32\n","          19       0.00      0.00      0.00        40\n","          20       0.87      0.91      0.89       584\n","          21       0.00      0.00      0.00        52\n","          22       0.00      0.00      0.00      4175\n","          23       0.57      0.98      0.72      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.16      0.88      0.26       888\n","          26       0.00      0.00      0.00         9\n","          27       0.31      0.96      0.47        69\n","          28       0.88      0.99      0.93      1864\n","          29       0.99      0.37      0.54       344\n","          30       0.81      0.75      0.78      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.61      0.88      0.72        86\n","          34       0.00      0.00      0.00        32\n","          35       0.00      0.00      0.00       474\n","          36       0.00      0.00      0.00       182\n","          37       0.63      0.14      0.23      1592\n","          38       0.21      0.96      0.34       404\n","          39       0.93      0.86      0.90       485\n","          40       0.00      0.00      0.00       573\n","          41       0.00      0.00      0.00       841\n","          42       0.93      0.91      0.92       575\n","          43       0.00      0.00      0.00       152\n","          44       0.00      0.00      0.00        75\n","          46       0.30      0.96      0.46        82\n","          48       0.06      0.94      0.11        79\n","\n","    accuracy                           0.62     28417\n","   macro avg       0.33      0.41      0.33     28417\n","weighted avg       0.57      0.62      0.56     28417\n","\n","Difference 182\n","\n","Loop 45\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.005760653410106897\n","step: 10, loss: 0.0006994575960561633\n","step: 20, loss: 2.4622780983918346e-05\n","step: 30, loss: 2.5687604647828266e-05\n","step: 40, loss: 7.573742186650634e-05\n","step: 50, loss: 0.0001449817355023697\n","step: 60, loss: 0.008539529517292976\n","step: 70, loss: 0.00047433850704692304\n","step: 80, loss: 0.018287384882569313\n","step: 90, loss: 0.0006411350332200527\n","step: 100, loss: 0.010880562476813793\n","step: 110, loss: 0.04693477228283882\n","step: 120, loss: 9.383283031638712e-05\n","acc=0.62\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      1.00      0.99      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.88      0.97      0.92       901\n","          11       0.87      1.00      0.93      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       0.00      0.00      0.00        43\n","          15       0.82      0.87      0.84      2778\n","          16       0.85      0.70      0.77      1151\n","          17       0.39      0.95      0.56        41\n","          18       0.00      0.00      0.00        32\n","          19       0.00      0.00      0.00        40\n","          20       0.84      0.91      0.87       584\n","          21       0.00      0.00      0.00        52\n","          22       0.00      0.00      0.00      4175\n","          23       0.44      0.98      0.61      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.21      0.83      0.33       888\n","          26       0.00      0.00      0.00         9\n","          27       0.27      0.96      0.43        69\n","          28       0.86      0.99      0.92      1864\n","          29       1.00      0.15      0.27       344\n","          30       0.80      0.78      0.79      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.61      0.88      0.72        86\n","          34       0.00      0.00      0.00        32\n","          35       0.00      0.00      0.00       474\n","          36       0.00      0.00      0.00       182\n","          37       0.70      0.21      0.33      1592\n","          38       0.20      0.96      0.32       404\n","          39       0.88      0.84      0.86       485\n","          40       0.00      0.00      0.00       573\n","          41       0.00      0.00      0.00       841\n","          42       0.90      0.92      0.91       575\n","          43       0.00      0.00      0.00       152\n","          44       0.00      0.00      0.00        75\n","          46       0.29      0.96      0.45        82\n","          48       0.06      0.94      0.11        79\n","\n","    accuracy                           0.62     28417\n","   macro avg       0.32      0.40      0.32     28417\n","weighted avg       0.56      0.62      0.56     28417\n","\n","Difference 132\n","\n","Loop 46\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.00017532783385831863\n","step: 10, loss: 0.051024746149778366\n","step: 20, loss: 5.5708551371935755e-05\n","step: 30, loss: 0.000953280134126544\n","step: 40, loss: 7.535293116234243e-05\n","step: 50, loss: 0.003333193948492408\n","step: 60, loss: 7.234265649458393e-05\n","step: 70, loss: 0.00037084147334098816\n","step: 80, loss: 0.0007136424537748098\n","step: 90, loss: 0.003478387836366892\n","step: 100, loss: 0.0013856963487342\n","step: 110, loss: 9.059809235623106e-05\n","step: 120, loss: 7.087206176947802e-05\n","acc=0.61\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.94      1.00      0.97      1570\n","           7       0.00      0.00      0.00       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.97      0.99       689\n","          10       0.74      0.97      0.84       901\n","          11       0.83      1.00      0.90      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       0.00      0.00      0.00        43\n","          15       0.81      0.87      0.84      2778\n","          16       0.88      0.67      0.76      1151\n","          17       0.40      0.95      0.56        41\n","          18       0.00      0.00      0.00        32\n","          19       0.00      0.00      0.00        40\n","          20       0.86      0.91      0.88       584\n","          21       0.00      0.00      0.00        52\n","          22       0.00      0.00      0.00      4175\n","          23       0.43      0.93      0.59      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.22      0.80      0.35       888\n","          26       0.00      0.00      0.00         9\n","          27       0.17      0.70      0.28        69\n","          28       0.93      0.99      0.96      1864\n","          29       1.00      0.10      0.18       344\n","          30       0.76      0.81      0.79      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.64      0.88      0.75        86\n","          34       0.00      0.00      0.00        32\n","          35       0.00      0.00      0.00       474\n","          36       0.00      0.00      0.00       182\n","          37       0.68      0.23      0.35      1592\n","          38       0.19      0.96      0.32       404\n","          39       0.86      0.85      0.85       485\n","          40       0.00      0.00      0.00       573\n","          41       0.00      0.00      0.00       841\n","          42       0.92      0.91      0.92       575\n","          43       0.00      0.00      0.00       152\n","          44       0.00      0.00      0.00        75\n","          46       0.28      0.96      0.44        82\n","          48       0.05      0.94      0.10        79\n","\n","    accuracy                           0.61     28417\n","   macro avg       0.32      0.40      0.31     28417\n","weighted avg       0.55      0.61      0.55     28417\n","\n","Difference 84\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"cc1ed683-272b-40ff-a4a5-39676d517f24\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"cc1ed683-272b-40ff-a4a5-39676d517f24\")) {                    Plotly.newPlot(                        \"cc1ed683-272b-40ff-a4a5-39676d517f24\",                        [{\"hovertemplate\":\"metric=precision<br>Loop=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"precision\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"markers+lines\",\"name\":\"precision\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46],\"xaxis\":\"x\",\"y\":[0.7945300660402925,0.7932571632500129,0.7828546389926568,0.7574242893413483,0.6912848047720423,0.6649288474349985,0.640098483040588,0.6458777160973413,0.6063220661632226,0.593013371581732,0.5952624147683119,0.6042470551423786,0.5785881994935086,0.5601123679903037,0.5527153046003338,0.5588712040291696,0.5422352447698924,0.5596743428655698,0.5619721936256178,0.5562503704221714,0.5413287927071908,0.529663370404333,0.5267531395730205,0.4997389978542836,0.5077476737579837,0.4488449441828371,0.44024835936607865,0.4465188091947307,0.4475470180640581,0.42243468784818317,0.4170410291012238,0.4128463512281796,0.3936002613051186,0.3877352528526345,0.3754594925314007,0.3710359038277459,0.3622001001523246,0.3677903148930161,0.36387656475051877,0.36291124862916535,0.35873034118188013,0.3584586843076271,0.3509053580224942,0.3548773680637936,0.3267969358368176,0.32313098980358784,0.31771137429446916],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"metric=recall<br>Loop=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"recall\",\"line\":{\"color\":\"#EF553B\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"markers+lines\",\"name\":\"recall\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46],\"xaxis\":\"x\",\"y\":[0.8005920263509698,0.787178276028531,0.7463633560972059,0.7227212436704681,0.648117979139542,0.650742038535805,0.6426840973315924,0.6248877063515141,0.6160267269917278,0.6182472793177295,0.5998107808828077,0.6044419733077648,0.5911724606472254,0.5887233339073871,0.5937388544393106,0.5640583870389068,0.5620610177501064,0.552652651652933,0.5575762293615032,0.5538364251241448,0.5518843763071569,0.5576376751200504,0.536000733746058,0.49193488934844515,0.4733286715604148,0.48219352159427836,0.4707692714228294,0.47755095860041424,0.4660105348336041,0.46387322775497686,0.4624811805702365,0.4646018592031986,0.4635312428575074,0.4654595541823543,0.4489935803180824,0.4500774453793955,0.4500394659621967,0.4315800242566201,0.4187763387773936,0.44041438078016465,0.43658379488256116,0.4354248854761878,0.43734981488622476,0.43460767333505085,0.4081735904819127,0.4036420909363748,0.39551998985857456],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"metric=f1<br>Loop=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"f1\",\"line\":{\"color\":\"#00cc96\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"markers+lines\",\"name\":\"f1\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46],\"xaxis\":\"x\",\"y\":[0.779434223557162,0.7642648264803024,0.7337903114006766,0.7023119779358403,0.6258849168513262,0.6246611505960044,0.6196017362009688,0.6054843752378297,0.5901615953789181,0.5932419431667153,0.5773289455167092,0.57634462577868,0.5663920751403999,0.5608609711344742,0.558389248968476,0.5517599496564841,0.5466750951114082,0.5423905199270984,0.5494424196415867,0.5463145034177154,0.5349471013869068,0.53176052443251,0.5142351676957846,0.47768110854687806,0.4439945339614864,0.45249029209204944,0.4404257137739363,0.44873318690903413,0.43904650681472074,0.4167804401534872,0.412694481416428,0.40987521974315017,0.40643506129063545,0.4050662900947673,0.38430025798750406,0.3803586853785962,0.3744608829083233,0.36573024806854393,0.34598927477332764,0.3605944272523009,0.35352609254688044,0.35203256447556913,0.35109667272041634,0.34996580806647953,0.3294571200709746,0.3219011980617506,0.3149063937832448],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Loop\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"metric\"},\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('cc1ed683-272b-40ff-a4a5-39676d517f24');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                            </script>        </div>\n","</body>\n","</html>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["preparing domain dir and files...\n","reading data for domain dev and test...\n","The number of samples: 2450\n","The number of tags 49\n","The number of samples: 2450\n","The number of tags 48\n","after filter tag 2427\n","after filter tag 2402\n","preparing evaluation placeholder for prevision, recall and f1...\n","prepare base model for domain emails...\n","evaluating prevision, recall and f1 for base model...\n","acc=0.91\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.79      0.94      0.86        35\n","           2       0.87      0.52      0.65        77\n","           3       1.00      0.79      0.88      1030\n","           4       1.00      0.84      0.91       291\n","           5       0.91      0.84      0.87       294\n","           6       0.99      0.98      0.99      1570\n","           7       0.61      0.94      0.74       186\n","           8       0.00      0.00      0.00        11\n","           9       0.99      0.98      0.98       689\n","          10       0.93      0.98      0.96       901\n","          11       0.96      1.00      0.98      2111\n","          12       0.98      0.96      0.97        47\n","          13       0.60      0.46      0.52        13\n","          14       0.28      1.00      0.44        43\n","          15       0.93      0.98      0.95      2778\n","          16       0.90      0.80      0.85      1151\n","          17       0.91      0.95      0.93        41\n","          18       0.94      1.00      0.97        32\n","          19       0.68      0.57      0.62        40\n","          20       1.00      0.96      0.98       584\n","          21       0.00      0.00      0.00        52\n","          22       0.93      0.75      0.83      4175\n","          23       0.73      0.95      0.83      2253\n","          24       0.37      0.68      0.48        44\n","          25       0.87      0.92      0.89       888\n","          26       1.00      0.78      0.88         9\n","          27       0.71      0.99      0.82        69\n","          28       1.00      1.00      1.00      1864\n","          29       1.00      0.99      0.99       344\n","          30       0.81      0.86      0.83      1136\n","          31       0.55      0.63      0.59        19\n","          32       1.00      0.75      0.86         8\n","          33       0.75      0.97      0.84        86\n","          34       0.19      0.38      0.25        32\n","          35       0.97      1.00      0.98       474\n","          36       1.00      0.14      0.24       182\n","          37       0.89      0.96      0.92      1592\n","          38       0.98      0.96      0.97       404\n","          39       0.97      0.93      0.95       485\n","          40       0.90      0.98      0.94       573\n","          41       0.93      0.94      0.94       841\n","          42       0.98      0.99      0.99       575\n","          43       0.94      0.89      0.92       152\n","          44       0.87      0.92      0.90        75\n","          46       0.96      0.99      0.98        82\n","          48       0.00      0.00      0.00        79\n","\n","    accuracy                           0.91     28417\n","   macro avg       0.79      0.80      0.78     28417\n","weighted avg       0.91      0.91      0.90     28417\n","\n","\n","Loop 1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.43354806303977966\n","step: 10, loss: 0.06995666027069092\n","step: 20, loss: 0.03294914588332176\n","step: 30, loss: 0.07877636700868607\n","step: 40, loss: 0.0035211651120334864\n","step: 50, loss: 0.006152035668492317\n","step: 60, loss: 0.05783380568027496\n","step: 70, loss: 0.02783914841711521\n","step: 80, loss: 0.0417768768966198\n","step: 90, loss: 0.07790660858154297\n","step: 100, loss: 0.04408635199069977\n","step: 110, loss: 0.022150591015815735\n","step: 120, loss: 0.02118614874780178\n","acc=0.90\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.71      1.00      0.83        35\n","           2       0.80      0.05      0.10        77\n","           3       0.99      0.79      0.88      1030\n","           4       0.97      0.86      0.91       291\n","           5       0.86      0.84      0.85       294\n","           6       0.98      0.97      0.98      1570\n","           7       0.52      0.94      0.67       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.88      0.98      0.93       901\n","          11       0.98      0.99      0.99      2111\n","          12       0.81      0.98      0.88        47\n","          13       0.00      0.00      0.00        13\n","          14       0.26      1.00      0.41        43\n","          15       0.94      0.98      0.96      2778\n","          16       0.93      0.78      0.85      1151\n","          17       1.00      0.95      0.97        41\n","          18       0.82      1.00      0.90        32\n","          19       1.00      0.20      0.33        40\n","          20       0.99      0.96      0.98       584\n","          21       0.00      0.00      0.00        52\n","          22       0.95      0.71      0.81      4175\n","          23       0.65      0.98      0.78      2253\n","          24       0.31      0.36      0.33        44\n","          25       0.87      0.89      0.88       888\n","          26       1.00      0.78      0.88         9\n","          27       0.88      1.00      0.94        69\n","          28       1.00      0.99      1.00      1864\n","          29       1.00      0.99      0.99       344\n","          30       0.92      0.84      0.88      1136\n","          31       0.56      0.74      0.64        19\n","          32       1.00      0.75      0.86         8\n","          33       0.79      0.93      0.86        86\n","          34       0.23      0.53      0.32        32\n","          35       0.98      0.99      0.98       474\n","          36       1.00      0.12      0.22       182\n","          37       0.88      0.95      0.91      1592\n","          38       0.97      0.97      0.97       404\n","          39       0.97      0.95      0.96       485\n","          40       0.90      0.98      0.93       573\n","          41       0.93      0.93      0.93       841\n","          42       0.99      0.99      0.99       575\n","          43       0.95      0.89      0.92       152\n","          44       0.87      0.92      0.90        75\n","          46       0.96      0.99      0.98        82\n","          48       0.00      0.00      0.00        79\n","\n","    accuracy                           0.90     28417\n","   macro avg       0.78      0.77      0.74     28417\n","weighted avg       0.91      0.90      0.89     28417\n","\n","Difference 968\n","\n","Loop 2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.03723767027258873\n","step: 10, loss: 0.016708455979824066\n","step: 20, loss: 0.002492827596142888\n","step: 30, loss: 0.002968581859022379\n","step: 40, loss: 0.003818025579676032\n","step: 50, loss: 0.000855152087751776\n","step: 60, loss: 0.00015787869051564485\n","step: 70, loss: 0.0008012930629774928\n","step: 80, loss: 0.00030115892877802253\n","step: 90, loss: 0.01037721149623394\n","step: 100, loss: 0.0012280961964279413\n","step: 110, loss: 0.03921348229050636\n","step: 120, loss: 0.005665700417011976\n","acc=0.89\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.47      1.00      0.64        35\n","           2       0.44      0.05      0.09        77\n","           3       1.00      0.79      0.88      1030\n","           4       0.99      0.72      0.83       291\n","           5       1.00      0.77      0.87       294\n","           6       0.99      0.96      0.98      1570\n","           7       0.64      0.92      0.76       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.77      0.97      0.86       901\n","          11       0.98      1.00      0.99      2111\n","          12       0.94      0.98      0.96        47\n","          13       0.00      0.00      0.00        13\n","          14       0.28      1.00      0.43        43\n","          15       0.92      0.98      0.95      2778\n","          16       0.91      0.81      0.86      1151\n","          17       0.95      0.98      0.96        41\n","          18       0.81      0.94      0.87        32\n","          19       0.00      0.00      0.00        40\n","          20       0.99      0.95      0.97       584\n","          21       0.00      0.00      0.00        52\n","          22       0.95      0.70      0.81      4175\n","          23       0.66      0.98      0.79      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.87      0.91      0.89       888\n","          26       1.00      1.00      1.00         9\n","          27       0.94      0.99      0.96        69\n","          28       1.00      0.99      0.99      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.93      0.83      0.88      1136\n","          31       0.71      0.63      0.67        19\n","          32       0.83      0.62      0.71         8\n","          33       0.86      0.81      0.84        86\n","          34       0.11      0.72      0.19        32\n","          35       0.97      0.99      0.98       474\n","          36       1.00      0.09      0.17       182\n","          37       0.89      0.93      0.91      1592\n","          38       0.94      0.97      0.95       404\n","          39       0.96      0.89      0.92       485\n","          40       0.90      0.95      0.92       573\n","          41       0.84      0.94      0.89       841\n","          42       0.97      0.97      0.97       575\n","          43       0.96      0.88      0.92       152\n","          44       0.87      0.92      0.90        75\n","          46       0.96      0.99      0.98        82\n","          48       0.01      0.01      0.01        79\n","\n","    accuracy                           0.89     28417\n","   macro avg       0.74      0.75      0.72     28417\n","weighted avg       0.91      0.89      0.89     28417\n","\n","Difference 228\n","\n","Loop 3\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0007117987843230367\n","step: 10, loss: 0.003920011222362518\n","step: 20, loss: 0.016160568222403526\n","step: 30, loss: 0.0006388785550370812\n","step: 40, loss: 0.0022540686186403036\n","step: 50, loss: 0.0011974782682955265\n","step: 60, loss: 0.0316736213862896\n","step: 70, loss: 0.0005376027547754347\n","step: 80, loss: 0.01887042261660099\n","step: 90, loss: 0.0008094238582998514\n","step: 100, loss: 0.0022519247140735388\n","step: 110, loss: 0.050065308809280396\n","step: 120, loss: 0.015417343005537987\n","acc=0.88\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.71      1.00      0.83        35\n","           2       1.00      0.01      0.03        77\n","           3       1.00      0.79      0.88      1030\n","           4       0.97      0.72      0.83       291\n","           5       0.99      0.82      0.90       294\n","           6       0.98      0.99      0.98      1570\n","           7       0.72      0.92      0.81       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.82      0.97      0.89       901\n","          11       0.98      1.00      0.99      2111\n","          12       0.96      0.98      0.97        47\n","          13       0.00      0.00      0.00        13\n","          14       0.27      1.00      0.43        43\n","          15       0.92      0.98      0.95      2778\n","          16       0.86      0.84      0.85      1151\n","          17       0.92      0.88      0.90        41\n","          18       0.90      0.88      0.89        32\n","          19       0.00      0.00      0.00        40\n","          20       0.99      0.96      0.98       584\n","          21       0.00      0.00      0.00        52\n","          22       0.95      0.71      0.81      4175\n","          23       0.65      0.98      0.78      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.87      0.91      0.89       888\n","          26       1.00      0.56      0.71         9\n","          27       0.82      1.00      0.90        69\n","          28       1.00      0.99      0.99      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.95      0.83      0.89      1136\n","          31       0.69      0.58      0.63        19\n","          32       1.00      0.62      0.77         8\n","          33       0.88      0.87      0.88        86\n","          34       0.14      0.69      0.24        32\n","          35       0.99      0.98      0.98       474\n","          36       1.00      0.04      0.08       182\n","          37       0.76      0.95      0.85      1592\n","          38       0.97      0.94      0.95       404\n","          39       0.93      0.70      0.80       485\n","          40       0.93      0.85      0.89       573\n","          41       0.87      0.90      0.88       841\n","          42       0.99      0.90      0.94       575\n","          43       0.94      0.89      0.91       152\n","          44       0.87      0.92      0.90        75\n","          46       0.99      0.99      0.99        82\n","          48       0.07      0.01      0.02        79\n","\n","    accuracy                           0.88     28417\n","   macro avg       0.77      0.73      0.71     28417\n","weighted avg       0.90      0.88      0.88     28417\n","\n","Difference 169\n","\n","Loop 4\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0012524493504315615\n","step: 10, loss: 0.017463181167840958\n","step: 20, loss: 0.035479024052619934\n","step: 30, loss: 0.028695745393633842\n","step: 40, loss: 0.004896390251815319\n","step: 50, loss: 0.011061643250286579\n","step: 60, loss: 0.06269150227308273\n","step: 70, loss: 0.02636849135160446\n","step: 80, loss: 0.001100413966923952\n","step: 90, loss: 0.044484466314315796\n","step: 100, loss: 0.01941857486963272\n","step: 110, loss: 0.004164992365986109\n","step: 120, loss: 0.0005195188568904996\n","acc=0.88\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.78      1.00      0.88        35\n","           2       0.00      0.00      0.00        77\n","           3       0.99      0.79      0.88      1030\n","           4       0.98      0.77      0.86       291\n","           5       0.79      0.84      0.81       294\n","           6       0.97      0.99      0.98      1570\n","           7       0.74      0.94      0.83       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.85      0.97      0.91       901\n","          11       0.97      1.00      0.98      2111\n","          12       0.96      0.98      0.97        47\n","          13       0.00      0.00      0.00        13\n","          14       0.39      1.00      0.56        43\n","          15       0.92      0.96      0.94      2778\n","          16       0.88      0.80      0.84      1151\n","          17       0.86      0.90      0.88        41\n","          18       0.90      0.84      0.87        32\n","          19       0.00      0.00      0.00        40\n","          20       0.99      0.95      0.97       584\n","          21       0.00      0.00      0.00        52\n","          22       0.94      0.72      0.82      4175\n","          23       0.68      0.97      0.80      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.85      0.93      0.89       888\n","          26       1.00      0.11      0.20         9\n","          27       0.91      1.00      0.95        69\n","          28       1.00      0.99      0.99      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.96      0.81      0.88      1136\n","          31       0.79      0.58      0.67        19\n","          32       0.83      0.62      0.71         8\n","          33       0.76      0.91      0.83        86\n","          34       0.16      0.72      0.27        32\n","          35       0.90      1.00      0.95       474\n","          36       1.00      0.04      0.08       182\n","          37       0.66      0.96      0.78      1592\n","          38       0.93      0.94      0.94       404\n","          39       0.99      0.21      0.34       485\n","          40       0.91      0.84      0.87       573\n","          41       0.87      0.85      0.86       841\n","          42       0.97      0.94      0.95       575\n","          43       0.92      0.88      0.90       152\n","          44       0.87      0.92      0.90        75\n","          46       0.95      0.99      0.97        82\n","          48       0.08      0.09      0.08        79\n","\n","    accuracy                           0.88     28417\n","   macro avg       0.74      0.71      0.69     28417\n","weighted avg       0.89      0.88      0.87     28417\n","\n","Difference 214\n","\n","Loop 5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.00030300882644951344\n","step: 10, loss: 0.02162904664874077\n","step: 20, loss: 0.03472308814525604\n","step: 30, loss: 4.293406891520135e-05\n","step: 40, loss: 0.0030363257974386215\n","step: 50, loss: 0.019707970321178436\n","step: 60, loss: 0.06389519572257996\n","step: 70, loss: 0.009221122600138187\n","step: 80, loss: 0.0016499594785273075\n","step: 90, loss: 0.0008895518840290606\n","step: 100, loss: 0.0009678379283286631\n","step: 110, loss: 0.004058517515659332\n","step: 120, loss: 0.0014078824315220118\n","acc=0.87\n","classification_report               precision    recall  f1-score   support\n","\n","           1       1.00      0.97      0.99        35\n","           2       0.00      0.00      0.00        77\n","           3       0.99      0.79      0.88      1030\n","           4       0.69      0.83      0.76       291\n","           5       0.93      0.73      0.82       294\n","           6       0.92      1.00      0.96      1570\n","           7       0.85      0.94      0.89       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.92      0.97      0.94       901\n","          11       0.97      1.00      0.98      2111\n","          12       0.98      0.98      0.98        47\n","          13       0.00      0.00      0.00        13\n","          14       0.25      0.98      0.40        43\n","          15       0.94      0.97      0.96      2778\n","          16       0.89      0.83      0.86      1151\n","          17       0.85      0.68      0.76        41\n","          18       0.88      0.94      0.91        32\n","          19       0.00      0.00      0.00        40\n","          20       0.98      0.95      0.97       584\n","          21       0.00      0.00      0.00        52\n","          22       0.96      0.68      0.79      4175\n","          23       0.63      0.98      0.76      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.87      0.91      0.89       888\n","          26       1.00      0.11      0.20         9\n","          27       0.97      0.91      0.94        69\n","          28       1.00      0.99      0.99      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.95      0.82      0.88      1136\n","          31       0.79      0.58      0.67        19\n","          32       1.00      0.25      0.40         8\n","          33       0.71      0.97      0.82        86\n","          34       0.10      0.62      0.17        32\n","          35       0.96      1.00      0.98       474\n","          36       0.00      0.00      0.00       182\n","          37       0.71      0.93      0.80      1592\n","          38       0.94      0.95      0.95       404\n","          39       0.97      0.18      0.31       485\n","          40       0.86      0.90      0.88       573\n","          41       0.83      0.92      0.88       841\n","          42       0.98      0.94      0.96       575\n","          43       0.91      0.91      0.91       152\n","          44       0.87      0.92      0.90        75\n","          46       1.00      0.96      0.98        82\n","          48       0.00      0.00      0.00        79\n","\n","    accuracy                           0.87     28417\n","   macro avg       0.72      0.69      0.68     28417\n","weighted avg       0.88      0.87      0.86     28417\n","\n","Difference 228\n","\n","Loop 6\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0002972824149765074\n","step: 10, loss: 0.0023974315263330936\n","step: 20, loss: 0.02493085339665413\n","step: 30, loss: 0.0005477145896293223\n","step: 40, loss: 0.03164992853999138\n","step: 50, loss: 0.00039075000677257776\n","step: 60, loss: 0.0015485218027606606\n","step: 70, loss: 0.004468914587050676\n","step: 80, loss: 0.00017221097368746996\n","step: 90, loss: 0.00019894845900125802\n","step: 100, loss: 0.013171393424272537\n","step: 110, loss: 0.04895893111824989\n","step: 120, loss: 0.00094796804478392\n","acc=0.87\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.58      0.97      0.72        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.72      0.84      1030\n","           4       0.81      0.81      0.81       291\n","           5       0.79      0.81      0.80       294\n","           6       0.94      1.00      0.97      1570\n","           7       0.82      0.94      0.87       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.97      0.99       689\n","          10       0.82      0.96      0.89       901\n","          11       0.97      0.99      0.98      2111\n","          12       0.96      0.98      0.97        47\n","          13       0.00      0.00      0.00        13\n","          14       0.53      0.79      0.64        43\n","          15       0.96      0.96      0.96      2778\n","          16       0.84      0.84      0.84      1151\n","          17       0.82      0.44      0.57        41\n","          18       0.85      0.91      0.88        32\n","          19       0.00      0.00      0.00        40\n","          20       0.99      0.96      0.97       584\n","          21       0.00      0.00      0.00        52\n","          22       0.95      0.69      0.80      4175\n","          23       0.62      0.98      0.76      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.85      0.93      0.89       888\n","          26       1.00      0.11      0.20         9\n","          27       0.92      0.87      0.90        69\n","          28       1.00      0.99      0.99      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.94      0.84      0.89      1136\n","          31       0.67      0.11      0.18        19\n","          32       0.00      0.00      0.00         8\n","          33       0.70      0.95      0.81        86\n","          34       0.11      0.62      0.19        32\n","          35       0.95      0.99      0.97       474\n","          36       0.00      0.00      0.00       182\n","          37       0.70      0.94      0.81      1592\n","          38       0.96      0.94      0.95       404\n","          39       0.95      0.12      0.21       485\n","          40       0.89      0.90      0.89       573\n","          41       0.87      0.90      0.88       841\n","          42       0.98      0.93      0.95       575\n","          43       0.85      0.89      0.87       152\n","          44       0.87      0.92      0.90        75\n","          46       1.00      0.96      0.98        82\n","          48       0.05      0.04      0.04        79\n","\n","    accuracy                           0.87     28417\n","   macro avg       0.68      0.67      0.65     28417\n","weighted avg       0.88      0.87      0.86     28417\n","\n","Difference 156\n","\n","Loop 7\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0028599705547094345\n","step: 10, loss: 0.027686411514878273\n","step: 20, loss: 0.00025129906134679914\n","step: 30, loss: 0.04068625345826149\n","step: 40, loss: 0.04879702255129814\n","step: 50, loss: 0.00013770982332061976\n","step: 60, loss: 0.05236917361617088\n","step: 70, loss: 0.0036239847540855408\n","step: 80, loss: 0.011513727717101574\n","step: 90, loss: 0.0022374417167156935\n","step: 100, loss: 0.0004344651533756405\n","step: 110, loss: 0.018224768340587616\n","step: 120, loss: 0.027438150718808174\n","acc=0.85\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.94      0.97      0.96        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.88      1030\n","           4       0.92      0.72      0.81       291\n","           5       0.86      0.82      0.84       294\n","           6       0.94      1.00      0.97      1570\n","           7       0.81      0.92      0.86       186\n","           8       0.00      0.00      0.00        11\n","           9       0.97      0.98      0.98       689\n","          10       0.91      0.96      0.94       901\n","          11       0.98      1.00      0.99      2111\n","          12       0.84      0.91      0.88        47\n","          13       0.00      0.00      0.00        13\n","          14       0.58      0.88      0.70        43\n","          15       0.93      0.96      0.95      2778\n","          16       0.93      0.69      0.79      1151\n","          17       0.88      0.73      0.80        41\n","          18       0.86      0.94      0.90        32\n","          19       0.00      0.00      0.00        40\n","          20       0.96      0.97      0.96       584\n","          21       0.00      0.00      0.00        52\n","          22       0.93      0.70      0.80      4175\n","          23       0.61      0.98      0.75      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.84      0.94      0.89       888\n","          26       0.00      0.00      0.00         9\n","          27       0.90      1.00      0.95        69\n","          28       1.00      0.99      0.99      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.92      0.83      0.87      1136\n","          31       0.50      0.16      0.24        19\n","          32       1.00      0.25      0.40         8\n","          33       0.80      0.87      0.83        86\n","          34       0.10      0.88      0.19        32\n","          35       0.96      0.99      0.97       474\n","          36       0.00      0.00      0.00       182\n","          37       0.59      0.96      0.73      1592\n","          38       0.94      0.77      0.84       404\n","          39       0.00      0.00      0.00       485\n","          40       0.91      0.79      0.84       573\n","          41       0.92      0.69      0.79       841\n","          42       0.99      0.93      0.96       575\n","          43       0.87      0.90      0.89       152\n","          44       0.87      0.92      0.90        75\n","          46       0.98      0.96      0.97        82\n","          48       0.03      0.03      0.03        79\n","\n","    accuracy                           0.85     28417\n","   macro avg       0.67      0.67      0.65     28417\n","weighted avg       0.86      0.85      0.85     28417\n","\n","Difference 116\n","\n","Loop 8\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.00024971901439130306\n","step: 10, loss: 0.0006387975881807506\n","step: 20, loss: 0.0013330501969903708\n","step: 30, loss: 0.05424380302429199\n","step: 40, loss: 0.0006434482056647539\n","step: 50, loss: 0.011384870857000351\n","step: 60, loss: 0.005277510732412338\n","step: 70, loss: 0.031194210052490234\n","step: 80, loss: 0.08274795114994049\n","step: 90, loss: 0.03678125515580177\n","step: 100, loss: 0.03262309357523918\n","step: 110, loss: 0.013946354389190674\n","step: 120, loss: 0.00033527688356116414\n","acc=0.85\n","classification_report               precision    recall  f1-score   support\n","\n","           1       1.00      0.97      0.99        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.88      1030\n","           4       0.97      0.77      0.86       291\n","           5       0.81      0.80      0.81       294\n","           6       0.93      1.00      0.96      1570\n","           7       0.81      0.92      0.86       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.91      0.96      0.93       901\n","          11       0.91      1.00      0.95      2111\n","          12       0.79      0.98      0.88        47\n","          13       0.00      0.00      0.00        13\n","          14       0.57      0.98      0.72        43\n","          15       0.91      0.94      0.92      2778\n","          16       0.87      0.79      0.83      1151\n","          17       1.00      0.49      0.66        41\n","          18       0.85      0.91      0.88        32\n","          19       0.00      0.00      0.00        40\n","          20       0.98      0.97      0.97       584\n","          21       0.00      0.00      0.00        52\n","          22       0.92      0.70      0.79      4175\n","          23       0.62      0.98      0.76      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.84      0.95      0.89       888\n","          26       0.00      0.00      0.00         9\n","          27       0.96      0.97      0.96        69\n","          28       1.00      0.99      0.99      1864\n","          29       0.99      0.98      0.99       344\n","          30       0.84      0.83      0.84      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.83      0.80      0.82        86\n","          34       0.15      0.75      0.25        32\n","          35       1.00      0.93      0.96       474\n","          36       0.00      0.00      0.00       182\n","          37       0.64      0.87      0.73      1592\n","          38       0.95      0.90      0.93       404\n","          39       0.00      0.00      0.00       485\n","          40       0.92      0.84      0.88       573\n","          41       0.93      0.71      0.81       841\n","          42       0.95      0.96      0.95       575\n","          43       0.59      0.91      0.71       152\n","          44       0.88      0.96      0.92        75\n","          46       0.78      0.96      0.86        82\n","          48       0.02      0.01      0.02        79\n","\n","    accuracy                           0.85     28417\n","   macro avg       0.63      0.66      0.63     28417\n","weighted avg       0.85      0.85      0.84     28417\n","\n","Difference 227\n","\n","Loop 9\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0024163159541785717\n","step: 10, loss: 5.682408664142713e-05\n","step: 20, loss: 0.001552764093503356\n","step: 30, loss: 0.00017899440717883408\n","step: 40, loss: 0.0004977218923158944\n","step: 50, loss: 0.0003390078782103956\n","step: 60, loss: 0.00019175624765921384\n","step: 70, loss: 0.02177744172513485\n","step: 80, loss: 0.044977396726608276\n","step: 90, loss: 0.0002500168338883668\n","step: 100, loss: 0.00031943595968186855\n","step: 110, loss: 0.02724761702120304\n","step: 120, loss: 0.0006006135954521596\n","acc=0.86\n","classification_report               precision    recall  f1-score   support\n","\n","           1       1.00      0.34      0.51        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.80      0.87      0.83       291\n","           5       0.95      0.81      0.87       294\n","           6       0.95      1.00      0.97      1570\n","           7       0.82      0.94      0.87       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.73      0.98      0.84       901\n","          11       0.96      1.00      0.98      2111\n","          12       0.78      0.98      0.87        47\n","          13       0.00      0.00      0.00        13\n","          14       0.61      1.00      0.75        43\n","          15       0.94      0.95      0.94      2778\n","          16       0.95      0.70      0.81      1151\n","          17       1.00      0.34      0.51        41\n","          18       0.83      0.94      0.88        32\n","          19       0.00      0.00      0.00        40\n","          20       0.98      0.99      0.98       584\n","          21       0.00      0.00      0.00        52\n","          22       0.92      0.70      0.79      4175\n","          23       0.62      0.98      0.76      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.86      0.84      0.85       888\n","          26       0.00      0.00      0.00         9\n","          27       0.89      0.99      0.94        69\n","          28       1.00      0.99      0.99      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.88      0.82      0.85      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.75      0.91      0.82        86\n","          34       0.18      0.72      0.28        32\n","          35       0.95      0.99      0.97       474\n","          36       0.00      0.00      0.00       182\n","          37       0.63      0.93      0.75      1592\n","          38       0.94      0.90      0.92       404\n","          39       0.00      0.00      0.00       485\n","          40       0.87      0.87      0.87       573\n","          41       0.91      0.78      0.84       841\n","          42       0.89      0.95      0.92       575\n","          43       0.72      0.93      0.81       152\n","          44       0.86      0.92      0.89        75\n","          46       0.91      0.96      0.93        82\n","          48       0.00      0.00      0.00        79\n","\n","    accuracy                           0.86     28417\n","   macro avg       0.63      0.65      0.62     28417\n","weighted avg       0.85      0.86      0.84     28417\n","\n","Difference 204\n","\n","Loop 10\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0001612301275599748\n","step: 10, loss: 0.027722079306840897\n","step: 20, loss: 0.0399925634264946\n","step: 30, loss: 3.2647356420056894e-05\n","step: 40, loss: 0.06715353578329086\n","step: 50, loss: 0.013929788023233414\n","step: 60, loss: 0.008788286708295345\n","step: 70, loss: 0.000649067631457001\n","step: 80, loss: 0.019274409860372543\n","step: 90, loss: 0.001410316675901413\n","step: 100, loss: 0.03012741357088089\n","step: 110, loss: 0.0008701272890903056\n","step: 120, loss: 0.04242999479174614\n","acc=0.85\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.90      0.83      0.86       291\n","           5       0.97      0.62      0.76       294\n","           6       0.96      0.95      0.95      1570\n","           7       0.82      0.94      0.87       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.97      0.99       689\n","          10       0.85      0.97      0.91       901\n","          11       0.96      0.99      0.98      2111\n","          12       0.78      0.98      0.87        47\n","          13       0.00      0.00      0.00        13\n","          14       0.40      0.98      0.57        43\n","          15       0.89      0.97      0.93      2778\n","          16       0.93      0.73      0.82      1151\n","          17       0.89      0.20      0.32        41\n","          18       0.86      0.94      0.90        32\n","          19       0.00      0.00      0.00        40\n","          20       0.98      0.99      0.99       584\n","          21       0.00      0.00      0.00        52\n","          22       0.91      0.70      0.79      4175\n","          23       0.57      0.98      0.73      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.85      0.91      0.88       888\n","          26       0.00      0.00      0.00         9\n","          27       0.87      1.00      0.93        69\n","          28       0.98      0.99      0.99      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.96      0.76      0.85      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       1.00      0.38      0.55        86\n","          34       0.10      0.75      0.17        32\n","          35       0.96      0.99      0.97       474\n","          36       0.00      0.00      0.00       182\n","          37       0.65      0.91      0.76      1592\n","          38       0.96      0.87      0.91       404\n","          39       0.00      0.00      0.00       485\n","          40       0.89      0.88      0.88       573\n","          41       0.91      0.82      0.87       841\n","          42       0.99      0.93      0.96       575\n","          43       0.87      0.83      0.85       152\n","          44       0.83      0.93      0.88        75\n","          46       0.92      0.95      0.93        82\n","          48       0.04      0.01      0.02        79\n","\n","    accuracy                           0.85     28417\n","   macro avg       0.62      0.62      0.60     28417\n","weighted avg       0.85      0.85      0.84     28417\n","\n","Difference 167\n","\n","Loop 11\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0005538577679544687\n","step: 10, loss: 0.00026823440566658974\n","step: 20, loss: 0.00026746754883788526\n","step: 30, loss: 0.030325474217534065\n","step: 40, loss: 0.03840794786810875\n","step: 50, loss: 0.04157701134681702\n","step: 60, loss: 0.0057939644902944565\n","step: 70, loss: 0.000185125318239443\n","step: 80, loss: 0.00126647821161896\n","step: 90, loss: 0.02858785353600979\n","step: 100, loss: 0.00039790949085727334\n","step: 110, loss: 0.0024863039143383503\n","step: 120, loss: 0.000562142813578248\n","acc=0.84\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.88      1030\n","           4       0.91      0.79      0.85       291\n","           5       0.88      0.28      0.42       294\n","           6       0.96      0.92      0.94      1570\n","           7       0.82      0.94      0.88       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.89      0.97      0.92       901\n","          11       0.96      1.00      0.98      2111\n","          12       0.78      0.98      0.87        47\n","          13       0.00      0.00      0.00        13\n","          14       0.42      0.98      0.59        43\n","          15       0.85      0.96      0.90      2778\n","          16       0.91      0.75      0.82      1151\n","          17       1.00      0.02      0.05        41\n","          18       0.91      0.91      0.91        32\n","          19       0.00      0.00      0.00        40\n","          20       0.99      1.00      0.99       584\n","          21       0.00      0.00      0.00        52\n","          22       0.95      0.68      0.79      4175\n","          23       0.54      0.99      0.70      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.86      0.88      0.87       888\n","          26       0.00      0.00      0.00         9\n","          27       0.83      1.00      0.91        69\n","          28       1.00      0.99      0.99      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.86      0.81      0.83      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.00      0.00      0.00        86\n","          34       0.12      0.91      0.22        32\n","          35       0.93      0.99      0.96       474\n","          36       0.00      0.00      0.00       182\n","          37       0.67      0.91      0.77      1592\n","          38       0.93      0.90      0.91       404\n","          39       0.00      0.00      0.00       485\n","          40       0.87      0.86      0.87       573\n","          41       0.91      0.86      0.88       841\n","          42       0.98      0.95      0.96       575\n","          43       0.96      0.70      0.81       152\n","          44       0.88      0.91      0.89        75\n","          46       0.90      0.96      0.93        82\n","          48       0.00      0.00      0.00        79\n","\n","    accuracy                           0.84     28417\n","   macro avg       0.60      0.60      0.57     28417\n","weighted avg       0.85      0.84      0.83     28417\n","\n","Difference 294\n","\n","Loop 12\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0020660010632127523\n","step: 10, loss: 0.002228527795523405\n","step: 20, loss: 0.0002689723332878202\n","step: 30, loss: 0.006295710802078247\n","step: 40, loss: 5.5172804422909394e-05\n","step: 50, loss: 0.018989164382219315\n","step: 60, loss: 0.00911176111549139\n","step: 70, loss: 0.011239562183618546\n","step: 80, loss: 0.009274815209209919\n","step: 90, loss: 8.018436346901581e-05\n","step: 100, loss: 0.0003058944421354681\n","step: 110, loss: 0.0026508758310228586\n","step: 120, loss: 0.0002923550782725215\n","acc=0.85\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.88      1030\n","           4       0.90      0.83      0.86       291\n","           5       0.96      0.69      0.80       294\n","           6       0.92      0.93      0.93      1570\n","           7       0.75      0.94      0.83       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.81      0.97      0.88       901\n","          11       0.96      1.00      0.98      2111\n","          12       0.78      0.98      0.87        47\n","          13       0.00      0.00      0.00        13\n","          14       0.83      0.81      0.82        43\n","          15       0.90      0.96      0.93      2778\n","          16       0.91      0.79      0.85      1151\n","          17       1.00      0.07      0.14        41\n","          18       0.91      0.91      0.91        32\n","          19       0.00      0.00      0.00        40\n","          20       0.99      0.99      0.99       584\n","          21       0.00      0.00      0.00        52\n","          22       0.94      0.69      0.80      4175\n","          23       0.57      0.98      0.72      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.83      0.89      0.86       888\n","          26       0.00      0.00      0.00         9\n","          27       0.93      0.97      0.95        69\n","          28       1.00      0.99      0.99      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.90      0.81      0.85      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.00      0.00      0.00        86\n","          34       0.10      0.81      0.17        32\n","          35       0.93      0.99      0.96       474\n","          36       0.00      0.00      0.00       182\n","          37       0.66      0.86      0.75      1592\n","          38       0.99      0.86      0.92       404\n","          39       0.00      0.00      0.00       485\n","          40       0.88      0.90      0.89       573\n","          41       0.87      0.88      0.87       841\n","          42       0.98      0.92      0.95       575\n","          43       0.96      0.71      0.82       152\n","          44       0.87      0.96      0.91        75\n","          46       0.87      0.96      0.91        82\n","          48       0.00      0.00      0.00        79\n","\n","    accuracy                           0.85     28417\n","   macro avg       0.61      0.60      0.59     28417\n","weighted avg       0.85      0.85      0.84     28417\n","\n","Difference 245\n","\n","Loop 13\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.012394240126013756\n","step: 10, loss: 5.111938662594184e-05\n","step: 20, loss: 7.793380791554227e-05\n","step: 30, loss: 0.06903024017810822\n","step: 40, loss: 0.0018378933891654015\n","step: 50, loss: 0.0002912477939389646\n","step: 60, loss: 0.0006105105858296156\n","step: 70, loss: 0.000359991128789261\n","step: 80, loss: 0.005115985404700041\n","step: 90, loss: 0.00016190505994018167\n","step: 100, loss: 6.948640657356009e-05\n","step: 110, loss: 0.014891993254423141\n","step: 120, loss: 0.01308750081807375\n","acc=0.85\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.88      1030\n","           4       0.91      0.83      0.87       291\n","           5       0.96      0.80      0.87       294\n","           6       0.92      0.94      0.93      1570\n","           7       0.55      0.94      0.69       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.89      0.97      0.93       901\n","          11       0.97      1.00      0.98      2111\n","          12       0.78      0.98      0.87        47\n","          13       0.00      0.00      0.00        13\n","          14       0.86      0.74      0.80        43\n","          15       0.89      0.97      0.93      2778\n","          16       0.85      0.84      0.84      1151\n","          17       1.00      0.05      0.09        41\n","          18       0.91      0.94      0.92        32\n","          19       0.00      0.00      0.00        40\n","          20       0.98      0.99      0.98       584\n","          21       0.00      0.00      0.00        52\n","          22       0.90      0.70      0.79      4175\n","          23       0.59      0.97      0.73      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.86      0.86      0.86       888\n","          26       0.00      0.00      0.00         9\n","          27       0.82      1.00      0.90        69\n","          28       1.00      0.99      0.99      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.94      0.80      0.86      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.00      0.00      0.00        86\n","          34       0.09      0.84      0.16        32\n","          35       0.98      0.96      0.97       474\n","          36       0.00      0.00      0.00       182\n","          37       0.68      0.84      0.75      1592\n","          38       0.95      0.93      0.94       404\n","          39       0.00      0.00      0.00       485\n","          40       0.90      0.87      0.89       573\n","          41       0.75      0.90      0.82       841\n","          42       0.98      0.70      0.82       575\n","          43       0.96      0.68      0.80       152\n","          44       0.87      0.96      0.91        75\n","          46       0.91      0.96      0.93        82\n","          48       0.00      0.00      0.00        79\n","\n","    accuracy                           0.85     28417\n","   macro avg       0.60      0.60      0.58     28417\n","weighted avg       0.84      0.85      0.84     28417\n","\n","Difference 192\n","\n","Loop 14\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.004894148092716932\n","step: 10, loss: 0.00016976836195681244\n","step: 20, loss: 0.00021505889890249819\n","step: 30, loss: 0.0003401107096578926\n","step: 40, loss: 7.929879211587831e-05\n","step: 50, loss: 0.0007871910929679871\n","step: 60, loss: 0.006749284453690052\n","step: 70, loss: 0.046189114451408386\n","step: 80, loss: 0.028312241658568382\n","step: 90, loss: 0.00039478312828578055\n","step: 100, loss: 0.0004872493736911565\n","step: 110, loss: 0.01216861791908741\n","step: 120, loss: 0.024793202057480812\n","acc=0.85\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.88      1030\n","           4       0.93      0.82      0.87       291\n","           5       0.98      0.74      0.84       294\n","           6       0.96      0.92      0.94      1570\n","           7       0.55      0.94      0.69       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.89      0.97      0.93       901\n","          11       0.96      1.00      0.98      2111\n","          12       0.78      0.98      0.87        47\n","          13       0.00      0.00      0.00        13\n","          14       0.80      0.91      0.85        43\n","          15       0.88      0.98      0.93      2778\n","          16       0.88      0.81      0.85      1151\n","          17       0.00      0.00      0.00        41\n","          18       0.91      0.91      0.91        32\n","          19       0.00      0.00      0.00        40\n","          20       0.99      0.99      0.99       584\n","          21       0.00      0.00      0.00        52\n","          22       0.91      0.70      0.79      4175\n","          23       0.58      0.96      0.73      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.84      0.89      0.87       888\n","          26       0.00      0.00      0.00         9\n","          27       0.70      1.00      0.83        69\n","          28       1.00      0.99      0.99      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.92      0.81      0.86      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.00      0.00      0.00        86\n","          34       0.10      0.81      0.18        32\n","          35       0.99      0.95      0.97       474\n","          36       0.00      0.00      0.00       182\n","          37       0.67      0.85      0.75      1592\n","          38       0.91      0.94      0.92       404\n","          39       0.00      0.00      0.00       485\n","          40       0.90      0.85      0.87       573\n","          41       0.73      0.93      0.82       841\n","          42       0.98      0.68      0.80       575\n","          43       0.92      0.66      0.77       152\n","          44       0.87      0.92      0.90        75\n","          46       0.92      0.96      0.94        82\n","          48       0.00      0.00      0.00        79\n","\n","    accuracy                           0.85     28417\n","   macro avg       0.57      0.60      0.58     28417\n","weighted avg       0.84      0.85      0.84     28417\n","\n","Difference 153\n","\n","Loop 15\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 9.343770216219127e-05\n","step: 10, loss: 9.507495633442886e-06\n","step: 20, loss: 0.00014303957868833095\n","step: 30, loss: 7.042445940896869e-05\n","step: 40, loss: 0.021741583943367004\n","step: 50, loss: 0.000106830608274322\n","step: 60, loss: 0.03715233504772186\n","step: 70, loss: 0.002059407765045762\n","step: 80, loss: 0.02900535613298416\n","step: 90, loss: 0.0017533927457407117\n","step: 100, loss: 0.0001659541594563052\n","step: 110, loss: 0.001152046024799347\n","step: 120, loss: 0.01587381400167942\n","acc=0.84\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.96      0.81      0.88       291\n","           5       0.00      0.00      0.00       294\n","           6       0.96      0.96      0.96      1570\n","           7       0.58      0.94      0.71       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.89      0.97      0.93       901\n","          11       0.96      1.00      0.98      2111\n","          12       0.78      0.98      0.87        47\n","          13       0.00      0.00      0.00        13\n","          14       0.87      0.77      0.81        43\n","          15       0.83      0.97      0.89      2778\n","          16       0.87      0.80      0.83      1151\n","          17       1.00      0.05      0.09        41\n","          18       0.91      0.91      0.91        32\n","          19       0.00      0.00      0.00        40\n","          20       0.98      0.97      0.98       584\n","          21       0.00      0.00      0.00        52\n","          22       0.92      0.70      0.80      4175\n","          23       0.62      0.96      0.76      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.84      0.91      0.88       888\n","          26       0.00      0.00      0.00         9\n","          27       0.80      1.00      0.89        69\n","          28       1.00      0.99      0.99      1864\n","          29       1.00      0.99      0.99       344\n","          30       0.90      0.82      0.85      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.00      0.00      0.00        86\n","          34       0.05      0.81      0.10        32\n","          35       0.95      0.98      0.97       474\n","          36       0.00      0.00      0.00       182\n","          37       0.67      0.88      0.76      1592\n","          38       0.95      0.92      0.94       404\n","          39       0.00      0.00      0.00       485\n","          40       0.88      0.86      0.87       573\n","          41       0.82      0.88      0.85       841\n","          42       0.99      0.85      0.92       575\n","          43       0.99      0.62      0.77       152\n","          44       0.87      0.92      0.90        75\n","          46       0.94      0.94      0.94        82\n","          48       0.00      0.00      0.00        79\n","\n","    accuracy                           0.84     28417\n","   macro avg       0.58      0.59      0.56     28417\n","weighted avg       0.83      0.84      0.83     28417\n","\n","Difference 166\n","\n","Loop 16\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 9.120717732002959e-05\n","step: 10, loss: 0.00010261438001180068\n","step: 20, loss: 5.785817120340653e-05\n","step: 30, loss: 0.008768601343035698\n","step: 40, loss: 0.00014412174641620368\n","step: 50, loss: 0.00016998444334603846\n","step: 60, loss: 0.006299276370555162\n","step: 70, loss: 0.0011445668060332537\n","step: 80, loss: 0.1454405039548874\n","step: 90, loss: 0.013148403726518154\n","step: 100, loss: 0.00014502192789223045\n","step: 110, loss: 0.0032628285698592663\n","step: 120, loss: 0.0027946073096245527\n","acc=0.84\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.88      1030\n","           4       0.94      0.51      0.66       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      0.98      0.97      1570\n","           7       0.21      0.99      0.35       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.89      0.97      0.93       901\n","          11       0.95      1.00      0.97      2111\n","          12       0.78      0.98      0.87        47\n","          13       0.00      0.00      0.00        13\n","          14       0.00      0.00      0.00        43\n","          15       0.88      0.96      0.92      2778\n","          16       0.87      0.77      0.82      1151\n","          17       0.00      0.00      0.00        41\n","          18       0.85      0.91      0.88        32\n","          19       0.00      0.00      0.00        40\n","          20       0.98      0.99      0.99       584\n","          21       0.00      0.00      0.00        52\n","          22       0.93      0.68      0.79      4175\n","          23       0.63      0.95      0.76      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.82      0.90      0.86       888\n","          26       0.00      0.00      0.00         9\n","          27       0.84      0.94      0.89        69\n","          28       0.99      0.99      0.99      1864\n","          29       1.00      0.99      0.99       344\n","          30       0.85      0.82      0.84      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.00      0.00      0.00        86\n","          34       0.06      0.72      0.11        32\n","          35       0.97      0.95      0.96       474\n","          36       0.00      0.00      0.00       182\n","          37       0.68      0.86      0.76      1592\n","          38       0.93      0.95      0.94       404\n","          39       0.00      0.00      0.00       485\n","          40       0.88      0.88      0.88       573\n","          41       0.82      0.91      0.86       841\n","          42       0.99      0.90      0.94       575\n","          43       0.96      0.57      0.71       152\n","          44       0.87      0.92      0.90        75\n","          46       0.95      0.94      0.94        82\n","          48       0.00      0.00      0.00        79\n","\n","    accuracy                           0.84     28417\n","   macro avg       0.53      0.56      0.53     28417\n","weighted avg       0.83      0.84      0.83     28417\n","\n","Difference 178\n","\n","Loop 17\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0002789823047351092\n","step: 10, loss: 0.003368247067555785\n","step: 20, loss: 4.1277649870608e-05\n","step: 30, loss: 0.00030203667120076716\n","step: 40, loss: 0.0003333650529384613\n","step: 50, loss: 0.04070819914340973\n","step: 60, loss: 0.10224571079015732\n","step: 70, loss: 0.0319906622171402\n","step: 80, loss: 0.006256101652979851\n","step: 90, loss: 0.0006870199576951563\n","step: 100, loss: 0.013215169310569763\n","step: 110, loss: 0.02952028065919876\n","step: 120, loss: 0.0015505388146266341\n","acc=0.83\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       0.83      0.79      0.81      1030\n","           4       1.00      0.07      0.13       291\n","           5       0.00      0.00      0.00       294\n","           6       0.96      0.98      0.97      1570\n","           7       0.34      0.96      0.50       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.82      0.97      0.89       901\n","          11       0.95      1.00      0.97      2111\n","          12       0.78      0.98      0.87        47\n","          13       0.00      0.00      0.00        13\n","          14       1.00      0.02      0.05        43\n","          15       0.87      0.95      0.91      2778\n","          16       0.90      0.77      0.83      1151\n","          17       0.00      0.00      0.00        41\n","          18       0.88      0.91      0.89        32\n","          19       0.00      0.00      0.00        40\n","          20       0.98      0.99      0.99       584\n","          21       0.00      0.00      0.00        52\n","          22       0.94      0.67      0.78      4175\n","          23       0.61      0.96      0.74      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.85      0.89      0.87       888\n","          26       0.00      0.00      0.00         9\n","          27       0.86      0.99      0.92        69\n","          28       1.00      0.99      0.99      1864\n","          29       1.00      0.99      0.99       344\n","          30       0.87      0.82      0.84      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.00      0.00      0.00        86\n","          34       0.05      0.78      0.09        32\n","          35       0.92      0.99      0.95       474\n","          36       0.00      0.00      0.00       182\n","          37       0.65      0.90      0.75      1592\n","          38       0.94      0.95      0.95       404\n","          39       0.00      0.00      0.00       485\n","          40       0.87      0.88      0.88       573\n","          41       0.90      0.83      0.86       841\n","          42       0.99      0.92      0.95       575\n","          43       1.00      0.63      0.77       152\n","          44       0.87      0.97      0.92        75\n","          46       0.92      0.96      0.94        82\n","          48       0.00      0.00      0.00        79\n","\n","    accuracy                           0.83     28417\n","   macro avg       0.55      0.55      0.52     28417\n","weighted avg       0.83      0.83      0.81     28417\n","\n","Difference 192\n","\n","Loop 18\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.00026327616069465876\n","step: 10, loss: 0.0009859793353825808\n","step: 20, loss: 0.00012500965385697782\n","step: 30, loss: 0.0001628200989216566\n","step: 40, loss: 0.06018613651394844\n","step: 50, loss: 5.54332509636879e-05\n","step: 60, loss: 0.03830787166953087\n","step: 70, loss: 0.00334409112110734\n","step: 80, loss: 0.03667428344488144\n","step: 90, loss: 0.0003028344945050776\n","step: 100, loss: 0.0006323209963738918\n","step: 110, loss: 0.0004449195403140038\n","step: 120, loss: 0.023364268243312836\n","acc=0.83\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       0.92      0.79      0.85      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.96      0.98      0.97      1570\n","           7       0.49      0.94      0.64       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.86      0.97      0.91       901\n","          11       0.96      0.99      0.98      2111\n","          12       0.85      0.94      0.89        47\n","          13       0.00      0.00      0.00        13\n","          14       0.00      0.00      0.00        43\n","          15       0.82      0.97      0.89      2778\n","          16       0.88      0.77      0.82      1151\n","          17       0.00      0.00      0.00        41\n","          18       0.88      0.91      0.89        32\n","          19       0.00      0.00      0.00        40\n","          20       0.97      0.95      0.96       584\n","          21       0.00      0.00      0.00        52\n","          22       0.93      0.66      0.77      4175\n","          23       0.60      0.96      0.74      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.85      0.88      0.86       888\n","          26       0.00      0.00      0.00         9\n","          27       0.83      0.94      0.88        69\n","          28       0.99      0.99      0.99      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.87      0.80      0.83      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.00      0.00      0.00        86\n","          34       0.04      0.84      0.08        32\n","          35       0.96      0.95      0.95       474\n","          36       0.00      0.00      0.00       182\n","          37       0.63      0.89      0.74      1592\n","          38       0.93      0.89      0.91       404\n","          39       0.00      0.00      0.00       485\n","          40       0.85      0.87      0.86       573\n","          41       0.88      0.78      0.83       841\n","          42       0.98      0.97      0.97       575\n","          43       0.96      0.65      0.78       152\n","          44       0.87      0.97      0.92        75\n","          46       0.92      0.96      0.94        82\n","          48       0.00      0.00      0.00        79\n","\n","    accuracy                           0.83     28417\n","   macro avg       0.51      0.55      0.52     28417\n","weighted avg       0.81      0.83      0.81     28417\n","\n","Difference 186\n","\n","Loop 19\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.009975134395062923\n","step: 10, loss: 3.706057395902462e-05\n","step: 20, loss: 0.0002163111639674753\n","step: 30, loss: 0.0004161826509516686\n","step: 40, loss: 0.0003744357090909034\n","step: 50, loss: 0.028436245396733284\n","step: 60, loss: 0.044752657413482666\n","step: 70, loss: 0.0009968735976144671\n","step: 80, loss: 0.00038365519139915705\n","step: 90, loss: 0.002227984368801117\n","step: 100, loss: 0.035359520465135574\n","step: 110, loss: 0.000795950589235872\n","step: 120, loss: 0.0013791181845590472\n","acc=0.83\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       0.70      0.82      0.76      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.96      0.98      0.97      1570\n","           7       0.32      0.95      0.48       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.88      0.97      0.92       901\n","          11       0.97      0.99      0.98      2111\n","          12       0.94      0.70      0.80        47\n","          13       0.00      0.00      0.00        13\n","          14       0.00      0.00      0.00        43\n","          15       0.88      0.97      0.92      2778\n","          16       0.92      0.74      0.82      1151\n","          17       0.00      0.00      0.00        41\n","          18       0.88      0.91      0.89        32\n","          19       0.00      0.00      0.00        40\n","          20       0.98      0.99      0.99       584\n","          21       0.00      0.00      0.00        52\n","          22       0.95      0.63      0.76      4175\n","          23       0.55      0.99      0.71      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.85      0.88      0.86       888\n","          26       0.00      0.00      0.00         9\n","          27       0.87      0.97      0.92        69\n","          28       0.99      0.99      0.99      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.87      0.81      0.84      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.00      0.00      0.00        86\n","          34       0.08      0.72      0.14        32\n","          35       0.98      0.93      0.96       474\n","          36       0.00      0.00      0.00       182\n","          37       0.66      0.87      0.75      1592\n","          38       0.92      0.94      0.93       404\n","          39       0.00      0.00      0.00       485\n","          40       0.88      0.87      0.87       573\n","          41       0.84      0.86      0.85       841\n","          42       0.99      0.95      0.97       575\n","          43       0.97      0.70      0.81       152\n","          44       0.87      0.97      0.92        75\n","          46       0.92      0.96      0.94        82\n","          48       0.00      0.00      0.00        79\n","\n","    accuracy                           0.83     28417\n","   macro avg       0.51      0.54      0.52     28417\n","weighted avg       0.81      0.83      0.81     28417\n","\n","Difference 200\n","\n","Loop 20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.00041047140257433057\n","step: 10, loss: 0.013849543407559395\n","step: 20, loss: 0.0018920612055808306\n","step: 30, loss: 0.00042087867041118443\n","step: 40, loss: 0.0008183902828022838\n","step: 50, loss: 0.0004938344354741275\n","step: 60, loss: 0.05032825842499733\n","step: 70, loss: 0.057479653507471085\n","step: 80, loss: 0.0006733300979249179\n","step: 90, loss: 0.000293712189886719\n","step: 100, loss: 0.0015328903682529926\n","step: 110, loss: 0.007332883775234222\n","step: 120, loss: 0.05767781287431717\n","acc=0.81\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       0.96      0.79      0.87      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      0.96      0.97      1570\n","           7       0.46      0.95      0.62       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.82      0.97      0.89       901\n","          11       0.96      0.99      0.98      2111\n","          12       0.94      0.34      0.50        47\n","          13       0.00      0.00      0.00        13\n","          14       0.00      0.00      0.00        43\n","          15       0.77      0.97      0.86      2778\n","          16       0.92      0.76      0.83      1151\n","          17       0.00      0.00      0.00        41\n","          18       0.91      0.91      0.91        32\n","          19       0.00      0.00      0.00        40\n","          20       0.99      1.00      0.99       584\n","          21       0.00      0.00      0.00        52\n","          22       0.96      0.63      0.76      4175\n","          23       0.56      0.98      0.71      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.81      0.90      0.85       888\n","          26       0.00      0.00      0.00         9\n","          27       0.88      0.99      0.93        69\n","          28       0.99      0.99      0.99      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.84      0.83      0.84      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.00      0.00      0.00        86\n","          34       0.03      0.75      0.06        32\n","          35       0.00      0.00      0.00       474\n","          36       0.00      0.00      0.00       182\n","          37       0.66      0.92      0.77      1592\n","          38       0.74      0.97      0.84       404\n","          39       0.00      0.00      0.00       485\n","          40       0.91      0.68      0.78       573\n","          41       0.89      0.88      0.88       841\n","          42       0.97      0.97      0.97       575\n","          43       1.00      0.39      0.56       152\n","          44       0.88      0.95      0.91        75\n","          46       0.95      0.96      0.96        82\n","          48       0.00      0.00      0.00        79\n","\n","    accuracy                           0.81     28417\n","   macro avg       0.50      0.51      0.48     28417\n","weighted avg       0.79      0.81      0.79     28417\n","\n","Difference 219\n","\n","Loop 21\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0006435930845327675\n","step: 10, loss: 0.02364204451441765\n","step: 20, loss: 0.05667734891176224\n","step: 30, loss: 0.012818786315619946\n","step: 40, loss: 0.0015857588732615113\n","step: 50, loss: 0.010291182436048985\n","step: 60, loss: 0.003881471697241068\n","step: 70, loss: 0.00816275179386139\n","step: 80, loss: 0.000568048155400902\n","step: 90, loss: 0.0011843241518363357\n","step: 100, loss: 0.002677117707207799\n","step: 110, loss: 0.058726366609334946\n","step: 120, loss: 0.005444735288619995\n","acc=0.81\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       0.97      0.79      0.87      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      0.97      0.97      1570\n","           7       0.49      0.95      0.65       186\n","           8       0.00      0.00      0.00        11\n","           9       0.99      0.98      0.98       689\n","          10       0.82      0.97      0.89       901\n","          11       0.94      1.00      0.97      2111\n","          12       0.96      0.53      0.68        47\n","          13       0.00      0.00      0.00        13\n","          14       0.00      0.00      0.00        43\n","          15       0.77      0.97      0.86      2778\n","          16       0.75      0.84      0.79      1151\n","          17       0.00      0.00      0.00        41\n","          18       0.94      0.91      0.92        32\n","          19       0.00      0.00      0.00        40\n","          20       0.99      1.00      0.99       584\n","          21       0.00      0.00      0.00        52\n","          22       0.93      0.65      0.76      4175\n","          23       0.61      0.96      0.74      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.81      0.90      0.85       888\n","          26       0.00      0.00      0.00         9\n","          27       0.88      0.91      0.89        69\n","          28       0.99      0.99      0.99      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.85      0.82      0.84      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.00      0.00      0.00        86\n","          34       0.03      0.75      0.06        32\n","          35       0.00      0.00      0.00       474\n","          36       0.00      0.00      0.00       182\n","          37       0.67      0.82      0.73      1592\n","          38       0.85      0.96      0.90       404\n","          39       0.00      0.00      0.00       485\n","          40       0.95      0.72      0.82       573\n","          41       0.82      0.92      0.86       841\n","          42       0.95      0.95      0.95       575\n","          43       1.00      0.35      0.52       152\n","          44       0.81      0.93      0.87        75\n","          46       0.93      0.96      0.95        82\n","          48       0.00      0.00      0.00        79\n","\n","    accuracy                           0.81     28417\n","   macro avg       0.49      0.51      0.48     28417\n","weighted avg       0.79      0.81      0.79     28417\n","\n","Difference 338\n","\n","Loop 22\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.00043286042637191713\n","step: 10, loss: 0.003320894669741392\n","step: 20, loss: 8.831957529764622e-05\n","step: 30, loss: 5.7067416491918266e-05\n","step: 40, loss: 2.7563904950511642e-05\n","step: 50, loss: 0.00017080378893297166\n","step: 60, loss: 0.0001464202650822699\n","step: 70, loss: 0.00011939449905185029\n","step: 80, loss: 0.00012943660840392113\n","step: 90, loss: 0.0002581346780061722\n","step: 100, loss: 0.012328128330409527\n","step: 110, loss: 0.03583325073122978\n","step: 120, loss: 0.11453934013843536\n","acc=0.80\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       0.97      0.80      0.87      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.96      0.98      0.97      1570\n","           7       0.25      0.98      0.40       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.98      0.99       689\n","          10       0.88      0.97      0.92       901\n","          11       0.95      0.99      0.97      2111\n","          12       1.00      0.17      0.29        47\n","          13       0.00      0.00      0.00        13\n","          14       0.00      0.00      0.00        43\n","          15       0.76      0.97      0.85      2778\n","          16       0.86      0.81      0.83      1151\n","          17       0.00      0.00      0.00        41\n","          18       0.86      0.94      0.90        32\n","          19       0.00      0.00      0.00        40\n","          20       0.98      1.00      0.99       584\n","          21       0.00      0.00      0.00        52\n","          22       0.93      0.63      0.75      4175\n","          23       0.56      0.98      0.71      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.86      0.88      0.87       888\n","          26       0.00      0.00      0.00         9\n","          27       0.60      0.99      0.74        69\n","          28       0.99      0.99      0.99      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.89      0.81      0.85      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.00      0.00      0.00        86\n","          34       0.04      0.66      0.08        32\n","          35       0.00      0.00      0.00       474\n","          36       0.00      0.00      0.00       182\n","          37       0.68      0.82      0.74      1592\n","          38       0.77      0.96      0.86       404\n","          39       0.00      0.00      0.00       485\n","          40       0.94      0.71      0.81       573\n","          41       0.85      0.88      0.87       841\n","          42       0.97      0.96      0.97       575\n","          43       1.00      0.30      0.46       152\n","          44       0.82      0.97      0.89        75\n","          46       0.81      0.96      0.88        82\n","          48       0.00      0.00      0.00        79\n","\n","    accuracy                           0.80     28417\n","   macro avg       0.48      0.50      0.47     28417\n","weighted avg       0.79      0.80      0.78     28417\n","\n","Difference 318\n","\n","Loop 23\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0006112844566814601\n","step: 10, loss: 2.70302716671722e-05\n","step: 20, loss: 0.010699313133955002\n","step: 30, loss: 0.00027101559680886567\n","step: 40, loss: 0.05272180959582329\n","step: 50, loss: 0.00014434890181291848\n","step: 60, loss: 0.0005798577331006527\n","step: 70, loss: 0.0003601395874284208\n","step: 80, loss: 0.06522109359502792\n","step: 90, loss: 0.02094188705086708\n","step: 100, loss: 0.0015155166620388627\n","step: 110, loss: 0.015316122211515903\n","step: 120, loss: 0.024547932669520378\n","acc=0.80\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.96      0.98      0.97      1570\n","           7       0.36      0.97      0.53       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.97      0.99       689\n","          10       0.87      0.97      0.92       901\n","          11       0.97      0.99      0.98      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       0.00      0.00      0.00        43\n","          15       0.75      0.98      0.85      2778\n","          16       0.86      0.80      0.83      1151\n","          17       0.00      0.00      0.00        41\n","          18       0.88      0.94      0.91        32\n","          19       0.00      0.00      0.00        40\n","          20       0.81      1.00      0.89       584\n","          21       0.00      0.00      0.00        52\n","          22       0.94      0.64      0.76      4175\n","          23       0.56      0.98      0.71      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.83      0.89      0.86       888\n","          26       0.00      0.00      0.00         9\n","          27       0.78      0.87      0.82        69\n","          28       0.99      0.99      0.99      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.92      0.77      0.84      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.00      0.00      0.00        86\n","          34       0.03      0.75      0.07        32\n","          35       0.00      0.00      0.00       474\n","          36       0.00      0.00      0.00       182\n","          37       0.65      0.85      0.74      1592\n","          38       0.68      0.97      0.80       404\n","          39       0.00      0.00      0.00       485\n","          40       0.94      0.59      0.72       573\n","          41       0.86      0.89      0.87       841\n","          42       0.98      0.95      0.97       575\n","          43       1.00      0.03      0.06       152\n","          44       0.80      0.92      0.86        75\n","          46       1.00      0.91      0.96        82\n","          48       0.00      0.00      0.00        79\n","\n","    accuracy                           0.80     28417\n","   macro avg       0.47      0.49      0.45     28417\n","weighted avg       0.79      0.80      0.78     28417\n","\n","Difference 325\n","\n","Loop 24\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.04820885509252548\n","step: 10, loss: 0.03818481042981148\n","step: 20, loss: 0.0004183006822131574\n","step: 30, loss: 0.05734717845916748\n","step: 40, loss: 0.0076876250095665455\n","step: 50, loss: 0.00039908484905026853\n","step: 60, loss: 0.008485290221869946\n","step: 70, loss: 0.01660456322133541\n","step: 80, loss: 0.0035228778142482042\n","step: 90, loss: 0.021526122465729713\n","step: 100, loss: 0.011382599361240864\n","step: 110, loss: 0.0007860189070925117\n","step: 120, loss: 0.00017757485329639167\n","acc=0.80\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      0.98      0.98      1570\n","           7       0.17      1.00      0.29       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.97      0.99       689\n","          10       0.88      0.97      0.92       901\n","          11       0.97      0.99      0.98      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       0.00      0.00      0.00        43\n","          15       0.75      0.98      0.85      2778\n","          16       0.86      0.79      0.82      1151\n","          17       0.00      0.00      0.00        41\n","          18       0.88      0.94      0.91        32\n","          19       0.00      0.00      0.00        40\n","          20       0.89      1.00      0.94       584\n","          21       0.00      0.00      0.00        52\n","          22       0.92      0.64      0.76      4175\n","          23       0.61      0.97      0.75      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.82      0.93      0.88       888\n","          26       0.00      0.00      0.00         9\n","          27       0.00      0.00      0.00        69\n","          28       0.99      0.99      0.99      1864\n","          29       0.98      0.99      0.99       344\n","          30       0.92      0.73      0.81      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.00      0.00      0.00        86\n","          34       0.12      0.41      0.19        32\n","          35       0.00      0.00      0.00       474\n","          36       0.00      0.00      0.00       182\n","          37       0.59      0.91      0.72      1592\n","          38       0.70      0.96      0.81       404\n","          39       0.00      0.00      0.00       485\n","          40       0.93      0.61      0.74       573\n","          41       0.85      0.89      0.87       841\n","          42       0.97      0.93      0.95       575\n","          43       1.00      0.03      0.06       152\n","          44       0.63      0.93      0.75        75\n","          46       0.94      0.96      0.95        82\n","          48       0.00      0.00      0.00        79\n","\n","    accuracy                           0.80     28417\n","   macro avg       0.44      0.46      0.43     28417\n","weighted avg       0.78      0.80      0.77     28417\n","\n","Difference 331\n","\n","Loop 25\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 5.5493183026555926e-05\n","step: 10, loss: 0.03801829367876053\n","step: 20, loss: 0.010120519436895847\n","step: 30, loss: 0.008095909841358662\n","step: 40, loss: 0.00602780980989337\n","step: 50, loss: 0.09854484349489212\n","step: 60, loss: 0.028729379177093506\n","step: 70, loss: 0.0003007327322848141\n","step: 80, loss: 0.0021257586777210236\n","step: 90, loss: 0.00014987947361078113\n","step: 100, loss: 0.0026555401273071766\n","step: 110, loss: 0.00342821073718369\n","step: 120, loss: 0.007058135233819485\n","acc=0.79\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      0.98      0.98      1570\n","           7       0.24      0.94      0.38       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.97      0.98       689\n","          10       0.86      0.97      0.91       901\n","          11       0.97      0.99      0.98      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       0.00      0.00      0.00        43\n","          15       0.74      0.98      0.84      2778\n","          16       0.84      0.81      0.82      1151\n","          17       0.00      0.00      0.00        41\n","          18       0.86      0.94      0.90        32\n","          19       0.00      0.00      0.00        40\n","          20       0.82      1.00      0.90       584\n","          21       0.00      0.00      0.00        52\n","          22       0.95      0.59      0.73      4175\n","          23       0.54      0.98      0.70      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.81      0.91      0.86       888\n","          26       0.00      0.00      0.00         9\n","          27       0.00      0.00      0.00        69\n","          28       0.99      0.99      0.99      1864\n","          29       0.98      0.99      0.99       344\n","          30       0.93      0.75      0.83      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.00      0.00      0.00        86\n","          34       0.04      0.53      0.07        32\n","          35       0.00      0.00      0.00       474\n","          36       0.00      0.00      0.00       182\n","          37       0.65      0.88      0.75      1592\n","          38       0.67      0.97      0.79       404\n","          39       0.00      0.00      0.00       485\n","          40       0.93      0.58      0.71       573\n","          41       0.86      0.87      0.87       841\n","          42       0.98      0.94      0.96       575\n","          43       0.00      0.00      0.00       152\n","          44       0.66      0.92      0.77        75\n","          46       0.93      0.96      0.95        82\n","          48       0.30      0.04      0.07        79\n","\n","    accuracy                           0.79     28417\n","   macro avg       0.42      0.46      0.43     28417\n","weighted avg       0.78      0.79      0.77     28417\n","\n","Difference 167\n","\n","Loop 26\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.002961805323138833\n","step: 10, loss: 0.011476457118988037\n","step: 20, loss: 0.0012941062450408936\n","step: 30, loss: 7.015197479631752e-05\n","step: 40, loss: 0.00030910337227396667\n","step: 50, loss: 0.0001995039638131857\n","step: 60, loss: 0.00027223568758927286\n","step: 70, loss: 0.09164239466190338\n","step: 80, loss: 0.011128450743854046\n","step: 90, loss: 0.0005979524576105177\n","step: 100, loss: 0.00033827655715867877\n","step: 110, loss: 0.024275902658700943\n","step: 120, loss: 0.0002856685023289174\n","acc=0.80\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      0.98      0.98      1570\n","           7       0.58      0.92      0.71       186\n","           8       0.00      0.00      0.00        11\n","           9       0.97      0.98      0.97       689\n","          10       0.85      0.97      0.91       901\n","          11       0.95      0.99      0.97      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       0.00      0.00      0.00        43\n","          15       0.74      0.98      0.84      2778\n","          16       0.78      0.80      0.79      1151\n","          17       0.00      0.00      0.00        41\n","          18       0.88      0.94      0.91        32\n","          19       0.00      0.00      0.00        40\n","          20       0.84      1.00      0.91       584\n","          21       0.00      0.00      0.00        52\n","          22       0.93      0.63      0.75      4175\n","          23       0.60      0.94      0.73      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.74      0.93      0.82       888\n","          26       0.00      0.00      0.00         9\n","          27       0.00      0.00      0.00        69\n","          28       0.99      0.99      0.99      1864\n","          29       0.99      0.97      0.98       344\n","          30       0.88      0.79      0.83      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.00      0.00      0.00        86\n","          34       0.03      0.75      0.06        32\n","          35       0.00      0.00      0.00       474\n","          36       0.00      0.00      0.00       182\n","          37       0.65      0.86      0.74      1592\n","          38       0.63      0.98      0.77       404\n","          39       0.00      0.00      0.00       485\n","          40       0.94      0.51      0.66       573\n","          41       0.87      0.86      0.87       841\n","          42       0.97      0.96      0.96       575\n","          43       0.00      0.00      0.00       152\n","          44       0.49      0.97      0.65        75\n","          46       0.89      0.96      0.92        82\n","          48       0.00      0.00      0.00        79\n","\n","    accuracy                           0.80     28417\n","   macro avg       0.42      0.47      0.43     28417\n","weighted avg       0.77      0.80      0.77     28417\n","\n","Difference 214\n","\n","Loop 27\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.00024499735445715487\n","step: 10, loss: 1.956730011443142e-05\n","step: 20, loss: 0.006713778246194124\n","step: 30, loss: 0.05916343256831169\n","step: 40, loss: 0.02190820872783661\n","step: 50, loss: 0.0185232050716877\n","step: 60, loss: 0.0115718524903059\n","step: 70, loss: 0.01729130558669567\n","step: 80, loss: 0.0006536375731229782\n","step: 90, loss: 0.07112112641334534\n","step: 100, loss: 0.007503474596887827\n","step: 110, loss: 0.0007325344486162066\n","step: 120, loss: 0.037041064351797104\n","acc=0.79\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      0.98      0.98      1570\n","           7       0.22      0.98      0.35       186\n","           8       0.00      0.00      0.00        11\n","           9       0.99      0.97      0.98       689\n","          10       0.83      0.97      0.90       901\n","          11       0.92      1.00      0.96      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       0.00      0.00      0.00        43\n","          15       0.76      0.96      0.85      2778\n","          16       0.83      0.83      0.83      1151\n","          17       0.00      0.00      0.00        41\n","          18       0.83      0.94      0.88        32\n","          19       0.00      0.00      0.00        40\n","          20       0.81      1.00      0.89       584\n","          21       0.00      0.00      0.00        52\n","          22       0.92      0.66      0.77      4175\n","          23       0.61      0.97      0.75      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.78      0.92      0.85       888\n","          26       0.00      0.00      0.00         9\n","          27       0.00      0.00      0.00        69\n","          28       0.96      0.99      0.98      1864\n","          29       0.99      0.97      0.98       344\n","          30       0.92      0.73      0.82      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.00      0.00      0.00        86\n","          34       0.08      0.59      0.14        32\n","          35       0.00      0.00      0.00       474\n","          36       0.00      0.00      0.00       182\n","          37       0.65      0.87      0.75      1592\n","          38       0.41      0.98      0.58       404\n","          39       0.00      0.00      0.00       485\n","          40       1.00      0.02      0.04       573\n","          41       0.85      0.86      0.86       841\n","          42       0.98      0.93      0.95       575\n","          43       0.00      0.00      0.00       152\n","          44       0.54      0.97      0.70        75\n","          46       0.66      0.96      0.79        82\n","          48       0.00      0.00      0.00        79\n","\n","    accuracy                           0.79     28417\n","   macro avg       0.40      0.45      0.40     28417\n","weighted avg       0.77      0.79      0.75     28417\n","\n","Difference 158\n","\n","Loop 28\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0006433514063246548\n","step: 10, loss: 0.024706833064556122\n","step: 20, loss: 4.3435575207695365e-05\n","step: 30, loss: 0.05019548535346985\n","step: 40, loss: 0.022868165746331215\n","step: 50, loss: 0.0034110830165445805\n","step: 60, loss: 0.0030908703338354826\n","step: 70, loss: 0.0026103330310434103\n","step: 80, loss: 0.011179718188941479\n","step: 90, loss: 0.0010212435154244304\n","step: 100, loss: 0.041908711194992065\n","step: 110, loss: 0.02363009937107563\n","step: 120, loss: 0.00045852744369767606\n","acc=0.78\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      0.98      0.98      1570\n","           7       0.45      0.94      0.61       186\n","           8       0.00      0.00      0.00        11\n","           9       0.99      0.97      0.98       689\n","          10       0.82      0.96      0.89       901\n","          11       0.86      1.00      0.92      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       0.00      0.00      0.00        43\n","          15       0.71      0.94      0.81      2778\n","          16       0.87      0.79      0.83      1151\n","          17       0.00      0.00      0.00        41\n","          18       0.83      0.94      0.88        32\n","          19       0.00      0.00      0.00        40\n","          20       0.80      1.00      0.89       584\n","          21       0.00      0.00      0.00        52\n","          22       0.91      0.67      0.77      4175\n","          23       0.60      0.97      0.74      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.80      0.90      0.85       888\n","          26       0.00      0.00      0.00         9\n","          27       0.00      0.00      0.00        69\n","          28       0.97      0.97      0.97      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.92      0.63      0.75      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.00      0.00      0.00        86\n","          34       0.04      0.72      0.07        32\n","          35       0.00      0.00      0.00       474\n","          36       0.00      0.00      0.00       182\n","          37       0.65      0.83      0.73      1592\n","          38       0.48      0.95      0.63       404\n","          39       0.00      0.00      0.00       485\n","          40       1.00      0.01      0.02       573\n","          41       0.84      0.86      0.85       841\n","          42       0.99      0.84      0.91       575\n","          43       0.00      0.00      0.00       152\n","          44       0.56      0.97      0.71        75\n","          46       0.37      0.96      0.53        82\n","          48       0.00      0.00      0.00        79\n","\n","    accuracy                           0.78     28417\n","   macro avg       0.40      0.45      0.40     28417\n","weighted avg       0.76      0.78      0.74     28417\n","\n","Difference 195\n","\n","Loop 29\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0005240216269157827\n","step: 10, loss: 1.2421450264810119e-05\n","step: 20, loss: 0.070183664560318\n","step: 30, loss: 2.1512018975045066e-06\n","step: 40, loss: 0.00048762865480966866\n","step: 50, loss: 0.007539053447544575\n","step: 60, loss: 0.001176791382022202\n","step: 70, loss: 0.0015100074233487248\n","step: 80, loss: 5.616417547571473e-05\n","step: 90, loss: 0.10891187936067581\n","step: 100, loss: 0.00041499792132526636\n","step: 110, loss: 0.0002647747751325369\n","step: 120, loss: 0.024316268041729927\n","acc=0.77\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.98      0.98      0.98      1570\n","           7       0.63      0.94      0.75       186\n","           8       0.00      0.00      0.00        11\n","           9       0.99      0.98      0.98       689\n","          10       0.86      0.97      0.91       901\n","          11       0.92      1.00      0.96      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       0.00      0.00      0.00        43\n","          15       0.75      0.96      0.84      2778\n","          16       0.88      0.77      0.82      1151\n","          17       0.00      0.00      0.00        41\n","          18       0.88      0.88      0.88        32\n","          19       0.00      0.00      0.00        40\n","          20       0.83      1.00      0.90       584\n","          21       0.00      0.00      0.00        52\n","          22       0.87      0.68      0.76      4175\n","          23       0.56      0.98      0.71      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.81      0.77      0.79       888\n","          26       0.00      0.00      0.00         9\n","          27       0.00      0.00      0.00        69\n","          28       0.98      0.97      0.97      1864\n","          29       1.00      0.98      0.99       344\n","          30       0.93      0.49      0.65      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.00      0.00      0.00        86\n","          34       0.03      0.75      0.06        32\n","          35       0.00      0.00      0.00       474\n","          36       0.00      0.00      0.00       182\n","          37       0.63      0.87      0.73      1592\n","          38       0.45      0.97      0.62       404\n","          39       0.00      0.00      0.00       485\n","          40       1.00      0.02      0.05       573\n","          41       0.88      0.84      0.86       841\n","          42       1.00      0.86      0.92       575\n","          43       0.00      0.00      0.00       152\n","          44       0.87      0.87      0.87        75\n","          46       0.19      0.96      0.31        82\n","          48       0.00      0.00      0.00        79\n","\n","    accuracy                           0.77     28417\n","   macro avg       0.41      0.44      0.40     28417\n","weighted avg       0.76      0.77      0.74     28417\n","\n","Difference 271\n","\n","Loop 30\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.013606890104711056\n","step: 10, loss: 0.0004115863121114671\n","step: 20, loss: 8.986623288365081e-05\n","step: 30, loss: 0.001769258757121861\n","step: 40, loss: 0.00021689296409022063\n","step: 50, loss: 0.0004951687878929079\n","step: 60, loss: 0.00015698597417213023\n","step: 70, loss: 0.14245016872882843\n","step: 80, loss: 0.0004064217791892588\n","step: 90, loss: 0.1753782331943512\n","step: 100, loss: 0.00939775537699461\n","step: 110, loss: 0.000305778841720894\n","step: 120, loss: 0.0035788281820714474\n","acc=0.77\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      0.98      0.98      1570\n","           7       0.38      0.94      0.54       186\n","           8       0.00      0.00      0.00        11\n","           9       0.99      0.98      0.98       689\n","          10       0.87      0.97      0.92       901\n","          11       0.92      1.00      0.96      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       0.00      0.00      0.00        43\n","          15       0.75      0.97      0.85      2778\n","          16       0.89      0.76      0.82      1151\n","          17       0.00      0.00      0.00        41\n","          18       0.83      0.94      0.88        32\n","          19       0.00      0.00      0.00        40\n","          20       0.86      1.00      0.92       584\n","          21       0.00      0.00      0.00        52\n","          22       0.92      0.66      0.77      4175\n","          23       0.60      0.97      0.74      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.85      0.88      0.86       888\n","          26       0.00      0.00      0.00         9\n","          27       0.00      0.00      0.00        69\n","          28       0.94      0.99      0.96      1864\n","          29       1.00      0.97      0.99       344\n","          30       0.90      0.43      0.58      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.00      0.00      0.00        86\n","          34       0.03      0.75      0.07        32\n","          35       0.00      0.00      0.00       474\n","          36       0.00      0.00      0.00       182\n","          37       0.62      0.91      0.74      1592\n","          38       0.42      0.97      0.58       404\n","          39       0.00      0.00      0.00       485\n","          40       0.00      0.00      0.00       573\n","          41       0.73      0.82      0.77       841\n","          42       0.96      0.61      0.75       575\n","          43       0.00      0.00      0.00       152\n","          44       0.84      0.92      0.88        75\n","          46       0.17      0.96      0.29        82\n","          48       0.33      0.37      0.35        79\n","\n","    accuracy                           0.77     28417\n","   macro avg       0.39      0.45      0.39     28417\n","weighted avg       0.75      0.77      0.74     28417\n","\n","Difference 183\n","\n","Loop 31\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0008268514066003263\n","step: 10, loss: 3.799978003371507e-05\n","step: 20, loss: 0.025615433230996132\n","step: 30, loss: 0.00026766402879729867\n","step: 40, loss: 0.21011029183864594\n","step: 50, loss: 7.560758967883885e-05\n","step: 60, loss: 0.016147427260875702\n","step: 70, loss: 0.02664526365697384\n","step: 80, loss: 0.00017661858873907477\n","step: 90, loss: 0.0406755693256855\n","step: 100, loss: 0.07522483915090561\n","step: 110, loss: 0.07257956266403198\n","step: 120, loss: 0.0016227506566792727\n","acc=0.76\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      0.98      0.98      1570\n","           7       0.42      0.95      0.59       186\n","           8       0.00      0.00      0.00        11\n","           9       1.00      0.97      0.99       689\n","          10       0.65      0.97      0.78       901\n","          11       0.93      1.00      0.96      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       0.00      0.00      0.00        43\n","          15       0.77      0.97      0.85      2778\n","          16       0.80      0.82      0.81      1151\n","          17       0.00      0.00      0.00        41\n","          18       0.79      0.94      0.86        32\n","          19       0.00      0.00      0.00        40\n","          20       0.84      1.00      0.91       584\n","          21       0.00      0.00      0.00        52\n","          22       0.91      0.65      0.76      4175\n","          23       0.59      0.97      0.73      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.84      0.86      0.85       888\n","          26       0.00      0.00      0.00         9\n","          27       0.00      0.00      0.00        69\n","          28       0.95      0.99      0.97      1864\n","          29       0.99      0.99      0.99       344\n","          30       0.93      0.55      0.69      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.00      0.00      0.00        86\n","          34       0.03      0.75      0.07        32\n","          35       0.00      0.00      0.00       474\n","          36       0.00      0.00      0.00       182\n","          37       0.65      0.85      0.74      1592\n","          38       0.41      0.97      0.58       404\n","          39       0.00      0.00      0.00       485\n","          40       0.00      0.00      0.00       573\n","          41       0.58      0.87      0.70       841\n","          42       0.97      0.25      0.39       575\n","          43       0.00      0.00      0.00       152\n","          44       0.87      0.91      0.89        75\n","          46       0.75      0.96      0.84        82\n","          48       0.00      0.00      0.00        79\n","\n","    accuracy                           0.76     28417\n","   macro avg       0.38      0.43      0.39     28417\n","weighted avg       0.73      0.76      0.73     28417\n","\n","Difference 172\n","\n","Loop 32\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0017798946937546134\n","step: 10, loss: 6.752636545570567e-05\n","step: 20, loss: 0.002333867596462369\n","step: 30, loss: 0.11205890029668808\n","step: 40, loss: 0.0008777420734986663\n","step: 50, loss: 0.0002610037918202579\n","step: 60, loss: 0.00030890529160387814\n","step: 70, loss: 0.0008085264707915485\n","step: 80, loss: 0.0005130010540597141\n","step: 90, loss: 0.057304497808218\n","step: 100, loss: 0.0007658895337954164\n","step: 110, loss: 0.0005963738658465445\n","step: 120, loss: 7.988061406649649e-05\n","acc=0.75\n","classification_report               precision    recall  f1-score   support\n","\n","           1       0.00      0.00      0.00        35\n","           2       0.00      0.00      0.00        77\n","           3       1.00      0.79      0.89      1030\n","           4       0.00      0.00      0.00       291\n","           5       0.00      0.00      0.00       294\n","           6       0.97      0.98      0.98      1570\n","           7       0.43      0.94      0.59       186\n","           8       0.00      0.00      0.00        11\n","           9       0.98      0.97      0.98       689\n","          10       0.65      0.97      0.78       901\n","          11       0.96      0.99      0.97      2111\n","          12       0.00      0.00      0.00        47\n","          13       0.00      0.00      0.00        13\n","          14       0.00      0.00      0.00        43\n","          15       0.72      0.99      0.83      2778\n","          16       0.78      0.81      0.80      1151\n","          17       0.00      0.00      0.00        41\n","          18       0.81      0.94      0.87        32\n","          19       0.00      0.00      0.00        40\n","          20       0.84      1.00      0.91       584\n","          21       0.00      0.00      0.00        52\n","          22       0.91      0.64      0.75      4175\n","          23       0.61      0.97      0.75      2253\n","          24       0.00      0.00      0.00        44\n","          25       0.85      0.84      0.84       888\n","          26       0.00      0.00      0.00         9\n","          27       0.00      0.00      0.00        69\n","          28       0.88      0.99      0.93      1864\n","          29       1.00      0.85      0.92       344\n","          30       0.92      0.36      0.52      1136\n","          31       0.00      0.00      0.00        19\n","          32       0.00      0.00      0.00         8\n","          33       0.00      0.00      0.00        86\n","          34       0.03      0.75      0.07        32\n","          35       0.00      0.00      0.00       474\n","          36       0.00      0.00      0.00       182\n","          37       0.64      0.85      0.73      1592\n","          38       0.42      0.98      0.58       404\n","          39       0.00      0.00      0.00       485\n","          40       0.00      0.00      0.00       573\n","          41       0.52      0.86      0.65       841\n","          42       1.00      0.02      0.04       575\n","          43       0.00      0.00      0.00       152\n","          44       0.61      0.97      0.75        75\n","          46       0.72      0.96      0.83        82\n","          48       0.00      0.00      0.00        79\n","\n","    accuracy                           0.75     28417\n","   macro avg       0.38      0.42      0.37     28417\n","weighted avg       0.72      0.75      0.71     28417\n","\n","Difference 191\n","\n","Loop 33\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.0003761031257454306\n","step: 10, loss: 4.279216955183074e-05\n","step: 20, loss: 1.6274301742669195e-05\n","step: 30, loss: 0.000315490789944306\n","step: 40, loss: 0.022603420540690422\n","step: 50, loss: 0.000629571033641696\n","step: 60, loss: 5.614175461232662e-05\n","step: 70, loss: 0.02650396153330803\n","step: 80, loss: 0.00011334251757944003\n","step: 90, loss: 0.0003002392186317593\n","step: 100, loss: 0.0002540556597523391\n","step: 110, loss: 0.0018074166728183627\n","step: 120, loss: 0.0008690599934197962\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-2b45fff0d891>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mthreshold_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdomain\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_name_lst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdomain_precision_value_lst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdomain_recall_value_lst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdomain_f1_value_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0;31m# plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   test_metric = pd.DataFrame({\n","\u001b[0;32m<ipython-input-32-310813b28a4a>\u001b[0m in \u001b[0;36mself_train\u001b[0;34m(domain, topn, threshold_ratio)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mtrain_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_train_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mdomain_precision_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdomain_recall_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdomain_f1_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdomain_test_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mdomain_precision_value_lst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdomain_precision_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mdomain_recall_value_lst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdomain_recall_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-15-00a9bd30f8a9>\u001b[0m in \u001b[0;36meval\u001b[0;34m(model, iterator, average)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mWords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIs_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqlens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1360\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1325\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1161\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1163\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1164\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrebuild_storage_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m     \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m'''Get the fd.  This should only be called once.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_resource_sharer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/multiprocessing/reduction.py\u001b[0m in \u001b[0;36mrecv_handle\u001b[0;34m(conn)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;34m'''Receive a handle over a local connection.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAF_UNIX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mrecvfds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mDupFd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/socket.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io_refs\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_real_close\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/socket.py\u001b[0m in \u001b[0;36m_real_close\u001b[0;34m(self, _ss)\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_real_close\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0;31m# This function should not reference any globals. See issue #808164.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0m_ss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# # save model for future usage\n","# new_model_suffix = f\"online_nonfixed_self_learned_{topn}.pt\"\n","# new_model_file = os.path.join(model_dir, new_model_suffix)\n","# # save the model only if we have not self train the model before\n","# if new_model_suffix not in os.listdir(model_dir):\n","#     torch.save(model.state_dict(), new_model_file)"],"metadata":{"id":"zRrUqL__xfVA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# topn = 300\n","# i = 0\n","# last_top_sen = set()\n","# top_words = domain_dev_word_lst[:topn]\n","# new_top_sen = set([tuple(sen) for sen in top_words])\n","\n","# while len(new_top_sen.difference(last_top_sen)) > 100:\n","#   i += 1\n","#   print(\"\\nLoop\", i)\n","\n","#   domain_dev_dataset = PosDataset(domain_dev_word_lst, domain_dev_tag_lst)\n","\n","#   domain_dev_iter = data.DataLoader(dataset=domain_dev_dataset,\n","#                               batch_size=8,\n","#                               shuffle=False,\n","#                               num_workers=1,\n","#                               collate_fn=pad)\n","\n","#   if i == 1:\n","#     last_top_sen = set()\n","#   else:\n","#     last_top_sen = new_top_sen\n","\n","#   top_words, top_tags, remain_words, remain_tags = gen_pseudo_data(model, domain_dev_iter, topn)\n","#   new_top_sen = set([tuple(sen) for sen in top_words])\n","\n","#   new_train_dataset = PosDataset_new(top_words, top_tags)\n","#   new_train_iter = data.DataLoader(dataset=new_train_dataset,\n","#                               batch_size=8,\n","#                               shuffle=True,\n","#                               num_workers=1,\n","#                               collate_fn=pad_new)\n","\n","#   optimizer = optim.Adam(model.parameters(), lr = 0.0001)\n","#   criterion = nn.CrossEntropyLoss(ignore_index=0)\n","\n","#   train_new(model, new_train_iter, optimizer, criterion)\n","\n","#   domain_precision_value, domain_recall_value, domain_f1_value = eval(model, domain_test_iter)\n","#   domain_precision_value_lst.append(domain_precision_value)\n","#   domain_recall_value_lst.append(domain_recall_value)\n","#   domain_f1_value_lst.append(domain_f1_value)\n","\n","#   print(\"Difference\", len(new_top_sen.difference(last_top_sen)))"],"metadata":{"id":"zl3VMmnVVD-8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from collections import Counter\n","\n","# c = Counter([tuple(sen) for sen in top_words])\n","# print( c.most_common(3))"],"metadata":{"id":"W-t80AQ7wb4U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import pandas as pd"],"metadata":{"id":"g4ZuWMYTojmJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test_metric = pd.DataFrame({\n","#     \"Loop\": list(range(len(domain_precision_value_lst))) * 3,\n","#     \"metric\": [\"precision\"]*len(domain_precision_value_lst) + [\"recall\"]*len(domain_precision_value_lst) + [\"f1\"]*len(domain_precision_value_lst),\n","#     \"value\": domain_precision_value_lst + domain_recall_value_lst + domain_f1_value_lst\n","# })"],"metadata":{"id":"jJxcl1cLn7rb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import seaborn as sns\n","# import matplotlib.pyplot as plt\n","\n","# import plotly\n","# import plotly.express as px\n","# import plotly.graph_objects as go"],"metadata":{"id":"EvkSQ18M7p2H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# fig = px.line(test_metric, x=\"Loop\", y=\"value\", color='metric', markers=True)\n","# fig.show()\n","# # save interactive version\n","# fig.write_html(f\"{plot_dir}/online_nonfixed_metric.html\")\n","# # save static version\n","# fig.write_image(f\"{plot_dir}/online_nonfixed_metric.png\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"O2DFUhCDorSf","executionInfo":{"status":"ok","timestamp":1669245957984,"user_tz":300,"elapsed":438,"user":{"displayName":"Zheng Wu","userId":"01190949623920087412"}},"outputId":"3afc2bf3-203e-4b4b-e1f6-809b3eba57f0"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"561b6aee-9682-4663-a856-d804226e2789\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"561b6aee-9682-4663-a856-d804226e2789\")) {                    Plotly.newPlot(                        \"561b6aee-9682-4663-a856-d804226e2789\",                        [{\"hovertemplate\":\"metric=precision<br>Loop=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"precision\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"precision\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2],\"xaxis\":\"x\",\"y\":[0.7945300660402925,0.8059496362463282,0.7575916110510039],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"metric=recall<br>Loop=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"recall\",\"line\":{\"color\":\"#EF553B\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"recall\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2],\"xaxis\":\"x\",\"y\":[0.8005920263509698,0.7976226235396524,0.7601220602563261],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"metric=f1<br>Loop=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"f1\",\"line\":{\"color\":\"#00cc96\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"f1\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2],\"xaxis\":\"x\",\"y\":[0.779434223557162,0.7717452007815867,0.7313310555561879],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Loop\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"metric\"},\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('561b6aee-9682-4663-a856-d804226e2789');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                            </script>        </div>\n","</body>\n","</html>"]},"metadata":{}}]}]}
{"cells":[{"cell_type":"markdown","metadata":{"id":"eZHQ9Ad1BBsh"},"source":["[BERT](https://arxiv.org/abs/1810.04805) is known to be good at Sequence tagging tasks like Named Entity Recognition. Let's see if it's true for POS-tagging."]},{"cell_type":"code","source":["! pip install pytorch_pretrained_bert"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CZeQB_QVBeF0","executionInfo":{"status":"ok","timestamp":1665375663056,"user_tz":240,"elapsed":13500,"user":{"displayName":"Alex Y","userId":"02188660656026482944"}},"outputId":"17b9e47e-34c8-46b8-adee-b7e035f78355"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytorch_pretrained_bert\n","  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n","\u001b[K     |████████████████████████████████| 123 kB 4.9 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (4.64.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.21.6)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.12.1+cu113)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2022.6.2)\n","Collecting boto3\n","  Downloading boto3-1.24.89-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 40.6 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (4.1.1)\n","Collecting s3transfer<0.7.0,>=0.6.0\n","  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 5.1 MB/s \n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n","  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Collecting botocore<1.28.0,>=1.27.89\n","  Downloading botocore-1.27.89-py3-none-any.whl (9.2 MB)\n","\u001b[K     |████████████████████████████████| 9.2 MB 7.0 MB/s \n","\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n","  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n","\u001b[K     |████████████████████████████████| 140 kB 50.6 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.89->boto3->pytorch_pretrained_bert) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.89->boto3->pytorch_pretrained_bert) (1.15.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2022.9.24)\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 21.0 MB/s \n","\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n","Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed boto3-1.24.89 botocore-1.27.89 jmespath-1.0.1 pytorch-pretrained-bert-0.6.2 s3transfer-0.6.0 urllib3-1.25.11\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ur3_uxNMBBsj"},"outputs":[],"source":["import os\n","from tqdm import tqdm_notebook as tqdm\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.utils import data\n","import torch.optim as optim\n","from pytorch_pretrained_bert import BertTokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NzyfaHZ5BBsj","outputId":"1523b2b1-09a6-4c09-f0d7-91c4fdbb16ef","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1665375665322,"user_tz":240,"elapsed":7,"user":{"displayName":"Alex Y","userId":"02188660656026482944"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'1.12.1+cu113'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}],"source":["torch.__version__"]},{"cell_type":"markdown","metadata":{"id":"rs35W5HwBBsk"},"source":["# Data preparation"]},{"cell_type":"markdown","metadata":{"id":"DRC-7SPXBBsk"},"source":["Thanks to the great NLTK, we don't have to worry about datasets. Some of Penn Tree Banks are included in it. I believe they serves for the purpose."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vxC0dFqaBBsk","outputId":"82adb829-0619-4ac5-e176-d60e068bd189","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665375669247,"user_tz":240,"elapsed":3931,"user":{"displayName":"Alex Y","userId":"02188660656026482944"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package treebank to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/treebank.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["3914"]},"metadata":{},"execution_count":4}],"source":["import nltk\n","nltk.download('treebank')\n","tagged_sents = nltk.corpus.treebank.tagged_sents()\n","len(tagged_sents)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1-wD0b6HBBsl","outputId":"f69e15db-d3bb-4280-e025-20aaeba52169","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665375669248,"user_tz":240,"elapsed":6,"user":{"displayName":"Alex Y","userId":"02188660656026482944"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('Pierre', 'NNP'),\n"," ('Vinken', 'NNP'),\n"," (',', ','),\n"," ('61', 'CD'),\n"," ('years', 'NNS'),\n"," ('old', 'JJ'),\n"," (',', ','),\n"," ('will', 'MD'),\n"," ('join', 'VB'),\n"," ('the', 'DT'),\n"," ('board', 'NN'),\n"," ('as', 'IN'),\n"," ('a', 'DT'),\n"," ('nonexecutive', 'JJ'),\n"," ('director', 'NN'),\n"," ('Nov.', 'NNP'),\n"," ('29', 'CD'),\n"," ('.', '.')]"]},"metadata":{},"execution_count":5}],"source":["tagged_sents[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JdNK5hvYBBsl"},"outputs":[],"source":["tags = list(set(word_pos[1] for sent in tagged_sents for word_pos in sent))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"prPMRFE-BBsl","outputId":"fc94ff41-6eca-4d3c-ecf5-5201f3d2fec7","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1665375671599,"user_tz":240,"elapsed":7,"user":{"displayName":"Alex Y","userId":"02188660656026482944"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"VB,SYM,PDT,EX,WP$,JJ,VBG,-RRB-,RBR,#,MD,:,LS,RB,RBS,PRP$,NN,$,NNP,UH,CC,NNS,WDT,JJR,-LRB-,VBP,POS,VBZ,CD,JJS,IN,WP,'',RP,DT,.,PRP,``,-NONE-,VBD,VBN,NNPS,WRB,,,FW,TO\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":7}],"source":["\",\".join(tags)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I5a1mUdxBBsm"},"outputs":[],"source":["# By convention, the 0'th slot is reserved for padding.\n","tags = [\"<pad>\"] + tags"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lvJCVEvPBBsm"},"outputs":[],"source":["tag2idx = {tag:idx for idx, tag in enumerate(tags)}\n","idx2tag = {idx:tag for idx, tag in enumerate(tags)}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QGVZtrn6BBsm","outputId":"c30cf904-2a53-452e-e319-4ff0b6e30916","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665375674945,"user_tz":240,"elapsed":3350,"user":{"displayName":"Alex Y","userId":"02188660656026482944"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3522, 392)"]},"metadata":{},"execution_count":10}],"source":["# Let's split the data into train and test (or eval)\n","from sklearn.model_selection import train_test_split\n","train_data, test_data = train_test_split(tagged_sents, test_size=.1)\n","len(train_data), len(test_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kSPXSyT5BBsm"},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"markdown","metadata":{"id":"LmpkQbt_BBsm"},"source":["# Data loader\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dxwQ-rL-BBsm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665375675576,"user_tz":240,"elapsed":461,"user":{"displayName":"Alex Y","userId":"02188660656026482944"}},"outputId":"b4e52dc6-cb65-40e2-c962-42aa0b93aeec"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 213450/213450 [00:00<00:00, 2727731.43B/s]\n"]}],"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)"]},{"cell_type":"code","source":["tagged_sents"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q_Dl5JQjET99","executionInfo":{"status":"ok","timestamp":1665375675576,"user_tz":240,"elapsed":6,"user":{"displayName":"Alex Y","userId":"02188660656026482944"}},"outputId":"3fc5ff4d-bdd2-446d-c2f0-f313a338fdc4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')], [('Mr.', 'NNP'), ('Vinken', 'NNP'), ('is', 'VBZ'), ('chairman', 'NN'), ('of', 'IN'), ('Elsevier', 'NNP'), ('N.V.', 'NNP'), (',', ','), ('the', 'DT'), ('Dutch', 'NNP'), ('publishing', 'VBG'), ('group', 'NN'), ('.', '.')], ...]"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# sents, tags_li = [], [] # list of lists\n","# for sent in tagged_sents:\n","#     words = [word_pos[0] for word_pos in sent]\n","#     tags = [word_pos[1] for word_pos in sent]\n","#     sents.append([\"[CLS]\"] + words + [\"[SEP]\"])\n","#     tags_li.append([\"<pad>\"] + tags + [\"<pad>\"])\n","#     break"],"metadata":{"id":"gbVoDqz_Eam9"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TNFuuo5PBBsm"},"outputs":[],"source":["class PosDataset(data.Dataset):\n","    def __init__(self, tagged_sents):\n","        sents, tags_li = [], [] # list of lists\n","        for sent in tagged_sents:\n","            words = [word_pos[0] for word_pos in sent]\n","            tags = [word_pos[1] for word_pos in sent]\n","            sents.append([\"[CLS]\"] + words + [\"[SEP]\"])\n","            tags_li.append([\"<pad>\"] + tags + [\"<pad>\"])\n","        self.sents, self.tags_li = sents, tags_li\n","\n","    def __len__(self):\n","        return len(self.sents)\n","\n","    def __getitem__(self, idx):\n","        words, tags = self.sents[idx], self.tags_li[idx] # words, tags: string list\n","\n","        # We give credits only to the first piece.\n","        x, y = [], [] # list of ids\n","        is_heads = [] # list. 1: the token is the first piece of a word\n","        for w, t in zip(words, tags):\n","            tokens = tokenizer.tokenize(w) if w not in (\"[CLS]\", \"[SEP]\") else [w]\n","            xx = tokenizer.convert_tokens_to_ids(tokens)\n","\n","            is_head = [1] + [0]*(len(tokens) - 1)\n","\n","            t = [t] + [\"<pad>\"] * (len(tokens) - 1)  # <PAD>: no decision\n","            yy = [tag2idx[each] for each in t]  # (T,)\n","\n","            x.extend(xx)\n","            is_heads.extend(is_head)\n","            y.extend(yy)\n","\n","        assert len(x)==len(y)==len(is_heads), \"len(x)={}, len(y)={}, len(is_heads)={}\".format(len(x), len(y), len(is_heads))\n","\n","        # seqlen\n","        seqlen = len(y)\n","\n","        # to string\n","        words = \" \".join(words)\n","        tags = \" \".join(tags)\n","        return words, x, is_heads, tags, y, seqlen\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wfHRwOlPBBsn"},"outputs":[],"source":["def pad(batch):\n","    '''Pads to the longest sample'''\n","    f = lambda x: [sample[x] for sample in batch]\n","    words = f(0)\n","    is_heads = f(2)\n","    tags = f(3)\n","    seqlens = f(-1)\n","    maxlen = np.array(seqlens).max()\n","\n","    f = lambda x, seqlen: [sample[x] + [0] * (seqlen - len(sample[x])) for sample in batch] # 0: <pad>\n","    x = f(1, maxlen)\n","    y = f(-2, maxlen)\n","\n","\n","    f = torch.LongTensor\n","\n","    return words, f(x), is_heads, tags, f(y), seqlens"]},{"cell_type":"markdown","metadata":{"id":"JorutNixBBsn"},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_RnhbQm0BBsn"},"outputs":[],"source":["from pytorch_pretrained_bert import BertModel"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OtG5dlP9BBsn"},"outputs":[],"source":["class Net(nn.Module):\n","    def __init__(self, vocab_size=None):\n","        super().__init__()\n","        self.bert = BertModel.from_pretrained('bert-base-cased')\n","\n","        self.fc = nn.Linear(768, vocab_size)\n","        self.device = device\n","\n","    def forward(self, x, y):\n","        '''\n","        x: (N, T). int64\n","        y: (N, T). int64\n","        '''\n","        x = x.to(device)\n","        y = y.to(device)\n","        \n","        if self.training:\n","            self.bert.train()\n","            encoded_layers, _ = self.bert(x)\n","            enc = encoded_layers[-1]\n","        else:\n","            self.bert.eval()\n","            with torch.no_grad():\n","                encoded_layers, _ = self.bert(x)\n","                enc = encoded_layers[-1]\n","        \n","        logits = self.fc(enc)\n","        y_hat = logits.argmax(-1)\n","        return logits, y, y_hat"]},{"cell_type":"markdown","metadata":{"id":"xSOjosRCBBsn"},"source":["# Train an evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W1nDERe0BBso"},"outputs":[],"source":["def train(model, iterator, optimizer, criterion):\n","    model.train()\n","    for i, batch in enumerate(iterator):\n","        words, x, is_heads, tags, y, seqlens = batch\n","        _y = y # for monitoring\n","        optimizer.zero_grad()\n","        logits, y, _ = model(x, y) # logits: (N, T, VOCAB), y: (N, T)\n","\n","        logits = logits.view(-1, logits.shape[-1]) # (N*T, VOCAB)\n","        y = y.view(-1)  # (N*T,)\n","\n","        loss = criterion(logits, y)\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        if i%10==0: # monitoring\n","            print(\"step: {}, loss: {}\".format(i, loss.item()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TJLKc4nGBBso"},"outputs":[],"source":["def eval(model, iterator):\n","    model.eval()\n","\n","    Words, Is_heads, Tags, Y, Y_hat = [], [], [], [], []\n","    with torch.no_grad():\n","        for i, batch in enumerate(iterator):\n","            words, x, is_heads, tags, y, seqlens = batch\n","\n","            _, _, y_hat = model(x, y)  # y_hat: (N, T)\n","\n","            Words.extend(words)\n","            Is_heads.extend(is_heads)\n","            Tags.extend(tags)\n","            Y.extend(y.numpy().tolist())\n","            Y_hat.extend(y_hat.cpu().numpy().tolist())\n","\n","    ## gets results and save\n","    with open(\"result\", 'w') as fout:\n","        for words, is_heads, tags, y_hat in zip(Words, Is_heads, Tags, Y_hat):\n","            y_hat = [hat for head, hat in zip(is_heads, y_hat) if head == 1]\n","            preds = [idx2tag[hat] for hat in y_hat]\n","            assert len(preds)==len(words.split())==len(tags.split())\n","            for w, t, p in zip(words.split()[1:-1], tags.split()[1:-1], preds[1:-1]):\n","                fout.write(\"{} {} {}\\n\".format(w, t, p))\n","            fout.write(\"\\n\")\n","            \n","    ## calc metric\n","    y_true =  np.array([tag2idx[line.split()[1]] for line in open('result', 'r').read().splitlines() if len(line) > 0])\n","    y_pred =  np.array([tag2idx[line.split()[2]] for line in open('result', 'r').read().splitlines() if len(line) > 0])\n","\n","    acc = (y_true==y_pred).astype(np.int32).sum() / len(y_true)\n","\n","    print(\"acc=%.2f\"%acc)\n"]},{"cell_type":"markdown","metadata":{"id":"q8779vCaBBso"},"source":["## Load model and train"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"w8yJK67dBBso","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665375693614,"user_tz":240,"elapsed":17883,"user":{"displayName":"Alex Y","userId":"02188660656026482944"}},"outputId":"f2e0ce82-5d9b-4ed0-93bd-030cbdb3a554"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 404400730/404400730 [00:06<00:00, 59561937.41B/s]\n"]}],"source":["model = Net(vocab_size=len(tag2idx))\n","model.to(device)\n","model = nn.DataParallel(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kNNFy3JbBBso"},"outputs":[],"source":["train_dataset = PosDataset(train_data)\n","eval_dataset = PosDataset(test_data)\n","\n","train_iter = data.DataLoader(dataset=train_dataset,\n","                             batch_size=8,\n","                             shuffle=True,\n","                             num_workers=1,\n","                             collate_fn=pad)\n","test_iter = data.DataLoader(dataset=eval_dataset,\n","                             batch_size=8,\n","                             shuffle=False,\n","                             num_workers=1,\n","                             collate_fn=pad)\n","\n","optimizer = optim.Adam(model.parameters(), lr = 0.0001)\n","\n","criterion = nn.CrossEntropyLoss(ignore_index=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"9c7vskB8BBso","outputId":"9b83ba83-7345-43de-e133-170a834c3397","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665375757601,"user_tz":240,"elapsed":63996,"user":{"displayName":"Alex Y","userId":"02188660656026482944"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["step: 0, loss: 3.964611291885376\n","step: 10, loss: 1.657906174659729\n","step: 20, loss: 0.4662945568561554\n","step: 30, loss: 0.3822211027145386\n","step: 40, loss: 0.2032579630613327\n","step: 50, loss: 0.1271943747997284\n","step: 60, loss: 0.08578399568796158\n","step: 70, loss: 0.25627240538597107\n","step: 80, loss: 0.09846189618110657\n","step: 90, loss: 0.12252505868673325\n","step: 100, loss: 0.1703256219625473\n","step: 110, loss: 0.08751732856035233\n","step: 120, loss: 0.10018518567085266\n","step: 130, loss: 0.1406237781047821\n","step: 140, loss: 0.07370074093341827\n","step: 150, loss: 0.09682586044073105\n","step: 160, loss: 0.07088088989257812\n","step: 170, loss: 0.06322076916694641\n","step: 180, loss: 0.09748023748397827\n","step: 190, loss: 0.18131068348884583\n","step: 200, loss: 0.07456100732088089\n","step: 210, loss: 0.1336268037557602\n","step: 220, loss: 0.19304615259170532\n","step: 230, loss: 0.0816136971116066\n","step: 240, loss: 0.12133247405290604\n","step: 250, loss: 0.067226342856884\n","step: 260, loss: 0.07155530154705048\n","step: 270, loss: 0.11954130232334137\n","step: 280, loss: 0.056635014712810516\n","step: 290, loss: 0.05572531372308731\n","step: 300, loss: 0.1474856436252594\n","step: 310, loss: 0.09210319072008133\n","step: 320, loss: 0.13287797570228577\n","step: 330, loss: 0.10388343036174774\n","step: 340, loss: 0.10972084105014801\n","step: 350, loss: 0.08207565546035767\n","step: 360, loss: 0.08917760103940964\n","step: 370, loss: 0.132871612906456\n","step: 380, loss: 0.07453823834657669\n","step: 390, loss: 0.16189071536064148\n","step: 400, loss: 0.10331971943378448\n","step: 410, loss: 0.06470651179552078\n","step: 420, loss: 0.14737550914287567\n","step: 430, loss: 0.11321954429149628\n","step: 440, loss: 0.03563816845417023\n","acc=0.98\n"]}],"source":["train(model, train_iter, optimizer, criterion)\n","eval(model, test_iter)\n"]},{"cell_type":"markdown","metadata":{"id":"5edx0B2tBBso"},"source":["Check the result."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x1AYSbOZBBso","outputId":"9ec5b004-064a-49cc-a8ac-dcff6197df62","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665375769345,"user_tz":240,"elapsed":102,"user":{"displayName":"Alex Y","userId":"02188660656026482944"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['But CC CC',\n"," 'the DT DT',\n"," 'legislation NN NN',\n"," 'reflected VBD VBD',\n"," 'a DT DT',\n"," 'compromise NN NN',\n"," 'agreed VBN VBN',\n"," 'to TO TO',\n"," '* -NONE- -NONE-',\n"," 'on IN IN',\n"," 'Tuesday NNP NNP',\n"," 'by IN IN',\n"," 'President NNP NNP',\n"," 'Bush NNP NNP',\n"," 'and CC CC',\n"," 'Democratic JJ JJ',\n"," 'leaders NNS NNS',\n"," 'in IN IN',\n"," 'Congress NNP NNP',\n"," ', , ,',\n"," 'after IN IN',\n"," 'congressional JJ JJ',\n"," 'Republicans NNPS NNS',\n"," 'urged VBD VBD',\n"," 'the DT DT',\n"," 'White NNP NNP',\n"," 'House NNP NNP',\n"," '*-2 -NONE- -NONE-',\n"," 'to TO TO',\n"," 'bend VB VB',\n"," 'a DT DT',\n"," 'bit NN NN',\n"," 'from IN IN',\n"," 'its PRP$ PRP$',\n"," 'previous JJ JJ',\n"," 'resistance NN NN',\n"," '* -NONE- -NONE-',\n"," 'to TO TO',\n"," 'compromise VB VB',\n"," '. . .',\n"," '',\n"," 'The DT DT',\n"," 'firm NN NN',\n"," 'and CC CC',\n"," 'Mr. NNP NNP',\n"," 'Whelen NNP NNP',\n"," 'allegedly RB RB',\n"," 'sold VBD VBD',\n"," 'securities NNS NNS',\n"," 'to TO TO',\n"," 'the DT DT',\n"," 'public NN NN',\n"," 'at IN IN',\n"," 'unfair JJ JJ',\n"," 'prices NNS NNS',\n"," ', , ,',\n"," 'among IN IN',\n"," 'other JJ JJ',\n"," 'alleged JJ VBN',\n"," 'violations NNS NNS',\n"," '. . .',\n"," '',\n"," 'Younkers NNS NNP',\n"," 'rang VBD VBD',\n"," 'up RP RP',\n"," 'sales NNS NNS',\n"," '*ICH*-1 -NONE- -NONE-',\n"," 'in IN IN',\n"," '1988 CD CD',\n"," 'of IN IN',\n"," '$ $ $',\n"," '313 CD CD',\n"," 'million CD CD',\n"," '*U* -NONE- -NONE-',\n"," '. . .',\n"," '',\n"," 'But CC CC',\n"," 'the DT DT',\n"," '1989 CD CD',\n"," 'fall NN NN',\n"," 'total NN NN',\n"," 'of IN IN',\n"," '80 CD CD',\n"," ', , ,',\n"," 'while IN IN',\n"," 'well RB RB',\n"," 'below IN IN',\n"," '1988 CD CD',\n"," 'activity NN NN',\n"," ', , ,',\n"," 'shows VBZ VBZ',\n"," '`` `` ``',\n"," 'a DT DT',\n"," 'steady JJ JJ',\n"," 'ratcheting VBG NN',\n"," 'up IN RP',\n"," 'in IN IN',\n"," 'citizen NN NN',\n"," 'referenda NN NN',\n"," 'and CC CC']"]},"metadata":{},"execution_count":25}],"source":["open('result', 'r').read().splitlines()[:100]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AI0fryd4BBso"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"colab":{"provenance":[{"file_id":"https://github.com/Kyubyong/nlp_made_easy/blob/master/Pos-tagging%20with%20Bert%20Fine-tuning.ipynb","timestamp":1665373843197}]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}